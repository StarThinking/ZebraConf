[msx] before_class
[msx] test Started org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay#testTcpNoDelayDisabled
[msx] unitTestCounterInClass = 0
2020-04-02 05:05:55,292 [main] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:testTcpNoDelayDisabled(110)) - Socket factory is org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay$SocketFactoryWrapper
2020-04-02 05:05:55,377 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-02 05:05:56,339 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:56,355 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:56,356 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:56,358 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:56,366 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:56,367 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:56,367 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:56,368 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:56,423 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:56,428 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:05:56,429 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:56,429 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:56,435 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:56,436 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:56
2020-04-02 05:05:56,440 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:56,441 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:56,443 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:56,444 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:56,472 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:56,480 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:56,480 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:56,481 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:56,481 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:56,481 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:56,482 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:56,482 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:56,482 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:56,483 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:56,483 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:56,484 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:56,519 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:05:56,538 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:56,539 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:56,543 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:56,544 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:56,551 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:56,551 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:56,552 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:56,552 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:56,561 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:56,566 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:56,572 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:56,573 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:56,573 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:56,574 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:56,585 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:56,586 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:56,586 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:56,591 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:56,592 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:56,596 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:56,596 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:56,597 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:56,597 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:56,647 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:05:56,687 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:56,690 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:56,718 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:56,718 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:56,876 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:56,879 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:56,904 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:56,908 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:57,131 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:05:57,200 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:57,809 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:57,810 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:57,815 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:57,846 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:57,901 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@48aca48b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:57,921 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:05:57,934 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:57,952 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4118ms
2020-04-02 05:05:58,113 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:58,118 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:58,118 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:58,127 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:58,130 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:58,130 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:58,131 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:58,166 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:58,167 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:58,177 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45056
2020-04-02 05:05:58,180 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:58,237 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49b2a47d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:58,239 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@415b0b49{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:58,305 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6b6776cb{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:58,323 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2d9caaeb{HTTP/1.1,[http/1.1]}{localhost:45056}
2020-04-02 05:05:58,324 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4490ms
2020-04-02 05:05:58,353 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:58,354 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:58,355 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:58,355 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:58,355 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:58,355 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:58,356 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:58,356 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:58,357 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:58,357 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:58,358 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:58,358 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:58,359 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:58
2020-04-02 05:05:58,359 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:58,359 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:58,360 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:58,360 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:58,370 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:58,370 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:58,371 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:58,371 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:58,406 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:58,406 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:58,406 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:58,407 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:58,407 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:58,407 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:58,407 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:58,407 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:58,408 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:58,408 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:58,409 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:58,409 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:58,411 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:58,411 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:58,421 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:58,422 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:58,429 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:58,429 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:58,430 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:58,430 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:58,430 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:58,431 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:58,431 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:58,432 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:58,432 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:58,432 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:58,432 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:58,433 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:58,433 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:58,434 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:58,434 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:58,460 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:05:58,466 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:05:58,470 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:58,471 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:58,471 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:58,472 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:58,546 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:58,553 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:58,554 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:58,559 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:58,560 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:58,594 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:58,595 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 158 msecs
2020-04-02 05:05:58,821 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:58,832 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:58,848 [Socket Reader #1 for port 44503] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44503
2020-04-02 05:05:59,223 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:44503 to access this namenode/service.
2020-04-02 05:05:59,227 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:59,317 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:59,352 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:59,354 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:59,354 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:59,354 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:59,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:59,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:59,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:59,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:59,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:59,390 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 29 msec
2020-04-02 05:05:59,447 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:44503
2020-04-02 05:05:59,451 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:59,451 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:59,444 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:59,445 [IPC Server listener on 44503] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44503: starting
2020-04-02 05:05:59,457 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 5 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:59,510 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 44503 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:59,530 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:59,554 [CacheReplicationMonitor(648132826)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:59,640 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:59,669 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:59,778 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:59,779 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:59,799 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:59,802 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:59,812 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:59,814 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:59,823 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:59,836 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40013
2020-04-02 05:05:59,847 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:59,847 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:59,879 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:59,882 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:59,894 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:59,894 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:59,899 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:59,900 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:59,901 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:59,901 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:59,907 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42702
2020-04-02 05:05:59,908 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:59,922 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f0b0a5e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:59,924 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@320de594{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:59,947 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@25b2cfcb{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:59,948 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@72758afa{HTTP/1.1,[http/1.1]}{localhost:42702}
2020-04-02 05:05:59,948 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6115ms
2020-04-02 05:06:00,673 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40430
2020-04-02 05:06:00,681 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:00,681 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:00,694 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@89c10b7] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:00,712 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:00,718 [Socket Reader #1 for port 37497] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37497
2020-04-02 05:06:00,800 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37497
2020-04-02 05:06:00,817 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:00,820 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:01,543 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44503 starting to offer service
2020-04-02 05:06:01,563 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:01,563 [IPC Server listener on 37497] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37497: starting
2020-04-02 05:06:01,570 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37497 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:01,572 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:01,627 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:01,628 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:01,649 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:01,649 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:01,650 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:01,650 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:01,650 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:01,651 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:01,651 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:01,652 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39182
2020-04-02 05:06:01,652 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:01,652 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:01,658 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:01,660 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:01,661 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:01,661 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:01,663 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:01,663 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:01,663 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:01,664 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:01,664 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35165
2020-04-02 05:06:01,665 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:01,667 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71e5f61d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:01,682 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e8f9e2d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:01,693 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5f2606b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:01,693 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2b58f754{HTTP/1.1,[http/1.1]}{localhost:35165}
2020-04-02 05:06:01,694 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7860ms
2020-04-02 05:06:01,906 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43549
2020-04-02 05:06:01,907 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2552f2cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:01,907 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:01,908 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:01,918 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:01,930 [Socket Reader #1 for port 44228] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44228
2020-04-02 05:06:01,947 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44228
2020-04-02 05:06:01,952 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:01,953 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:01,967 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44503 starting to offer service
2020-04-02 05:06:01,987 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:01,987 [IPC Server listener on 44228] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44228: starting
2020-04-02 05:06:01,989 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44228 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:01,991 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:01,992 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:01,993 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:01,994 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:01,994 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:02,010 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:02,010 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:02,010 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:02,011 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:02,011 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:02,018 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42882
2020-04-02 05:06:02,019 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:02,019 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:02,024 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:02,026 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:02,027 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:02,028 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:02,029 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:02,030 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:02,030 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:02,031 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:02,031 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44158
2020-04-02 05:06:02,032 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:02,034 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f9879ac{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:02,034 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5f4d427e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:02,046 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a1d204a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:02,047 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62dae245{HTTP/1.1,[http/1.1]}{localhost:44158}
2020-04-02 05:06:02,050 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8214ms
2020-04-02 05:06:02,067 [Thread-59] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:02,090 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38072
2020-04-02 05:06:02,092 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:02,092 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:02,110 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6fff253c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:02,110 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:02,130 [Socket Reader #1 for port 34370] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34370
2020-04-02 05:06:02,149 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34370
2020-04-02 05:06:02,158 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:02,183 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:02,184 [Thread-108] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44503 starting to offer service
2020-04-02 05:06:02,184 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:02,185 [IPC Server listener on 34370] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34370: starting
2020-04-02 05:06:02,188 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34370 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:02,477 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44503
2020-04-02 05:06:02,481 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44503
2020-04-02 05:06:02,482 [Thread-108] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44503
2020-04-02 05:06:02,487 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:02,488 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:02,495 [Thread-108] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:02,507 [Thread-83] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:02,508 [Thread-108] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:02,508 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:02,508 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 2123249663. Formatting...
2020-04-02 05:06:02,508 [Thread-108] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 2123249663. Formatting...
2020-04-02 05:06:02,508 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 2123249663. Formatting...
2020-04-02 05:06:02,510 [Thread-108] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6be56f95-45a6-42fd-8e12-71064a0d6852 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:06:02,509 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f8fe1d32-27f0-461f-ab6d-103b24a09729 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:06:02,510 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-599e7b89-c45c-40f8-97c3-5d13427e8194 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:02,518 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:02,519 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 2123249663. Formatting...
2020-04-02 05:06:02,519 [Thread-108] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:02,519 [Thread-108] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 2123249663. Formatting...
2020-04-02 05:06:02,519 [Thread-108] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-03518e33-23ed-4781-9367-584bf1f125ce for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:06:02,521 [Thread-83] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:02,521 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 2123249663. Formatting...
2020-04-02 05:06:02,519 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c447a982-569b-4b73-9e1d-6404b9ac1f4c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:02,522 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9b70d1b7-0024-4ee3-90c4-16eb399fee81 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:06:02,547 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,547 [Thread-83] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,548 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-888001862-172.17.0.17-1585803956629 is not formatted. Formatting ...
2020-04-02 05:06:02,548 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-888001862-172.17.0.17-1585803956629 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-888001862-172.17.0.17-1585803956629/current
2020-04-02 05:06:02,563 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,563 [Thread-83] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,564 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-888001862-172.17.0.17-1585803956629 is not formatted. Formatting ...
2020-04-02 05:06:02,564 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-888001862-172.17.0.17-1585803956629 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-888001862-172.17.0.17-1585803956629/current
2020-04-02 05:06:02,566 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2123249663;bpid=BP-888001862-172.17.0.17-1585803956629;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2123249663;c=1585803956629;bpid=BP-888001862-172.17.0.17-1585803956629;dnuuid=null
2020-04-02 05:06:02,568 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,569 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,569 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-888001862-172.17.0.17-1585803956629 is not formatted. Formatting ...
2020-04-02 05:06:02,569 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-888001862-172.17.0.17-1585803956629 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-888001862-172.17.0.17-1585803956629/current
2020-04-02 05:06:02,590 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID d9f40411-190e-4b74-997d-b5782f022498
2020-04-02 05:06:02,597 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,597 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,597 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-888001862-172.17.0.17-1585803956629 is not formatted. Formatting ...
2020-04-02 05:06:02,597 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-888001862-172.17.0.17-1585803956629 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-888001862-172.17.0.17-1585803956629/current
2020-04-02 05:06:02,598 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,598 [Thread-108] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,598 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-888001862-172.17.0.17-1585803956629 is not formatted. Formatting ...
2020-04-02 05:06:02,598 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-888001862-172.17.0.17-1585803956629 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-888001862-172.17.0.17-1585803956629/current
2020-04-02 05:06:02,602 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2123249663;bpid=BP-888001862-172.17.0.17-1585803956629;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2123249663;c=1585803956629;bpid=BP-888001862-172.17.0.17-1585803956629;dnuuid=null
2020-04-02 05:06:02,614 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a4eec8a0-8419-4ab2-9910-28a844326ac6
2020-04-02 05:06:02,645 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,645 [Thread-108] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,658 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-888001862-172.17.0.17-1585803956629 is not formatted. Formatting ...
2020-04-02 05:06:02,658 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-888001862-172.17.0.17-1585803956629 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-888001862-172.17.0.17-1585803956629/current
2020-04-02 05:06:02,664 [Thread-108] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2123249663;bpid=BP-888001862-172.17.0.17-1585803956629;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2123249663;c=1585803956629;bpid=BP-888001862-172.17.0.17-1585803956629;dnuuid=null
2020-04-02 05:06:02,666 [Thread-108] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ef95897c-3071-44a2-86c4-3a26a60fe1b2
2020-04-02 05:06:02,830 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f8fe1d32-27f0-461f-ab6d-103b24a09729
2020-04-02 05:06:02,830 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:06:02,832 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9b70d1b7-0024-4ee3-90c4-16eb399fee81
2020-04-02 05:06:02,832 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:06:02,845 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6be56f95-45a6-42fd-8e12-71064a0d6852
2020-04-02 05:06:02,878 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:06:02,880 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-03518e33-23ed-4781-9367-584bf1f125ce
2020-04-02 05:06:02,880 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:06:02,881 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:02,836 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-599e7b89-c45c-40f8-97c3-5d13427e8194
2020-04-02 05:06:02,882 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:06:02,882 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:02,892 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:02,897 [Thread-108] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:02,899 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c447a982-569b-4b73-9e1d-6404b9ac1f4c
2020-04-02 05:06:02,899 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:02,900 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:02,901 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:02,923 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:02,925 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:02,925 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:02,934 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:02,942 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:02,943 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:02,942 [Thread-108] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:02,944 [Thread-108] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:02,944 [Thread-108] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:02,964 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:02,974 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:06:02,978 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:06:03,023 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,025 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:06:03,026 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,026 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:06:03,029 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:03,030 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:03,189 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-888001862-172.17.0.17-1585803956629 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 161ms
2020-04-02 05:06:03,195 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-888001862-172.17.0.17-1585803956629 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 217ms
2020-04-02 05:06:03,197 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-888001862-172.17.0.17-1585803956629 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 166ms
2020-04-02 05:06:03,197 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-888001862-172.17.0.17-1585803956629 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 172ms
2020-04-02 05:06:03,197 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-888001862-172.17.0.17-1585803956629 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 223ms
2020-04-02 05:06:03,206 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-888001862-172.17.0.17-1585803956629: 242ms
2020-04-02 05:06:03,218 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:06:03,218 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:06:03,218 [Thread-139] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-888001862-172.17.0.17-1585803956629/current/replicas doesn't exist 
2020-04-02 05:06:03,222 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-888001862-172.17.0.17-1585803956629: 196ms
2020-04-02 05:06:03,218 [Thread-138] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-888001862-172.17.0.17-1585803956629/current/replicas doesn't exist 
2020-04-02 05:06:03,266 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 48ms
2020-04-02 05:06:03,271 [main] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:03,282 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-888001862-172.17.0.17-1585803956629 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 256ms
2020-04-02 05:06:03,282 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-888001862-172.17.0.17-1585803956629: 259ms
2020-04-02 05:06:03,302 [Thread-143] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:03,302 [Thread-143] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-888001862-172.17.0.17-1585803956629/current/replicas doesn't exist 
2020-04-02 05:06:03,310 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 92ms
2020-04-02 05:06:03,313 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-888001862-172.17.0.17-1585803956629: 106ms
2020-04-02 05:06:03,317 [Thread-145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:06:03,317 [Thread-145] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-888001862-172.17.0.17-1585803956629/current/replicas doesn't exist 
2020-04-02 05:06:03,322 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:03,322 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:03,322 [Thread-141] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-888001862-172.17.0.17-1585803956629/current/replicas doesn't exist 
2020-04-02 05:06:03,322 [Thread-144] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:06:03,322 [Thread-144] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-888001862-172.17.0.17-1585803956629/current/replicas doesn't exist 
2020-04-02 05:06:03,330 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:03,356 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:41 AM with interval of 21600000ms
2020-04-02 05:06:03,358 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-9b70d1b7-0024-4ee3-90c4-16eb399fee81): finished scanning block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,359 [Thread-144] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 37ms
2020-04-02 05:06:03,358 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-f8fe1d32-27f0-461f-ab6d-103b24a09729): finished scanning block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,362 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 40ms
2020-04-02 05:06:03,363 [Thread-145] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 46ms
2020-04-02 05:06:03,363 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-888001862-172.17.0.17-1585803956629: 81ms
2020-04-02 05:06:03,363 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:03,364 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:03,364 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6be56f95-45a6-42fd-8e12-71064a0d6852): finished scanning block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,364 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-03518e33-23ed-4781-9367-584bf1f125ce): finished scanning block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,380 [Thread-143] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 78ms
2020-04-02 05:06:03,381 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-888001862-172.17.0.17-1585803956629: 149ms
2020-04-02 05:06:03,382 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:03,397 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-599e7b89-c45c-40f8-97c3-5d13427e8194): finished scanning block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,397 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-888001862-172.17.0.17-1585803956629 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:03,398 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c447a982-569b-4b73-9e1d-6404b9ac1f4c): finished scanning block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,398 [Thread-108] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:37 AM with interval of 21600000ms
2020-04-02 05:06:03,398 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:21 AM with interval of 21600000ms
2020-04-02 05:06:03,440 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid d9f40411-190e-4b74-997d-b5782f022498) service to localhost/127.0.0.1:44503 beginning handshake with NN
2020-04-02 05:06:03,462 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid a4eec8a0-8419-4ab2-9910-28a844326ac6) service to localhost/127.0.0.1:44503 beginning handshake with NN
2020-04-02 05:06:03,467 [IPC Server handler 6 on 44503] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40013, datanodeUuid=a4eec8a0-8419-4ab2-9910-28a844326ac6, infoPort=40430, infoSecurePort=0, ipcPort=37497, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629) storage a4eec8a0-8419-4ab2-9910-28a844326ac6
2020-04-02 05:06:03,469 [IPC Server handler 6 on 44503] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40013
2020-04-02 05:06:03,470 [IPC Server handler 6 on 44503] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a4eec8a0-8419-4ab2-9910-28a844326ac6 (127.0.0.1:40013).
2020-04-02 05:06:03,492 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-03518e33-23ed-4781-9367-584bf1f125ce): no suitable block pools found to scan.  Waiting 1814399871 ms.
2020-04-02 05:06:03,493 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid a4eec8a0-8419-4ab2-9910-28a844326ac6) service to localhost/127.0.0.1:44503 successfully registered with NN
2020-04-02 05:06:03,493 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44503 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:03,493 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-f8fe1d32-27f0-461f-ab6d-103b24a09729): no suitable block pools found to scan.  Waiting 1814399826 ms.
2020-04-02 05:06:03,493 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6be56f95-45a6-42fd-8e12-71064a0d6852): no suitable block pools found to scan.  Waiting 1814399870 ms.
2020-04-02 05:06:03,494 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c447a982-569b-4b73-9e1d-6404b9ac1f4c): no suitable block pools found to scan.  Waiting 1814399887 ms.
2020-04-02 05:06:03,494 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid ef95897c-3071-44a2-86c4-3a26a60fe1b2) service to localhost/127.0.0.1:44503 beginning handshake with NN
2020-04-02 05:06:03,510 [IPC Server handler 5 on 44503] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=d9f40411-190e-4b74-997d-b5782f022498, infoPort=43549, infoSecurePort=0, ipcPort=44228, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629) storage d9f40411-190e-4b74-997d-b5782f022498
2020-04-02 05:06:03,510 [IPC Server handler 5 on 44503] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39182
2020-04-02 05:06:03,525 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-9b70d1b7-0024-4ee3-90c4-16eb399fee81): no suitable block pools found to scan.  Waiting 1814399794 ms.
2020-04-02 05:06:03,544 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-599e7b89-c45c-40f8-97c3-5d13427e8194): no suitable block pools found to scan.  Waiting 1814399837 ms.
2020-04-02 05:06:03,558 [IPC Server handler 5 on 44503] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d9f40411-190e-4b74-997d-b5782f022498 (127.0.0.1:39182).
2020-04-02 05:06:03,569 [IPC Server handler 4 on 44503] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42882, datanodeUuid=ef95897c-3071-44a2-86c4-3a26a60fe1b2, infoPort=38072, infoSecurePort=0, ipcPort=34370, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629) storage ef95897c-3071-44a2-86c4-3a26a60fe1b2
2020-04-02 05:06:03,569 [IPC Server handler 4 on 44503] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42882
2020-04-02 05:06:03,570 [IPC Server handler 4 on 44503] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ef95897c-3071-44a2-86c4-3a26a60fe1b2 (127.0.0.1:42882).
2020-04-02 05:06:03,571 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid d9f40411-190e-4b74-997d-b5782f022498) service to localhost/127.0.0.1:44503 successfully registered with NN
2020-04-02 05:06:03,572 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44503 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:03,583 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid ef95897c-3071-44a2-86c4-3a26a60fe1b2) service to localhost/127.0.0.1:44503 successfully registered with NN
2020-04-02 05:06:03,583 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44503 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:03,591 [IPC Server handler 3 on 44503] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-599e7b89-c45c-40f8-97c3-5d13427e8194 for DN 127.0.0.1:40013
2020-04-02 05:06:03,592 [IPC Server handler 3 on 44503] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c447a982-569b-4b73-9e1d-6404b9ac1f4c for DN 127.0.0.1:40013
2020-04-02 05:06:03,616 [IPC Server handler 2 on 44503] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6be56f95-45a6-42fd-8e12-71064a0d6852 for DN 127.0.0.1:42882
2020-04-02 05:06:03,627 [IPC Server handler 2 on 44503] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-03518e33-23ed-4781-9367-584bf1f125ce for DN 127.0.0.1:42882
2020-04-02 05:06:03,633 [IPC Server handler 1 on 44503] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f8fe1d32-27f0-461f-ab6d-103b24a09729 for DN 127.0.0.1:39182
2020-04-02 05:06:03,634 [IPC Server handler 1 on 44503] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9b70d1b7-0024-4ee3-90c4-16eb399fee81 for DN 127.0.0.1:39182
2020-04-02 05:06:03,657 [IPC Server handler 8 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,680 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf0712ef55bc5e0e2: Processing first storage report for DS-6be56f95-45a6-42fd-8e12-71064a0d6852 from datanode ef95897c-3071-44a2-86c4-3a26a60fe1b2
2020-04-02 05:06:03,683 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:03,687 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf0712ef55bc5e0e2: from storage DS-6be56f95-45a6-42fd-8e12-71064a0d6852 node DatanodeRegistration(127.0.0.1:42882, datanodeUuid=ef95897c-3071-44a2-86c4-3a26a60fe1b2, infoPort=38072, infoSecurePort=0, ipcPort=34370, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629), blocks: 0, hasStaleStorage: true, processing time: 7 msecs, invalidatedBlocks: 0
2020-04-02 05:06:03,687 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc2e891aa9b4c3f1b: Processing first storage report for DS-f8fe1d32-27f0-461f-ab6d-103b24a09729 from datanode d9f40411-190e-4b74-997d-b5782f022498
2020-04-02 05:06:03,688 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc2e891aa9b4c3f1b: from storage DS-f8fe1d32-27f0-461f-ab6d-103b24a09729 node DatanodeRegistration(127.0.0.1:39182, datanodeUuid=d9f40411-190e-4b74-997d-b5782f022498, infoPort=43549, infoSecurePort=0, ipcPort=44228, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:03,688 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf0712ef55bc5e0e2: Processing first storage report for DS-03518e33-23ed-4781-9367-584bf1f125ce from datanode ef95897c-3071-44a2-86c4-3a26a60fe1b2
2020-04-02 05:06:03,688 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf0712ef55bc5e0e2: from storage DS-03518e33-23ed-4781-9367-584bf1f125ce node DatanodeRegistration(127.0.0.1:42882, datanodeUuid=ef95897c-3071-44a2-86c4-3a26a60fe1b2, infoPort=38072, infoSecurePort=0, ipcPort=34370, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:03,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc2e891aa9b4c3f1b: Processing first storage report for DS-9b70d1b7-0024-4ee3-90c4-16eb399fee81 from datanode d9f40411-190e-4b74-997d-b5782f022498
2020-04-02 05:06:03,690 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc2e891aa9b4c3f1b: from storage DS-9b70d1b7-0024-4ee3-90c4-16eb399fee81 node DatanodeRegistration(127.0.0.1:39182, datanodeUuid=d9f40411-190e-4b74-997d-b5782f022498, infoPort=43549, infoSecurePort=0, ipcPort=44228, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:03,724 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd31e1d63347ee8a2: Processing first storage report for DS-599e7b89-c45c-40f8-97c3-5d13427e8194 from datanode a4eec8a0-8419-4ab2-9910-28a844326ac6
2020-04-02 05:06:03,724 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd31e1d63347ee8a2: from storage DS-599e7b89-c45c-40f8-97c3-5d13427e8194 node DatanodeRegistration(127.0.0.1:40013, datanodeUuid=a4eec8a0-8419-4ab2-9910-28a844326ac6, infoPort=40430, infoSecurePort=0, ipcPort=37497, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:03,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd31e1d63347ee8a2: Processing first storage report for DS-c447a982-569b-4b73-9e1d-6404b9ac1f4c from datanode a4eec8a0-8419-4ab2-9910-28a844326ac6
2020-04-02 05:06:03,729 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd31e1d63347ee8a2: from storage DS-c447a982-569b-4b73-9e1d-6404b9ac1f4c node DatanodeRegistration(127.0.0.1:40013, datanodeUuid=a4eec8a0-8419-4ab2-9910-28a844326ac6, infoPort=40430, infoSecurePort=0, ipcPort=37497, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:03,750 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf0712ef55bc5e0e2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 80 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:03,750 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,751 [IPC Server handler 6 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,753 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:03,786 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc2e891aa9b4c3f1b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 104 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:03,786 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,789 [IPC Server handler 5 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/test-dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:03,798 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd31e1d63347ee8a2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 98 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:03,799 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:03,883 [IPC Server handler 4 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/test-dir/file0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:04,002 [IPC Server handler 2 on 44503] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:39182, 127.0.0.1:42882, 127.0.0.1:40013 for /user/root/test-dir/file0
2020-04-02 05:06:04,022 [Thread-155] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:04,168 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:45610 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001 src: /127.0.0.1:45610 dest: /127.0.0.1:39182
2020-04-02 05:06:04,198 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:45610 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:04,219 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:49256 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001 src: /127.0.0.1:49256 dest: /127.0.0.1:42882
2020-04-02 05:06:04,220 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:49256 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:04,231 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:54146 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001 src: /127.0.0.1:54146 dest: /127.0.0.1:40013
2020-04-02 05:06:04,342 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54146, dest: /127.0.0.1:40013, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: a4eec8a0-8419-4ab2-9910-28a844326ac6, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, duration(ns): 39898062
2020-04-02 05:06:04,343 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:04,349 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40013]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49256, dest: /127.0.0.1:42882, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: ef95897c-3071-44a2-86c4-3a26a60fe1b2, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, duration(ns): 65795805
2020-04-02 05:06:04,350 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40013]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40013] terminating
2020-04-02 05:06:04,354 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42882, 127.0.0.1:40013]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45610, dest: /127.0.0.1:39182, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: d9f40411-190e-4b74-997d-b5782f022498, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, duration(ns): 79363579
2020-04-02 05:06:04,355 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42882, 127.0.0.1:40013]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:42882, 127.0.0.1:40013] terminating
2020-04-02 05:06:04,387 [IPC Server handler 8 on 44503] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/test-dir/file0
2020-04-02 05:06:04,795 [IPC Server handler 5 on 44503] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/test-dir/file0 is closed by DFSClient_NONMAPREDUCE_-1629901819_1
2020-04-02 05:06:04,800 [IPC Server handler 4 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/test-dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:04,811 [IPC Server handler 2 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/test-dir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:04,829 [IPC Server handler 1 on 44503] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:40013, 127.0.0.1:39182, 127.0.0.1:42882 for /user/root/test-dir/file1
2020-04-02 05:06:04,834 [Thread-164] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:04,843 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:54160 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002 src: /127.0.0.1:54160 dest: /127.0.0.1:40013
2020-04-02 05:06:04,844 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:54160 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:04,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:45630 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002 src: /127.0.0.1:45630 dest: /127.0.0.1:39182
2020-04-02 05:06:04,847 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:45630 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:04,862 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:49276 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002 src: /127.0.0.1:49276 dest: /127.0.0.1:42882
2020-04-02 05:06:04,946 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49276, dest: /127.0.0.1:42882, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: ef95897c-3071-44a2-86c4-3a26a60fe1b2, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, duration(ns): 74632487
2020-04-02 05:06:04,946 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:04,953 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42882]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45630, dest: /127.0.0.1:39182, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: d9f40411-190e-4b74-997d-b5782f022498, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, duration(ns): 56176001
2020-04-02 05:06:04,954 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42882]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42882] terminating
2020-04-02 05:06:04,963 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39182, 127.0.0.1:42882]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54160, dest: /127.0.0.1:40013, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: a4eec8a0-8419-4ab2-9910-28a844326ac6, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, duration(ns): 87432862
2020-04-02 05:06:04,963 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39182, 127.0.0.1:42882]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39182, 127.0.0.1:42882] terminating
2020-04-02 05:06:04,969 [IPC Server handler 8 on 44503] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/test-dir/file1 is closed by DFSClient_NONMAPREDUCE_-1629901819_1
2020-04-02 05:06:04,990 [IPC Server handler 9 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/test-dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:05,001 [IPC Server handler 6 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/test-dir/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:05,019 [IPC Server handler 5 on 44503] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:39182, 127.0.0.1:40013, 127.0.0.1:42882 for /user/root/test-dir/file2
2020-04-02 05:06:05,030 [Thread-172] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:05,039 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:45638 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003 src: /127.0.0.1:45638 dest: /127.0.0.1:39182
2020-04-02 05:06:05,040 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:45638 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:05,047 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:54174 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003 src: /127.0.0.1:54174 dest: /127.0.0.1:40013
2020-04-02 05:06:05,048 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:54174 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:05,053 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:49288 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003 src: /127.0.0.1:49288 dest: /127.0.0.1:42882
2020-04-02 05:06:05,104 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49288, dest: /127.0.0.1:42882, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: ef95897c-3071-44a2-86c4-3a26a60fe1b2, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, duration(ns): 44983278
2020-04-02 05:06:05,138 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:05,140 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42882]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54174, dest: /127.0.0.1:40013, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: a4eec8a0-8419-4ab2-9910-28a844326ac6, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, duration(ns): 74054635
2020-04-02 05:06:05,140 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42882]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:42882] terminating
2020-04-02 05:06:05,152 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40013, 127.0.0.1:42882]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45638, dest: /127.0.0.1:39182, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: d9f40411-190e-4b74-997d-b5782f022498, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, duration(ns): 85595753
2020-04-02 05:06:05,152 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40013, 127.0.0.1:42882]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40013, 127.0.0.1:42882] terminating
2020-04-02 05:06:05,204 [IPC Server handler 3 on 44503] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/test-dir/file2 is closed by DFSClient_NONMAPREDUCE_-1629901819_1
2020-04-02 05:06:05,256 [IPC Server handler 7 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/test-block-transfer	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:05,267 [IPC Server handler 0 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/test-block-transfer/testfile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:05,283 [IPC Server handler 8 on 44503] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:39182 for /user/root/test-block-transfer/testfile
2020-04-02 05:06:05,288 [Thread-180] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:05,301 [DataXceiver for client DFSClient_NONMAPREDUCE_-1629901819_1 at /127.0.0.1:45654 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004 src: /127.0.0.1:45654 dest: /127.0.0.1:39182
2020-04-02 05:06:05,346 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45654, dest: /127.0.0.1:39182, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1629901819_1, offset: 0, srvID: d9f40411-190e-4b74-997d-b5782f022498, blockid: BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004, duration(ns): 37110347
2020-04-02 05:06:05,347 [PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:05,354 [IPC Server handler 6 on 44503] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/test-block-transfer/testfile is closed by DFSClient_NONMAPREDUCE_-1629901819_1
2020-04-02 05:06:05,369 [IPC Server handler 5 on 44503] INFO  namenode.FSDirectory (FSDirAttrOp.java:unprotectedSetReplication(408)) - Increasing replication from 1 to 2 for /user/root/test-block-transfer/testfile
2020-04-02 05:06:05,370 [IPC Server handler 5 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,387 [IPC Server handler 4 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,396 [IPC Server handler 2 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,508 [IPC Server handler 1 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,510 [IPC Server handler 3 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,613 [IPC Server handler 7 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,616 [IPC Server handler 0 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,723 [IPC Server handler 8 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,726 [IPC Server handler 9 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,830 [IPC Server handler 6 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,832 [IPC Server handler 5 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,936 [IPC Server handler 4 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,939 [IPC Server handler 2 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,042 [IPC Server handler 1 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,047 [IPC Server handler 3 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,150 [IPC Server handler 7 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,152 [IPC Server handler 0 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,256 [IPC Server handler 8 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,258 [IPC Server handler 9 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,361 [IPC Server handler 6 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,364 [IPC Server handler 5 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,468 [IPC Server handler 4 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,470 [IPC Server handler 2 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,579 [IPC Server handler 3 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,582 [IPC Server handler 0 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,599 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:39182, datanodeUuid=d9f40411-190e-4b74-997d-b5782f022498, infoPort=43549, infoSecurePort=0, ipcPort=44228, storageInfo=lv=-57;cid=testClusterID;nsid=2123249663;c=1585803956629) Starting thread to transfer BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004 to 127.0.0.1:42882 
2020-04-02 05:06:06,601 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@1e3af5c8] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:06,649 [DataXceiver for client  at /127.0.0.1:49332 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004 src: /127.0.0.1:49332 dest: /127.0.0.1:42882
2020-04-02 05:06:06,653 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@1e3af5c8] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:39182: Transmitted BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004 (numBytes=10240) to /127.0.0.1:42882
2020-04-02 05:06:06,654 [DataXceiver for client  at /127.0.0.1:49332 [Receiving block BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-888001862-172.17.0.17-1585803956629:blk_1073741828_1004 src: /127.0.0.1:49332 dest: /127.0.0.1:42882 of size 10240
2020-04-02 05:06:06,697 [IPC Server handler 6 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,710 [IPC Server handler 5 on 44503] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,718 [main] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:wasTcpNoDelayActive(172)) - Checking 13 sockets for TCP_NODELAY
2020-04-02 05:06:06,719 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:06,719 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:06:06,719 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34370 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:06,720 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:06,720 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1e5f4170] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:06,727 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-03518e33-23ed-4781-9367-584bf1f125ce) exiting.
2020-04-02 05:06:06,728 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6be56f95-45a6-42fd-8e12-71064a0d6852) exiting.
2020-04-02 05:06:06,917 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a1d204a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:06,938 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62dae245{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:06,952 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5f4d427e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:06,953 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f9879ac{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:07,014 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34370
2020-04-02 05:06:07,017 [IPC Server listener on 34370] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34370
2020-04-02 05:06:07,038 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:07,039 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:07,039 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid ef95897c-3071-44a2-86c4-3a26a60fe1b2) service to localhost/127.0.0.1:44503
2020-04-02 05:06:07,040 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid ef95897c-3071-44a2-86c4-3a26a60fe1b2)
2020-04-02 05:06:07,040 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:07,066 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-888001862-172.17.0.17-1585803956629] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:07,087 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-888001862-172.17.0.17-1585803956629] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:07,129 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:07,130 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:07,131 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:07,131 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:07,146 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:07,146 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:07,147 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44228 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:07,147 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:07,147 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@9635fa] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:07,151 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-9b70d1b7-0024-4ee3-90c4-16eb399fee81) exiting.
2020-04-02 05:06:07,151 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-f8fe1d32-27f0-461f-ab6d-103b24a09729) exiting.
2020-04-02 05:06:07,355 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5f2606b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:07,359 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2b58f754{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:07,360 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e8f9e2d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:07,360 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71e5f61d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:07,366 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44228
2020-04-02 05:06:07,394 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:07,405 [IPC Server listener on 44228] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44228
2020-04-02 05:06:07,394 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:07,423 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid d9f40411-190e-4b74-997d-b5782f022498) service to localhost/127.0.0.1:44503
2020-04-02 05:06:07,423 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid d9f40411-190e-4b74-997d-b5782f022498)
2020-04-02 05:06:07,423 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:07,462 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-888001862-172.17.0.17-1585803956629] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:07,465 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-888001862-172.17.0.17-1585803956629] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:07,470 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:07,471 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:07,472 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:07,472 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:07,485 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:07,486 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:07,486 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37497 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:07,486 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:07,488 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c447a982-569b-4b73-9e1d-6404b9ac1f4c) exiting.
2020-04-02 05:06:07,489 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-599e7b89-c45c-40f8-97c3-5d13427e8194) exiting.
2020-04-02 05:06:07,490 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3542162a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:07,960 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@25b2cfcb{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:07,980 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@72758afa{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:07,981 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@320de594{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:07,981 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f0b0a5e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:08,014 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37497
2020-04-02 05:06:08,034 [IPC Server listener on 37497] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37497
2020-04-02 05:06:08,041 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:08,041 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:08,042 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid a4eec8a0-8419-4ab2-9910-28a844326ac6) service to localhost/127.0.0.1:44503
2020-04-02 05:06:08,154 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-888001862-172.17.0.17-1585803956629 (Datanode Uuid a4eec8a0-8419-4ab2-9910-28a844326ac6)
2020-04-02 05:06:08,154 [BP-888001862-172.17.0.17-1585803956629 heartbeating to localhost/127.0.0.1:44503] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-888001862-172.17.0.17-1585803956629
2020-04-02 05:06:08,176 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-888001862-172.17.0.17-1585803956629] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:08,195 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-888001862-172.17.0.17-1585803956629] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:08,203 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:08,204 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:08,205 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:08,205 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:08,225 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:08,225 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:08,225 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 44503 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:08,225 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:08,226 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 26
2020-04-02 05:06:08,226 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7e276594] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:08,227 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3401a114] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:08,227 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 27 Total time for transactions(ms): 64 Number of transactions batched in Syncs: 8 Number of syncs: 20 SyncTimes(ms): 1 8 
2020-04-02 05:06:08,229 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000027
2020-04-02 05:06:08,229 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000027
2020-04-02 05:06:08,231 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:08,233 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44503
2020-04-02 05:06:08,236 [CacheReplicationMonitor(648132826)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:08,240 [IPC Server listener on 44503] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44503
2020-04-02 05:06:08,240 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:08,243 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:08,243 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:08,308 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:08,308 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:08,326 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6b6776cb{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:08,354 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2d9caaeb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:08,356 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@415b0b49{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:08,357 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49b2a47d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:08,360 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:08,370 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:08,371 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay#testTcpNoDelayDisabled
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay#testTcpNoDelayDisabled
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay#testTcpNoDelayEnabled
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:08,402 [main] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:testTcpNoDelayEnabled(82)) - Socket factory is org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay$SocketFactoryWrapper
2020-04-02 05:06:08,402 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-02 05:06:08,420 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:08,420 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:08,420 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:08,420 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:08,421 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:08,421 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:08,421 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:08,421 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:08,421 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:08,422 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:06:08,423 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:08,423 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:08,424 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:08
2020-04-02 05:06:08,424 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:08,424 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:08,424 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:08,424 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:08,428 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:08,428 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:08,428 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:08,428 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:08,429 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:08,429 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:06:08,429 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:08,429 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:08,429 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:08,429 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:08,430 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:08,430 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:08,430 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:08,430 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:08,431 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:08,431 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:08,433 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:08,433 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:08,433 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:08,433 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:08,433 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:08,434 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:08,434 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:08,434 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:08,434 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:08,434 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:08,435 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:08,435 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:08,435 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:08,436 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:08,436 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:08,436 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:08,436 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:08,437 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:08,437 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:08,438 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:08,458 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:08,474 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:08,507 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:08,507 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:08,555 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:08,557 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:08,563 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:08,564 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:08,568 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:08,584 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:08,584 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:08,586 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:08,587 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:08,598 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:08,598 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:08,599 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e4efc1b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:08,605 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:08,610 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:08,610 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:08,612 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:08,612 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:08,613 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:08,613 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:08,615 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:08,616 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:08,616 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35627
2020-04-02 05:06:08,616 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:08,620 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a76b80a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:08,620 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f4854d6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:08,626 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@551a20d6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:08,627 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@578524c3{HTTP/1.1,[http/1.1]}{localhost:35627}
2020-04-02 05:06:08,627 [main] INFO  server.Server (Server.java:doStart(419)) - Started @14794ms
2020-04-02 05:06:08,633 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:08,634 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:08,634 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:08,634 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:08,634 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:08,634 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:08,634 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:08,634 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:08,635 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:08,635 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:06:08,635 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:08,635 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:08,635 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:08
2020-04-02 05:06:08,635 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:08,635 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:08,636 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:08,636 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:08,641 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:08,641 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:08,641 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:08,641 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:08,642 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:08,642 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:06:08,642 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:08,642 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:08,642 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:08,642 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:08,642 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:08,642 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:08,643 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:08,643 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:08,643 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:08,643 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:08,646 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:08,646 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:08,646 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:08,646 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:08,646 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:08,646 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:08,646 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:08,646 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:08,647 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:08,647 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:08,647 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:08,647 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:08,647 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:08,648 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:08,648 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:08,648 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:08,648 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:08,648 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:08,648 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:08,652 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:08,655 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:08,657 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:08,657 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:08,657 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:08,658 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:08,659 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:08,661 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:08,661 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:08,661 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:08,669 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:08,781 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:08,781 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 131 msecs
2020-04-02 05:06:08,782 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:08,782 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:08,785 [Socket Reader #1 for port 35064] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35064
2020-04-02 05:06:08,796 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:35064 to access this namenode/service.
2020-04-02 05:06:08,796 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:08,914 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:08,932 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:08,932 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:08,933 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:06:08,933 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:08,956 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:08,956 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:08,957 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:08,957 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:08,957 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:08,957 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 24 msec
2020-04-02 05:06:09,038 [IPC Server listener on 35064] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35064: starting
2020-04-02 05:06:09,043 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:35064
2020-04-02 05:06:09,038 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:09,061 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:09,061 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:09,064 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:09,174 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 35064 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:09,206 [CacheReplicationMonitor(478799828)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:09,239 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:09,241 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:09,254 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:09,274 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:09,275 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:09,275 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:09,284 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:09,285 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:09,285 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:09,285 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:09,292 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44837
2020-04-02 05:06:09,293 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:09,293 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:09,302 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:09,304 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:09,306 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:09,306 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:09,307 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:09,308 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:09,308 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:09,308 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:09,309 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33386
2020-04-02 05:06:09,309 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:09,324 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ca27722{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:09,324 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@9573b3b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:09,344 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@245a26e1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:09,344 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d63b624{HTTP/1.1,[http/1.1]}{localhost:33386}
2020-04-02 05:06:09,345 [main] INFO  server.Server (Server.java:doStart(419)) - Started @15511ms
2020-04-02 05:06:09,389 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43562
2020-04-02 05:06:09,394 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:09,394 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:09,395 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:09,394 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b800468] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:09,396 [Socket Reader #1 for port 40473] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40473
2020-04-02 05:06:09,426 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40473
2020-04-02 05:06:09,432 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:09,434 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:09,435 [Thread-241] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35064 starting to offer service
2020-04-02 05:06:09,446 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:09,450 [IPC Server listener on 40473] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40473: starting
2020-04-02 05:06:09,451 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40473 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:09,453 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:09,459 [Thread-241] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:09,490 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:09,498 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:09,534 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:09,535 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:09,535 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:09,535 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:09,542 [Thread-241] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35064
2020-04-02 05:06:09,543 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:09,543 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:09,543 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:09,544 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40756
2020-04-02 05:06:09,544 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:09,544 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:09,552 [Thread-241] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:09,555 [Thread-241] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:09,555 [Thread-241] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 683382114. Formatting...
2020-04-02 05:06:09,555 [Thread-241] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0d93bba2-1df8-4d2f-afcc-c1b50f256aa6 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:09,558 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:09,558 [Thread-241] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:09,559 [Thread-241] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 683382114. Formatting...
2020-04-02 05:06:09,559 [Thread-241] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fb6ecea8-4323-403e-983e-ddfcbc72b03b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:09,559 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:09,568 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:09,568 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:09,570 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:09,570 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,570 [Thread-241] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,570 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-2001708588-172.17.0.17-1585803968438 is not formatted. Formatting ...
2020-04-02 05:06:09,570 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001708588-172.17.0.17-1585803968438 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2001708588-172.17.0.17-1585803968438/current
2020-04-02 05:06:09,570 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:09,571 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:09,571 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:09,571 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33164
2020-04-02 05:06:09,572 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:09,574 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1f130eaf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:09,574 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21362712{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:09,581 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,582 [Thread-241] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,582 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-2001708588-172.17.0.17-1585803968438 is not formatted. Formatting ...
2020-04-02 05:06:09,583 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001708588-172.17.0.17-1585803968438 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2001708588-172.17.0.17-1585803968438/current
2020-04-02 05:06:09,586 [Thread-241] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=683382114;bpid=BP-2001708588-172.17.0.17-1585803968438;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=683382114;c=1585803968438;bpid=BP-2001708588-172.17.0.17-1585803968438;dnuuid=null
2020-04-02 05:06:09,593 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@641856{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:09,593 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1b58ff9e{HTTP/1.1,[http/1.1]}{localhost:33164}
2020-04-02 05:06:09,594 [main] INFO  server.Server (Server.java:doStart(419)) - Started @15760ms
2020-04-02 05:06:09,608 [Thread-241] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID b17058f2-3d44-497b-9477-5070f583e61c
2020-04-02 05:06:09,616 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0d93bba2-1df8-4d2f-afcc-c1b50f256aa6
2020-04-02 05:06:09,645 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35228
2020-04-02 05:06:09,646 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:06:09,647 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:09,647 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:09,648 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:09,647 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@56b78e55] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:09,650 [Socket Reader #1 for port 39200] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39200
2020-04-02 05:06:09,656 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-fb6ecea8-4323-403e-983e-ddfcbc72b03b
2020-04-02 05:06:09,656 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:09,656 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:09,658 [Thread-241] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:09,661 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39200
2020-04-02 05:06:09,664 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:09,664 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:09,665 [Thread-267] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35064 starting to offer service
2020-04-02 05:06:09,665 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:09,665 [IPC Server listener on 39200] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39200: starting
2020-04-02 05:06:09,666 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39200 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:09,667 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:09,668 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:09,669 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:09,669 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:09,670 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:09,670 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:09,670 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:09,682 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:09,682 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:09,683 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:09,700 [Thread-267] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35064
2020-04-02 05:06:09,702 [Thread-241] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:09,702 [Thread-241] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:09,704 [Thread-267] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:09,705 [Thread-241] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:09,705 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,705 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38004
2020-04-02 05:06:09,705 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:09,706 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:09,707 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:09,708 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:09,709 [Thread-267] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:09,709 [Thread-267] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 683382114. Formatting...
2020-04-02 05:06:09,709 [Thread-267] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2f1458fa-b8af-41b9-aa15-12a0d1255fce for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:06:09,710 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:09,710 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:09,711 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:09,711 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:09,713 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:09,714 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:09,714 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:09,714 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:09,715 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33810
2020-04-02 05:06:09,715 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:09,721 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@352c308{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:09,722 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d6bc158{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:09,734 [Thread-267] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:09,734 [Thread-267] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 683382114. Formatting...
2020-04-02 05:06:09,735 [Thread-267] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d25bc44b-56eb-4f35-b41f-a33a9e4d8179 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:06:09,767 [Thread-267] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,767 [Thread-267] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,768 [Thread-267] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-2001708588-172.17.0.17-1585803968438 is not formatted. Formatting ...
2020-04-02 05:06:09,768 [Thread-267] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001708588-172.17.0.17-1585803968438 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2001708588-172.17.0.17-1585803968438/current
2020-04-02 05:06:09,776 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@287f94b1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:09,777 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30b34287{HTTP/1.1,[http/1.1]}{localhost:33810}
2020-04-02 05:06:09,777 [main] INFO  server.Server (Server.java:doStart(419)) - Started @15943ms
2020-04-02 05:06:09,926 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2001708588-172.17.0.17-1585803968438 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 220ms
2020-04-02 05:06:09,928 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2001708588-172.17.0.17-1585803968438 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 218ms
2020-04-02 05:06:09,928 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2001708588-172.17.0.17-1585803968438: 223ms
2020-04-02 05:06:09,929 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:09,930 [Thread-288] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2001708588-172.17.0.17-1585803968438/current/replicas doesn't exist 
2020-04-02 05:06:09,930 [Thread-267] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,930 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:06:09,932 [Thread-267] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,946 [Thread-267] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-2001708588-172.17.0.17-1585803968438 is not formatted. Formatting ...
2020-04-02 05:06:09,954 [Thread-267] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001708588-172.17.0.17-1585803968438 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2001708588-172.17.0.17-1585803968438/current
2020-04-02 05:06:09,974 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:09,975 [Thread-289] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2001708588-172.17.0.17-1585803968438/current/replicas doesn't exist 
2020-04-02 05:06:09,978 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-04-02 05:06:09,981 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438: 54ms
2020-04-02 05:06:09,987 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:09,988 [Thread-241] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:50 AM with interval of 21600000ms
2020-04-02 05:06:09,988 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-fb6ecea8-4323-403e-983e-ddfcbc72b03b): finished scanning block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:09,988 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-fb6ecea8-4323-403e-983e-ddfcbc72b03b): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:09,989 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42634
2020-04-02 05:06:09,989 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:09,995 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid b17058f2-3d44-497b-9477-5070f583e61c) service to localhost/127.0.0.1:35064 beginning handshake with NN
2020-04-02 05:06:09,998 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0d93bba2-1df8-4d2f-afcc-c1b50f256aa6): finished scanning block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,009 [IPC Server handler 2 on 35064] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44837, datanodeUuid=b17058f2-3d44-497b-9477-5070f583e61c, infoPort=43562, infoSecurePort=0, ipcPort=40473, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438) storage b17058f2-3d44-497b-9477-5070f583e61c
2020-04-02 05:06:10,010 [IPC Server handler 2 on 35064] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44837
2020-04-02 05:06:10,010 [IPC Server handler 2 on 35064] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b17058f2-3d44-497b-9477-5070f583e61c (127.0.0.1:44837).
2020-04-02 05:06:10,020 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:10,020 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:10,020 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3676ac27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:10,021 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:10,020 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid b17058f2-3d44-497b-9477-5070f583e61c) service to localhost/127.0.0.1:35064 successfully registered with NN
2020-04-02 05:06:10,021 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35064 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:10,021 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0d93bba2-1df8-4d2f-afcc-c1b50f256aa6): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-04-02 05:06:10,022 [Socket Reader #1 for port 41109] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41109
2020-04-02 05:06:10,029 [Thread-267] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=683382114;bpid=BP-2001708588-172.17.0.17-1585803968438;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=683382114;c=1585803968438;bpid=BP-2001708588-172.17.0.17-1585803968438;dnuuid=null
2020-04-02 05:06:10,075 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41109
2020-04-02 05:06:10,077 [Thread-267] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 72c8574d-8114-490e-a30f-0f94455a95ac
2020-04-02 05:06:10,093 [IPC Server handler 7 on 35064] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0d93bba2-1df8-4d2f-afcc-c1b50f256aa6 for DN 127.0.0.1:44837
2020-04-02 05:06:10,094 [IPC Server handler 7 on 35064] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fb6ecea8-4323-403e-983e-ddfcbc72b03b for DN 127.0.0.1:44837
2020-04-02 05:06:10,094 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:10,095 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:10,143 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2f1458fa-b8af-41b9-aa15-12a0d1255fce
2020-04-02 05:06:10,143 [Thread-267] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:06:10,148 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:10,148 [IPC Server listener on 41109] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41109: starting
2020-04-02 05:06:10,149 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41109 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:10,150 [Thread-299] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35064 starting to offer service
2020-04-02 05:06:10,151 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d25bc44b-56eb-4f35-b41f-a33a9e4d8179
2020-04-02 05:06:10,151 [Thread-267] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:06:10,151 [Thread-267] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:10,157 [Thread-267] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:10,175 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb5eae77739c5f485: Processing first storage report for DS-0d93bba2-1df8-4d2f-afcc-c1b50f256aa6 from datanode b17058f2-3d44-497b-9477-5070f583e61c
2020-04-02 05:06:10,176 [main] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:10,183 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb5eae77739c5f485: from storage DS-0d93bba2-1df8-4d2f-afcc-c1b50f256aa6 node DatanodeRegistration(127.0.0.1:44837, datanodeUuid=b17058f2-3d44-497b-9477-5070f583e61c, infoPort=43562, infoSecurePort=0, ipcPort=40473, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:10,184 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb5eae77739c5f485: Processing first storage report for DS-fb6ecea8-4323-403e-983e-ddfcbc72b03b from datanode b17058f2-3d44-497b-9477-5070f583e61c
2020-04-02 05:06:10,184 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb5eae77739c5f485: from storage DS-fb6ecea8-4323-403e-983e-ddfcbc72b03b node DatanodeRegistration(127.0.0.1:44837, datanodeUuid=b17058f2-3d44-497b-9477-5070f583e61c, infoPort=43562, infoSecurePort=0, ipcPort=40473, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:10,184 [Thread-267] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:10,184 [Thread-267] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:10,184 [Thread-267] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:10,201 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb5eae77739c5f485,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 28 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:10,202 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,246 [Thread-267] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,247 [Thread-299] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35064
2020-04-02 05:06:10,248 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:06:10,273 [IPC Server handler 2 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:10,273 [Thread-299] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:10,276 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:06:10,282 [Thread-299] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:10,282 [Thread-299] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 683382114. Formatting...
2020-04-02 05:06:10,282 [Thread-299] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-aca6356d-b14b-4753-bcff-6b56b5b8999d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:06:10,327 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:10,328 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:10,330 [Thread-299] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7469@1b26ddd29aee
2020-04-02 05:06:10,330 [Thread-299] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 683382114. Formatting...
2020-04-02 05:06:10,330 [Thread-299] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-438c90a9-82bb-45cf-9ee8-e4c6fcde6e27 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:06:10,409 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2001708588-172.17.0.17-1585803968438 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 160ms
2020-04-02 05:06:10,418 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2001708588-172.17.0.17-1585803968438 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 142ms
2020-04-02 05:06:10,419 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2001708588-172.17.0.17-1585803968438: 173ms
2020-04-02 05:06:10,420 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,420 [Thread-299] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,420 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-2001708588-172.17.0.17-1585803968438 is not formatted. Formatting ...
2020-04-02 05:06:10,420 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001708588-172.17.0.17-1585803968438 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2001708588-172.17.0.17-1585803968438/current
2020-04-02 05:06:10,425 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:06:10,426 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2001708588-172.17.0.17-1585803968438/current/replicas doesn't exist 
2020-04-02 05:06:10,426 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:06:10,444 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:06:10,454 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,456 [IPC Server handler 6 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:10,455 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2001708588-172.17.0.17-1585803968438/current/replicas doesn't exist 
2020-04-02 05:06:10,458 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:10,459 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:10,462 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 7ms
2020-04-02 05:06:10,462 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438: 43ms
2020-04-02 05:06:10,462 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:10,463 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2f1458fa-b8af-41b9-aa15-12a0d1255fce): finished scanning block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,463 [Thread-267] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:48 AM with interval of 21600000ms
2020-04-02 05:06:10,463 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:10,463 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2f1458fa-b8af-41b9-aa15-12a0d1255fce): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:10,463 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d25bc44b-56eb-4f35-b41f-a33a9e4d8179): finished scanning block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,464 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d25bc44b-56eb-4f35-b41f-a33a9e4d8179): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:06:10,465 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid 72c8574d-8114-490e-a30f-0f94455a95ac) service to localhost/127.0.0.1:35064 beginning handshake with NN
2020-04-02 05:06:10,466 [IPC Server handler 8 on 35064] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40756, datanodeUuid=72c8574d-8114-490e-a30f-0f94455a95ac, infoPort=35228, infoSecurePort=0, ipcPort=39200, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438) storage 72c8574d-8114-490e-a30f-0f94455a95ac
2020-04-02 05:06:10,466 [IPC Server handler 8 on 35064] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40756
2020-04-02 05:06:10,467 [IPC Server handler 8 on 35064] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 72c8574d-8114-490e-a30f-0f94455a95ac (127.0.0.1:40756).
2020-04-02 05:06:10,467 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid 72c8574d-8114-490e-a30f-0f94455a95ac) service to localhost/127.0.0.1:35064 successfully registered with NN
2020-04-02 05:06:10,467 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35064 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:10,470 [Thread-299] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,470 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-2001708588-172.17.0.17-1585803968438 is not formatted. Formatting ...
2020-04-02 05:06:10,470 [Thread-299] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2001708588-172.17.0.17-1585803968438 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2001708588-172.17.0.17-1585803968438/current
2020-04-02 05:06:10,479 [IPC Server handler 9 on 35064] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2f1458fa-b8af-41b9-aa15-12a0d1255fce for DN 127.0.0.1:40756
2020-04-02 05:06:10,479 [Thread-299] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=683382114;bpid=BP-2001708588-172.17.0.17-1585803968438;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=683382114;c=1585803968438;bpid=BP-2001708588-172.17.0.17-1585803968438;dnuuid=null
2020-04-02 05:06:10,480 [IPC Server handler 9 on 35064] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d25bc44b-56eb-4f35-b41f-a33a9e4d8179 for DN 127.0.0.1:40756
2020-04-02 05:06:10,484 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x87a7e75b72c7c7e9: Processing first storage report for DS-2f1458fa-b8af-41b9-aa15-12a0d1255fce from datanode 72c8574d-8114-490e-a30f-0f94455a95ac
2020-04-02 05:06:10,484 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x87a7e75b72c7c7e9: from storage DS-2f1458fa-b8af-41b9-aa15-12a0d1255fce node DatanodeRegistration(127.0.0.1:40756, datanodeUuid=72c8574d-8114-490e-a30f-0f94455a95ac, infoPort=35228, infoSecurePort=0, ipcPort=39200, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:10,484 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x87a7e75b72c7c7e9: Processing first storage report for DS-d25bc44b-56eb-4f35-b41f-a33a9e4d8179 from datanode 72c8574d-8114-490e-a30f-0f94455a95ac
2020-04-02 05:06:10,484 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x87a7e75b72c7c7e9: from storage DS-d25bc44b-56eb-4f35-b41f-a33a9e4d8179 node DatanodeRegistration(127.0.0.1:40756, datanodeUuid=72c8574d-8114-490e-a30f-0f94455a95ac, infoPort=35228, infoSecurePort=0, ipcPort=39200, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:10,487 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x87a7e75b72c7c7e9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:10,487 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,490 [Thread-299] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID e0e646f7-3a15-487d-af46-2a3520fd2089
2020-04-02 05:06:10,494 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-aca6356d-b14b-4753-bcff-6b56b5b8999d
2020-04-02 05:06:10,494 [Thread-299] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:06:10,499 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-438c90a9-82bb-45cf-9ee8-e4c6fcde6e27
2020-04-02 05:06:10,499 [Thread-299] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:06:10,500 [Thread-299] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:10,501 [Thread-299] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:10,516 [Thread-299] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:10,517 [Thread-299] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:10,517 [Thread-299] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:10,542 [Thread-299] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,549 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:06:10,549 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:06:10,563 [IPC Server handler 3 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:10,564 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:10,564 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:10,592 [Thread-325] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2001708588-172.17.0.17-1585803968438 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 38ms
2020-04-02 05:06:10,611 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2001708588-172.17.0.17-1585803968438 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 57ms
2020-04-02 05:06:10,614 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2001708588-172.17.0.17-1585803968438: 73ms
2020-04-02 05:06:10,615 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:06:10,615 [Thread-328] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2001708588-172.17.0.17-1585803968438/current/replicas doesn't exist 
2020-04-02 05:06:10,616 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:06:10,616 [Thread-329] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2001708588-172.17.0.17-1585803968438/current/replicas doesn't exist 
2020-04-02 05:06:10,616 [Thread-328] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:06:10,622 [Thread-329] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 6ms
2020-04-02 05:06:10,630 [Thread-299] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2001708588-172.17.0.17-1585803968438: 15ms
2020-04-02 05:06:10,631 [Thread-299] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:55 AM with interval of 21600000ms
2020-04-02 05:06:10,632 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:10,633 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-aca6356d-b14b-4753-bcff-6b56b5b8999d): finished scanning block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,634 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-aca6356d-b14b-4753-bcff-6b56b5b8999d): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:06:10,633 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2001708588-172.17.0.17-1585803968438 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:10,634 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-438c90a9-82bb-45cf-9ee8-e4c6fcde6e27): finished scanning block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,634 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-438c90a9-82bb-45cf-9ee8-e4c6fcde6e27): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:06:10,638 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid e0e646f7-3a15-487d-af46-2a3520fd2089) service to localhost/127.0.0.1:35064 beginning handshake with NN
2020-04-02 05:06:10,640 [IPC Server handler 7 on 35064] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38004, datanodeUuid=e0e646f7-3a15-487d-af46-2a3520fd2089, infoPort=42634, infoSecurePort=0, ipcPort=41109, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438) storage e0e646f7-3a15-487d-af46-2a3520fd2089
2020-04-02 05:06:10,640 [IPC Server handler 7 on 35064] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38004
2020-04-02 05:06:10,641 [IPC Server handler 7 on 35064] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e0e646f7-3a15-487d-af46-2a3520fd2089 (127.0.0.1:38004).
2020-04-02 05:06:10,642 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid e0e646f7-3a15-487d-af46-2a3520fd2089) service to localhost/127.0.0.1:35064 successfully registered with NN
2020-04-02 05:06:10,642 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35064 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:10,650 [IPC Server handler 1 on 35064] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-aca6356d-b14b-4753-bcff-6b56b5b8999d for DN 127.0.0.1:38004
2020-04-02 05:06:10,650 [IPC Server handler 1 on 35064] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-438c90a9-82bb-45cf-9ee8-e4c6fcde6e27 for DN 127.0.0.1:38004
2020-04-02 05:06:10,662 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x299e160927217004: Processing first storage report for DS-aca6356d-b14b-4753-bcff-6b56b5b8999d from datanode e0e646f7-3a15-487d-af46-2a3520fd2089
2020-04-02 05:06:10,662 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x299e160927217004: from storage DS-aca6356d-b14b-4753-bcff-6b56b5b8999d node DatanodeRegistration(127.0.0.1:38004, datanodeUuid=e0e646f7-3a15-487d-af46-2a3520fd2089, infoPort=42634, infoSecurePort=0, ipcPort=41109, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:10,663 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x299e160927217004: Processing first storage report for DS-438c90a9-82bb-45cf-9ee8-e4c6fcde6e27 from datanode e0e646f7-3a15-487d-af46-2a3520fd2089
2020-04-02 05:06:10,663 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x299e160927217004: from storage DS-438c90a9-82bb-45cf-9ee8-e4c6fcde6e27 node DatanodeRegistration(127.0.0.1:38004, datanodeUuid=e0e646f7-3a15-487d-af46-2a3520fd2089, infoPort=42634, infoSecurePort=0, ipcPort=41109, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:10,666 [IPC Server handler 2 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:10,667 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:10,683 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x299e160927217004,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 13 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:10,683 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:10,686 [IPC Server handler 6 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:10,688 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:10,691 [IPC Server handler 8 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/test-dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:10,714 [IPC Server handler 9 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/test-dir/file0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:10,727 [IPC Server handler 4 on 35064] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38004, 127.0.0.1:44837, 127.0.0.1:40756 for /user/root/test-dir/file0
2020-04-02 05:06:10,730 [Thread-333] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:10,737 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:33456 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001 src: /127.0.0.1:33456 dest: /127.0.0.1:38004
2020-04-02 05:06:10,738 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:33456 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:10,750 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:46270 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001 src: /127.0.0.1:46270 dest: /127.0.0.1:44837
2020-04-02 05:06:10,751 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:46270 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:10,770 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:43734 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001 src: /127.0.0.1:43734 dest: /127.0.0.1:40756
2020-04-02 05:06:10,844 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43734, dest: /127.0.0.1:40756, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: 72c8574d-8114-490e-a30f-0f94455a95ac, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, duration(ns): 70710502
2020-04-02 05:06:10,847 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:10,851 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40756]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46270, dest: /127.0.0.1:44837, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: b17058f2-3d44-497b-9477-5070f583e61c, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, duration(ns): 63822486
2020-04-02 05:06:10,852 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40756]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40756] terminating
2020-04-02 05:06:10,862 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44837, 127.0.0.1:40756]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33456, dest: /127.0.0.1:38004, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: e0e646f7-3a15-487d-af46-2a3520fd2089, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, duration(ns): 72886723
2020-04-02 05:06:10,862 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44837, 127.0.0.1:40756]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44837, 127.0.0.1:40756] terminating
2020-04-02 05:06:10,868 [IPC Server handler 5 on 35064] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/test-dir/file0 is closed by DFSClient_NONMAPREDUCE_-2003256619_1
2020-04-02 05:06:10,876 [IPC Server handler 2 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/test-dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:10,882 [IPC Server handler 6 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/test-dir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:10,903 [IPC Server handler 8 on 35064] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:38004, 127.0.0.1:40756, 127.0.0.1:44837 for /user/root/test-dir/file1
2020-04-02 05:06:10,905 [Thread-342] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:10,917 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:33462 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002 src: /127.0.0.1:33462 dest: /127.0.0.1:38004
2020-04-02 05:06:10,917 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:33462 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:10,933 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:43738 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002 src: /127.0.0.1:43738 dest: /127.0.0.1:40756
2020-04-02 05:06:10,934 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:43738 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:10,944 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:46278 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002 src: /127.0.0.1:46278 dest: /127.0.0.1:44837
2020-04-02 05:06:11,001 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46278, dest: /127.0.0.1:44837, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: b17058f2-3d44-497b-9477-5070f583e61c, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, duration(ns): 41349499
2020-04-02 05:06:11,002 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:11,012 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44837]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43738, dest: /127.0.0.1:40756, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: 72c8574d-8114-490e-a30f-0f94455a95ac, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, duration(ns): 56088839
2020-04-02 05:06:11,013 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44837]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44837] terminating
2020-04-02 05:06:11,017 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40756, 127.0.0.1:44837]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33462, dest: /127.0.0.1:38004, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: e0e646f7-3a15-487d-af46-2a3520fd2089, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, duration(ns): 60579007
2020-04-02 05:06:11,017 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40756, 127.0.0.1:44837]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40756, 127.0.0.1:44837] terminating
2020-04-02 05:06:11,027 [IPC Server handler 0 on 35064] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/test-dir/file1 is closed by DFSClient_NONMAPREDUCE_-2003256619_1
2020-04-02 05:06:11,063 [IPC Server handler 7 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/test-dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:11,071 [IPC Server handler 1 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/test-dir/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:11,095 [IPC Server handler 5 on 35064] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:38004, 127.0.0.1:40756, 127.0.0.1:44837 for /user/root/test-dir/file2
2020-04-02 05:06:11,097 [Thread-350] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:11,106 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:33470 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003 src: /127.0.0.1:33470 dest: /127.0.0.1:38004
2020-04-02 05:06:11,108 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:33470 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:11,122 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:43746 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003 src: /127.0.0.1:43746 dest: /127.0.0.1:40756
2020-04-02 05:06:11,123 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:43746 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003]] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:11,125 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:46286 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003 src: /127.0.0.1:46286 dest: /127.0.0.1:44837
2020-04-02 05:06:11,197 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46286, dest: /127.0.0.1:44837, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: b17058f2-3d44-497b-9477-5070f583e61c, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, duration(ns): 68695039
2020-04-02 05:06:11,198 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:11,209 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44837]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43746, dest: /127.0.0.1:40756, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: 72c8574d-8114-490e-a30f-0f94455a95ac, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, duration(ns): 64691447
2020-04-02 05:06:11,209 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44837]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44837] terminating
2020-04-02 05:06:11,214 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40756, 127.0.0.1:44837]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33470, dest: /127.0.0.1:38004, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: e0e646f7-3a15-487d-af46-2a3520fd2089, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, duration(ns): 67807219
2020-04-02 05:06:11,215 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40756, 127.0.0.1:44837]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:40756, 127.0.0.1:44837] terminating
2020-04-02 05:06:11,230 [IPC Server handler 9 on 35064] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/test-dir/file2 is closed by DFSClient_NONMAPREDUCE_-2003256619_1
2020-04-02 05:06:11,247 [IPC Server handler 4 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/user/root/test-block-transfer	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:11,250 [IPC Server handler 0 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/test-block-transfer/testfile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:11,262 [IPC Server handler 3 on 35064] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:40756 for /user/root/test-block-transfer/testfile
2020-04-02 05:06:11,268 [Thread-358] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:11,271 [DataXceiver for client DFSClient_NONMAPREDUCE_-2003256619_1 at /127.0.0.1:43756 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004 src: /127.0.0.1:43756 dest: /127.0.0.1:40756
2020-04-02 05:06:11,351 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43756, dest: /127.0.0.1:40756, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2003256619_1, offset: 0, srvID: 72c8574d-8114-490e-a30f-0f94455a95ac, blockid: BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004, duration(ns): 65400496
2020-04-02 05:06:11,351 [PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:11,357 [IPC Server handler 7 on 35064] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741828_1004 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/test-block-transfer/testfile
2020-04-02 05:06:11,770 [IPC Server handler 5 on 35064] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/test-block-transfer/testfile is closed by DFSClient_NONMAPREDUCE_-2003256619_1
2020-04-02 05:06:11,785 [IPC Server handler 2 on 35064] INFO  namenode.FSDirectory (FSDirAttrOp.java:unprotectedSetReplication(408)) - Increasing replication from 1 to 2 for /user/root/test-block-transfer/testfile
2020-04-02 05:06:11,786 [IPC Server handler 2 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setReplication	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:11,790 [IPC Server handler 6 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:11,818 [IPC Server handler 8 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:11,932 [IPC Server handler 9 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:11,939 [IPC Server handler 4 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,062 [IPC Server handler 0 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,065 [IPC Server handler 3 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,172 [IPC Server handler 7 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,174 [IPC Server handler 5 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,282 [IPC Server handler 2 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,284 [IPC Server handler 6 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,391 [IPC Server handler 8 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,394 [IPC Server handler 9 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,499 [IPC Server handler 4 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,501 [IPC Server handler 0 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,604 [IPC Server handler 3 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,606 [IPC Server handler 1 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,710 [IPC Server handler 7 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,712 [IPC Server handler 5 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,820 [IPC Server handler 2 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,822 [IPC Server handler 6 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,924 [IPC Server handler 8 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,927 [IPC Server handler 9 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,033 [IPC Server handler 0 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,035 [IPC Server handler 3 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,138 [IPC Server handler 1 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,140 [IPC Server handler 7 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,243 [IPC Server handler 5 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,245 [IPC Server handler 2 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,351 [IPC Server handler 6 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,357 [IPC Server handler 8 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,461 [IPC Server handler 9 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,465 [IPC Server handler 4 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,473 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:40756, datanodeUuid=72c8574d-8114-490e-a30f-0f94455a95ac, infoPort=35228, infoSecurePort=0, ipcPort=39200, storageInfo=lv=-57;cid=testClusterID;nsid=683382114;c=1585803968438) Starting thread to transfer BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004 to 127.0.0.1:38004 
2020-04-02 05:06:13,475 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@5b94e720] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:createSocket(187)) - Creating new socket
2020-04-02 05:06:13,481 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@5b94e720] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at 127.0.0.1:40756: Transmitted BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004 (numBytes=10240) to /127.0.0.1:38004
2020-04-02 05:06:13,490 [DataXceiver for client  at /127.0.0.1:33546 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004 src: /127.0.0.1:33546 dest: /127.0.0.1:38004
2020-04-02 05:06:13,491 [DataXceiver for client  at /127.0.0.1:33546 [Receiving block BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-2001708588-172.17.0.17-1585803968438:blk_1073741828_1004 src: /127.0.0.1:33546 dest: /127.0.0.1:38004 of size 10240
2020-04-02 05:06:13,568 [IPC Server handler 1 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,570 [IPC Server handler 7 on 35064] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/test-block-transfer/testfile	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,572 [main] INFO  datanode.TestDataNodeTcpNoDelay (TestDataNodeTcpNoDelay.java:wasTcpNoDelayActive(172)) - Checking 13 sockets for TCP_NODELAY
2020-04-02 05:06:13,572 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:13,573 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:06:13,573 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41109 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,573 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:13,573 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3174cb09] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:13,574 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-438c90a9-82bb-45cf-9ee8-e4c6fcde6e27) exiting.
2020-04-02 05:06:13,575 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-aca6356d-b14b-4753-bcff-6b56b5b8999d) exiting.
2020-04-02 05:06:13,645 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid e0e646f7-3a15-487d-af46-2a3520fd2089) service to localhost/127.0.0.1:35064
2020-04-02 05:06:13,646 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid e0e646f7-3a15-487d-af46-2a3520fd2089)
2020-04-02 05:06:13,646 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:13,692 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2001708588-172.17.0.17-1585803968438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:13,712 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@287f94b1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:13,712 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2001708588-172.17.0.17-1585803968438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:13,714 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30b34287{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:13,714 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d6bc158{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:13,714 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@352c308{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:13,720 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41109
2020-04-02 05:06:13,726 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:13,730 [IPC Server listener on 41109] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41109
2020-04-02 05:06:13,757 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:13,758 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:13,766 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:13,767 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:13,770 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:13,770 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:13,770 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39200 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,770 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:13,771 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7889a1ac] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:13,775 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2f1458fa-b8af-41b9-aa15-12a0d1255fce) exiting.
2020-04-02 05:06:13,776 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-d25bc44b-56eb-4f35-b41f-a33a9e4d8179) exiting.
2020-04-02 05:06:13,871 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@641856{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:13,874 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1b58ff9e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:13,875 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21362712{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:13,875 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1f130eaf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:13,883 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39200
2020-04-02 05:06:13,912 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:13,912 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid 72c8574d-8114-490e-a30f-0f94455a95ac) service to localhost/127.0.0.1:35064
2020-04-02 05:06:13,913 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid 72c8574d-8114-490e-a30f-0f94455a95ac)
2020-04-02 05:06:13,913 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:13,913 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:13,922 [IPC Server listener on 39200] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39200
2020-04-02 05:06:13,937 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2001708588-172.17.0.17-1585803968438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:13,945 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2001708588-172.17.0.17-1585803968438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:13,953 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:13,953 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:13,955 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:13,956 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:13,962 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:13,962 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:13,962 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40473 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,962 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:13,969 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1ee4730] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:13,978 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0d93bba2-1df8-4d2f-afcc-c1b50f256aa6) exiting.
2020-04-02 05:06:13,979 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-fb6ecea8-4323-403e-983e-ddfcbc72b03b) exiting.
2020-04-02 05:06:14,050 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@245a26e1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:14,052 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d63b624{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:14,052 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@9573b3b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:14,052 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ca27722{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:14,058 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40473
2020-04-02 05:06:14,120 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:14,120 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:14,121 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid b17058f2-3d44-497b-9477-5070f583e61c) service to localhost/127.0.0.1:35064
2020-04-02 05:06:14,121 [IPC Server listener on 40473] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40473
2020-04-02 05:06:14,230 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2001708588-172.17.0.17-1585803968438 (Datanode Uuid b17058f2-3d44-497b-9477-5070f583e61c)
2020-04-02 05:06:14,230 [BP-2001708588-172.17.0.17-1585803968438 heartbeating to localhost/127.0.0.1:35064] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2001708588-172.17.0.17-1585803968438
2020-04-02 05:06:14,240 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2001708588-172.17.0.17-1585803968438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:14,259 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2001708588-172.17.0.17-1585803968438] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:14,267 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:14,267 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:14,269 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:14,270 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:14,273 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:14,274 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:14,274 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 35064 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:14,274 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:14,274 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 26
2020-04-02 05:06:14,275 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@e24ddd0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:14,274 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@780ec4a5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:14,275 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 27 Total time for transactions(ms): 70 Number of transactions batched in Syncs: 10 Number of syncs: 18 SyncTimes(ms): 3 20 
2020-04-02 05:06:14,276 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000027
2020-04-02 05:06:14,277 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000027
2020-04-02 05:06:14,277 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:14,278 [CacheReplicationMonitor(478799828)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:14,318 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35064
2020-04-02 05:06:14,374 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:14,376 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:14,378 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:14,384 [IPC Server listener on 35064] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35064
2020-04-02 05:06:14,410 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:14,410 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:14,415 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@551a20d6{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:14,428 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@578524c3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:14,429 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f4854d6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:14,429 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a76b80a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:14,431 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:14,443 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:14,443 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay#testTcpNoDelayEnabled
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.TestDataNodeTcpNoDelay#testTcpNoDelayEnabled
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] all testRunFinished

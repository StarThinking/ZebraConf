[msx] before_class
2020-04-02 05:07:53,482 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-02 05:07:54,199 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:54,214 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:54,216 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:54,218 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:54,238 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:54,239 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:54,239 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:54,240 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:54,290 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:54,294 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:07:54,295 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:54,295 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:54,299 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:54,300 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:54
2020-04-02 05:07:54,302 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:54,304 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:54,310 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:54,311 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:54,332 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:54,340 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:54,340 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:54,341 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:54,341 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:54,341 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:07:54,342 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:54,342 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:54,342 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:54,343 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:54,343 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:54,343 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:54,377 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:07:54,399 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:54,400 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:54,400 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:54,401 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:54,407 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:54,407 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:54,408 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:54,408 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:54,414 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:54,417 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:54,423 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:54,423 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:54,424 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:54,424 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:54,434 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:54,434 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:54,434 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:54,438 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:54,438 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:54,440 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:54,441 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:54,441 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:54,441 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:54,475 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:54,488 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:54,491 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:54,500 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:54,500 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:54,638 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:07:54,638 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:07:54,664 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:54,668 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:54,819 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:07:54,875 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:55,186 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:55,187 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:55,193 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:55,223 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:55,267 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@428640fa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:55,282 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:55,288 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:55,313 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @2758ms
2020-04-02 05:07:55,429 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:55,433 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:55,433 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:55,440 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:55,442 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:55,442 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:55,442 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:55,467 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:55,467 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:55,474 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41406
2020-04-02 05:07:55,476 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:55,543 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e16c0aa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:55,545 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@565f390{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:55,593 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4e07b95f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:55,604 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@26df6e3a{HTTP/1.1,[http/1.1]}{localhost:41406}
2020-04-02 05:07:55,605 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3050ms
2020-04-02 05:07:55,619 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:55,619 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:55,620 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:55,620 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:55,620 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:55,620 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:55,621 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:55,621 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:55,622 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:55,622 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:55,622 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:55,623 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:55,624 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:55
2020-04-02 05:07:55,624 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:55,624 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:55,625 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:07:55,625 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:55,630 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:55,630 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:55,631 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:55,631 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:55,631 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:55,631 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:07:55,631 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:55,631 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:55,632 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:55,632 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:55,632 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:55,632 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:55,633 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:55,633 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:55,633 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:07:55,634 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:55,636 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:55,636 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:55,637 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:55,637 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:55,637 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:55,637 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:55,637 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:55,637 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:55,638 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:07:55,638 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:55,639 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:55,639 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:55,639 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:55,639 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:55,640 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:55,640 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:55,640 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:55,640 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:07:55,640 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:55,646 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 12414@1b26ddd29aee
2020-04-02 05:07:55,656 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 12414@1b26ddd29aee
2020-04-02 05:07:55,659 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:55,660 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:55,660 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:55,660 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:55,696 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:55,703 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:55,703 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:55,709 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:55,709 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:55,729 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:55,729 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 87 msecs
2020-04-02 05:07:55,915 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:55,927 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:55,941 [Socket Reader #1 for port 35706] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35706
2020-04-02 05:07:56,225 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:35706 to access this namenode/service.
2020-04-02 05:07:56,229 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:56,246 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:56,259 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:56,260 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:56,260 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:56,260 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:56,264 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:56,265 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:56,265 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:56,265 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:56,265 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:56,265 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-02 05:07:56,300 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:56,301 [IPC Server listener on 35706] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35706: starting
2020-04-02 05:07:56,307 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:35706
2020-04-02 05:07:56,311 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:56,311 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:56,315 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:56,319 [CacheReplicationMonitor(1168542147)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:56,319 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 35706 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:56,327 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:56,428 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:56,439 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:56,466 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:56,466 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:56,472 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:56,475 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:56,483 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:56,484 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:56,488 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:56,496 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43708
2020-04-02 05:07:56,497 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:56,498 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:56,514 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:56,516 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:56,516 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:56,517 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:56,521 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:56,521 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:56,522 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:56,522 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:56,525 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45066
2020-04-02 05:07:56,525 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:56,527 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7516e4e5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:56,528 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e81e5ac{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:56,536 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4b20ca2b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:56,537 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1cbf6e72{HTTP/1.1,[http/1.1]}{localhost:45066}
2020-04-02 05:07:56,538 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3983ms
2020-04-02 05:07:56,943 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39965
2020-04-02 05:07:56,944 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77192705] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:56,945 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:56,946 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:56,966 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:56,967 [Socket Reader #1 for port 37730] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37730
2020-04-02 05:07:56,976 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37730
2020-04-02 05:07:56,993 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:56,997 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:57,382 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35706 starting to offer service
2020-04-02 05:07:57,390 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:57,391 [IPC Server listener on 37730] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37730: starting
2020-04-02 05:07:57,404 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37730 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:57,406 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:07:57,408 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:07:57,411 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:07:57,452 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:57,452 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:57,453 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:57,453 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:57,456 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:57,457 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:57,458 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:57,459 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43378
2020-04-02 05:07:57,459 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:57,459 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:57,460 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:57,462 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:57,464 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:57,465 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:57,468 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:57,469 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:57,469 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:57,469 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:57,470 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42077
2020-04-02 05:07:57,486 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:57,515 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53ab0286{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:57,533 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d10e0b1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:57,543 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@89ff02e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:57,544 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6865c751{HTTP/1.1,[http/1.1]}{localhost:42077}
2020-04-02 05:07:57,544 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4990ms
2020-04-02 05:07:57,713 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35774
2020-04-02 05:07:57,714 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:57,714 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a988392] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:57,714 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:57,715 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:57,716 [Socket Reader #1 for port 46622] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46622
2020-04-02 05:07:57,736 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46622
2020-04-02 05:07:57,751 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:57,752 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:57,757 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35706 starting to offer service
2020-04-02 05:07:57,770 [IPC Server listener on 46622] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46622: starting
2020-04-02 05:07:57,771 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46622 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:57,774 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:57,790 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:07:57,811 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:07:57,812 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:07:57,813 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:57,813 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:57,814 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:57,814 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:57,815 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:57,819 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:57,819 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:57,821 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43619
2020-04-02 05:07:57,821 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:57,821 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:57,824 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:57,827 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:57,828 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:57,829 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:57,831 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:57,832 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:57,832 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:57,832 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:57,836 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33865
2020-04-02 05:07:57,836 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:57,838 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b5966e1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:57,842 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1568159{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:57,848 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@31024624{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:57,849 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@25bcd0c7{HTTP/1.1,[http/1.1]}{localhost:33865}
2020-04-02 05:07:57,850 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5295ms
2020-04-02 05:07:57,886 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42461
2020-04-02 05:07:57,886 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:57,886 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:57,887 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:57,886 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@63cd604c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:57,888 [Socket Reader #1 for port 36744] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36744
2020-04-02 05:07:57,896 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36744
2020-04-02 05:07:57,918 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:57,919 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:57,927 [IPC Server listener on 36744] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36744: starting
2020-04-02 05:07:57,935 [Thread-107] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35706 starting to offer service
2020-04-02 05:07:57,937 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:57,938 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36744 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:58,080 [Thread-107] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35706
2020-04-02 05:07:58,083 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35706
2020-04-02 05:07:58,089 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35706
2020-04-02 05:07:58,091 [Thread-107] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:58,092 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:58,092 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:58,093 [Thread-107] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 12414@1b26ddd29aee
2020-04-02 05:07:58,093 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 12414@1b26ddd29aee
2020-04-02 05:07:58,094 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 12414@1b26ddd29aee
2020-04-02 05:07:58,094 [Thread-107] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 563687807. Formatting...
2020-04-02 05:07:58,094 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 563687807. Formatting...
2020-04-02 05:07:58,095 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 563687807. Formatting...
2020-04-02 05:07:58,095 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b461453e-09ce-41de-b59a-eca98a2e5e7d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:07:58,096 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2edd0218-5d89-4b32-99d9-6df032c5bd80 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:58,102 [Thread-107] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2b7ac133-f349-42e8-89ff-eee1289458dc for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:07:58,107 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 12414@1b26ddd29aee
2020-04-02 05:07:58,108 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 563687807. Formatting...
2020-04-02 05:07:58,108 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5cc13679-5d77-4297-8c1d-160d9d87bbb8 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:58,111 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 12414@1b26ddd29aee
2020-04-02 05:07:58,112 [Thread-107] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 12414@1b26ddd29aee
2020-04-02 05:07:58,112 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 563687807. Formatting...
2020-04-02 05:07:58,112 [Thread-107] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 563687807. Formatting...
2020-04-02 05:07:58,112 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3ad28697-c0ae-465b-a0f1-cf4c42f3e6f3 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:07:58,112 [Thread-107] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-66bce74f-f8b3-42d8-8cfa-7992b76851a2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:07:58,123 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,123 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,124 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-925864317-172.17.0.17-1585804074461 is not formatted. Formatting ...
2020-04-02 05:07:58,124 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-925864317-172.17.0.17-1585804074461 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-925864317-172.17.0.17-1585804074461/current
2020-04-02 05:07:58,140 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,140 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,140 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-925864317-172.17.0.17-1585804074461 is not formatted. Formatting ...
2020-04-02 05:07:58,140 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-925864317-172.17.0.17-1585804074461 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-925864317-172.17.0.17-1585804074461/current
2020-04-02 05:07:58,150 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,151 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,151 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-925864317-172.17.0.17-1585804074461 is not formatted. Formatting ...
2020-04-02 05:07:58,151 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-925864317-172.17.0.17-1585804074461 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-925864317-172.17.0.17-1585804074461/current
2020-04-02 05:07:58,158 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,158 [Thread-107] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,159 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-925864317-172.17.0.17-1585804074461 is not formatted. Formatting ...
2020-04-02 05:07:58,159 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-925864317-172.17.0.17-1585804074461 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-925864317-172.17.0.17-1585804074461/current
2020-04-02 05:07:58,170 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=563687807;bpid=BP-925864317-172.17.0.17-1585804074461;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=563687807;c=1585804074461;bpid=BP-925864317-172.17.0.17-1585804074461;dnuuid=null
2020-04-02 05:07:58,177 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,178 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,178 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-925864317-172.17.0.17-1585804074461 is not formatted. Formatting ...
2020-04-02 05:07:58,178 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-925864317-172.17.0.17-1585804074461 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-925864317-172.17.0.17-1585804074461/current
2020-04-02 05:07:58,179 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a2fcf997-c0c0-4c24-b674-969a14499c96
2020-04-02 05:07:58,180 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,180 [Thread-107] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,180 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-925864317-172.17.0.17-1585804074461 is not formatted. Formatting ...
2020-04-02 05:07:58,180 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-925864317-172.17.0.17-1585804074461 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-925864317-172.17.0.17-1585804074461/current
2020-04-02 05:07:58,226 [Thread-107] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=563687807;bpid=BP-925864317-172.17.0.17-1585804074461;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=563687807;c=1585804074461;bpid=BP-925864317-172.17.0.17-1585804074461;dnuuid=null
2020-04-02 05:07:58,228 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=563687807;bpid=BP-925864317-172.17.0.17-1585804074461;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=563687807;c=1585804074461;bpid=BP-925864317-172.17.0.17-1585804074461;dnuuid=null
2020-04-02 05:07:58,231 [Thread-107] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a062927e-3d3f-47d5-a9de-d0d3090eccdd
2020-04-02 05:07:58,234 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID c344204c-7830-470e-b9c8-4dac191a1a7b
2020-04-02 05:07:58,404 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b461453e-09ce-41de-b59a-eca98a2e5e7d
2020-04-02 05:07:58,418 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2edd0218-5d89-4b32-99d9-6df032c5bd80
2020-04-02 05:07:58,404 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2b7ac133-f349-42e8-89ff-eee1289458dc
2020-04-02 05:07:58,425 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:07:58,426 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:58,425 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:07:58,427 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-66bce74f-f8b3-42d8-8cfa-7992b76851a2
2020-04-02 05:07:58,428 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:07:58,430 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3ad28697-c0ae-465b-a0f1-cf4c42f3e6f3
2020-04-02 05:07:58,430 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:07:58,432 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:58,432 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:58,443 [Thread-107] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:07:58,445 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:07:58,460 [Thread-107] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:07:58,461 [Thread-107] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:07:58,462 [Thread-107] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:07:58,445 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5cc13679-5d77-4297-8c1d-160d9d87bbb8
2020-04-02 05:07:58,463 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:58,460 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:07:58,463 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,467 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:07:58,468 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:07:58,467 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:58,484 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:58,492 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:58,492 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:58,485 [Thread-124] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:07:58,485 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:07:58,502 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:58,514 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,514 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,515 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:07:58,522 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:58,524 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:58,525 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:07:58,584 [Thread-124] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-925864317-172.17.0.17-1585804074461 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 87ms
2020-04-02 05:07:58,612 [Thread-125] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-925864317-172.17.0.17-1585804074461 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 115ms
2020-04-02 05:07:58,618 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-925864317-172.17.0.17-1585804074461: 151ms
2020-04-02 05:07:58,630 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-925864317-172.17.0.17-1585804074461 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 106ms
2020-04-02 05:07:58,645 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-925864317-172.17.0.17-1585804074461 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 119ms
2020-04-02 05:07:58,657 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:07:58,657 [Thread-137] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-925864317-172.17.0.17-1585804074461/current/replicas doesn't exist 
2020-04-02 05:07:58,666 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-925864317-172.17.0.17-1585804074461 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 143ms
2020-04-02 05:07:58,666 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-925864317-172.17.0.17-1585804074461: 153ms
2020-04-02 05:07:58,667 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-925864317-172.17.0.17-1585804074461 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 152ms
2020-04-02 05:07:58,667 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:58,668 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-925864317-172.17.0.17-1585804074461: 154ms
2020-04-02 05:07:58,670 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:58,670 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:07:58,667 [Thread-138] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-925864317-172.17.0.17-1585804074461/current/replicas doesn't exist 
2020-04-02 05:07:58,670 [Thread-139] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-925864317-172.17.0.17-1585804074461/current/replicas doesn't exist 
2020-04-02 05:07:58,670 [Thread-136] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-925864317-172.17.0.17-1585804074461/current/replicas doesn't exist 
2020-04-02 05:07:58,698 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 28ms
2020-04-02 05:07:58,699 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 32ms
2020-04-02 05:07:58,699 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-925864317-172.17.0.17-1585804074461: 32ms
2020-04-02 05:07:58,699 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:07:58,700 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:07:58,700 [Thread-136] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 30ms
2020-04-02 05:07:58,700 [Thread-140] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-925864317-172.17.0.17-1585804074461/current/replicas doesn't exist 
2020-04-02 05:07:58,700 [Thread-137] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 43ms
2020-04-02 05:07:58,700 [Thread-141] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-925864317-172.17.0.17-1585804074461/current/replicas doesn't exist 
2020-04-02 05:07:58,703 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:58,708 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 8ms
2020-04-02 05:07:58,701 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-925864317-172.17.0.17-1585804074461: 81ms
2020-04-02 05:07:58,713 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 13ms
2020-04-02 05:07:58,705 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:58,719 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-925864317-172.17.0.17-1585804074461: 51ms
2020-04-02 05:07:58,719 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:07:58,720 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:07:58,720 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:07:58,720 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-925864317-172.17.0.17-1585804074461 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:07:58,722 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2edd0218-5d89-4b32-99d9-6df032c5bd80): finished scanning block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,722 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-66bce74f-f8b3-42d8-8cfa-7992b76851a2): finished scanning block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,726 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5cc13679-5d77-4297-8c1d-160d9d87bbb8): finished scanning block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,727 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-2b7ac133-f349-42e8-89ff-eee1289458dc): finished scanning block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,726 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-3ad28697-c0ae-465b-a0f1-cf4c42f3e6f3): finished scanning block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,727 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-b461453e-09ce-41de-b59a-eca98a2e5e7d): finished scanning block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:58,737 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:20 AM with interval of 21600000ms
2020-04-02 05:07:58,737 [Thread-107] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:28 AM with interval of 21600000ms
2020-04-02 05:07:58,737 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:47 AM with interval of 21600000ms
2020-04-02 05:07:58,765 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid a062927e-3d3f-47d5-a9de-d0d3090eccdd) service to localhost/127.0.0.1:35706 beginning handshake with NN
2020-04-02 05:07:58,771 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid a2fcf997-c0c0-4c24-b674-969a14499c96) service to localhost/127.0.0.1:35706 beginning handshake with NN
2020-04-02 05:07:58,771 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid c344204c-7830-470e-b9c8-4dac191a1a7b) service to localhost/127.0.0.1:35706 beginning handshake with NN
2020-04-02 05:07:58,796 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2edd0218-5d89-4b32-99d9-6df032c5bd80): no suitable block pools found to scan.  Waiting 1814399907 ms.
2020-04-02 05:07:58,798 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-66bce74f-f8b3-42d8-8cfa-7992b76851a2): no suitable block pools found to scan.  Waiting 1814399921 ms.
2020-04-02 05:07:58,797 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5cc13679-5d77-4297-8c1d-160d9d87bbb8): no suitable block pools found to scan.  Waiting 1814399906 ms.
2020-04-02 05:07:58,798 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-2b7ac133-f349-42e8-89ff-eee1289458dc): no suitable block pools found to scan.  Waiting 1814399921 ms.
2020-04-02 05:07:58,798 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-b461453e-09ce-41de-b59a-eca98a2e5e7d): no suitable block pools found to scan.  Waiting 1814399922 ms.
2020-04-02 05:07:58,798 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-3ad28697-c0ae-465b-a0f1-cf4c42f3e6f3): no suitable block pools found to scan.  Waiting 1814399922 ms.
2020-04-02 05:07:58,798 [IPC Server handler 8 on 35706] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43378, datanodeUuid=c344204c-7830-470e-b9c8-4dac191a1a7b, infoPort=35774, infoSecurePort=0, ipcPort=46622, storageInfo=lv=-57;cid=testClusterID;nsid=563687807;c=1585804074461) storage c344204c-7830-470e-b9c8-4dac191a1a7b
2020-04-02 05:07:58,801 [IPC Server handler 8 on 35706] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43378
2020-04-02 05:07:58,801 [IPC Server handler 8 on 35706] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c344204c-7830-470e-b9c8-4dac191a1a7b (127.0.0.1:43378).
2020-04-02 05:07:58,806 [IPC Server handler 4 on 35706] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43619, datanodeUuid=a062927e-3d3f-47d5-a9de-d0d3090eccdd, infoPort=42461, infoSecurePort=0, ipcPort=36744, storageInfo=lv=-57;cid=testClusterID;nsid=563687807;c=1585804074461) storage a062927e-3d3f-47d5-a9de-d0d3090eccdd
2020-04-02 05:07:58,806 [IPC Server handler 4 on 35706] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43619
2020-04-02 05:07:58,806 [IPC Server handler 4 on 35706] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a062927e-3d3f-47d5-a9de-d0d3090eccdd (127.0.0.1:43619).
2020-04-02 05:07:58,806 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid c344204c-7830-470e-b9c8-4dac191a1a7b) service to localhost/127.0.0.1:35706 successfully registered with NN
2020-04-02 05:07:58,807 [IPC Server handler 6 on 35706] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43708, datanodeUuid=a2fcf997-c0c0-4c24-b674-969a14499c96, infoPort=39965, infoSecurePort=0, ipcPort=37730, storageInfo=lv=-57;cid=testClusterID;nsid=563687807;c=1585804074461) storage a2fcf997-c0c0-4c24-b674-969a14499c96
2020-04-02 05:07:58,807 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35706 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:58,807 [IPC Server handler 6 on 35706] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43708
2020-04-02 05:07:58,807 [IPC Server handler 6 on 35706] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a2fcf997-c0c0-4c24-b674-969a14499c96 (127.0.0.1:43708).
2020-04-02 05:07:58,808 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid a2fcf997-c0c0-4c24-b674-969a14499c96) service to localhost/127.0.0.1:35706 successfully registered with NN
2020-04-02 05:07:58,808 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35706 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:58,808 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid a062927e-3d3f-47d5-a9de-d0d3090eccdd) service to localhost/127.0.0.1:35706 successfully registered with NN
2020-04-02 05:07:58,808 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35706 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:58,886 [IPC Server handler 9 on 35706] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2b7ac133-f349-42e8-89ff-eee1289458dc for DN 127.0.0.1:43619
2020-04-02 05:07:58,902 [IPC Server handler 9 on 35706] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-66bce74f-f8b3-42d8-8cfa-7992b76851a2 for DN 127.0.0.1:43619
2020-04-02 05:07:58,917 [IPC Server handler 7 on 35706] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2edd0218-5d89-4b32-99d9-6df032c5bd80 for DN 127.0.0.1:43708
2020-04-02 05:07:58,918 [IPC Server handler 7 on 35706] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5cc13679-5d77-4297-8c1d-160d9d87bbb8 for DN 127.0.0.1:43708
2020-04-02 05:07:58,919 [IPC Server handler 2 on 35706] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b461453e-09ce-41de-b59a-eca98a2e5e7d for DN 127.0.0.1:43378
2020-04-02 05:07:58,920 [IPC Server handler 2 on 35706] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3ad28697-c0ae-465b-a0f1-cf4c42f3e6f3 for DN 127.0.0.1:43378
2020-04-02 05:07:58,966 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x543a9c216e7ab2f0: Processing first storage report for DS-2edd0218-5d89-4b32-99d9-6df032c5bd80 from datanode a2fcf997-c0c0-4c24-b674-969a14499c96
2020-04-02 05:07:58,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x543a9c216e7ab2f0: from storage DS-2edd0218-5d89-4b32-99d9-6df032c5bd80 node DatanodeRegistration(127.0.0.1:43708, datanodeUuid=a2fcf997-c0c0-4c24-b674-969a14499c96, infoPort=39965, infoSecurePort=0, ipcPort=37730, storageInfo=lv=-57;cid=testClusterID;nsid=563687807;c=1585804074461), blocks: 0, hasStaleStorage: true, processing time: 3 msecs, invalidatedBlocks: 0
2020-04-02 05:07:58,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x543a9c216e7ab2f0: Processing first storage report for DS-5cc13679-5d77-4297-8c1d-160d9d87bbb8 from datanode a2fcf997-c0c0-4c24-b674-969a14499c96
2020-04-02 05:07:58,969 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x543a9c216e7ab2f0: from storage DS-5cc13679-5d77-4297-8c1d-160d9d87bbb8 node DatanodeRegistration(127.0.0.1:43708, datanodeUuid=a2fcf997-c0c0-4c24-b674-969a14499c96, infoPort=39965, infoSecurePort=0, ipcPort=37730, storageInfo=lv=-57;cid=testClusterID;nsid=563687807;c=1585804074461), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:58,979 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x84caa02e5dc87658: Processing first storage report for DS-2b7ac133-f349-42e8-89ff-eee1289458dc from datanode a062927e-3d3f-47d5-a9de-d0d3090eccdd
2020-04-02 05:07:58,980 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x84caa02e5dc87658: from storage DS-2b7ac133-f349-42e8-89ff-eee1289458dc node DatanodeRegistration(127.0.0.1:43619, datanodeUuid=a062927e-3d3f-47d5-a9de-d0d3090eccdd, infoPort=42461, infoSecurePort=0, ipcPort=36744, storageInfo=lv=-57;cid=testClusterID;nsid=563687807;c=1585804074461), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:58,980 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb50e03aaea837b0f: Processing first storage report for DS-b461453e-09ce-41de-b59a-eca98a2e5e7d from datanode c344204c-7830-470e-b9c8-4dac191a1a7b
2020-04-02 05:07:58,980 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb50e03aaea837b0f: from storage DS-b461453e-09ce-41de-b59a-eca98a2e5e7d node DatanodeRegistration(127.0.0.1:43378, datanodeUuid=c344204c-7830-470e-b9c8-4dac191a1a7b, infoPort=35774, infoSecurePort=0, ipcPort=46622, storageInfo=lv=-57;cid=testClusterID;nsid=563687807;c=1585804074461), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:58,980 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb50e03aaea837b0f: Processing first storage report for DS-3ad28697-c0ae-465b-a0f1-cf4c42f3e6f3 from datanode c344204c-7830-470e-b9c8-4dac191a1a7b
2020-04-02 05:07:58,980 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb50e03aaea837b0f: from storage DS-3ad28697-c0ae-465b-a0f1-cf4c42f3e6f3 node DatanodeRegistration(127.0.0.1:43378, datanodeUuid=c344204c-7830-470e-b9c8-4dac191a1a7b, infoPort=35774, infoSecurePort=0, ipcPort=46622, storageInfo=lv=-57;cid=testClusterID;nsid=563687807;c=1585804074461), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:58,981 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x84caa02e5dc87658: Processing first storage report for DS-66bce74f-f8b3-42d8-8cfa-7992b76851a2 from datanode a062927e-3d3f-47d5-a9de-d0d3090eccdd
2020-04-02 05:07:58,981 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x84caa02e5dc87658: from storage DS-66bce74f-f8b3-42d8-8cfa-7992b76851a2 node DatanodeRegistration(127.0.0.1:43619, datanodeUuid=a062927e-3d3f-47d5-a9de-d0d3090eccdd, infoPort=42461, infoSecurePort=0, ipcPort=36744, storageInfo=lv=-57;cid=testClusterID;nsid=563687807;c=1585804074461), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:59,000 [IPC Server handler 5 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,006 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb50e03aaea837b0f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 16 msec to generate and 62 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:59,007 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:59,009 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x84caa02e5dc87658,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 16 msec to generate and 67 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:59,009 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x543a9c216e7ab2f0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 61 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:59,022 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:59,022 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:07:59,041 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:59,066 [IPC Server handler 8 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,070 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
[msx] test Started org.apache.hadoop.hdfs.TestExtendedAcls#testAccessAclNotInherited
[msx] unitTestCounterInClass = 0
2020-04-02 05:07:59,098 [IPC Server handler 4 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testAccessAclNotInherited	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,153 [IPC Server handler 6 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setAcl	src=/testAccessAclNotInherited	dst=null	perm=root:supergroup:rw-rwxr--	proto=rpc
2020-04-02 05:07:59,164 [IPC Server handler 9 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testAccessAclNotInherited/childDir	dst=null	perm=root:supergroup:rw-r-xr--	proto=rpc
2020-04-02 05:07:59,173 [IPC Server handler 2 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testAccessAclNotInherited/childDir	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,223 [IPC Server handler 7 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testAccessAclNotInherited/childFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:59,278 [IPC Server handler 0 on 35706] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testAccessAclNotInherited/childFile is closed by DFSClient_NONMAPREDUCE_-1620420284_1
2020-04-02 05:07:59,293 [IPC Server handler 3 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testAccessAclNotInherited/childFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,311 [IPC Server handler 1 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testAccessAclNotInherited	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.TestExtendedAcls#testAccessAclNotInherited
[msx] writeFile testName = org.apache.hadoop.hdfs.TestExtendedAcls#testAccessAclNotInherited
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestExtendedAcls#testDefaultAclExistingDirFile
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:59,320 [IPC Server handler 5 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testDefaultAclExistingDirFile	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,326 [IPC Server handler 8 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setAcl	src=/testDefaultAclExistingDirFile	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,330 [IPC Server handler 4 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testDefaultAclExistingDirFile/childDir	dst=null	perm=root:supergroup:rwxrwxr-x	proto=rpc
2020-04-02 05:07:59,342 [IPC Server handler 6 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testDefaultAclExistingDirFile/childDir	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,347 [IPC Server handler 9 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testDefaultAclExistingDirFile/childDir/childFile	dst=null	perm=root:supergroup:rw-rw-r--	proto=rpc
2020-04-02 05:07:59,352 [IPC Server handler 2 on 35706] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testDefaultAclExistingDirFile/childDir/childFile is closed by DFSClient_NONMAPREDUCE_-1620420284_1
2020-04-02 05:07:59,358 [IPC Server handler 7 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testDefaultAclExistingDirFile/childDir/childFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,376 [IPC Server handler 0 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setAcl	src=/testDefaultAclExistingDirFile	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,399 [IPC Server handler 3 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testDefaultAclExistingDirFile/childDir	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,403 [IPC Server handler 1 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testDefaultAclExistingDirFile/childDir/childFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,409 [IPC Server handler 5 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeAcl	src=/testDefaultAclExistingDirFile	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,414 [IPC Server handler 8 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testDefaultAclExistingDirFile/childDir	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,417 [IPC Server handler 4 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testDefaultAclExistingDirFile/childDir/childFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,428 [IPC Server handler 6 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testDefaultAclExistingDirFile/childDir/childFile	dst=null	perm=root:supergroup:rw-r-----	proto=rpc
2020-04-02 05:07:59,471 [IPC Server handler 9 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=other (auth:SIMPLE)	ip=/127.0.0.1	cmd=checkAccess	src=/testDefaultAclExistingDirFile/childDir/childFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,472 [IPC Server handler 9 on 35706] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 35706, call Call#36 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.checkAccess from 127.0.0.1:57690: org.apache.hadoop.security.AccessControlException: Permission denied: user=other, access=READ, inode="/testDefaultAclExistingDirFile/childDir/childFile":root:supergroup:-rw-r-----
2020-04-02 05:07:59,485 [IPC Server handler 2 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testDefaultAclExistingDirFile	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.TestExtendedAcls#testDefaultAclExistingDirFile
[msx] writeFile testName = org.apache.hadoop.hdfs.TestExtendedAcls#testDefaultAclExistingDirFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestExtendedAcls#testGradSubdirMoreAccess
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:59,493 [IPC Server handler 7 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testGradSubdirMoreAccess	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,507 [IPC Server handler 0 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setAcl	src=/testGradSubdirMoreAccess	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,510 [IPC Server handler 3 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testGradSubdirMoreAccess	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,513 [IPC Server handler 1 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testGradSubdirMoreAccess/childDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,519 [IPC Server handler 5 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/testGradSubdirMoreAccess/childDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,522 [IPC Server handler 8 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testGradSubdirMoreAccess/childDir	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,540 [IPC Server handler 4 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testGradSubdirMoreAccess/parentFile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:59,544 [IPC Server handler 6 on 35706] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testGradSubdirMoreAccess/parentFile is closed by DFSClient_NONMAPREDUCE_-1620420284_1
2020-04-02 05:07:59,551 [IPC Server handler 9 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testGradSubdirMoreAccess/parentFile	dst=null	perm=root:supergroup:rw-r-----	proto=rpc
2020-04-02 05:07:59,554 [IPC Server handler 2 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testGradSubdirMoreAccess/parentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,564 [IPC Server handler 7 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testGradSubdirMoreAccess/childDir/childFile	dst=null	perm=root:supergroup:rw-rw-r--	proto=rpc
2020-04-02 05:07:59,572 [IPC Server handler 0 on 35706] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testGradSubdirMoreAccess/childDir/childFile is closed by DFSClient_NONMAPREDUCE_-1620420284_1
2020-04-02 05:07:59,576 [IPC Server handler 3 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testGradSubdirMoreAccess/childDir/childFile	dst=null	perm=root:supergroup:rw-r-----	proto=rpc
2020-04-02 05:07:59,582 [IPC Server handler 1 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testGradSubdirMoreAccess/childDir/childFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,597 [IPC Server handler 5 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=barUser (auth:SIMPLE)	ip=/127.0.0.1	cmd=checkAccess	src=/testGradSubdirMoreAccess/parentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,598 [IPC Server handler 5 on 35706] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 35706, call Call#52 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.checkAccess from 127.0.0.1:57710: org.apache.hadoop.security.AccessControlException: Permission denied: user=barUser, access=READ, inode="/testGradSubdirMoreAccess/parentFile":root:supergroup:-rw-r-----
2020-04-02 05:07:59,677 [IPC Server handler 9 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testGradSubdirMoreAccess	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.TestExtendedAcls#testGradSubdirMoreAccess
[msx] writeFile testName = org.apache.hadoop.hdfs.TestExtendedAcls#testGradSubdirMoreAccess
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestExtendedAcls#testRestrictAtSubDir
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:59,681 [IPC Server handler 2 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testRestrictAtSubDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,685 [IPC Server handler 7 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setAcl	src=/testRestrictAtSubDir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,689 [IPC Server handler 0 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testRestrictAtSubDir	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,696 [IPC Server handler 3 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testRestrictAtSubDir/parentFile	dst=null	perm=root:supergroup:rw-rw-r--	proto=rpc
2020-04-02 05:07:59,705 [IPC Server handler 1 on 35706] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testRestrictAtSubDir/parentFile is closed by DFSClient_NONMAPREDUCE_-1620420284_1
2020-04-02 05:07:59,714 [IPC Server handler 5 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testRestrictAtSubDir/parentFile	dst=null	perm=root:supergroup:rw-r-----	proto=rpc
2020-04-02 05:07:59,722 [IPC Server handler 8 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testRestrictAtSubDir/parentFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,731 [IPC Server handler 4 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testRestrictAtSubDir/childDir	dst=null	perm=root:supergroup:rwxrwxr-x	proto=rpc
2020-04-02 05:07:59,735 [IPC Server handler 6 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/testRestrictAtSubDir/childDir	dst=null	perm=root:supergroup:rwxrwxr-x	proto=rpc
2020-04-02 05:07:59,746 [IPC Server handler 9 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testRestrictAtSubDir/childDir	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,750 [IPC Server handler 2 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testRestrictAtSubDir/childDir/childFile	dst=null	perm=root:supergroup:rw-rw-r--	proto=rpc
2020-04-02 05:07:59,761 [IPC Server handler 7 on 35706] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testRestrictAtSubDir/childDir/childFile is closed by DFSClient_NONMAPREDUCE_-1620420284_1
2020-04-02 05:07:59,766 [IPC Server handler 0 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/testRestrictAtSubDir/childDir/childFile	dst=null	perm=root:supergroup:rw-r-----	proto=rpc
2020-04-02 05:07:59,774 [IPC Server handler 3 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testRestrictAtSubDir/childDir/childFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,780 [IPC Server handler 1 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=barUser (auth:SIMPLE)	ip=/127.0.0.1	cmd=checkAccess	src=/testRestrictAtSubDir/childDir/childFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,781 [IPC Server handler 1 on 35706] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 35706, call Call#71 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.checkAccess from 127.0.0.1:57756: org.apache.hadoop.security.AccessControlException: Permission denied: user=barUser, access=READ, inode="/testRestrictAtSubDir/childDir/childFile":root:supergroup:-rw-r-----
2020-04-02 05:07:59,840 [IPC Server handler 6 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testRestrictAtSubDir	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.TestExtendedAcls#testRestrictAtSubDir
[msx] writeFile testName = org.apache.hadoop.hdfs.TestExtendedAcls#testRestrictAtSubDir
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestExtendedAcls#testDefaultAclNewChildDirFile
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:59,845 [IPC Server handler 9 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testDefaultAclNewChildDirFile	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,849 [IPC Server handler 2 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setAcl	src=/testDefaultAclNewChildDirFile	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:59,852 [IPC Server handler 7 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/testDefaultAclNewChildDirFile/childDir	dst=null	perm=root:supergroup:rwxrwxr-x	proto=rpc
2020-04-02 05:07:59,854 [IPC Server handler 0 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testDefaultAclNewChildDirFile/childDir	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,857 [IPC Server handler 3 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testDefaultAclNewChildDirFile/childFile	dst=null	perm=root:supergroup:rw-rw-r--	proto=rpc
2020-04-02 05:07:59,861 [IPC Server handler 1 on 35706] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testDefaultAclNewChildDirFile/childFile is closed by DFSClient_NONMAPREDUCE_-1620420284_1
2020-04-02 05:07:59,863 [IPC Server handler 5 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getAclStatus	src=/testDefaultAclNewChildDirFile/childFile	dst=null	perm=null	proto=rpc
2020-04-02 05:07:59,865 [IPC Server handler 8 on 35706] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/testDefaultAclNewChildDirFile	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.TestExtendedAcls#testDefaultAclNewChildDirFile
[msx] writeFile testName = org.apache.hadoop.hdfs.TestExtendedAcls#testDefaultAclNewChildDirFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:59,866 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:59,866 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:07:59,867 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36744 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:59,867 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:59,867 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5fd62371] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:59,874 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-2b7ac133-f349-42e8-89ff-eee1289458dc) exiting.
2020-04-02 05:07:59,876 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-66bce74f-f8b3-42d8-8cfa-7992b76851a2) exiting.
2020-04-02 05:07:59,969 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@31024624{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:59,979 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@25bcd0c7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:59,980 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1568159{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:59,983 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b5966e1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:08:00,028 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36744
2020-04-02 05:08:00,029 [IPC Server listener on 36744] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36744
2020-04-02 05:08:00,048 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:08:00,050 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:08:00,050 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid a062927e-3d3f-47d5-a9de-d0d3090eccdd) service to localhost/127.0.0.1:35706
2020-04-02 05:08:00,050 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid a062927e-3d3f-47d5-a9de-d0d3090eccdd)
2020-04-02 05:08:00,051 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:08:00,086 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-925864317-172.17.0.17-1585804074461] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:08:00,098 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-925864317-172.17.0.17-1585804074461] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:08:00,116 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:08:00,116 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:08:00,117 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:08:00,117 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:08:00,130 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:08:00,130 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:08:00,130 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46622 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:00,130 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:08:00,132 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@35beb15e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:08:00,133 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-3ad28697-c0ae-465b-a0f1-cf4c42f3e6f3) exiting.
2020-04-02 05:08:00,134 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-b461453e-09ce-41de-b59a-eca98a2e5e7d) exiting.
2020-04-02 05:08:00,244 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@89ff02e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:08:00,245 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6865c751{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:08:00,245 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d10e0b1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:08:00,245 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53ab0286{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:08:00,248 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46622
2020-04-02 05:08:00,269 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:08:00,270 [IPC Server listener on 46622] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46622
2020-04-02 05:08:00,270 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:08:00,272 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid c344204c-7830-470e-b9c8-4dac191a1a7b) service to localhost/127.0.0.1:35706
2020-04-02 05:08:00,272 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid c344204c-7830-470e-b9c8-4dac191a1a7b)
2020-04-02 05:08:00,272 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:08:00,281 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-925864317-172.17.0.17-1585804074461] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:08:00,292 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-925864317-172.17.0.17-1585804074461] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:08:00,301 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:08:00,301 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:08:00,302 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:08:00,302 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:08:00,305 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:08:00,305 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:08:00,305 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37730 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:00,306 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:08:00,306 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@b6b1987] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:08:00,307 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2edd0218-5d89-4b32-99d9-6df032c5bd80) exiting.
2020-04-02 05:08:00,308 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5cc13679-5d77-4297-8c1d-160d9d87bbb8) exiting.
2020-04-02 05:08:00,562 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4b20ca2b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:08:00,627 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1cbf6e72{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:08:00,633 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e81e5ac{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:08:00,639 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7516e4e5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:08:00,641 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37730
2020-04-02 05:08:00,649 [IPC Server listener on 37730] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37730
2020-04-02 05:08:00,650 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:08:00,650 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:08:00,650 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid a2fcf997-c0c0-4c24-b674-969a14499c96) service to localhost/127.0.0.1:35706
2020-04-02 05:08:00,653 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-925864317-172.17.0.17-1585804074461 (Datanode Uuid a2fcf997-c0c0-4c24-b674-969a14499c96)
2020-04-02 05:08:00,653 [BP-925864317-172.17.0.17-1585804074461 heartbeating to localhost/127.0.0.1:35706] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-925864317-172.17.0.17-1585804074461
2020-04-02 05:08:00,665 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-925864317-172.17.0.17-1585804074461] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:08:00,673 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-925864317-172.17.0.17-1585804074461] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:08:00,685 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:08:00,685 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:08:00,692 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:08:00,692 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:08:00,698 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:08:00,698 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:08:00,698 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 35706 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:00,698 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:08:00,699 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 44
2020-04-02 05:08:00,699 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@c055c54] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:08:00,701 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3d9f6567] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:08:00,701 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 45 Total time for transactions(ms): 29 Number of transactions batched in Syncs: 0 Number of syncs: 46 SyncTimes(ms): 2 0 
2020-04-02 05:08:00,703 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000045
2020-04-02 05:08:00,704 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000045
2020-04-02 05:08:00,704 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:08:00,705 [CacheReplicationMonitor(1168542147)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:08:00,750 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35706
2020-04-02 05:08:00,752 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:08:00,753 [IPC Server listener on 35706] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35706
2020-04-02 05:08:00,756 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:08:00,766 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:08:00,807 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:08:00,808 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:08:00,809 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4e07b95f{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:08:00,842 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@26df6e3a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:08:00,843 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@565f390{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:08:00,844 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e16c0aa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:08:00,852 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:08:00,868 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:08:00,869 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

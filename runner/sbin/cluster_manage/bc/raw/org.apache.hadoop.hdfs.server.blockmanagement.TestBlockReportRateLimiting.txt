[msx] before_class
[msx] test Started org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting#testLeaseExpiration
[msx] unitTestCounterInClass = 0
2020-04-02 05:05:44,365 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=2
Formatting using clusterid: testClusterID
2020-04-02 05:05:45,131 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:45,148 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:45,150 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:45,151 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:45,159 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:45,159 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:45,159 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:45,160 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:45,200 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:45,205 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:05:45,205 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:45,206 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:45,211 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:45,212 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:45
2020-04-02 05:05:45,215 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:45,217 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:45,219 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:45,220 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:45,243 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:45,250 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:45,251 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:45,252 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:45,252 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:45,253 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 2
2020-04-02 05:05:45,253 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:45,253 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:45,254 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:45,254 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:45,254 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:45,255 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:45,287 [Thread-1] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:05:45,311 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:45,312 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:45,313 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:45,313 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:45,322 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:45,323 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:45,323 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:45,324 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:45,331 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:45,333 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:45,338 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:45,339 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:45,339 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:45,339 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:45,352 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:45,353 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:45,354 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:45,360 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:45,364 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:45,370 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:45,371 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:45,372 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:45,373 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:45,413 [Thread-1] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:45,442 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:45,448 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:45,464 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:45,466 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:45,627 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:45,627 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:45,652 [Thread-1] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:45,659 [Thread-1] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:45,862 [Thread-1] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:05:46,379 [Thread-1] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:46,538 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:46,538 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:46,545 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:46,571 [Thread-1] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:46,626 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7dd1a5b2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:46,654 [Thread-1] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:05:46,661 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:46,681 [Thread-1] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4046ms
2020-04-02 05:05:46,831 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:46,835 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:46,836 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:46,843 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:46,846 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:46,847 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:46,847 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:46,883 [Thread-1] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:46,883 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:46,893 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46240
2020-04-02 05:05:46,896 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:46,962 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1ab4154d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:46,966 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77e9ab58{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:47,013 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@c8ba2a2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:47,022 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@157b5a8b{HTTP/1.1,[http/1.1]}{localhost:46240}
2020-04-02 05:05:47,023 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @4388ms
2020-04-02 05:05:47,069 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:47,070 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:47,070 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:47,070 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:47,071 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:47,071 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:47,072 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:47,072 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:47,073 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:47,073 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:47,074 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:47,074 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:47,075 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:47
2020-04-02 05:05:47,075 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:47,075 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:47,076 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:47,076 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:47,087 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:47,088 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:47,088 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:47,088 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:47,088 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:47,089 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 2
2020-04-02 05:05:47,089 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:47,089 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:47,089 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:47,090 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:47,090 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:47,090 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:47,090 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:47,091 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:47,091 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:47,091 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:47,095 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:47,096 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:47,096 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:47,096 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:47,096 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:47,097 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:47,097 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:47,097 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:47,097 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:47,098 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:47,099 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:47,099 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:47,099 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:47,100 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:47,100 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:47,100 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:47,100 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:47,101 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:47,101 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:47,107 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:47,109 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:47,111 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:47,112 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:47,112 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:47,112 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:47,157 [Thread-1] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:47,164 [Thread-1] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:47,165 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:47,170 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:47,171 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:47,197 [Thread-1] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:47,197 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 93 msecs
2020-04-02 05:05:47,410 [Thread-1] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:47,423 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:47,437 [Socket Reader #1 for port 39859] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39859
2020-04-02 05:05:47,771 [Thread-1] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:39859 to access this namenode/service.
2020-04-02 05:05:47,784 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:47,815 [Thread-1] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:47,822 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7b702251] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:05:47,844 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:47,846 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:47,846 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:47,846 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:47,859 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:47,860 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:47,860 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:47,860 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:47,861 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:47,861 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-04-02 05:05:47,886 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:47,887 [IPC Server listener on 39859] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39859: starting
2020-04-02 05:05:47,889 [Thread-1] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:39859
2020-04-02 05:05:47,895 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:47,896 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:47,910 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 14 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:47,938 [Thread-1] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 39859 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:47,987 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:47,998 [CacheReplicationMonitor(1979745896)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:48,075 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:48,103 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:48,127 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:48,129 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:48,141 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:48,145 [Thread-1] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:48,167 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:48,173 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:48,180 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:48,200 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46749
2020-04-02 05:05:48,203 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:48,203 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:48,235 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:48,238 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:48,239 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:48,239 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:48,241 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:48,242 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:48,242 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:48,242 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:48,259 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41235
2020-04-02 05:05:48,259 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:48,263 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@17adbde5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:48,264 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c487d4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:48,275 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1bc4e8dc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:48,276 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@769d20c4{HTTP/1.1,[http/1.1]}{localhost:41235}
2020-04-02 05:05:48,276 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @5642ms
2020-04-02 05:05:48,914 [Thread-1] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39922
2020-04-02 05:05:48,915 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6aedcb0c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:48,916 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:48,916 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:48,936 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:48,944 [Socket Reader #1 for port 37457] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37457
2020-04-02 05:05:48,967 [Thread-1] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37457
2020-04-02 05:05:48,981 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:48,984 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:49,418 [Thread-60] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39859 starting to offer service
2020-04-02 05:05:49,423 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:49,424 [IPC Server listener on 37457] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37457: starting
2020-04-02 05:05:49,464 [Thread-1] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37457 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:49,469 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:49,472 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:49,511 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:49,517 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:49,518 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:49,518 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:49,519 [Thread-1] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:49,526 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:49,526 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:49,527 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:49,528 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45893
2020-04-02 05:05:49,528 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:49,528 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:49,530 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:49,532 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:49,533 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:49,533 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:49,535 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:49,535 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:49,536 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:49,536 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:49,536 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33481
2020-04-02 05:05:49,537 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:49,538 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a5c489b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:49,546 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b080869{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:49,557 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@10d1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:49,557 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1937684d{HTTP/1.1,[http/1.1]}{localhost:33481}
2020-04-02 05:05:49,558 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @6923ms
2020-04-02 05:05:49,726 [Thread-1] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45629
2020-04-02 05:05:49,727 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@614b7dc8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:49,727 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:49,727 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:49,728 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:49,738 [Socket Reader #1 for port 35559] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35559
2020-04-02 05:05:49,778 [Thread-1] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35559
2020-04-02 05:05:49,796 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:49,796 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:49,805 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39859 starting to offer service
2020-04-02 05:05:49,830 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:49,830 [IPC Server listener on 35559] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35559: starting
2020-04-02 05:05:49,831 [Thread-1] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35559 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:50,289 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39859
2020-04-02 05:05:50,290 [Thread-60] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39859
2020-04-02 05:05:50,292 [Thread-60] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:50,293 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:50,303 [Thread-60] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:50,304 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 395723325. Formatting...
2020-04-02 05:05:50,305 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-16255d3c-a7f5-4c86-8670-7258c0378330 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:50,306 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:50,306 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 395723325. Formatting...
2020-04-02 05:05:50,306 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-458e3dca-f159-49b8-8632-9370a4d800d5 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:50,318 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:50,319 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 395723325. Formatting...
2020-04-02 05:05:50,319 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bec000c9-fbd5-4d20-84a6-7884ae2bd2ba for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:50,319 [Thread-60] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:50,320 [Thread-60] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 395723325. Formatting...
2020-04-02 05:05:50,320 [Thread-60] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-65f11a35-f2c7-4b25-8aaa-508922cf9671 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:50,357 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,358 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,382 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,382 [Thread-60] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,386 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-633402387-172.17.0.12-1585803945398 is not formatted. Formatting ...
2020-04-02 05:05:50,387 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-633402387-172.17.0.12-1585803945398 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-633402387-172.17.0.12-1585803945398/current
2020-04-02 05:05:50,389 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-633402387-172.17.0.12-1585803945398 is not formatted. Formatting ...
2020-04-02 05:05:50,393 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-633402387-172.17.0.12-1585803945398 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-633402387-172.17.0.12-1585803945398/current
2020-04-02 05:05:50,418 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,419 [Thread-60] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,419 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-633402387-172.17.0.12-1585803945398 is not formatted. Formatting ...
2020-04-02 05:05:50,420 [Thread-60] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-633402387-172.17.0.12-1585803945398 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-633402387-172.17.0.12-1585803945398/current
2020-04-02 05:05:50,429 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,432 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,432 [Thread-60] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=395723325;bpid=BP-633402387-172.17.0.12-1585803945398;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=395723325;c=1585803945398;bpid=BP-633402387-172.17.0.12-1585803945398;dnuuid=null
2020-04-02 05:05:50,433 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-633402387-172.17.0.12-1585803945398 is not formatted. Formatting ...
2020-04-02 05:05:50,434 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-633402387-172.17.0.12-1585803945398 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-633402387-172.17.0.12-1585803945398/current
2020-04-02 05:05:50,436 [Thread-60] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d
2020-04-02 05:05:50,436 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=395723325;bpid=BP-633402387-172.17.0.12-1585803945398;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=395723325;c=1585803945398;bpid=BP-633402387-172.17.0.12-1585803945398;dnuuid=null
2020-04-02 05:05:50,446 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 109b5c00-7894-4454-a05f-ffe157537063
2020-04-02 05:05:50,666 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-458e3dca-f159-49b8-8632-9370a4d800d5
2020-04-02 05:05:50,667 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:50,690 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-bec000c9-fbd5-4d20-84a6-7884ae2bd2ba
2020-04-02 05:05:50,691 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:50,687 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-16255d3c-a7f5-4c86-8670-7258c0378330
2020-04-02 05:05:50,694 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:50,696 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-65f11a35-f2c7-4b25-8aaa-508922cf9671
2020-04-02 05:05:50,696 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:50,709 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:50,718 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:50,722 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:50,737 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:50,757 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:50,758 [Thread-60] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:50,758 [Thread-60] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:50,762 [Thread-60] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,763 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:50,767 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:50,767 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:50,785 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:50,786 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:50,787 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,787 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:50,787 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:50,843 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-633402387-172.17.0.12-1585803945398 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 55ms
2020-04-02 05:05:50,857 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-633402387-172.17.0.12-1585803945398 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 94ms
2020-04-02 05:05:50,894 [IPC Server handler 0 on 39859] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:50,897 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-633402387-172.17.0.12-1585803945398 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 115ms
2020-04-02 05:05:50,897 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-633402387-172.17.0.12-1585803945398: 136ms
2020-04-02 05:05:50,899 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-633402387-172.17.0.12-1585803945398 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 111ms
2020-04-02 05:05:50,901 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-633402387-172.17.0.12-1585803945398: 114ms
2020-04-02 05:05:50,902 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:50,902 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:50,903 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:50,903 [Thread-113] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-633402387-172.17.0.12-1585803945398/current/replicas doesn't exist 
2020-04-02 05:05:50,904 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:50,904 [Thread-115] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:50,905 [Thread-114] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:50,905 [Thread-114] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-633402387-172.17.0.12-1585803945398/current/replicas doesn't exist 
2020-04-02 05:05:50,906 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 3ms
2020-04-02 05:05:50,907 [Thread-114] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:05:50,904 [Thread-112] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-633402387-172.17.0.12-1585803945398/current/replicas doesn't exist 
2020-04-02 05:05:50,905 [Thread-115] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-633402387-172.17.0.12-1585803945398/current/replicas doesn't exist 
2020-04-02 05:05:50,914 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 10ms
2020-04-02 05:05:50,919 [Thread-60] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-633402387-172.17.0.12-1585803945398: 18ms
2020-04-02 05:05:50,921 [Thread-115] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 17ms
2020-04-02 05:05:50,921 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:50,922 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-633402387-172.17.0.12-1585803945398: 21ms
2020-04-02 05:05:50,925 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:50,926 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-65f11a35-f2c7-4b25-8aaa-508922cf9671): finished scanning block pool BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,926 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:50,927 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bec000c9-fbd5-4d20-84a6-7884ae2bd2ba): finished scanning block pool BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,923 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-633402387-172.17.0.12-1585803945398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:50,930 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-458e3dca-f159-49b8-8632-9370a4d800d5): finished scanning block pool BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,934 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-16255d3c-a7f5-4c86-8670-7258c0378330): finished scanning block pool BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:50,939 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:29 AM with interval of 21600000ms
2020-04-02 05:05:50,950 [Thread-60] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:53 AM with interval of 21600000ms
2020-04-02 05:05:50,983 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-633402387-172.17.0.12-1585803945398 (Datanode Uuid 109b5c00-7894-4454-a05f-ffe157537063) service to localhost/127.0.0.1:39859 beginning handshake with NN
2020-04-02 05:05:50,994 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-633402387-172.17.0.12-1585803945398 (Datanode Uuid 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d) service to localhost/127.0.0.1:39859 beginning handshake with NN
2020-04-02 05:05:51,012 [IPC Server handler 7 on 39859] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45893, datanodeUuid=109b5c00-7894-4454-a05f-ffe157537063, infoPort=45629, infoSecurePort=0, ipcPort=35559, storageInfo=lv=-57;cid=testClusterID;nsid=395723325;c=1585803945398) storage 109b5c00-7894-4454-a05f-ffe157537063
2020-04-02 05:05:51,013 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-16255d3c-a7f5-4c86-8670-7258c0378330): no suitable block pools found to scan.  Waiting 1814399908 ms.
2020-04-02 05:05:51,014 [IPC Server handler 7 on 39859] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45893
2020-04-02 05:05:51,018 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-458e3dca-f159-49b8-8632-9370a4d800d5): no suitable block pools found to scan.  Waiting 1814399904 ms.
2020-04-02 05:05:51,016 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-65f11a35-f2c7-4b25-8aaa-508922cf9671): no suitable block pools found to scan.  Waiting 1814399905 ms.
2020-04-02 05:05:51,014 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bec000c9-fbd5-4d20-84a6-7884ae2bd2ba): no suitable block pools found to scan.  Waiting 1814399908 ms.
2020-04-02 05:05:51,019 [IPC Server handler 7 on 39859] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 109b5c00-7894-4454-a05f-ffe157537063 (127.0.0.1:45893).
2020-04-02 05:05:51,022 [IPC Server handler 0 on 39859] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:51,022 [IPC Server handler 2 on 39859] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46749, datanodeUuid=5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d, infoPort=39922, infoSecurePort=0, ipcPort=37457, storageInfo=lv=-57;cid=testClusterID;nsid=395723325;c=1585803945398) storage 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d
2020-04-02 05:05:51,023 [IPC Server handler 2 on 39859] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46749
2020-04-02 05:05:51,024 [IPC Server handler 2 on 39859] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d (127.0.0.1:46749).
2020-04-02 05:05:51,026 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-633402387-172.17.0.12-1585803945398 (Datanode Uuid 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d) service to localhost/127.0.0.1:39859 successfully registered with NN
2020-04-02 05:05:51,026 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39859 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:51,029 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:51,030 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:51,034 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-633402387-172.17.0.12-1585803945398 (Datanode Uuid 109b5c00-7894-4454-a05f-ffe157537063) service to localhost/127.0.0.1:39859 successfully registered with NN
2020-04-02 05:05:51,034 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39859 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:51,045 [IPC Server handler 4 on 39859] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-458e3dca-f159-49b8-8632-9370a4d800d5 for DN 127.0.0.1:45893
2020-04-02 05:05:51,046 [IPC Server handler 4 on 39859] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bec000c9-fbd5-4d20-84a6-7884ae2bd2ba for DN 127.0.0.1:45893
2020-04-02 05:05:51,047 [IPC Server handler 4 on 39859] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:pruneExpiredPending(294)) - No entries remaining in the pending list.
2020-04-02 05:05:51,047 [IPC Server handler 4 on 39859] DEBUG blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(266)) - Created a new BR lease 0x13760ccc7d5d0eb6 for DN 109b5c00-7894-4454-a05f-ffe157537063.  numPending = 1
2020-04-02 05:05:51,059 [IPC Server handler 9 on 39859] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-16255d3c-a7f5-4c86-8670-7258c0378330 for DN 127.0.0.1:46749
2020-04-02 05:05:51,062 [IPC Server handler 9 on 39859] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-65f11a35-f2c7-4b25-8aaa-508922cf9671 for DN 127.0.0.1:46749
2020-04-02 05:05:51,062 [IPC Server handler 9 on 39859] DEBUG blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(255)) - Can't create a new BR lease for DN 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d, because numPending equals maxPending at 1.  Current leases: 109b5c00-7894-4454-a05f-ffe157537063
2020-04-02 05:05:51,102 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x13760ccc7d5d0eb6 is valid for DN 109b5c00-7894-4454-a05f-ffe157537063.
2020-04-02 05:05:51,102 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xdd148f850bebaf13: Processing first storage report for DS-458e3dca-f159-49b8-8632-9370a4d800d5 from datanode 109b5c00-7894-4454-a05f-ffe157537063
2020-04-02 05:05:51,104 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xdd148f850bebaf13: from storage DS-458e3dca-f159-49b8-8632-9370a4d800d5 node DatanodeRegistration(127.0.0.1:45893, datanodeUuid=109b5c00-7894-4454-a05f-ffe157537063, infoPort=45629, infoSecurePort=0, ipcPort=35559, storageInfo=lv=-57;cid=testClusterID;nsid=395723325;c=1585803945398), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:05:51,104 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x13760ccc7d5d0eb6 is valid for DN 109b5c00-7894-4454-a05f-ffe157537063.
2020-04-02 05:05:51,104 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xdd148f850bebaf13: Processing first storage report for DS-bec000c9-fbd5-4d20-84a6-7884ae2bd2ba from datanode 109b5c00-7894-4454-a05f-ffe157537063
2020-04-02 05:05:51,105 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xdd148f850bebaf13: from storage DS-bec000c9-fbd5-4d20-84a6-7884ae2bd2ba node DatanodeRegistration(127.0.0.1:45893, datanodeUuid=109b5c00-7894-4454-a05f-ffe157537063, infoPort=45629, infoSecurePort=0, ipcPort=35559, storageInfo=lv=-57;cid=testClusterID;nsid=395723325;c=1585803945398), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:51,105 [IPC Server handler 8 on 39859] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:removeLease(349)) - Removed BR lease 0x13760ccc7d5d0eb6 for DN 109b5c00-7894-4454-a05f-ffe157537063.  numPending = 0
2020-04-02 05:05:51,105 [IPC Server handler 8 on 39859] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xdd148f850bebaf13
2020-04-02 05:05:51,106 [IPC Server handler 8 on 39859] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 8 on 39859, call Call#8 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.blockReport from 127.0.0.1:45016
java.io.IOException: Injecting failure into block report RPC for DatanodeRegistration(127.0.0.1:45893, datanodeUuid=109b5c00-7894-4454-a05f-ffe157537063, infoPort=45629, infoSecurePort=0, ipcPort=35559, storageInfo=lv=-57;cid=testClusterID;nsid=395723325;c=1585803945398)
	at org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting$3.incomingBlockReportRpc(TestBlockReportRateLimiting.java:187)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1541)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:181)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:05:51,116 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Unsuccessfully sent block report 0xdd148f850bebaf13,  containing 2 storage report(s), of which we sent 0. The reports had 0 total blocks and used 0 RPC(s). This took 4 msec to generate and 37 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:05:51,117 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] WARN  datanode.DataNode (BPServiceActor.java:offerService(725)) - RemoteException in offerService
org.apache.hadoop.ipc.RemoteException(java.io.IOException): Injecting failure into block report RPC for DatanodeRegistration(127.0.0.1:45893, datanodeUuid=109b5c00-7894-4454-a05f-ffe157537063, infoPort=45629, infoSecurePort=0, ipcPort=35559, storageInfo=lv=-57;cid=testClusterID;nsid=395723325;c=1585803945398)
	at org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting$3.incomingBlockReportRpc(TestBlockReportRateLimiting.java:187)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.blockReport(NameNodeRpcServer.java:1541)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.blockReport(DatanodeProtocolServerSideTranslatorPB.java:181)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31662)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy23.blockReport(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.blockReport(DatanodeProtocolClientSideTranslatorPB.java:216)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.blockReport(BPServiceActor.java:388)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.offerService(BPServiceActor.java:698)
	at org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:842)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:51,133 [IPC Server handler 6 on 39859] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:51,136 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:51,147 [IPC Server handler 1 on 39859] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:51,148 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:51,148 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2280)) - MiniDFSCluster Stopping DataNode 127.0.0.1:45893 from a total of 2 datanodes.
2020-04-02 05:05:51,148 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35559 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:51,149 [Thread-1] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:51,150 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2378afd5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:51,150 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-bec000c9-fbd5-4d20-84a6-7884ae2bd2ba) exiting.
2020-04-02 05:05:51,150 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-458e3dca-f159-49b8-8632-9370a4d800d5) exiting.
2020-04-02 05:05:51,232 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@10d1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:51,240 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1937684d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:51,241 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b080869{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:51,241 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a5c489b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:51,254 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35559
2020-04-02 05:05:51,350 [IPC Server listener on 35559] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35559
2020-04-02 05:05:51,351 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-633402387-172.17.0.12-1585803945398 (Datanode Uuid 109b5c00-7894-4454-a05f-ffe157537063) service to localhost/127.0.0.1:39859
2020-04-02 05:05:51,351 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-633402387-172.17.0.12-1585803945398 (Datanode Uuid 109b5c00-7894-4454-a05f-ffe157537063)
2020-04-02 05:05:51,351 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:51,354 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:51,390 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-633402387-172.17.0.12-1585803945398] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:51,401 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:51,402 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:51,405 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:51,406 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:51,409 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-633402387-172.17.0.12-1585803945398] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:51,436 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:54,030 [IPC Server handler 0 on 39859] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:pruneExpiredPending(294)) - No entries remaining in the pending list.
2020-04-02 05:05:54,031 [IPC Server handler 0 on 39859] DEBUG blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(266)) - Created a new BR lease 0x13760ccc7d5d0eb7 for DN 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d.  numPending = 1
2020-04-02 05:05:54,034 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x13760ccc7d5d0eb7 is valid for DN 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d.
2020-04-02 05:05:54,034 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xee7e9dd3bb968693: Processing first storage report for DS-16255d3c-a7f5-4c86-8670-7258c0378330 from datanode 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d
2020-04-02 05:05:54,035 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xee7e9dd3bb968693: from storage DS-16255d3c-a7f5-4c86-8670-7258c0378330 node DatanodeRegistration(127.0.0.1:46749, datanodeUuid=5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d, infoPort=39922, infoSecurePort=0, ipcPort=37457, storageInfo=lv=-57;cid=testClusterID;nsid=395723325;c=1585803945398), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,035 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x13760ccc7d5d0eb7 is valid for DN 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d.
2020-04-02 05:05:54,035 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xee7e9dd3bb968693: Processing first storage report for DS-65f11a35-f2c7-4b25-8aaa-508922cf9671 from datanode 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d
2020-04-02 05:05:54,035 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xee7e9dd3bb968693: from storage DS-65f11a35-f2c7-4b25-8aaa-508922cf9671 node DatanodeRegistration(127.0.0.1:46749, datanodeUuid=5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d, infoPort=39922, infoSecurePort=0, ipcPort=37457, storageInfo=lv=-57;cid=testClusterID;nsid=395723325;c=1585803945398), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,035 [IPC Server handler 9 on 39859] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:removeLease(349)) - Removed BR lease 0x13760ccc7d5d0eb7 for DN 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d.  numPending = 0
2020-04-02 05:05:54,036 [IPC Server handler 9 on 39859] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xee7e9dd3bb968693
2020-04-02 05:05:54,036 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:54,036 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:54,036 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37457 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:54,036 [Thread-1] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:54,037 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@733de88a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:54,057 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-16255d3c-a7f5-4c86-8670-7258c0378330) exiting.
2020-04-02 05:05:54,057 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-65f11a35-f2c7-4b25-8aaa-508922cf9671) exiting.
2020-04-02 05:05:54,102 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xee7e9dd3bb968693,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 44 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,102 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:54,164 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1bc4e8dc{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:54,167 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@769d20c4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:54,168 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c487d4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:54,169 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@17adbde5{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:54,174 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37457
2020-04-02 05:05:54,175 [IPC Server listener on 37457] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37457
2020-04-02 05:05:54,176 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:54,176 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:54,176 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-633402387-172.17.0.12-1585803945398 (Datanode Uuid 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d) service to localhost/127.0.0.1:39859
2020-04-02 05:05:54,277 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-633402387-172.17.0.12-1585803945398 (Datanode Uuid 5a20a8e0-6c3e-4b8b-bfcf-6ed43dc9cf4d)
2020-04-02 05:05:54,277 [BP-633402387-172.17.0.12-1585803945398 heartbeating to localhost/127.0.0.1:39859] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-633402387-172.17.0.12-1585803945398
2020-04-02 05:05:54,292 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-633402387-172.17.0.12-1585803945398] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:54,307 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-633402387-172.17.0.12-1585803945398] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:54,312 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:54,313 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:54,313 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:54,322 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:54,324 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:54,325 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:54,325 [Thread-1] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 39859 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:54,325 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:54,333 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 1
2020-04-02 05:05:54,337 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6f0c8df2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:54,340 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7838ae57] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:54,348 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 1 
2020-04-02 05:05:54,349 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:05:54,350 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:05:54,351 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:54,351 [CacheReplicationMonitor(1979745896)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:54,355 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39859
2020-04-02 05:05:54,358 [IPC Server listener on 39859] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39859
2020-04-02 05:05:54,358 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:54,362 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:54,362 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:54,370 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7b702251] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:54,425 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:54,426 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:54,429 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@c8ba2a2{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:54,466 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@157b5a8b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:54,466 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77e9ab58{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:54,466 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1ab4154d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:54,476 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:05:54,487 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:05:54,490 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting#testLeaseExpiration
[msx] writeFile testName = org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting#testLeaseExpiration
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting#testRateLimitingDuringDataNodeStartup
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:54,512 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=5
Formatting using clusterid: testClusterID
2020-04-02 05:05:54,517 [Thread-127] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:54,518 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:54,518 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:54,518 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:54,518 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:54,518 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:54,519 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:54,519 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:54,519 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:54,520 [Thread-127] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:54,520 [Thread-127] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:54,520 [Thread-127] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:54,521 [Thread-127] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:54
2020-04-02 05:05:54,521 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:54,521 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:54,521 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:54,522 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:54,551 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:54,552 [Thread-127] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:54,552 [Thread-127] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:54,552 [Thread-127] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:54,552 [Thread-127] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:54,552 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:54,552 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:54,553 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:54,553 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:54,553 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:54,553 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:54,553 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:54,553 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:54,553 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:54,554 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:54,554 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:54,560 [Thread-127] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:54,560 [Thread-127] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:54,560 [Thread-127] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:54,560 [Thread-127] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:54,560 [Thread-127] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:54,560 [Thread-127] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:54,561 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:54,561 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:54,561 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:54,561 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:54,563 [Thread-127] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:54,563 [Thread-127] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:54,563 [Thread-127] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:54,564 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:54,564 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:54,564 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:54,564 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:54,564 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:54,565 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:54,567 [Thread-127] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:54,590 [Thread-127] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:54,602 [Thread-127] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:54,639 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:54,640 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:54,644 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:54,648 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:54,657 [Thread-127] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:54,659 [Thread-127] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:54,664 [Thread-127] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:54,667 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:54,667 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:54,668 [Thread-127] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:54,669 [Thread-127] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:54,675 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e58cdb5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:54,675 [Thread-127] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:05:54,675 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:54,677 [Thread-127] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:54,701 [Thread-127] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:54,703 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:54,705 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:54,706 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:54,706 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:54,707 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:54,709 [Thread-127] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:54,709 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:54,709 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35904
2020-04-02 05:05:54,713 [Thread-127] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:54,723 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b6992d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:54,724 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f0c86d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:54,753 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5a18ae5b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:54,757 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@698d5f5{HTTP/1.1,[http/1.1]}{localhost:35904}
2020-04-02 05:05:54,758 [Thread-127] INFO  server.Server (Server.java:doStart(419)) - Started @12124ms
2020-04-02 05:05:54,789 [Thread-127] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:54,804 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:54,804 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:54,804 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:54,804 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:54,804 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:54,805 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:54,805 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:54,805 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:54,809 [Thread-127] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:54,809 [Thread-127] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:54,810 [Thread-127] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:54,810 [Thread-127] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:54
2020-04-02 05:05:54,810 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:54,810 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:54,811 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:54,811 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:54,823 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:54,824 [Thread-127] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:54,830 [Thread-127] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:54,830 [Thread-127] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:54,830 [Thread-127] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:54,830 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:54,831 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:54,831 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:54,831 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:54,831 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:54,831 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:54,831 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:54,832 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:54,832 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:54,832 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:54,832 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:54,970 [Thread-127] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:54,970 [Thread-127] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:54,970 [Thread-127] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:54,970 [Thread-127] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:54,970 [Thread-127] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:54,970 [Thread-127] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:54,970 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:54,971 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:54,971 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:54,971 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:54,973 [Thread-127] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:54,973 [Thread-127] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:54,973 [Thread-127] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:54,974 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:54,974 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:54,975 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:54,975 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:54,976 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:54,976 [Thread-127] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:55,017 [Thread-127] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:55,019 [Thread-127] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:55,022 [Thread-127] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:55,023 [Thread-127] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:55,023 [Thread-127] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:55,024 [Thread-127] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:55,026 [Thread-127] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:55,029 [Thread-127] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:55,029 [Thread-127] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:55,029 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:55,030 [Thread-127] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:55,049 [Thread-127] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:55,050 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 60 msecs
2020-04-02 05:05:55,051 [Thread-127] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:55,051 [Thread-127] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:55,052 [Socket Reader #1 for port 33359] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33359
2020-04-02 05:05:55,069 [Thread-127] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33359 to access this namenode/service.
2020-04-02 05:05:55,070 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:55,118 [Thread-127] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:55,119 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@58e9d68e] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:05:55,120 [Thread-127] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:55,121 [Thread-127] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:55,121 [Thread-127] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:55,121 [Thread-127] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:55,126 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:55,126 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:55,137 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:55,137 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:55,137 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:55,137 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2020-04-02 05:05:55,139 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:55,150 [IPC Server listener on 33359] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33359: starting
2020-04-02 05:05:55,158 [Thread-127] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33359
2020-04-02 05:05:55,159 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:55,159 [Thread-127] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:55,160 [Thread-127] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:55,162 [Thread-127] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33359 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:55,181 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:55,187 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:55,188 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:55,201 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:55,202 [Thread-127] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:55,202 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:55,202 [Thread-127] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:55,206 [Thread-127] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:55,206 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:55,207 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:55,207 [Thread-127] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:32794
2020-04-02 05:05:55,207 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:55,207 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:55,209 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:55,210 [Thread-127] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:55,208 [CacheReplicationMonitor(457836447)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:55,215 [Thread-127] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:55,216 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:55,244 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:55,245 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:55,245 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:55,245 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:55,252 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37548
2020-04-02 05:05:55,252 [Thread-127] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:55,266 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10091c3f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:55,267 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65958f14{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:55,275 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@39968cd5{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:55,276 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@17b1a5fc{HTTP/1.1,[http/1.1]}{localhost:37548}
2020-04-02 05:05:55,276 [Thread-127] INFO  server.Server (Server.java:doStart(419)) - Started @12642ms
2020-04-02 05:05:55,326 [Thread-127] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33696
2020-04-02 05:05:55,328 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@22368284] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:55,328 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:55,328 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:55,330 [Thread-127] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:55,338 [Socket Reader #1 for port 42308] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42308
2020-04-02 05:05:55,341 [Thread-127] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42308
2020-04-02 05:05:55,370 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:55,371 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:55,378 [Thread-182] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359 starting to offer service
2020-04-02 05:05:55,407 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:55,408 [IPC Server listener on 42308] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42308: starting
2020-04-02 05:05:55,409 [Thread-127] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42308 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:55,410 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:55,412 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:55,412 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:55,448 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:55,448 [Thread-127] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:55,448 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:55,448 [Thread-127] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:55,449 [Thread-127] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:55,449 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:55,449 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:55,458 [Thread-127] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36080
2020-04-02 05:05:55,458 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:55,458 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:55,460 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:55,461 [Thread-127] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:55,462 [Thread-127] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:55,462 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:55,463 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:55,464 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:55,464 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:55,464 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:55,464 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45075
2020-04-02 05:05:55,464 [Thread-127] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:55,468 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1542e245{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:55,468 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@221b62fb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:55,503 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3f1838cc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:55,504 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4dc912d8{HTTP/1.1,[http/1.1]}{localhost:45075}
2020-04-02 05:05:55,513 [Thread-127] INFO  server.Server (Server.java:doStart(419)) - Started @12878ms
2020-04-02 05:05:55,540 [Thread-182] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359
2020-04-02 05:05:55,545 [Thread-182] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:55,548 [Thread-182] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:55,549 [Thread-182] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:55,549 [Thread-182] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dbdffed6-29ec-4cde-99fc-158fac748b78 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:55,550 [Thread-127] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35493
2020-04-02 05:05:55,550 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:55,550 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:55,551 [Thread-127] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:55,550 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4a32631] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:55,554 [Socket Reader #1 for port 36476] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36476
2020-04-02 05:05:55,557 [Thread-127] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36476
2020-04-02 05:05:55,575 [Thread-182] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:55,576 [Thread-182] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:55,576 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:55,576 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:55,577 [Thread-206] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359 starting to offer service
2020-04-02 05:05:55,576 [Thread-182] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-725d713c-ef3d-4223-b81c-e0ef9f801570 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:55,627 [Thread-127] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36476 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:55,626 [IPC Server listener on 36476] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36476: starting
2020-04-02 05:05:55,632 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:55,626 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:55,633 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:55,634 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:55,642 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:55,642 [Thread-127] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:55,643 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:55,643 [Thread-127] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:55,643 [Thread-127] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:55,643 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:55,650 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:55,651 [Thread-127] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40413
2020-04-02 05:05:55,651 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:55,651 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:55,654 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:55,654 [Thread-182] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:55,654 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:55,654 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:55,658 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:55,660 [Thread-127] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:55,664 [Thread-127] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:55,664 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:55,666 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:55,667 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:55,667 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:55,667 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:55,668 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41029
2020-04-02 05:05:55,668 [Thread-127] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:55,683 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@150e022e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:55,684 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e4d2bda{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:55,690 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2ebb470b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:55,711 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@569bbc97{HTTP/1.1,[http/1.1]}{localhost:41029}
2020-04-02 05:05:55,712 [Thread-127] INFO  server.Server (Server.java:doStart(419)) - Started @13077ms
2020-04-02 05:05:55,722 [Thread-206] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359
2020-04-02 05:05:55,752 [Thread-206] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:55,753 [Thread-206] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:55,754 [Thread-206] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:55,754 [Thread-206] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2d00bb83-63b8-43fb-8355-d6d49a8a026b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:55,759 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:55,759 [Thread-182] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:55,759 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:55,759 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:55,879 [Thread-206] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:55,879 [Thread-182] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2046363315;bpid=BP-857860265-172.17.0.12-1585803954567;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2046363315;c=1585803954567;bpid=BP-857860265-172.17.0.12-1585803954567;dnuuid=null
2020-04-02 05:05:55,879 [Thread-206] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:55,879 [Thread-206] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-453630a3-be7c-4799-8644-6d13e0a5913e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:55,882 [Thread-182] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 4195daf9-1c45-4269-b408-70f3ccefaf96
2020-04-02 05:05:55,892 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-dbdffed6-29ec-4cde-99fc-158fac748b78
2020-04-02 05:05:55,892 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:55,893 [Thread-127] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34657
2020-04-02 05:05:55,894 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:55,894 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:55,894 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-725d713c-ef3d-4223-b81c-e0ef9f801570
2020-04-02 05:05:55,895 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:55,895 [Thread-127] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:55,895 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@783238ca] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:55,896 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:55,897 [Thread-182] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:55,898 [Socket Reader #1 for port 34235] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34235
2020-04-02 05:05:55,901 [Thread-127] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34235
2020-04-02 05:05:55,905 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:55,914 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:55,916 [Thread-231] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359 starting to offer service
2020-04-02 05:05:55,916 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:55,917 [IPC Server listener on 34235] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34235: starting
2020-04-02 05:05:55,918 [Thread-127] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34235 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:55,919 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:55,920 [Thread-206] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:55,920 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:05:55,921 [Thread-206] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:55,921 [Thread-206] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:55,921 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:55,921 [Thread-206] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:55,931 [Thread-182] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:55,931 [Thread-182] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:55,936 [Thread-182] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:55,938 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:55,939 [Thread-127] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:55,939 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:55,939 [Thread-127] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:55,940 [Thread-127] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:55,940 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:55,940 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:55,941 [Thread-127] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40894
2020-04-02 05:05:55,941 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:55,941 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:55,942 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:55,944 [Thread-127] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:55,944 [Thread-127] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:55,945 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:55,946 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:55,947 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:55,947 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:55,947 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:55,948 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33985
2020-04-02 05:05:55,948 [Thread-127] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:55,954 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@674fbfd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:55,955 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72094b34{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:56,006 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5003afe5{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:56,026 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,030 [Thread-248] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:56,031 [Thread-249] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:56,056 [Thread-206] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,057 [Thread-206] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,057 [Thread-206] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:56,057 [Thread-206] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:56,082 [Thread-206] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2046363315;bpid=BP-857860265-172.17.0.12-1585803954567;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2046363315;c=1585803954567;bpid=BP-857860265-172.17.0.12-1585803954567;dnuuid=null
2020-04-02 05:05:56,086 [Thread-206] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a3ea893c-8063-4f4e-b248-e0b1c6c957a4
2020-04-02 05:05:56,090 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1b416d2f{HTTP/1.1,[http/1.1]}{localhost:33985}
2020-04-02 05:05:56,090 [Thread-127] INFO  server.Server (Server.java:doStart(419)) - Started @13456ms
2020-04-02 05:05:56,095 [Thread-231] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359
2020-04-02 05:05:56,102 [Thread-231] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:56,113 [Thread-231] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:56,114 [Thread-231] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:56,114 [Thread-231] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9652fd31-f8cb-498b-bf6b-ac8636cae699 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:05:56,117 [Thread-127] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34309
2020-04-02 05:05:56,123 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:56,126 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:56,127 [Thread-127] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:56,133 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2d00bb83-63b8-43fb-8355-d6d49a8a026b
2020-04-02 05:05:56,135 [Thread-206] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:56,137 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@673d7fbc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:56,137 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-453630a3-be7c-4799-8644-6d13e0a5913e
2020-04-02 05:05:56,147 [Thread-206] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:56,148 [Thread-206] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:56,149 [Thread-206] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:56,146 [Socket Reader #1 for port 46298] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46298
2020-04-02 05:05:56,141 [Thread-231] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:56,153 [Thread-231] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:56,153 [Thread-231] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d57fc70d-76e3-4549-aca5-762e0aa27843 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:05:56,189 [Thread-127] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46298
2020-04-02 05:05:56,194 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:56,195 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:56,196 [Thread-260] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359 starting to offer service
2020-04-02 05:05:56,201 [Thread-249] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 147ms
2020-04-02 05:05:56,202 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:56,203 [IPC Server listener on 46298] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46298: starting
2020-04-02 05:05:56,207 [Thread-127] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46298 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:56,208 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:56,210 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:05:56,210 [Thread-127] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:56,217 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:56,217 [Thread-127] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:56,218 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:56,218 [Thread-127] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:56,219 [Thread-127] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:56,219 [Thread-127] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:56,219 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:56,220 [Thread-127] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40062
2020-04-02 05:05:56,220 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:56,220 [Thread-127] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:56,222 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:56,223 [Thread-127] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:56,224 [Thread-127] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:56,224 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:56,226 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:56,227 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:56,227 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:56,227 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:56,228 [Thread-127] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33476
2020-04-02 05:05:56,228 [Thread-127] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:56,230 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1304712a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:56,231 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2dfaad05{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:56,237 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@56c9c819{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:56,237 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2ebba377{HTTP/1.1,[http/1.1]}{localhost:33476}
2020-04-02 05:05:56,238 [Thread-127] INFO  server.Server (Server.java:doStart(419)) - Started @13603ms
2020-04-02 05:05:56,256 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,257 [Thread-231] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,257 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:56,257 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:56,274 [Thread-248] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 244ms
2020-04-02 05:05:56,279 [Thread-206] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:56,279 [Thread-206] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:56,279 [Thread-206] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:56,279 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-857860265-172.17.0.12-1585803954567: 253ms
2020-04-02 05:05:56,280 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:56,280 [Thread-277] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:56,291 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 11ms
2020-04-02 05:05:56,307 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:56,310 [Thread-278] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:56,311 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:05:56,332 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,333 [Thread-231] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,370 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:56,370 [Thread-231] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:56,373 [Thread-231] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2046363315;bpid=BP-857860265-172.17.0.12-1585803954567;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2046363315;c=1585803954567;bpid=BP-857860265-172.17.0.12-1585803954567;dnuuid=null
2020-04-02 05:05:56,368 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-857860265-172.17.0.12-1585803954567: 89ms
2020-04-02 05:05:56,374 [Thread-182] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:15 AM with interval of 21600000ms
2020-04-02 05:05:56,376 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:56,377 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-725d713c-ef3d-4223-b81c-e0ef9f801570): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,377 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:56,378 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-dbdffed6-29ec-4cde-99fc-158fac748b78): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,378 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-725d713c-ef3d-4223-b81c-e0ef9f801570): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:05:56,388 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-dbdffed6-29ec-4cde-99fc-158fac748b78): no suitable block pools found to scan.  Waiting 1814399986 ms.
2020-04-02 05:05:56,390 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 4195daf9-1c45-4269-b408-70f3ccefaf96) service to localhost/127.0.0.1:33359 beginning handshake with NN
2020-04-02 05:05:56,391 [Thread-206] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,391 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:56,392 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:56,396 [Thread-260] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359
2020-04-02 05:05:56,396 [IPC Server handler 1 on 33359] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:32794, datanodeUuid=4195daf9-1c45-4269-b408-70f3ccefaf96, infoPort=33696, infoSecurePort=0, ipcPort=42308, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567) storage 4195daf9-1c45-4269-b408-70f3ccefaf96
2020-04-02 05:05:56,397 [IPC Server handler 1 on 33359] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:32794
2020-04-02 05:05:56,397 [IPC Server handler 1 on 33359] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 4195daf9-1c45-4269-b408-70f3ccefaf96 (127.0.0.1:32794).
2020-04-02 05:05:56,398 [Thread-260] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:56,401 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 4195daf9-1c45-4269-b408-70f3ccefaf96) service to localhost/127.0.0.1:33359 successfully registered with NN
2020-04-02 05:05:56,401 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33359 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:56,415 [Thread-260] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:56,415 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:56,415 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5984d1dd-8002-40f3-9a79-7370a4337744 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:05:56,497 [Thread-260] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:56,497 [Thread-260] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:56,497 [Thread-260] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-dcc207a5-bc18-4acf-87f3-28b5be7fda4c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:05:56,506 [IPC Server handler 2 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dbdffed6-29ec-4cde-99fc-158fac748b78 for DN 127.0.0.1:32794
2020-04-02 05:05:56,506 [IPC Server handler 2 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-725d713c-ef3d-4223-b81c-e0ef9f801570 for DN 127.0.0.1:32794
2020-04-02 05:05:56,515 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 124ms
2020-04-02 05:05:56,516 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,516 [Thread-260] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,516 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:56,516 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:56,547 [IPC Server handler 2 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:pruneExpiredPending(294)) - No entries remaining in the pending list.
2020-04-02 05:05:56,548 [IPC Server handler 2 on 33359] DEBUG blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(266)) - Created a new BR lease 0x9a1e07f1fe9ab177 for DN 4195daf9-1c45-4269-b408-70f3ccefaf96.  numPending = 1
2020-04-02 05:05:56,548 [IPC Server handler 2 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:requestBlockReportLease(114)) - requestBlockReportLease(node=127.0.0.1:32794, leaseId=0x9a1e07f1fe9ab177).  expectedFbrDns = 127.0.0.1:32794
2020-04-02 05:05:56,549 [Thread-231] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 09222c78-a838-4777-b081-b26210c576c4
2020-04-02 05:05:56,570 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab177 is valid for DN 4195daf9-1c45-4269-b408-70f3ccefaf96.
2020-04-02 05:05:56,570 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x13a0ff317e527b80: Processing first storage report for DS-725d713c-ef3d-4223-b81c-e0ef9f801570 from datanode 4195daf9-1c45-4269-b408-70f3ccefaf96
2020-04-02 05:05:56,586 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x13a0ff317e527b80: from storage DS-725d713c-ef3d-4223-b81c-e0ef9f801570 node DatanodeRegistration(127.0.0.1:32794, datanodeUuid=4195daf9-1c45-4269-b408-70f3ccefaf96, infoPort=33696, infoSecurePort=0, ipcPort=42308, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:56,587 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab177 is valid for DN 4195daf9-1c45-4269-b408-70f3ccefaf96.
2020-04-02 05:05:56,587 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x13a0ff317e527b80: Processing first storage report for DS-dbdffed6-29ec-4cde-99fc-158fac748b78 from datanode 4195daf9-1c45-4269-b408-70f3ccefaf96
2020-04-02 05:05:56,587 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x13a0ff317e527b80: from storage DS-dbdffed6-29ec-4cde-99fc-158fac748b78 node DatanodeRegistration(127.0.0.1:32794, datanodeUuid=4195daf9-1c45-4269-b408-70f3ccefaf96, infoPort=33696, infoSecurePort=0, ipcPort=42308, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:56,610 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,613 [Thread-127] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40897
2020-04-02 05:05:56,614 [Thread-260] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,616 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:56,617 [Thread-127] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:56,624 [Thread-127] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:56,617 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:56,626 [Thread-260] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:56,622 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9652fd31-f8cb-498b-bf6b-ac8636cae699
2020-04-02 05:05:56,630 [Thread-231] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:05:56,618 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 225ms
2020-04-02 05:05:56,617 [IPC Server handler 9 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:removeLease(349)) - Removed BR lease 0x9a1e07f1fe9ab177 for DN 4195daf9-1c45-4269-b408-70f3ccefaf96.  numPending = 0
2020-04-02 05:05:56,631 [IPC Server handler 9 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:removeBlockReportLease(125)) - removeBlockReportLease(node=127.0.0.1:32794, leaseId=0x9a1e07f1fe9ab177)
2020-04-02 05:05:56,617 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@19325104] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:56,630 [Socket Reader #1 for port 43280] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43280
2020-04-02 05:05:56,632 [Thread-260] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2046363315;bpid=BP-857860265-172.17.0.12-1585803954567;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2046363315;c=1585803954567;bpid=BP-857860265-172.17.0.12-1585803954567;dnuuid=null
2020-04-02 05:05:56,633 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-857860265-172.17.0.12-1585803954567: 243ms
2020-04-02 05:05:56,639 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:56,639 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:56,639 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:56,639 [Thread-290] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:56,640 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:05:56,641 [IPC Server handler 9 on 33359] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x13a0ff317e527b80
2020-04-02 05:05:56,641 [IPC Server handler 9 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(85)) - Incoming full block report from DatanodeRegistration(127.0.0.1:32794, datanodeUuid=4195daf9-1c45-4269-b408-70f3ccefaf96, infoPort=33696, infoSecurePort=0, ipcPort=42308, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab177
2020-04-02 05:05:56,653 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 15ms
2020-04-02 05:05:56,654 [Thread-260] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID d3a307a4-967c-45e0-bf4f-1cc8a75fc30f
2020-04-02 05:05:56,655 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-857860265-172.17.0.12-1585803954567: 22ms
2020-04-02 05:05:56,656 [Thread-206] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:59 AM with interval of 21600000ms
2020-04-02 05:05:56,657 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5984d1dd-8002-40f3-9a79-7370a4337744
2020-04-02 05:05:56,657 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:05:56,657 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:56,658 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2d00bb83-63b8-43fb-8355-d6d49a8a026b): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,659 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2d00bb83-63b8-43fb-8355-d6d49a8a026b): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:05:56,660 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:56,661 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-453630a3-be7c-4799-8644-6d13e0a5913e): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,661 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-453630a3-be7c-4799-8644-6d13e0a5913e): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:05:56,673 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-dcc207a5-bc18-4acf-87f3-28b5be7fda4c
2020-04-02 05:05:56,674 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:05:56,674 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:56,676 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:05:56,686 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid a3ea893c-8063-4f4e-b248-e0b1c6c957a4) service to localhost/127.0.0.1:33359 beginning handshake with NN
2020-04-02 05:05:56,697 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d57fc70d-76e3-4549-aca5-762e0aa27843
2020-04-02 05:05:56,697 [Thread-231] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:05:56,698 [Thread-231] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:56,700 [Thread-231] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:56,698 [IPC Server handler 8 on 33359] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36080, datanodeUuid=a3ea893c-8063-4f4e-b248-e0b1c6c957a4, infoPort=35493, infoSecurePort=0, ipcPort=36476, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567) storage a3ea893c-8063-4f4e-b248-e0b1c6c957a4
2020-04-02 05:05:56,706 [IPC Server handler 8 on 33359] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36080
2020-04-02 05:05:56,706 [IPC Server handler 8 on 33359] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a3ea893c-8063-4f4e-b248-e0b1c6c957a4 (127.0.0.1:36080).
2020-04-02 05:05:56,707 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid a3ea893c-8063-4f4e-b248-e0b1c6c957a4) service to localhost/127.0.0.1:33359 successfully registered with NN
2020-04-02 05:05:56,708 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33359 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:56,699 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:05:56,708 [Thread-260] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:56,709 [Thread-260] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:56,699 [Thread-127] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43280
2020-04-02 05:05:56,713 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:56,714 [Thread-127] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:56,722 [Thread-231] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:56,723 [Thread-231] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:56,723 [Thread-231] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:56,726 [Thread-301] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359 starting to offer service
2020-04-02 05:05:56,734 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:56,735 [IPC Server listener on 43280] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43280: starting
2020-04-02 05:05:56,775 [Thread-127] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43280 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:56,780 [IPC Server handler 7 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2d00bb83-63b8-43fb-8355-d6d49a8a026b for DN 127.0.0.1:36080
2020-04-02 05:05:56,780 [Thread-231] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,780 [Thread-260] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,782 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:56,782 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:56,798 [IPC Server handler 7 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-453630a3-be7c-4799-8644-6d13e0a5913e for DN 127.0.0.1:36080
2020-04-02 05:05:56,798 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:05:56,799 [IPC Server handler 7 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:pruneExpiredPending(294)) - No entries remaining in the pending list.
2020-04-02 05:05:56,799 [IPC Server handler 7 on 33359] DEBUG blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(266)) - Created a new BR lease 0x9a1e07f1fe9ab178 for DN a3ea893c-8063-4f4e-b248-e0b1c6c957a4.  numPending = 1
2020-04-02 05:05:56,799 [IPC Server handler 7 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:requestBlockReportLease(114)) - requestBlockReportLease(node=127.0.0.1:36080, leaseId=0x9a1e07f1fe9ab178).  expectedFbrDns = 127.0.0.1:36080, 127.0.0.1:32794
2020-04-02 05:05:56,802 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:05:56,819 [Thread-301] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33359
2020-04-02 05:05:56,839 [Thread-301] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:56,846 [Thread-301] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:56,847 [Thread-301] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:56,847 [Thread-301] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5e06a1fd-9d92-4d95-8096-fc863ea5b681 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:05:56,853 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab178 is valid for DN a3ea893c-8063-4f4e-b248-e0b1c6c957a4.
2020-04-02 05:05:56,881 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc3b5aacc7cd26010: Processing first storage report for DS-2d00bb83-63b8-43fb-8355-d6d49a8a026b from datanode a3ea893c-8063-4f4e-b248-e0b1c6c957a4
2020-04-02 05:05:56,882 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc3b5aacc7cd26010: from storage DS-2d00bb83-63b8-43fb-8355-d6d49a8a026b node DatanodeRegistration(127.0.0.1:36080, datanodeUuid=a3ea893c-8063-4f4e-b248-e0b1c6c957a4, infoPort=35493, infoSecurePort=0, ipcPort=36476, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: true, processing time: 29 msecs, invalidatedBlocks: 0
2020-04-02 05:05:56,892 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab178 is valid for DN a3ea893c-8063-4f4e-b248-e0b1c6c957a4.
2020-04-02 05:05:56,892 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc3b5aacc7cd26010: Processing first storage report for DS-453630a3-be7c-4799-8644-6d13e0a5913e from datanode a3ea893c-8063-4f4e-b248-e0b1c6c957a4
2020-04-02 05:05:56,892 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc3b5aacc7cd26010: from storage DS-453630a3-be7c-4799-8644-6d13e0a5913e node DatanodeRegistration(127.0.0.1:36080, datanodeUuid=a3ea893c-8063-4f4e-b248-e0b1c6c957a4, infoPort=35493, infoSecurePort=0, ipcPort=36476, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:56,892 [IPC Server handler 5 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:removeLease(349)) - Removed BR lease 0x9a1e07f1fe9ab178 for DN a3ea893c-8063-4f4e-b248-e0b1c6c957a4.  numPending = 0
2020-04-02 05:05:56,893 [IPC Server handler 5 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:removeBlockReportLease(125)) - removeBlockReportLease(node=127.0.0.1:36080, leaseId=0x9a1e07f1fe9ab178)
2020-04-02 05:05:56,893 [IPC Server handler 5 on 33359] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xc3b5aacc7cd26010
2020-04-02 05:05:56,893 [IPC Server handler 5 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(85)) - Incoming full block report from DatanodeRegistration(127.0.0.1:36080, datanodeUuid=a3ea893c-8063-4f4e-b248-e0b1c6c957a4, infoPort=35493, infoSecurePort=0, ipcPort=36476, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab178
2020-04-02 05:05:56,894 [Thread-301] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 7416@374173d81202
2020-04-02 05:05:56,894 [Thread-301] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 2046363315. Formatting...
2020-04-02 05:05:56,895 [Thread-301] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-13037a33-a2cd-4c63-8c34-2eb0c8994257 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:05:56,929 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 130ms
2020-04-02 05:05:56,971 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 188ms
2020-04-02 05:05:56,971 [Thread-301] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,971 [Thread-301] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:56,972 [Thread-301] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:56,972 [Thread-301] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:56,986 [IPC Server handler 4 on 33359] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:56,988 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:56,988 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:56,999 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 196ms
2020-04-02 05:05:57,000 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-857860265-172.17.0.12-1585803954567: 219ms
2020-04-02 05:05:57,002 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:05:57,002 [Thread-321] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:57,002 [Thread-301] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,011 [Thread-301] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,012 [Thread-301] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-857860265-172.17.0.12-1585803954567 is not formatted. Formatting ...
2020-04-02 05:05:57,012 [Thread-301] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-857860265-172.17.0.12-1585803954567 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-857860265-172.17.0.12-1585803954567/current
2020-04-02 05:05:57,011 [Thread-312] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 229ms
2020-04-02 05:05:57,013 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-857860265-172.17.0.12-1585803954567: 233ms
2020-04-02 05:05:57,003 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:05:57,003 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-04-02 05:05:57,018 [Thread-322] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:57,018 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:57,018 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:57,018 [Thread-323] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:57,018 [Thread-324] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:57,019 [Thread-324] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:05:57,019 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 5ms
2020-04-02 05:05:57,025 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-857860265-172.17.0.12-1585803954567: 26ms
2020-04-02 05:05:57,026 [Thread-260] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:30 AM with interval of 21600000ms
2020-04-02 05:05:57,027 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:57,019 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:05:57,039 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-857860265-172.17.0.12-1585803954567: 26ms
2020-04-02 05:05:57,040 [Thread-231] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:32 AM with interval of 21600000ms
2020-04-02 05:05:57,040 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:57,040 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-9652fd31-f8cb-498b-bf6b-ac8636cae699): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,041 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-9652fd31-f8cb-498b-bf6b-ac8636cae699): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:05:57,041 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:57,034 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid d3a307a4-967c-45e0-bf4f-1cc8a75fc30f) service to localhost/127.0.0.1:33359 beginning handshake with NN
2020-04-02 05:05:57,038 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:05:57,055 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-5984d1dd-8002-40f3-9a79-7370a4337744): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,056 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-5984d1dd-8002-40f3-9a79-7370a4337744): no suitable block pools found to scan.  Waiting 1814399970 ms.
2020-04-02 05:05:57,051 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 09222c78-a838-4777-b081-b26210c576c4) service to localhost/127.0.0.1:33359 beginning handshake with NN
2020-04-02 05:05:57,042 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-d57fc70d-76e3-4549-aca5-762e0aa27843): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,061 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-d57fc70d-76e3-4549-aca5-762e0aa27843): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-04-02 05:05:57,063 [Thread-301] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=2046363315;bpid=BP-857860265-172.17.0.12-1585803954567;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=2046363315;c=1585803954567;bpid=BP-857860265-172.17.0.12-1585803954567;dnuuid=null
2020-04-02 05:05:57,078 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-dcc207a5-bc18-4acf-87f3-28b5be7fda4c): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,079 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-dcc207a5-bc18-4acf-87f3-28b5be7fda4c): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-04-02 05:05:57,082 [Thread-301] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 120ae74a-82b6-4bb9-b4f1-615fb4554737
2020-04-02 05:05:57,082 [IPC Server handler 3 on 33359] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40894, datanodeUuid=d3a307a4-967c-45e0-bf4f-1cc8a75fc30f, infoPort=34309, infoSecurePort=0, ipcPort=46298, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567) storage d3a307a4-967c-45e0-bf4f-1cc8a75fc30f
2020-04-02 05:05:57,082 [IPC Server handler 3 on 33359] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40894
2020-04-02 05:05:57,082 [IPC Server handler 3 on 33359] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d3a307a4-967c-45e0-bf4f-1cc8a75fc30f (127.0.0.1:40894).
2020-04-02 05:05:57,086 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid d3a307a4-967c-45e0-bf4f-1cc8a75fc30f) service to localhost/127.0.0.1:33359 successfully registered with NN
2020-04-02 05:05:57,086 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33359 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:57,108 [IPC Server handler 0 on 33359] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:57,121 [IPC Server handler 1 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5984d1dd-8002-40f3-9a79-7370a4337744 for DN 127.0.0.1:40894
2020-04-02 05:05:57,122 [IPC Server handler 1 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-dcc207a5-bc18-4acf-87f3-28b5be7fda4c for DN 127.0.0.1:40894
2020-04-02 05:05:57,122 [IPC Server handler 1 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:pruneExpiredPending(294)) - No entries remaining in the pending list.
2020-04-02 05:05:57,122 [IPC Server handler 1 on 33359] DEBUG blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(266)) - Created a new BR lease 0x9a1e07f1fe9ab179 for DN d3a307a4-967c-45e0-bf4f-1cc8a75fc30f.  numPending = 1
2020-04-02 05:05:57,122 [IPC Server handler 1 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:requestBlockReportLease(114)) - requestBlockReportLease(node=127.0.0.1:40894, leaseId=0x9a1e07f1fe9ab179).  expectedFbrDns = 127.0.0.1:36080, 127.0.0.1:40894, 127.0.0.1:32794
2020-04-02 05:05:57,133 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5e06a1fd-9d92-4d95-8096-fc863ea5b681
2020-04-02 05:05:57,134 [Thread-301] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:05:57,136 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-13037a33-a2cd-4c63-8c34-2eb0c8994257
2020-04-02 05:05:57,136 [Thread-301] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:05:57,137 [Thread-301] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:57,138 [Thread-301] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:05:57,150 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:57,150 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:57,152 [IPC Server handler 2 on 33359] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40413, datanodeUuid=09222c78-a838-4777-b081-b26210c576c4, infoPort=34657, infoSecurePort=0, ipcPort=34235, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567) storage 09222c78-a838-4777-b081-b26210c576c4
2020-04-02 05:05:57,153 [IPC Server handler 2 on 33359] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40413
2020-04-02 05:05:57,153 [IPC Server handler 2 on 33359] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 09222c78-a838-4777-b081-b26210c576c4 (127.0.0.1:40413).
2020-04-02 05:05:57,154 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 09222c78-a838-4777-b081-b26210c576c4) service to localhost/127.0.0.1:33359 successfully registered with NN
2020-04-02 05:05:57,154 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33359 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:57,158 [Thread-301] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:05:57,158 [Thread-301] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:57,158 [Thread-301] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:57,163 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab179 is valid for DN d3a307a4-967c-45e0-bf4f-1cc8a75fc30f.
2020-04-02 05:05:57,163 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb95b660f098e14b0: Processing first storage report for DS-5984d1dd-8002-40f3-9a79-7370a4337744 from datanode d3a307a4-967c-45e0-bf4f-1cc8a75fc30f
2020-04-02 05:05:57,167 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb95b660f098e14b0: from storage DS-5984d1dd-8002-40f3-9a79-7370a4337744 node DatanodeRegistration(127.0.0.1:40894, datanodeUuid=d3a307a4-967c-45e0-bf4f-1cc8a75fc30f, infoPort=34309, infoSecurePort=0, ipcPort=46298, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:57,168 [Thread-301] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,179 [IPC Server handler 7 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9652fd31-f8cb-498b-bf6b-ac8636cae699 for DN 127.0.0.1:40413
2020-04-02 05:05:57,180 [IPC Server handler 7 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d57fc70d-76e3-4549-aca5-762e0aa27843 for DN 127.0.0.1:40413
2020-04-02 05:05:57,180 [IPC Server handler 7 on 33359] DEBUG blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(255)) - Can't create a new BR lease for DN 09222c78-a838-4777-b081-b26210c576c4, because numPending equals maxPending at 1.  Current leases: d3a307a4-967c-45e0-bf4f-1cc8a75fc30f
2020-04-02 05:05:57,181 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab179 is valid for DN d3a307a4-967c-45e0-bf4f-1cc8a75fc30f.
2020-04-02 05:05:57,181 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb95b660f098e14b0: Processing first storage report for DS-dcc207a5-bc18-4acf-87f3-28b5be7fda4c from datanode d3a307a4-967c-45e0-bf4f-1cc8a75fc30f
2020-04-02 05:05:57,181 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb95b660f098e14b0: from storage DS-dcc207a5-bc18-4acf-87f3-28b5be7fda4c node DatanodeRegistration(127.0.0.1:40894, datanodeUuid=d3a307a4-967c-45e0-bf4f-1cc8a75fc30f, infoPort=34309, infoSecurePort=0, ipcPort=46298, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:57,181 [IPC Server handler 8 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:removeLease(349)) - Removed BR lease 0x9a1e07f1fe9ab179 for DN d3a307a4-967c-45e0-bf4f-1cc8a75fc30f.  numPending = 0
2020-04-02 05:05:57,181 [IPC Server handler 8 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:removeBlockReportLease(125)) - removeBlockReportLease(node=127.0.0.1:40894, leaseId=0x9a1e07f1fe9ab179)
2020-04-02 05:05:57,181 [IPC Server handler 8 on 33359] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb95b660f098e14b0
2020-04-02 05:05:57,181 [IPC Server handler 8 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(85)) - Incoming full block report from DatanodeRegistration(127.0.0.1:40894, datanodeUuid=d3a307a4-967c-45e0-bf4f-1cc8a75fc30f, infoPort=34309, infoSecurePort=0, ipcPort=46298, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab179
2020-04-02 05:05:57,198 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:05:57,206 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:05:57,259 [Thread-334] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 53ms
2020-04-02 05:05:57,286 [IPC Server handler 6 on 33359] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:57,288 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:57,288 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:57,297 [Thread-333] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-857860265-172.17.0.12-1585803954567 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 99ms
2020-04-02 05:05:57,299 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-857860265-172.17.0.12-1585803954567: 131ms
2020-04-02 05:05:57,306 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:05:57,307 [Thread-337] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:57,310 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 3ms
2020-04-02 05:05:57,312 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:05:57,312 [Thread-338] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-857860265-172.17.0.12-1585803954567/current/replicas doesn't exist 
2020-04-02 05:05:57,312 [Thread-338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 0ms
2020-04-02 05:05:57,312 [Thread-301] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-857860265-172.17.0.12-1585803954567: 14ms
2020-04-02 05:05:57,313 [Thread-301] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:26 AM with interval of 21600000ms
2020-04-02 05:05:57,314 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:57,314 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-13037a33-a2cd-4c63-8c34-2eb0c8994257): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,315 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-13037a33-a2cd-4c63-8c34-2eb0c8994257): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:05:57,315 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-857860265-172.17.0.12-1585803954567 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:05:57,315 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-5e06a1fd-9d92-4d95-8096-fc863ea5b681): finished scanning block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,315 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-5e06a1fd-9d92-4d95-8096-fc863ea5b681): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:05:57,338 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 120ae74a-82b6-4bb9-b4f1-615fb4554737) service to localhost/127.0.0.1:33359 beginning handshake with NN
2020-04-02 05:05:57,340 [IPC Server handler 4 on 33359] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40062, datanodeUuid=120ae74a-82b6-4bb9-b4f1-615fb4554737, infoPort=40897, infoSecurePort=0, ipcPort=43280, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567) storage 120ae74a-82b6-4bb9-b4f1-615fb4554737
2020-04-02 05:05:57,341 [IPC Server handler 4 on 33359] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40062
2020-04-02 05:05:57,341 [IPC Server handler 4 on 33359] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 120ae74a-82b6-4bb9-b4f1-615fb4554737 (127.0.0.1:40062).
2020-04-02 05:05:57,343 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 120ae74a-82b6-4bb9-b4f1-615fb4554737) service to localhost/127.0.0.1:33359 successfully registered with NN
2020-04-02 05:05:57,343 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33359 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:57,347 [IPC Server handler 3 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5e06a1fd-9d92-4d95-8096-fc863ea5b681 for DN 127.0.0.1:40062
2020-04-02 05:05:57,347 [IPC Server handler 3 on 33359] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-13037a33-a2cd-4c63-8c34-2eb0c8994257 for DN 127.0.0.1:40062
2020-04-02 05:05:57,347 [IPC Server handler 3 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:pruneExpiredPending(294)) - No entries remaining in the pending list.
2020-04-02 05:05:57,347 [IPC Server handler 3 on 33359] DEBUG blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(266)) - Created a new BR lease 0x9a1e07f1fe9ab17a for DN 120ae74a-82b6-4bb9-b4f1-615fb4554737.  numPending = 1
2020-04-02 05:05:57,347 [IPC Server handler 3 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:requestBlockReportLease(114)) - requestBlockReportLease(node=127.0.0.1:40062, leaseId=0x9a1e07f1fe9ab17a).  expectedFbrDns = 127.0.0.1:40062, 127.0.0.1:36080, 127.0.0.1:40894, 127.0.0.1:32794
2020-04-02 05:05:57,370 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab17a is valid for DN 120ae74a-82b6-4bb9-b4f1-615fb4554737.
2020-04-02 05:05:57,371 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xbf348b99d3901b82: Processing first storage report for DS-13037a33-a2cd-4c63-8c34-2eb0c8994257 from datanode 120ae74a-82b6-4bb9-b4f1-615fb4554737
2020-04-02 05:05:57,371 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xbf348b99d3901b82: from storage DS-13037a33-a2cd-4c63-8c34-2eb0c8994257 node DatanodeRegistration(127.0.0.1:40062, datanodeUuid=120ae74a-82b6-4bb9-b4f1-615fb4554737, infoPort=40897, infoSecurePort=0, ipcPort=43280, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:57,371 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab17a is valid for DN 120ae74a-82b6-4bb9-b4f1-615fb4554737.
2020-04-02 05:05:57,371 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xbf348b99d3901b82: Processing first storage report for DS-5e06a1fd-9d92-4d95-8096-fc863ea5b681 from datanode 120ae74a-82b6-4bb9-b4f1-615fb4554737
2020-04-02 05:05:57,371 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xbf348b99d3901b82: from storage DS-5e06a1fd-9d92-4d95-8096-fc863ea5b681 node DatanodeRegistration(127.0.0.1:40062, datanodeUuid=120ae74a-82b6-4bb9-b4f1-615fb4554737, infoPort=40897, infoSecurePort=0, ipcPort=43280, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:57,372 [IPC Server handler 1 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:removeLease(349)) - Removed BR lease 0x9a1e07f1fe9ab17a for DN 120ae74a-82b6-4bb9-b4f1-615fb4554737.  numPending = 0
2020-04-02 05:05:57,372 [IPC Server handler 1 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:removeBlockReportLease(125)) - removeBlockReportLease(node=127.0.0.1:40062, leaseId=0x9a1e07f1fe9ab17a)
2020-04-02 05:05:57,372 [IPC Server handler 1 on 33359] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xbf348b99d3901b82
2020-04-02 05:05:57,372 [IPC Server handler 1 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(85)) - Incoming full block report from DatanodeRegistration(127.0.0.1:40062, datanodeUuid=120ae74a-82b6-4bb9-b4f1-615fb4554737, infoPort=40897, infoSecurePort=0, ipcPort=43280, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab17a
2020-04-02 05:05:57,399 [IPC Server handler 0 on 33359] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:57,400 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:57,409 [IPC Server handler 2 on 33359] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:57,413 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:57,414 [Thread-127] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:testRateLimitingDuringDataNodeStartup(139)) - Waiting for 1 datanode(s) to report in.
2020-04-02 05:05:57,414 [IPC Server handler 9 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(99)) - Proceeding with full block report from DatanodeRegistration(127.0.0.1:32794, datanodeUuid=4195daf9-1c45-4269-b408-70f3ccefaf96, infoPort=33696, infoSecurePort=0, ipcPort=42308, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab177
2020-04-02 05:05:57,424 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x13a0ff317e527b80,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 860 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:57,424 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,454 [Thread-127] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:testRateLimitingDuringDataNodeStartup(139)) - Waiting for 2 datanode(s) to report in.
2020-04-02 05:05:57,454 [IPC Server handler 5 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(99)) - Proceeding with full block report from DatanodeRegistration(127.0.0.1:36080, datanodeUuid=a3ea893c-8063-4f4e-b248-e0b1c6c957a4, infoPort=35493, infoSecurePort=0, ipcPort=36476, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab178
2020-04-02 05:05:57,458 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc3b5aacc7cd26010,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 620 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:57,458 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,477 [Thread-127] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:testRateLimitingDuringDataNodeStartup(139)) - Waiting for 3 datanode(s) to report in.
2020-04-02 05:05:57,483 [IPC Server handler 8 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(99)) - Proceeding with full block report from DatanodeRegistration(127.0.0.1:40894, datanodeUuid=d3a307a4-967c-45e0-bf4f-1cc8a75fc30f, infoPort=34309, infoSecurePort=0, ipcPort=46298, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab179
2020-04-02 05:05:57,490 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb95b660f098e14b0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 339 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:57,490 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,501 [Thread-127] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:testRateLimitingDuringDataNodeStartup(139)) - Waiting for 4 datanode(s) to report in.
2020-04-02 05:05:57,503 [IPC Server handler 1 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(99)) - Proceeding with full block report from DatanodeRegistration(127.0.0.1:40062, datanodeUuid=120ae74a-82b6-4bb9-b4f1-615fb4554737, infoPort=40897, infoSecurePort=0, ipcPort=43280, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab17a
2020-04-02 05:05:57,504 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xbf348b99d3901b82,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 155 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:57,504 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:05:57,525 [Thread-127] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:testRateLimitingDuringDataNodeStartup(139)) - Waiting for 5 datanode(s) to report in.
2020-04-02 05:06:00,159 [IPC Server handler 4 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:pruneExpiredPending(294)) - No entries remaining in the pending list.
2020-04-02 05:06:00,159 [IPC Server handler 4 on 33359] DEBUG blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(266)) - Created a new BR lease 0x9a1e07f1fe9ab17b for DN 09222c78-a838-4777-b081-b26210c576c4.  numPending = 1
2020-04-02 05:06:00,159 [IPC Server handler 4 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:requestBlockReportLease(114)) - requestBlockReportLease(node=127.0.0.1:40413, leaseId=0x9a1e07f1fe9ab17b).  expectedFbrDns = 127.0.0.1:40413
2020-04-02 05:06:00,161 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab17b is valid for DN 09222c78-a838-4777-b081-b26210c576c4.
2020-04-02 05:06:00,161 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcd43469dea6165c0: Processing first storage report for DS-9652fd31-f8cb-498b-bf6b-ac8636cae699 from datanode 09222c78-a838-4777-b081-b26210c576c4
2020-04-02 05:06:00,162 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcd43469dea6165c0: from storage DS-9652fd31-f8cb-498b-bf6b-ac8636cae699 node DatanodeRegistration(127.0.0.1:40413, datanodeUuid=09222c78-a838-4777-b081-b26210c576c4, infoPort=34657, infoSecurePort=0, ipcPort=34235, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:00,162 [Block report processor] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:checkLease(328)) - BR lease 0x9a1e07f1fe9ab17b is valid for DN 09222c78-a838-4777-b081-b26210c576c4.
2020-04-02 05:06:00,162 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcd43469dea6165c0: Processing first storage report for DS-d57fc70d-76e3-4549-aca5-762e0aa27843 from datanode 09222c78-a838-4777-b081-b26210c576c4
2020-04-02 05:06:00,162 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcd43469dea6165c0: from storage DS-d57fc70d-76e3-4549-aca5-762e0aa27843 node DatanodeRegistration(127.0.0.1:40413, datanodeUuid=09222c78-a838-4777-b081-b26210c576c4, infoPort=34657, infoSecurePort=0, ipcPort=34235, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:00,162 [IPC Server handler 3 on 33359] TRACE blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:removeLease(349)) - Removed BR lease 0x9a1e07f1fe9ab17b for DN 09222c78-a838-4777-b081-b26210c576c4.  numPending = 0
2020-04-02 05:06:00,162 [IPC Server handler 3 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:removeBlockReportLease(125)) - removeBlockReportLease(node=127.0.0.1:40413, leaseId=0x9a1e07f1fe9ab17b)
2020-04-02 05:06:00,162 [IPC Server handler 3 on 33359] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xcd43469dea6165c0
2020-04-02 05:06:00,162 [IPC Server handler 3 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(85)) - Incoming full block report from DatanodeRegistration(127.0.0.1:40413, datanodeUuid=09222c78-a838-4777-b081-b26210c576c4, infoPort=34657, infoSecurePort=0, ipcPort=34235, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab17b
2020-04-02 05:06:00,162 [IPC Server handler 3 on 33359] INFO  blockmanagement.TestBlockReportRateLimiting (TestBlockReportRateLimiting.java:incomingBlockReportRpc(99)) - Proceeding with full block report from DatanodeRegistration(127.0.0.1:40413, datanodeUuid=09222c78-a838-4777-b081-b26210c576c4, infoPort=34657, infoSecurePort=0, ipcPort=34235, storageInfo=lv=-57;cid=testClusterID;nsid=2046363315;c=1585803954567).  Lease ID = 0x9a1e07f1fe9ab17b
2020-04-02 05:06:00,163 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xcd43469dea6165c0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:00,163 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:06:00,166 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:00,166 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:06:00,166 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43280 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:00,166 [Thread-127] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:00,166 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@575963d4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:00,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-13037a33-a2cd-4c63-8c34-2eb0c8994257) exiting.
2020-04-02 05:06:00,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-5e06a1fd-9d92-4d95-8096-fc863ea5b681) exiting.
2020-04-02 05:06:00,187 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@56c9c819{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:00,187 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2ebba377{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:00,188 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2dfaad05{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:00,188 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1304712a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:00,191 [Thread-127] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43280
2020-04-02 05:06:00,192 [IPC Server listener on 43280] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43280
2020-04-02 05:06:00,192 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:00,193 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:00,193 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 120ae74a-82b6-4bb9-b4f1-615fb4554737) service to localhost/127.0.0.1:33359
2020-04-02 05:06:00,193 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 120ae74a-82b6-4bb9-b4f1-615fb4554737)
2020-04-02 05:06:00,193 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:06:00,204 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:00,297 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:00,298 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:00,300 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:00,300 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:00,315 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:00,367 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:00,367 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:06:00,367 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46298 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:00,368 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@856ef4e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:00,368 [Thread-127] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:00,372 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-dcc207a5-bc18-4acf-87f3-28b5be7fda4c) exiting.
2020-04-02 05:06:00,373 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-5984d1dd-8002-40f3-9a79-7370a4337744) exiting.
2020-04-02 05:06:00,488 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5003afe5{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:00,490 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1b416d2f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:00,490 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72094b34{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:00,491 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@674fbfd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:00,494 [Thread-127] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46298
2020-04-02 05:06:00,535 [IPC Server listener on 46298] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46298
2020-04-02 05:06:00,535 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:00,534 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:00,542 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid d3a307a4-967c-45e0-bf4f-1cc8a75fc30f) service to localhost/127.0.0.1:33359
2020-04-02 05:06:00,542 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid d3a307a4-967c-45e0-bf4f-1cc8a75fc30f)
2020-04-02 05:06:00,543 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:06:00,567 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:00,576 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:00,597 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:00,597 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:00,598 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:00,598 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:00,602 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:00,602 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:06:00,602 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34235 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:00,602 [Thread-127] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:00,604 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@24284b2a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:00,605 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-d57fc70d-76e3-4549-aca5-762e0aa27843) exiting.
2020-04-02 05:06:00,605 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-9652fd31-f8cb-498b-bf6b-ac8636cae699) exiting.
2020-04-02 05:06:00,663 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2ebb470b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:00,665 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@569bbc97{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:00,666 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e4d2bda{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:00,666 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@150e022e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:00,672 [Thread-127] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34235
2020-04-02 05:06:00,676 [IPC Server listener on 34235] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34235
2020-04-02 05:06:00,676 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:00,676 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 09222c78-a838-4777-b081-b26210c576c4) service to localhost/127.0.0.1:33359
2020-04-02 05:06:00,676 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 09222c78-a838-4777-b081-b26210c576c4)
2020-04-02 05:06:00,676 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:00,676 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:06:00,686 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:00,699 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:00,795 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:00,795 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:00,808 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:00,809 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:00,816 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:00,816 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:00,816 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36476 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:00,817 [Thread-127] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:00,817 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@12ce6546] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:00,825 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2d00bb83-63b8-43fb-8355-d6d49a8a026b) exiting.
2020-04-02 05:06:00,825 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-453630a3-be7c-4799-8644-6d13e0a5913e) exiting.
2020-04-02 05:06:00,978 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3f1838cc{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:00,982 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4dc912d8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:00,985 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@221b62fb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:00,991 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1542e245{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:01,014 [Thread-127] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36476
2020-04-02 05:06:01,050 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:01,050 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:01,051 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid a3ea893c-8063-4f4e-b248-e0b1c6c957a4) service to localhost/127.0.0.1:33359
2020-04-02 05:06:01,051 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid a3ea893c-8063-4f4e-b248-e0b1c6c957a4)
2020-04-02 05:06:01,051 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:06:01,058 [IPC Server listener on 36476] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36476
2020-04-02 05:06:01,072 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:01,146 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:01,160 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:01,161 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:01,169 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:01,169 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:01,189 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:01,189 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:01,189 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42308 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:01,189 [Thread-127] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:01,191 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1b48fc8f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:01,196 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-dbdffed6-29ec-4cde-99fc-158fac748b78) exiting.
2020-04-02 05:06:01,197 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-725d713c-ef3d-4223-b81c-e0ef9f801570) exiting.
2020-04-02 05:06:01,276 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@39968cd5{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:01,278 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@17b1a5fc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:01,279 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65958f14{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:01,279 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10091c3f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:01,334 [Thread-127] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42308
2020-04-02 05:06:01,335 [IPC Server listener on 42308] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42308
2020-04-02 05:06:01,359 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:01,359 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:01,360 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 4195daf9-1c45-4269-b408-70f3ccefaf96) service to localhost/127.0.0.1:33359
2020-04-02 05:06:01,462 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-857860265-172.17.0.12-1585803954567 (Datanode Uuid 4195daf9-1c45-4269-b408-70f3ccefaf96)
2020-04-02 05:06:01,462 [BP-857860265-172.17.0.12-1585803954567 heartbeating to localhost/127.0.0.1:33359] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-857860265-172.17.0.12-1585803954567
2020-04-02 05:06:01,474 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:01,483 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-857860265-172.17.0.12-1585803954567] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:01,545 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:01,545 [Thread-127] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:01,548 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:01,548 [Thread-127] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:01,582 [Thread-127] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:01,582 [Thread-127] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:01,582 [Thread-127] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33359 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:01,582 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:01,585 [Thread-127] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 1
2020-04-02 05:06:01,586 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@64339a5c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:01,586 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4a4a0bbe] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:01,617 [Thread-127] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 26 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 12 1 
2020-04-02 05:06:01,618 [Thread-127] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:06:01,619 [Thread-127] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:06:01,620 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:01,625 [CacheReplicationMonitor(457836447)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:01,722 [Thread-127] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33359
2020-04-02 05:06:01,734 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:01,735 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:01,753 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:01,755 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@58e9d68e] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:01,757 [IPC Server listener on 33359] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33359
2020-04-02 05:06:01,782 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:01,782 [Thread-127] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:01,791 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5a18ae5b{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:01,810 [Thread-127] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@698d5f5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:01,811 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f0c86d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:01,811 [Thread-127] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b6992d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:01,814 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:01,882 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:01,882 [Thread-127] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting#testRateLimitingDuringDataNodeStartup
[msx] writeFile testName = org.apache.hadoop.hdfs.server.blockmanagement.TestBlockReportRateLimiting#testRateLimitingDuringDataNodeStartup
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] all testRunFinished

[msx] before_class
2020-04-02 05:05:34,438 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(225)) - Configuration:
2020-04-02 05:05:34,445 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(226)) - ---------------------------------------------------------------
2020-04-02 05:05:34,447 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   debug: false
2020-04-02 05:05:34,447 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   transport: TCP
2020-04-02 05:05:34,448 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.ticket.lifetime: 86400000
2020-04-02 05:05:34,448 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.name: EXAMPLE
2020-04-02 05:05:34,448 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.port: 0
2020-04-02 05:05:34,449 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.domain: COM
2020-04-02 05:05:34,449 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.renewable.lifetime: 604800000
2020-04-02 05:05:34,449 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   instance: DefaultKrbServer
2020-04-02 05:05:34,449 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.bind.address: localhost
2020-04-02 05:05:34,450 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(230)) - ---------------------------------------------------------------
2020-04-02 05:05:34,619 [main] INFO  minikdc.MiniKdc (MiniKdc.java:start(285)) - MiniKdc started.
[msx] test Started org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer#testBalancer0Integrity
[msx] unitTestCounterInClass = 0
2020-04-02 05:05:35,562 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(819)) - capacities = [5000]
2020-04-02 05:05:35,562 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(820)) - racks      = [/rack0]
2020-04-02 05:05:35,563 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(821)) - newCapacity= 2500
2020-04-02 05:05:35,565 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(822)) - newRack    = /rack0
2020-04-02 05:05:35,566 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(823)) - useTool    = false
2020-04-02 05:05:35,621 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=0
Formatting using clusterid: testClusterID
2020-04-02 05:05:36,170 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:36,182 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:36,184 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:36,186 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:36,197 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:36,198 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:36,198 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:36,212 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:36,270 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:36,275 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:05:36,275 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:36,276 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:36,276 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:36,276 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:36,276 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:36,281 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:36,282 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:36
2020-04-02 05:05:36,284 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:36,285 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:36,287 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:36,287 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:36,305 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:36,306 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:36,308 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:36,309 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:36,322 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:05:36,323 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:36,328 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:36,329 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:36,329 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:36,329 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:36,330 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:05:36,330 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:36,330 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:36,331 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:36,331 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:05:36,331 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:36,332 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:36,378 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:05:36,393 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:36,393 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:36,394 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:36,394 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:36,400 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:36,401 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:36,401 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:36,402 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:36,782 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:36,785 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:36,792 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:36,792 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:36,793 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:36,793 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:36,802 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:36,803 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:36,803 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:36,811 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:36,812 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:36,815 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:36,816 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:36,816 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:36,817 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:36,881 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-2052720059-172.17.0.6-1585803936865
2020-04-02 05:05:36,903 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:36,906 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:36,918 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:36,920 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:37,055 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:37,055 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:37,082 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:37,086 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:37,255 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:05:37,313 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:37,410 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:37,411 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:37,419 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:37,444 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:37,542 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803937504,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:37,557 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:37,589 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26adfd2d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:37,608 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:37,610 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:37,617 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:37,650 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3965ms
2020-04-02 05:05:37,766 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:37,770 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:37,771 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:37,779 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:37,782 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:37,782 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:37,782 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:37,827 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:37,827 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:37,831 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:37,832 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:37,836 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39229
2020-04-02 05:05:37,838 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:37,893 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2796aeae{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:37,895 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1fa1cab1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:37,938 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:37,943 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:37,951 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4f25b795{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:37,979 [main] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@1a6c1270(server,h=[],w=[]) for SslContextFactory@18a136ac(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:37,990 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@421bba99{SSL,[ssl, http/1.1]}{localhost:39229}
2020-04-02 05:05:37,995 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4306ms
2020-04-02 05:05:38,028 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:38,030 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:38,032 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:38,032 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:38,033 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:38,033 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:38,033 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:38,034 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:38,034 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:38,035 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:38,036 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:38,036 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:38,036 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:38,036 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:38,046 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:38,047 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:38
2020-04-02 05:05:38,064 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:38,065 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:38,066 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:38,077 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:38,084 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:38,085 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:38,085 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:38,086 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:38,087 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:05:38,087 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:38,088 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:38,088 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:38,088 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:38,089 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:38,089 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:05:38,089 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:38,090 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:38,090 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:38,090 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:05:38,091 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:38,091 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:38,092 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:38,092 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:38,093 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:38,096 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:38,099 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:38,100 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:38,101 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:38,101 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:38,102 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:38,102 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:38,103 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:38,104 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:38,105 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:38,106 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:38,110 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:38,110 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:38,111 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:38,111 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:38,112 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:38,112 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:38,112 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:38,113 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:38,113 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:38,121 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:05:38,123 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:05:38,126 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:38,126 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:38,126 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:38,127 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:38,156 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:38,163 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:38,163 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:38,168 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:38,169 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:38,192 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:38,192 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 76 msecs
2020-04-02 05:05:38,424 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:38,435 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:38,452 [Socket Reader #1 for port 36341] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36341
2020-04-02 05:05:39,182 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36341 to access this namenode/service.
2020-04-02 05:05:39,196 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:39,265 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:39,286 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@691939c9] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:39,291 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:39,302 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:39,302 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:39,303 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:39,308 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:39,313 [Thread[Thread-30,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:39,314 [Thread[Thread-30,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:39,317 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:39,317 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:39,317 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:39,317 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:39,317 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:39,317 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2020-04-02 05:05:39,364 [IPC Server listener on 36341] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36341: starting
2020-04-02 05:05:39,394 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:39,495 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36341
2020-04-02 05:05:39,502 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:39,502 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:39,539 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 36 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:39,560 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36341 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:39,630 [CacheReplicationMonitor(620144428)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:40,381 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803940379,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:40,454 [Socket Reader #1 for port 36341] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:40,757 [IPC Server handler 9 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:40,879 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:40,888 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:40,888 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 0 with hostname set to: host0.foo.com
2020-04-02 05:05:40,888 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host0.foo.com to rack /rack0
2020-04-02 05:05:40,917 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803940916,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:40,963 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:41,014 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:41,076 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:41,076 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:41,081 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:41,084 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:41,089 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host0.foo.com
2020-04-02 05:05:41,091 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:41,091 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:41,091 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:41,093 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:41,102 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34854
2020-04-02 05:05:41,105 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:41,105 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:41,115 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:41,117 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:41,124 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:41,124 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:41,126 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:41,128 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:41,128 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:41,128 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:41,131 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39995
2020-04-02 05:05:41,131 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:41,134 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1b822fcc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:41,135 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56102e1c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:41,142 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@60094a13{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:41,143 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5aceec94{HTTP/1.1,[http/1.1]}{localhost:39995}
2020-04-02 05:05:41,144 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7459ms
2020-04-02 05:05:41,630 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:43526
2020-04-02 05:05:41,632 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ee55e70] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:41,632 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:41,632 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:41,646 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:41,647 [Socket Reader #1 for port 41706] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41706
2020-04-02 05:05:41,667 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41706
2020-04-02 05:05:41,683 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:41,687 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:41,696 [Thread-65] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36341 starting to offer service
2020-04-02 05:05:41,705 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:34854 to rack /rack0
2020-04-02 05:05:41,725 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:41,726 [IPC Server listener on 41706] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41706: starting
2020-04-02 05:05:41,747 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41706 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:41,835 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803941812,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:41,866 [Socket Reader #1 for port 36341] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:41,894 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803941875,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:41,900 [IPC Server handler 0 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:41,910 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:41,911 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:41,924 [Socket Reader #1 for port 36341] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:41,995 [Thread-65] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36341
2020-04-02 05:05:41,996 [Thread-65] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8994c3a9-2d79-47c2-a3cc-ad72ea33f330
2020-04-02 05:05:41,998 [Thread-65] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:05:41,998 [Thread-65] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:42,010 [Thread-65] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2df263c0
2020-04-02 05:05:42,034 [IPC Server handler 3 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:42,042 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:42,042 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:42,043 [Thread-65] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2df263c0
2020-04-02 05:05:42,045 [Thread-65] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:05:42,063 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2052720059-172.17.0.6-1585803936865 (Datanode Uuid 8994c3a9-2d79-47c2-a3cc-ad72ea33f330) service to localhost/127.0.0.1:36341 beginning handshake with NN
2020-04-02 05:05:42,079 [IPC Server handler 6 on 36341] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34854, datanodeUuid=8994c3a9-2d79-47c2-a3cc-ad72ea33f330, infoPort=0, infoSecurePort=43526, ipcPort=41706, storageInfo=lv=-57;cid=testClusterID;nsid=708953514;c=1585803936865) storage 8994c3a9-2d79-47c2-a3cc-ad72ea33f330
2020-04-02 05:05:42,082 [IPC Server handler 6 on 36341] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:34854
2020-04-02 05:05:42,083 [IPC Server handler 6 on 36341] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8994c3a9-2d79-47c2-a3cc-ad72ea33f330 (127.0.0.1:34854).
2020-04-02 05:05:42,089 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2052720059-172.17.0.6-1585803936865 (Datanode Uuid 8994c3a9-2d79-47c2-a3cc-ad72ea33f330) service to localhost/127.0.0.1:36341 successfully registered with NN
2020-04-02 05:05:42,089 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-2052720059-172.17.0.6-1585803936865 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:42,090 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:42,090 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36341 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:05:42,120 [IPC Server handler 4 on 36341] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-7c7efe99-ef50-457d-94f6-ce5b7e49e4c0 for DN 127.0.0.1:34854
2020-04-02 05:05:42,153 [IPC Server handler 1 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:42,181 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x675ee4c3c5030c4: Processing first storage report for SimulatedStorage-DS-7c7efe99-ef50-457d-94f6-ce5b7e49e4c0 from datanode 8994c3a9-2d79-47c2-a3cc-ad72ea33f330
2020-04-02 05:05:42,183 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:42,183 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x675ee4c3c5030c4: from storage SimulatedStorage-DS-7c7efe99-ef50-457d-94f6-ce5b7e49e4c0 node DatanodeRegistration(127.0.0.1:34854, datanodeUuid=8994c3a9-2d79-47c2-a3cc-ad72ea33f330, infoPort=0, infoSecurePort=43526, ipcPort=41706, storageInfo=lv=-57;cid=testClusterID;nsid=708953514;c=1585803936865), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:05:42,211 [IPC Server handler 5 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:42,213 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:42,252 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x675ee4c3c5030c4,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 111 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:42,252 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2052720059-172.17.0.6-1585803936865
2020-04-02 05:05:42,261 [IPC Server handler 8 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:05:42,324 [IPC Server handler 9 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/tmp.txt	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:42,410 [IPC Server handler 0 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:42,609 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57272 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001 src: /127.0.0.1:57272 dest: /127.0.0.1:34854
2020-04-02 05:05:42,693 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57272, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001, duration(ns): 37845045
2020-04-02 05:05:42,693 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:42,717 [IPC Server handler 3 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:42,787 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57278 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002 src: /127.0.0.1:57278 dest: /127.0.0.1:34854
2020-04-02 05:05:42,818 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57278, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002, duration(ns): 24503257
2020-04-02 05:05:42,826 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:42,849 [IPC Server handler 1 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:42,863 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57280 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003 src: /127.0.0.1:57280 dest: /127.0.0.1:34854
2020-04-02 05:05:42,887 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57280, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003, duration(ns): 22515754
2020-04-02 05:05:42,888 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:42,911 [IPC Server handler 8 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:42,931 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57284 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004 src: /127.0.0.1:57284 dest: /127.0.0.1:34854
2020-04-02 05:05:42,982 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57284, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004, duration(ns): 50071983
2020-04-02 05:05:42,984 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:42,996 [IPC Server handler 0 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,003 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57288 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741829_1005 src: /127.0.0.1:57288 dest: /127.0.0.1:34854
2020-04-02 05:05:43,029 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57288, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741829_1005, duration(ns): 24191195
2020-04-02 05:05:43,029 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,036 [IPC Server handler 7 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,055 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57290 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741830_1006 src: /127.0.0.1:57290 dest: /127.0.0.1:34854
2020-04-02 05:05:43,084 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57290, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741830_1006, duration(ns): 28007991
2020-04-02 05:05:43,085 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,119 [IPC Server handler 6 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,154 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57292 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741831_1007 src: /127.0.0.1:57292 dest: /127.0.0.1:34854
2020-04-02 05:05:43,168 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57292, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741831_1007, duration(ns): 5402175
2020-04-02 05:05:43,178 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,193 [IPC Server handler 5 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,220 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57294 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741832_1008 src: /127.0.0.1:57294 dest: /127.0.0.1:34854
2020-04-02 05:05:43,249 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57294, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741832_1008, duration(ns): 26945997
2020-04-02 05:05:43,249 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,279 [IPC Server handler 8 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,307 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57298 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741833_1009 src: /127.0.0.1:57298 dest: /127.0.0.1:34854
2020-04-02 05:05:43,339 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57298, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741833_1009, duration(ns): 6059213
2020-04-02 05:05:43,341 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,359 [IPC Server handler 2 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,369 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57300 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741834_1010 src: /127.0.0.1:57300 dest: /127.0.0.1:34854
2020-04-02 05:05:43,404 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57300, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741834_1010, duration(ns): 11812553
2020-04-02 05:05:43,405 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,415 [IPC Server handler 3 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,430 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57302 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741835_1011 src: /127.0.0.1:57302 dest: /127.0.0.1:34854
2020-04-02 05:05:43,481 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57302, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741835_1011, duration(ns): 46732650
2020-04-02 05:05:43,482 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,525 [IPC Server handler 4 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,542 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57304 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741836_1012 src: /127.0.0.1:57304 dest: /127.0.0.1:34854
2020-04-02 05:05:43,563 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57304, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741836_1012, duration(ns): 18915505
2020-04-02 05:05:43,563 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,591 [IPC Server handler 5 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,622 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57306 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741837_1013 src: /127.0.0.1:57306 dest: /127.0.0.1:34854
2020-04-02 05:05:43,683 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57306, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741837_1013, duration(ns): 58335676
2020-04-02 05:05:43,689 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,699 [IPC Server handler 8 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,719 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57310 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741838_1014 src: /127.0.0.1:57310 dest: /127.0.0.1:34854
2020-04-02 05:05:43,739 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57310, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741838_1014, duration(ns): 18645053
2020-04-02 05:05:43,740 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,759 [IPC Server handler 2 on 36341] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:34854 for /tmp.txt
2020-04-02 05:05:43,787 [DataXceiver for client DFSClient_NONMAPREDUCE_-459712677_1 at /127.0.0.1:57312 [Receiving block BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015 src: /127.0.0.1:57312 dest: /127.0.0.1:34854
2020-04-02 05:05:43,806 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57312, dest: /127.0.0.1:34854, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-459712677_1, offset: 0, srvID: 8994c3a9-2d79-47c2-a3cc-ad72ea33f330, blockid: BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015, duration(ns): 14676843
2020-04-02 05:05:43,806 [PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:43,842 [IPC Server handler 3 on 36341] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp.txt is closed by DFSClient_NONMAPREDUCE_-459712677_1
2020-04-02 05:05:43,854 [IPC Server handler 6 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp.txt	dst=null	perm=null	proto=rpc
2020-04-02 05:05:43,869 [IPC Server handler 4 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/tmp.txt	dst=null	perm=null	proto=rpc
All blocks of file /tmp.txt verified to have replication factor 1
2020-04-02 05:05:43,889 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:43,889 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 1 with hostname set to: host1.foo.com
2020-04-02 05:05:43,889 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host1.foo.com to rack /rack0
2020-04-02 05:05:43,899 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803943897,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:43,920 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:43,921 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:43,930 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:43,931 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:43,931 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:43,932 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:43,932 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1.foo.com
2020-04-02 05:05:43,933 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:43,933 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:43,933 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:43,934 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:43,935 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37579
2020-04-02 05:05:43,935 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:43,936 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:43,943 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:43,945 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:43,946 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:43,947 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:43,949 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:43,954 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:43,955 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:43,955 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:43,956 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39774
2020-04-02 05:05:43,959 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:43,961 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e11ab3d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:43,961 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2392212b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:43,966 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5ab9b447{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:43,967 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@76f10035{HTTP/1.1,[http/1.1]}{localhost:39774}
2020-04-02 05:05:43,967 [main] INFO  server.Server (Server.java:doStart(419)) - Started @10282ms
2020-04-02 05:05:44,092 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:46818
2020-04-02 05:05:44,093 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:44,093 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@15b986cd] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:44,093 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:44,094 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:44,107 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41470
2020-04-02 05:05:44,116 [Socket Reader #1 for port 41470] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41470
2020-04-02 05:05:44,120 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:44,121 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:44,122 [Thread-138] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36341 starting to offer service
2020-04-02 05:05:44,123 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:37579 to rack /rack0
2020-04-02 05:05:44,139 [IPC Server listener on 41470] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41470: starting
2020-04-02 05:05:44,169 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41470 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:44,170 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:44,208 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803944207,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:44,223 [Socket Reader #1 for port 36341] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:44,262 [IPC Server handler 5 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:44,270 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:44,270 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:44,271 [Socket Reader #1 for port 36341] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:44,283 [Thread-138] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36341
2020-04-02 05:05:44,284 [Thread-138] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 01c230ed-b38f-4b50-b028-494a62bb9d37
2020-04-02 05:05:44,284 [Thread-138] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:05:44,285 [Thread-138] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:44,286 [Thread-138] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2191233d
2020-04-02 05:05:44,307 [Thread-138] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2191233d
2020-04-02 05:05:44,308 [Thread-138] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:05:44,308 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2052720059-172.17.0.6-1585803936865 (Datanode Uuid 01c230ed-b38f-4b50-b028-494a62bb9d37) service to localhost/127.0.0.1:36341 beginning handshake with NN
2020-04-02 05:05:44,313 [IPC Server handler 8 on 36341] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37579, datanodeUuid=01c230ed-b38f-4b50-b028-494a62bb9d37, infoPort=0, infoSecurePort=46818, ipcPort=41470, storageInfo=lv=-57;cid=testClusterID;nsid=708953514;c=1585803936865) storage 01c230ed-b38f-4b50-b028-494a62bb9d37
2020-04-02 05:05:44,313 [IPC Server handler 8 on 36341] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:37579
2020-04-02 05:05:44,313 [IPC Server handler 8 on 36341] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 01c230ed-b38f-4b50-b028-494a62bb9d37 (127.0.0.1:37579).
2020-04-02 05:05:44,317 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2052720059-172.17.0.6-1585803936865 (Datanode Uuid 01c230ed-b38f-4b50-b028-494a62bb9d37) service to localhost/127.0.0.1:36341 successfully registered with NN
2020-04-02 05:05:44,317 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-2052720059-172.17.0.6-1585803936865 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:44,318 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:44,318 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36341 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:05:44,325 [IPC Server handler 0 on 36341] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-4eb03ad6-df71-4778-890d-8d30393b320d for DN 127.0.0.1:37579
2020-04-02 05:05:44,338 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x950e6e2111a6912c: Processing first storage report for SimulatedStorage-DS-4eb03ad6-df71-4778-890d-8d30393b320d from datanode 01c230ed-b38f-4b50-b028-494a62bb9d37
2020-04-02 05:05:44,338 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x950e6e2111a6912c: from storage SimulatedStorage-DS-4eb03ad6-df71-4778-890d-8d30393b320d node DatanodeRegistration(127.0.0.1:37579, datanodeUuid=01c230ed-b38f-4b50-b028-494a62bb9d37, infoPort=0, infoSecurePort=46818, ipcPort=41470, storageInfo=lv=-57;cid=testClusterID;nsid=708953514;c=1585803936865), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:44,349 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x950e6e2111a6912c,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:44,349 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2052720059-172.17.0.6-1585803936865
2020-04-02 05:05:44,374 [IPC Server handler 7 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:44,378 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:44,386 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(984)) - namenodes  = [hdfs://localhost:36341]
2020-04-02 05:05:44,386 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(985)) - parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]
2020-04-02 05:05:44,387 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(986)) - Print stack trace
java.lang.Throwable
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:986)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:945)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:921)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:793)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:787)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.oneNodeTest(TestBalancer.java:1093)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1208)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity(TestBalancerWithSaslDataTransfer.java:34)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved
2020-04-02 05:05:44,470 [Socket Reader #1 for port 36341] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:44,502 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(75)) - Block token params received from NN: update interval=10hrs, 0sec, token lifetime=10hrs, 0sec
2020-04-02 05:05:44,503 [main] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:44,503 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(172)) - Update block keys every 2hrs, 30mins, 0sec
2020-04-02 05:05:44,514 [IPC Server handler 5 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:05:44,520 [IPC Server handler 9 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/system/balancer.id	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:44,539 [IPC Server handler 8 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:05:44,555 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:05:44,556 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:05:44,556 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:05:44,556 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:05:44,556 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:05:44,556 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:05:44,560 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:44,560 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:44,560 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:05:44,561 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:05:44,564 [IPC Server handler 2 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:44,569 [org.apache.hadoop.hdfs.server.balancer.KeyManager$BlockKeyUpdater@2fb69ff6] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:44,582 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:34854
2020-04-02 05:05:44,582 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:37579
2020-04-02 05:05:44,585 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:05:44,586 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 1 above-average: [127.0.0.1:34854:DISK]
2020-04-02 05:05:44,586 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 below-average: []
2020-04-02 05:05:44,586 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 1 underutilized: [127.0.0.1:37579:DISK]
2020-04-02 05:05:44,586 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(615)) - Need to move 250 B to make the cluster balanced.
2020-04-02 05:05:44,606 [IPC Server handler 3 on 36341] INFO  namenode.NameNode (NameNodeRpcServer.java:rollingUpgrade(1333)) - rollingUpgrade QUERY
2020-04-02 05:05:44,614 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for SAME_RACK: overUtilized => underUtilized
2020-04-02 05:05:44,614 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for SAME_RACK: overUtilized => belowAvgUtilized
2020-04-02 05:05:44,614 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for SAME_RACK: underUtilized => aboveAvgUtilized
2020-04-02 05:05:44,615 [main] INFO  balancer.Balancer (Balancer.java:matchSourceWithTargetToMove(537)) - Decided to move 500 B bytes from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK
2020-04-02 05:05:44,615 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for ANY_OTHER: overUtilized => underUtilized
2020-04-02 05:05:44,615 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for ANY_OTHER: overUtilized => belowAvgUtilized
2020-04-02 05:05:44,615 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for ANY_OTHER: underUtilized => aboveAvgUtilized
2020-04-02 05:05:44,617 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(639)) - Will move 500 B in this iteration
2020-04-02 05:05:44,617 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1189)) - Balancer allowed RPCs per sec = 20
2020-04-02 05:05:44,617 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1190)) - Balancer concurrent threads = 1
2020-04-02 05:05:44,618 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1191)) - Disperse Interval sec = 0
2020-04-02 05:05:44,618 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1207)) - Limiting threads per target to the specified max.
2020-04-02 05:05:44,618 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1210)) - Allocating 50 threads per target.
2020-04-02 05:05:44,655 [pool-27-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741839_1015 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,659 [pool-27-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,659 [pool-28-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741839_1015 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,659 [pool-27-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,660 [pool-28-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,660 [pool-27-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741827_1003 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,661 [pool-28-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,662 [pool-27-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741828_1004 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,663 [pool-28-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741827_1003 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,663 [pool-28-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741828_1004 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,865 [DataXceiver for client /127.0.0.1:57338 [Copying block BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003 to /127.0.0.1:57338
2020-04-02 05:05:44,866 [DataXceiver for client /127.0.0.1:57336 [Copying block BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002 to /127.0.0.1:57336
2020-04-02 05:05:44,866 [DataXceiver for client /127.0.0.1:57334 [Copying block BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001 to /127.0.0.1:57334
2020-04-02 05:05:44,867 [DataXceiver for client /127.0.0.1:57332 [Copying block BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004 to /127.0.0.1:57332
2020-04-02 05:05:44,867 [DataXceiver for client /127.0.0.1:43814 [Replacing block BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002 from 8994c3a9-2d79-47c2-a3cc-ad72ea33f330]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-2052720059-172.17.0.6-1585803936865:blk_1073741826_1002 from /127.0.0.1:43814, delHint=8994c3a9-2d79-47c2-a3cc-ad72ea33f330
2020-04-02 05:05:44,867 [DataXceiver for client /127.0.0.1:43812 [Replacing block BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001 from 8994c3a9-2d79-47c2-a3cc-ad72ea33f330]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-2052720059-172.17.0.6-1585803936865:blk_1073741825_1001 from /127.0.0.1:43812, delHint=8994c3a9-2d79-47c2-a3cc-ad72ea33f330
2020-04-02 05:05:44,867 [DataXceiver for client /127.0.0.1:57340 [Copying block BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015 to /127.0.0.1:57340
2020-04-02 05:05:44,867 [DataXceiver for client /127.0.0.1:43816 [Replacing block BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003 from 8994c3a9-2d79-47c2-a3cc-ad72ea33f330]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-2052720059-172.17.0.6-1585803936865:blk_1073741827_1003 from /127.0.0.1:43816, delHint=8994c3a9-2d79-47c2-a3cc-ad72ea33f330
2020-04-02 05:05:44,868 [pool-28-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741827_1003 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,870 [pool-28-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,870 [pool-28-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,875 [DataXceiver for client /127.0.0.1:43818 [Replacing block BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004 from 8994c3a9-2d79-47c2-a3cc-ad72ea33f330]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-2052720059-172.17.0.6-1585803936865:blk_1073741828_1004 from /127.0.0.1:43818, delHint=8994c3a9-2d79-47c2-a3cc-ad72ea33f330
2020-04-02 05:05:44,876 [pool-28-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741828_1004 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
2020-04-02 05:05:44,876 [DataXceiver for client /127.0.0.1:43810 [Replacing block BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015 from 8994c3a9-2d79-47c2-a3cc-ad72ea33f330]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-2052720059-172.17.0.6-1585803936865:blk_1073741839_1015 from /127.0.0.1:43810, delHint=8994c3a9-2d79-47c2-a3cc-ad72ea33f330
2020-04-02 05:05:44,878 [pool-28-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741839_1015 with size=100 from 127.0.0.1:34854:DISK to 127.0.0.1:37579:DISK through 127.0.0.1:34854
Apr 2, 2020 5:05:45 AM            0                500 B               250 B              500 B
2020-04-02 05:05:48,673 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:05:48,673 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:05:48,673 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:05:48,673 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:05:48,673 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:05:48,674 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:05:48,675 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:48,675 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:48,675 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:05:48,675 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:05:48,677 [IPC Server handler 4 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:48,678 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:37579
2020-04-02 05:05:48,678 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:34854
2020-04-02 05:05:48,678 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:05:48,679 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 above-average: []
2020-04-02 05:05:48,679 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 2 below-average: [127.0.0.1:37579:DISK, 127.0.0.1:34854:DISK]
2020-04-02 05:05:48,679 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 underutilized: []
The cluster is balanced. Exiting...
Apr 2, 2020 5:05:48 AM            1                500 B                 0 B                0 B
2020-04-02 05:05:48,681 [IPC Server handler 1 on 36341] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /system/balancer.id is closed by DFSClient_NONMAPREDUCE_948028346_1
2020-04-02 05:05:48,693 [IPC Server handler 5 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=delete	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:05:48,698 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(956)) -   .
2020-04-02 05:05:48,699 [IPC Server handler 8 on 36341] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:48,701 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:48,701 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:05:48,701 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41470 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:48,702 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@232024b9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:49,109 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5ab9b447{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:49,139 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@76f10035{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:49,140 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2392212b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:49,140 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e11ab3d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:49,159 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41470
2020-04-02 05:05:49,164 [IPC Server listener on 41470] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41470
2020-04-02 05:05:49,170 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:49,170 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:49,172 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2052720059-172.17.0.6-1585803936865 (Datanode Uuid 01c230ed-b38f-4b50-b028-494a62bb9d37) service to localhost/127.0.0.1:36341
2020-04-02 05:05:49,172 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2052720059-172.17.0.6-1585803936865 (Datanode Uuid 01c230ed-b38f-4b50-b028-494a62bb9d37)
2020-04-02 05:05:49,191 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:49,191 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:49,192 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41706 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:49,194 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1ac85b0c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:49,439 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@60094a13{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:49,441 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5aceec94{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:49,441 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56102e1c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:49,441 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1b822fcc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:49,445 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41706
2020-04-02 05:05:49,474 [IPC Server listener on 41706] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41706
2020-04-02 05:05:49,474 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:49,474 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:49,476 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2052720059-172.17.0.6-1585803936865 (Datanode Uuid 8994c3a9-2d79-47c2-a3cc-ad72ea33f330) service to localhost/127.0.0.1:36341
2020-04-02 05:05:49,476 [BP-2052720059-172.17.0.6-1585803936865 heartbeating to localhost/127.0.0.1:36341] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2052720059-172.17.0.6-1585803936865 (Datanode Uuid 8994c3a9-2d79-47c2-a3cc-ad72ea33f330)
2020-04-02 05:05:49,477 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:49,477 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:49,477 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36341 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:49,477 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:49,478 [Thread[Thread-30,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:49,478 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 54
2020-04-02 05:05:49,479 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@18518ccf] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:49,480 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1991f767] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:49,481 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 55 Total time for transactions(ms): 20 Number of transactions batched in Syncs: 25 Number of syncs: 31 SyncTimes(ms): 5 0 
2020-04-02 05:05:49,482 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:05:49,483 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:05:49,484 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:49,485 [CacheReplicationMonitor(620144428)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:49,487 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36341
2020-04-02 05:05:49,513 [IPC Server listener on 36341] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36341
2020-04-02 05:05:49,517 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:49,531 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:49,533 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:49,592 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:49,593 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:49,598 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4f25b795{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:49,618 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@421bba99{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:05:49,618 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1fa1cab1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:49,619 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2796aeae{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:49,631 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:05:49,643 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:05:49,644 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:05:49,649 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(819)) - capacities = [5000, 5000]
2020-04-02 05:05:49,650 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(820)) - racks      = [/rack0, /rack1]
2020-04-02 05:05:49,650 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(821)) - newCapacity= 5000
2020-04-02 05:05:49,650 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(822)) - newRack    = /rack2
2020-04-02 05:05:49,650 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(823)) - useTool    = false
2020-04-02 05:05:49,650 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-04-02 05:05:49,671 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803949670,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:49,684 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:49,686 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:49,687 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:49,687 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:49,687 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:49,687 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:49,687 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:49,687 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:49,688 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:49,688 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:49,688 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,689 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:49,689 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:49,689 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,689 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:49,689 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:49,690 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:49
2020-04-02 05:05:49,690 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:49,690 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,690 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:49,690 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:49,694 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,694 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,694 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:49,694 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:49,695 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:05:49,695 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,695 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:49,696 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:49,696 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:49,696 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:49,696 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:05:49,696 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:49,696 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:49,696 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:49,696 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:05:49,697 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:49,697 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:49,697 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:49,697 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,698 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:49,698 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:49,699 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:49,699 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:49,699 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:49,700 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:49,700 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:49,700 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:49,700 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:49,700 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,700 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:49,701 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:49,701 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:49,702 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:49,702 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:49,702 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:49,702 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:49,702 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:49,703 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,703 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:49,703 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:49,704 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-578793322-172.17.0.6-1585803949704
2020-04-02 05:05:49,707 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:49,709 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:49,734 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:49,738 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:49,741 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:49,752 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:49,755 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:49,757 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:49,763 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:49,765 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:49,765 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:49,766 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:49,766 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:49,773 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803949772,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:49,780 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:49,794 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:49,795 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:39229
2020-04-02 05:05:49,795 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:49,796 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3003697] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:49,797 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:49,800 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:49,800 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:49,801 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:49,802 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:49,803 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:49,803 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:49,806 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:49,806 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:49,806 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:49,806 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:49,807 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39229
2020-04-02 05:05:49,807 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:49,809 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1bdbf9be{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:49,810 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1da6ee17{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:49,815 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:49,816 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:49,817 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@49d98dc5{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:49,819 [main] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@2c30b71f(server,h=[],w=[]) for SslContextFactory@1d81e101(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:49,821 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@ec50f54{SSL,[ssl, http/1.1]}{localhost:39229}
2020-04-02 05:05:49,822 [main] INFO  server.Server (Server.java:doStart(419)) - Started @16137ms
2020-04-02 05:05:49,826 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:49,826 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:49,827 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:49,827 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:49,827 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:49,827 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:49,828 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:49,828 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:49,828 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:49,829 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,829 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:49,829 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:49,829 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,830 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:49,830 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:49,832 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:49
2020-04-02 05:05:49,832 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:49,832 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,832 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:49,833 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:49,838 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,838 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,839 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:49,839 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:49,840 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:05:49,840 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,840 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:49,841 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:49,841 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:49,841 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:49,841 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:05:49,841 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:49,842 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:49,842 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:49,842 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:05:49,842 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:49,842 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:49,843 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:49,843 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,844 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:49,848 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:49,851 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:49,851 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:49,851 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:49,851 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:49,852 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:49,852 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:49,852 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:49,852 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,853 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:49,853 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:49,854 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:49,854 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:49,854 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:49,855 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:49,855 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:49,855 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:49,855 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,856 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:49,856 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:49,858 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:05:49,860 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:05:49,864 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:49,864 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:49,864 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:49,865 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:49,866 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:49,867 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:49,869 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:49,869 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:49,874 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:49,899 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:49,899 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 42 msecs
2020-04-02 05:05:49,900 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:49,900 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:49,901 [Socket Reader #1 for port 41168] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41168
2020-04-02 05:05:49,926 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:41168 to access this namenode/service.
2020-04-02 05:05:49,927 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:50,014 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:50,051 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:50,051 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:50,051 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:50,051 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:50,057 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@2577d6c8] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:50,057 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:50,072 [Thread[Thread-195,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:50,072 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:50,082 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:50,082 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:50,082 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:50,082 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:50,082 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 31 msec
2020-04-02 05:05:50,078 [Thread[Thread-195,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:50,097 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:50,104 [IPC Server listener on 41168] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41168: starting
2020-04-02 05:05:50,130 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:41168
2020-04-02 05:05:50,130 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:50,131 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:50,131 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:50,146 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 41168 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:50,185 [CacheReplicationMonitor(1721346700)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:50,231 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803950229,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:50,281 [Socket Reader #1 for port 41168] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:50,334 [IPC Server handler 0 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:50,362 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:50,364 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:50,365 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 0 with hostname set to: host0.foo.com
2020-04-02 05:05:50,365 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host0.foo.com to rack /rack0
2020-04-02 05:05:50,374 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803950373,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:50,376 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:50,377 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:50,398 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:50,398 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:50,398 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:50,399 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:50,399 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host0.foo.com
2020-04-02 05:05:50,400 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:50,400 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:50,400 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:50,401 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:50,402 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45226
2020-04-02 05:05:50,402 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:50,402 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:50,404 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:50,405 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:50,406 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:50,406 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:50,408 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:50,409 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:50,409 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:50,409 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:50,410 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45092
2020-04-02 05:05:50,410 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:50,456 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60e949e1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:50,462 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@680362a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:50,475 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2bfeb1ef{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:50,481 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@778ca8ef{HTTP/1.1,[http/1.1]}{localhost:45092}
2020-04-02 05:05:50,482 [main] INFO  server.Server (Server.java:doStart(419)) - Started @16797ms
2020-04-02 05:05:50,533 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:33903
2020-04-02 05:05:50,534 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:50,534 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@261d8190] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:50,534 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:50,535 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:50,536 [Socket Reader #1 for port 41635] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41635
2020-04-02 05:05:50,558 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41635
2020-04-02 05:05:50,574 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:50,574 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:50,576 [Thread-225] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41168 starting to offer service
2020-04-02 05:05:50,582 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:45226 to rack /rack0
2020-04-02 05:05:50,585 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:50,586 [IPC Server listener on 41635] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41635: starting
2020-04-02 05:05:50,593 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41635 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:50,600 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:50,600 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 1 with hostname set to: host1.foo.com
2020-04-02 05:05:50,600 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host1.foo.com to rack /rack1
2020-04-02 05:05:50,621 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803950620,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:50,624 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:50,641 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:50,660 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:50,661 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:50,661 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:50,670 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:50,670 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1.foo.com
2020-04-02 05:05:50,670 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:50,671 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:50,671 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:50,672 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:50,672 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37246
2020-04-02 05:05:50,673 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:50,673 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:50,682 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:50,697 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:50,703 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:50,751 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:50,753 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:50,760 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:50,760 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:50,761 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:50,762 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35510
2020-04-02 05:05:50,762 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:50,786 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b56b654{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:50,787 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@534243e4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:50,793 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7f9e1534{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:50,793 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@138a7441{HTTP/1.1,[http/1.1]}{localhost:35510}
2020-04-02 05:05:50,794 [main] INFO  server.Server (Server.java:doStart(419)) - Started @17109ms
2020-04-02 05:05:50,837 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803950836,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:50,857 [Socket Reader #1 for port 41168] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:50,864 [Thread-225] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41168
2020-04-02 05:05:50,866 [Thread-225] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID fc7da941-4cf8-40c2-bf9a-8dfcba457a18
2020-04-02 05:05:50,869 [Thread-225] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:05:50,870 [Thread-225] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:50,872 [Thread-225] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@a388c35
2020-04-02 05:05:50,878 [Thread-225] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@a388c35
2020-04-02 05:05:50,878 [Thread-225] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:05:50,889 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid fc7da941-4cf8-40c2-bf9a-8dfcba457a18) service to localhost/127.0.0.1:41168 beginning handshake with NN
2020-04-02 05:05:50,925 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:37374
2020-04-02 05:05:50,956 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:50,956 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:50,957 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:50,958 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@99a65d3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:50,976 [Socket Reader #1 for port 35361] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35361
2020-04-02 05:05:51,010 [IPC Server handler 2 on 41168] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45226, datanodeUuid=fc7da941-4cf8-40c2-bf9a-8dfcba457a18, infoPort=0, infoSecurePort=33903, ipcPort=41635, storageInfo=lv=-57;cid=testClusterID;nsid=1505629276;c=1585803949704) storage fc7da941-4cf8-40c2-bf9a-8dfcba457a18
2020-04-02 05:05:51,011 [IPC Server handler 2 on 41168] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:45226
2020-04-02 05:05:51,011 [IPC Server handler 2 on 41168] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fc7da941-4cf8-40c2-bf9a-8dfcba457a18 (127.0.0.1:45226).
2020-04-02 05:05:51,019 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35361
2020-04-02 05:05:51,064 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:51,064 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:51,066 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid fc7da941-4cf8-40c2-bf9a-8dfcba457a18) service to localhost/127.0.0.1:41168 successfully registered with NN
2020-04-02 05:05:51,066 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-578793322-172.17.0.6-1585803949704 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:51,067 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:51,067 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41168 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:05:51,068 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:37246 to rack /rack1
2020-04-02 05:05:51,070 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:51,086 [Thread-249] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41168 starting to offer service
2020-04-02 05:05:51,101 [IPC Server handler 3 on 41168] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-14c65f81-14ff-4954-a73e-3272b56bfff1 for DN 127.0.0.1:45226
2020-04-02 05:05:51,103 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35361 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:51,155 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc43b491e0a903146: Processing first storage report for SimulatedStorage-DS-14c65f81-14ff-4954-a73e-3272b56bfff1 from datanode fc7da941-4cf8-40c2-bf9a-8dfcba457a18
2020-04-02 05:05:51,101 [IPC Server listener on 35361] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35361: starting
2020-04-02 05:05:51,157 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc43b491e0a903146: from storage SimulatedStorage-DS-14c65f81-14ff-4954-a73e-3272b56bfff1 node DatanodeRegistration(127.0.0.1:45226, datanodeUuid=fc7da941-4cf8-40c2-bf9a-8dfcba457a18, infoPort=0, infoSecurePort=33903, ipcPort=41635, storageInfo=lv=-57;cid=testClusterID;nsid=1505629276;c=1585803949704), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:51,185 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc43b491e0a903146,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 23 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:51,185 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-578793322-172.17.0.6-1585803949704
2020-04-02 05:05:51,205 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803951204,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:51,205 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803951204,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:51,246 [Socket Reader #1 for port 41168] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:51,247 [Socket Reader #1 for port 41168] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:51,278 [IPC Server handler 0 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:51,298 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:51,298 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:51,310 [Thread-249] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41168
2020-04-02 05:05:51,311 [Thread-249] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b
2020-04-02 05:05:51,312 [Thread-249] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:05:51,312 [Thread-249] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:51,314 [Thread-249] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2a665280
2020-04-02 05:05:51,321 [Thread-249] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2a665280
2020-04-02 05:05:51,322 [Thread-249] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:05:51,324 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b) service to localhost/127.0.0.1:41168 beginning handshake with NN
2020-04-02 05:05:51,326 [IPC Server handler 2 on 41168] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37246, datanodeUuid=ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, infoPort=0, infoSecurePort=37374, ipcPort=35361, storageInfo=lv=-57;cid=testClusterID;nsid=1505629276;c=1585803949704) storage ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b
2020-04-02 05:05:51,327 [IPC Server handler 2 on 41168] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack1/127.0.0.1:37246
2020-04-02 05:05:51,327 [IPC Server handler 2 on 41168] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:checkIfClusterIsNowMultiRack(1386)) - DN 127.0.0.1:37246 joining cluster has expanded a formerly single-rack cluster to be multi-rack. Re-checking all blocks for replication, since they should now be replicated cross-rack
2020-04-02 05:05:51,335 [IPC Server handler 2 on 41168] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b (127.0.0.1:37246).
2020-04-02 05:05:51,338 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b) service to localhost/127.0.0.1:41168 successfully registered with NN
2020-04-02 05:05:51,338 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-578793322-172.17.0.6-1585803949704 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:51,338 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:51,339 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41168 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:05:51,374 [IPC Server handler 3 on 41168] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-7c2948cc-2be8-4fd7-925e-66f744f7e75e for DN 127.0.0.1:37246
2020-04-02 05:05:51,375 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:51,375 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:51,375 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:51,376 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:51,376 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:51,376 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 41 msec
2020-04-02 05:05:51,381 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x899540531b91949a: Processing first storage report for SimulatedStorage-DS-7c2948cc-2be8-4fd7-925e-66f744f7e75e from datanode ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b
2020-04-02 05:05:51,382 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x899540531b91949a: from storage SimulatedStorage-DS-7c2948cc-2be8-4fd7-925e-66f744f7e75e node DatanodeRegistration(127.0.0.1:37246, datanodeUuid=ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, infoPort=0, infoSecurePort=37374, ipcPort=35361, storageInfo=lv=-57;cid=testClusterID;nsid=1505629276;c=1585803949704), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:51,385 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x899540531b91949a,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:51,385 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-578793322-172.17.0.6-1585803949704
2020-04-02 05:05:51,402 [IPC Server handler 9 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:51,405 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:51,408 [IPC Server handler 8 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:51,410 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:51,422 [IPC Server handler 7 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:05:51,425 [IPC Server handler 6 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/tmp.txt	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:51,479 [IPC Server handler 4 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:37246, 127.0.0.1:45226 for /tmp.txt
2020-04-02 05:05:51,539 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41216 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001 src: /127.0.0.1:41216 dest: /127.0.0.1:37246
2020-04-02 05:05:51,590 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56336 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001 src: /127.0.0.1:56336 dest: /127.0.0.1:45226
2020-04-02 05:05:51,635 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56336, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001, duration(ns): 42176220
2020-04-02 05:05:51,636 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:51,639 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41216, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001, duration(ns): 41504498
2020-04-02 05:05:51,639 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226] terminating
2020-04-02 05:05:51,657 [IPC Server handler 3 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:45226, 127.0.0.1:37246 for /tmp.txt
2020-04-02 05:05:51,665 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56338 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002 src: /127.0.0.1:56338 dest: /127.0.0.1:45226
2020-04-02 05:05:51,682 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41222 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002 src: /127.0.0.1:41222 dest: /127.0.0.1:37246
2020-04-02 05:05:51,734 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41222, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002, duration(ns): 43843257
2020-04-02 05:05:51,734 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:51,742 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56338, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002, duration(ns): 43333723
2020-04-02 05:05:51,743 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246] terminating
2020-04-02 05:05:51,746 [IPC Server handler 9 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:45226, 127.0.0.1:37246 for /tmp.txt
2020-04-02 05:05:51,765 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56342 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003 src: /127.0.0.1:56342 dest: /127.0.0.1:45226
2020-04-02 05:05:51,777 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41226 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003 src: /127.0.0.1:41226 dest: /127.0.0.1:37246
2020-04-02 05:05:51,824 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41226, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003, duration(ns): 46174036
2020-04-02 05:05:51,825 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:51,826 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56342, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003, duration(ns): 43770937
2020-04-02 05:05:51,826 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246] terminating
2020-04-02 05:05:51,835 [IPC Server handler 4 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:45226, 127.0.0.1:37246 for /tmp.txt
2020-04-02 05:05:51,864 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56346 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004 src: /127.0.0.1:56346 dest: /127.0.0.1:45226
2020-04-02 05:05:51,879 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41230 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004 src: /127.0.0.1:41230 dest: /127.0.0.1:37246
2020-04-02 05:05:51,900 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41230, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004, duration(ns): 19850963
2020-04-02 05:05:51,900 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:51,901 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56346, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004, duration(ns): 20618031
2020-04-02 05:05:51,902 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246] terminating
2020-04-02 05:05:51,907 [IPC Server handler 0 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:37246, 127.0.0.1:45226 for /tmp.txt
2020-04-02 05:05:51,915 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41232 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005 src: /127.0.0.1:41232 dest: /127.0.0.1:37246
2020-04-02 05:05:51,920 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56352 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005 src: /127.0.0.1:56352 dest: /127.0.0.1:45226
2020-04-02 05:05:51,973 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56352, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005, duration(ns): 23373893
2020-04-02 05:05:51,974 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:51,974 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41232, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005, duration(ns): 28520467
2020-04-02 05:05:51,975 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226] terminating
2020-04-02 05:05:51,980 [IPC Server handler 5 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:37246, 127.0.0.1:45226 for /tmp.txt
2020-04-02 05:05:51,987 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41236 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006 src: /127.0.0.1:41236 dest: /127.0.0.1:37246
2020-04-02 05:05:51,997 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56356 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006 src: /127.0.0.1:56356 dest: /127.0.0.1:45226
2020-04-02 05:05:52,020 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56356, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006, duration(ns): 5925906
2020-04-02 05:05:52,021 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,026 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41236, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006, duration(ns): 11428228
2020-04-02 05:05:52,026 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226] terminating
2020-04-02 05:05:52,039 [IPC Server handler 6 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:37246, 127.0.0.1:45226 for /tmp.txt
2020-04-02 05:05:52,045 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41240 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007 src: /127.0.0.1:41240 dest: /127.0.0.1:37246
2020-04-02 05:05:52,049 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56360 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007 src: /127.0.0.1:56360 dest: /127.0.0.1:45226
2020-04-02 05:05:52,082 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56360, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007, duration(ns): 29359650
2020-04-02 05:05:52,085 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,086 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41240, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007, duration(ns): 33282273
2020-04-02 05:05:52,087 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226] terminating
2020-04-02 05:05:52,091 [IPC Server handler 0 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:45226, 127.0.0.1:37246 for /tmp.txt
2020-04-02 05:05:52,097 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56362 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008 src: /127.0.0.1:56362 dest: /127.0.0.1:45226
2020-04-02 05:05:52,111 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41246 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008 src: /127.0.0.1:41246 dest: /127.0.0.1:37246
2020-04-02 05:05:52,126 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41246, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008, duration(ns): 14471964
2020-04-02 05:05:52,127 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,129 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56362, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008, duration(ns): 15146460
2020-04-02 05:05:52,129 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246] terminating
2020-04-02 05:05:52,147 [IPC Server handler 5 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:45226, 127.0.0.1:37246 for /tmp.txt
2020-04-02 05:05:52,185 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56366 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009 src: /127.0.0.1:56366 dest: /127.0.0.1:45226
2020-04-02 05:05:52,199 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41250 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009 src: /127.0.0.1:41250 dest: /127.0.0.1:37246
2020-04-02 05:05:52,211 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41250, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009, duration(ns): 9559451
2020-04-02 05:05:52,211 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,213 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56366, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009, duration(ns): 4719200
2020-04-02 05:05:52,213 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246] terminating
2020-04-02 05:05:52,218 [IPC Server handler 6 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:37246, 127.0.0.1:45226 for /tmp.txt
2020-04-02 05:05:52,242 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41254 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010 src: /127.0.0.1:41254 dest: /127.0.0.1:37246
2020-04-02 05:05:52,252 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56374 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010 src: /127.0.0.1:56374 dest: /127.0.0.1:45226
2020-04-02 05:05:52,294 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56374, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010, duration(ns): 26920873
2020-04-02 05:05:52,294 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,295 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41254, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010, duration(ns): 16375789
2020-04-02 05:05:52,295 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226] terminating
2020-04-02 05:05:52,298 [IPC Server handler 1 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:37246, 127.0.0.1:45226 for /tmp.txt
2020-04-02 05:05:52,309 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41260 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011 src: /127.0.0.1:41260 dest: /127.0.0.1:37246
2020-04-02 05:05:52,313 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56380 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011 src: /127.0.0.1:56380 dest: /127.0.0.1:45226
2020-04-02 05:05:52,333 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56380, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011, duration(ns): 19188197
2020-04-02 05:05:52,333 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,334 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41260, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011, duration(ns): 19538458
2020-04-02 05:05:52,334 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226] terminating
2020-04-02 05:05:52,339 [IPC Server handler 8 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:37246, 127.0.0.1:45226 for /tmp.txt
2020-04-02 05:05:52,347 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41264 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012 src: /127.0.0.1:41264 dest: /127.0.0.1:37246
2020-04-02 05:05:52,351 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56384 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012 src: /127.0.0.1:56384 dest: /127.0.0.1:45226
2020-04-02 05:05:52,382 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56384, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012, duration(ns): 30216419
2020-04-02 05:05:52,382 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,383 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41264, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012, duration(ns): 19769290
2020-04-02 05:05:52,384 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226] terminating
2020-04-02 05:05:52,388 [IPC Server handler 9 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:45226, 127.0.0.1:37246 for /tmp.txt
2020-04-02 05:05:52,421 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56386 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013 src: /127.0.0.1:56386 dest: /127.0.0.1:45226
2020-04-02 05:05:52,458 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41270 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013 src: /127.0.0.1:41270 dest: /127.0.0.1:37246
2020-04-02 05:05:52,476 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41270, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013, duration(ns): 14143988
2020-04-02 05:05:52,476 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,477 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56386, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013, duration(ns): 15131905
2020-04-02 05:05:52,477 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246] terminating
2020-04-02 05:05:52,484 [IPC Server handler 2 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:45226, 127.0.0.1:37246 for /tmp.txt
2020-04-02 05:05:52,521 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56390 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014 src: /127.0.0.1:56390 dest: /127.0.0.1:45226
2020-04-02 05:05:52,546 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41274 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014 src: /127.0.0.1:41274 dest: /127.0.0.1:37246
2020-04-02 05:05:52,590 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41274, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014, duration(ns): 37526002
2020-04-02 05:05:52,590 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,591 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56390, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014, duration(ns): 29582445
2020-04-02 05:05:52,591 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:37246] terminating
2020-04-02 05:05:52,595 [IPC Server handler 5 on 41168] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:37246, 127.0.0.1:45226 for /tmp.txt
2020-04-02 05:05:52,608 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:41278 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015 src: /127.0.0.1:41278 dest: /127.0.0.1:37246
2020-04-02 05:05:52,616 [DataXceiver for client DFSClient_NONMAPREDUCE_-21318846_1 at /127.0.0.1:56398 [Receiving block BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015 src: /127.0.0.1:56398 dest: /127.0.0.1:45226
2020-04-02 05:05:52,634 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56398, dest: /127.0.0.1:45226, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: fc7da941-4cf8-40c2-bf9a-8dfcba457a18, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015, duration(ns): 17193443
2020-04-02 05:05:52,634 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:52,637 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41278, dest: /127.0.0.1:37246, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-21318846_1, offset: 0, srvID: ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b, blockid: BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015, duration(ns): 10913789
2020-04-02 05:05:52,637 [PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45226] terminating
2020-04-02 05:05:52,644 [IPC Server handler 7 on 41168] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp.txt is closed by DFSClient_NONMAPREDUCE_-21318846_1
2020-04-02 05:05:52,646 [IPC Server handler 6 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp.txt	dst=null	perm=null	proto=rpc
2020-04-02 05:05:52,651 [IPC Server handler 4 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/tmp.txt	dst=null	perm=null	proto=rpc
All blocks of file /tmp.txt verified to have replication factor 2
2020-04-02 05:05:52,658 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:52,658 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 2 with hostname set to: host2.foo.com
2020-04-02 05:05:52,658 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host2.foo.com to rack /rack2
2020-04-02 05:05:52,671 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803952667,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:52,674 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:52,675 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:52,681 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:52,681 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:52,682 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,682 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:52,682 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host2.foo.com
2020-04-02 05:05:52,683 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,683 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:52,683 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:52,684 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:52,685 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40671
2020-04-02 05:05:52,685 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:52,685 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:52,687 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,689 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:52,690 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:52,691 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,692 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:52,693 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:52,693 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:52,693 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:52,694 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37272
2020-04-02 05:05:52,694 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:52,696 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f63c44f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:52,697 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62a8fd44{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:52,703 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@155d1021{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:52,715 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4bd2f0dc{HTTP/1.1,[http/1.1]}{localhost:37272}
2020-04-02 05:05:52,715 [main] INFO  server.Server (Server.java:doStart(419)) - Started @19031ms
2020-04-02 05:05:52,759 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:33969
2020-04-02 05:05:52,762 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:52,762 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:52,762 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:52,763 [Socket Reader #1 for port 35264] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35264
2020-04-02 05:05:52,768 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@deb3b60] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:52,771 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35264
2020-04-02 05:05:52,775 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:52,775 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:52,776 [Thread-352] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41168 starting to offer service
2020-04-02 05:05:52,807 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:40671 to rack /rack2
2020-04-02 05:05:52,813 [IPC Server listener on 35264] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35264: starting
2020-04-02 05:05:52,846 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:52,855 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35264 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:52,889 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803952888,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:52,925 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803952924,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:52,936 [Socket Reader #1 for port 41168] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:52,945 [Thread-352] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41168
2020-04-02 05:05:52,953 [Thread-352] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 56bec9b3-171b-4ea0-ad58-615c3a9d27d2
2020-04-02 05:05:52,954 [Thread-352] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:05:52,954 [Thread-352] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,955 [Thread-352] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@51604367
2020-04-02 05:05:52,957 [Socket Reader #1 for port 41168] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:52,959 [Thread-352] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@51604367
2020-04-02 05:05:52,959 [Thread-352] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:05:52,965 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid 56bec9b3-171b-4ea0-ad58-615c3a9d27d2) service to localhost/127.0.0.1:41168 beginning handshake with NN
2020-04-02 05:05:52,969 [IPC Server handler 2 on 41168] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40671, datanodeUuid=56bec9b3-171b-4ea0-ad58-615c3a9d27d2, infoPort=0, infoSecurePort=33969, ipcPort=35264, storageInfo=lv=-57;cid=testClusterID;nsid=1505629276;c=1585803949704) storage 56bec9b3-171b-4ea0-ad58-615c3a9d27d2
2020-04-02 05:05:52,969 [IPC Server handler 2 on 41168] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack2/127.0.0.1:40671
2020-04-02 05:05:52,969 [IPC Server handler 2 on 41168] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 56bec9b3-171b-4ea0-ad58-615c3a9d27d2 (127.0.0.1:40671).
2020-04-02 05:05:52,970 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid 56bec9b3-171b-4ea0-ad58-615c3a9d27d2) service to localhost/127.0.0.1:41168 successfully registered with NN
2020-04-02 05:05:52,970 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-578793322-172.17.0.6-1585803949704 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:05:52,970 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:52,970 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41168 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:05:52,979 [IPC Server handler 0 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:52,982 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:40671
2020-04-02 05:05:52,982 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:52,982 [IPC Server handler 3 on 41168] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-e68d80e9-1566-4726-9e52-ccb7f32dbccc for DN 127.0.0.1:40671
2020-04-02 05:05:52,990 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x88c42f7cfc066314: Processing first storage report for SimulatedStorage-DS-e68d80e9-1566-4726-9e52-ccb7f32dbccc from datanode 56bec9b3-171b-4ea0-ad58-615c3a9d27d2
2020-04-02 05:05:52,990 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x88c42f7cfc066314: from storage SimulatedStorage-DS-e68d80e9-1566-4726-9e52-ccb7f32dbccc node DatanodeRegistration(127.0.0.1:40671, datanodeUuid=56bec9b3-171b-4ea0-ad58-615c3a9d27d2, infoPort=0, infoSecurePort=33969, ipcPort=35264, storageInfo=lv=-57;cid=testClusterID;nsid=1505629276;c=1585803949704), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:52,994 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x88c42f7cfc066314,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:52,994 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-578793322-172.17.0.6-1585803949704
2020-04-02 05:05:53,084 [IPC Server handler 9 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:53,086 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:53,400 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(984)) - namenodes  = [hdfs://localhost:41168]
2020-04-02 05:05:53,401 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(985)) - parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]
2020-04-02 05:05:53,401 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(986)) - Print stack trace
java.lang.Throwable
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:986)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:945)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:921)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:793)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:787)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.twoNodeTest(TestBalancer.java:1099)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1209)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Integrity(TestBalancerWithSaslDataTransfer.java:34)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved
2020-04-02 05:05:53,415 [Socket Reader #1 for port 41168] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:53,443 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(75)) - Block token params received from NN: update interval=10hrs, 0sec, token lifetime=10hrs, 0sec
2020-04-02 05:05:53,444 [main] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:53,444 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(172)) - Update block keys every 2hrs, 30mins, 0sec
2020-04-02 05:05:53,445 [IPC Server handler 8 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:05:53,448 [IPC Server handler 9 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/system/balancer.id	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:53,452 [IPC Server handler 7 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:05:53,458 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:05:53,458 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:05:53,458 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:05:53,459 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:05:53,459 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:05:53,459 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:05:53,459 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:53,459 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:53,462 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:05:53,462 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:05:53,466 [IPC Server handler 6 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:53,468 [org.apache.hadoop.hdfs.server.balancer.KeyManager$BlockKeyUpdater@78c7f9b3] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:05:53,468 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:45226
2020-04-02 05:05:53,469 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack1/127.0.0.1:37246
2020-04-02 05:05:53,469 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack2/127.0.0.1:40671
2020-04-02 05:05:53,469 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:05:53,469 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 2 above-average: [127.0.0.1:45226:DISK, 127.0.0.1:37246:DISK]
2020-04-02 05:05:53,470 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 below-average: []
2020-04-02 05:05:53,470 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 1 underutilized: [127.0.0.1:40671:DISK]
2020-04-02 05:05:53,470 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(615)) - Need to move 500 B to make the cluster balanced.
2020-04-02 05:05:53,477 [IPC Server handler 2 on 41168] INFO  namenode.NameNode (NameNodeRpcServer.java:rollingUpgrade(1333)) - rollingUpgrade QUERY
2020-04-02 05:05:53,478 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for SAME_RACK: overUtilized => underUtilized
2020-04-02 05:05:53,478 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for SAME_RACK: overUtilized => belowAvgUtilized
2020-04-02 05:05:53,478 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for SAME_RACK: underUtilized => aboveAvgUtilized
2020-04-02 05:05:53,478 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for ANY_OTHER: overUtilized => underUtilized
2020-04-02 05:05:53,478 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for ANY_OTHER: overUtilized => belowAvgUtilized
2020-04-02 05:05:53,479 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for ANY_OTHER: underUtilized => aboveAvgUtilized
2020-04-02 05:05:53,479 [main] INFO  balancer.Balancer (Balancer.java:matchSourceWithTargetToMove(537)) - Decided to move 500 B bytes from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK
2020-04-02 05:05:53,479 [main] INFO  balancer.Balancer (Balancer.java:matchSourceWithTargetToMove(537)) - Decided to move 500 B bytes from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK
2020-04-02 05:05:53,479 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(639)) - Will move 1000 B in this iteration
2020-04-02 05:05:53,479 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1189)) - Balancer allowed RPCs per sec = 20
2020-04-02 05:05:53,479 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1190)) - Balancer concurrent threads = 2
2020-04-02 05:05:53,480 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1191)) - Disperse Interval sec = 0
2020-04-02 05:05:53,480 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1207)) - Limiting threads per target to the specified max.
2020-04-02 05:05:53,480 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1210)) - Allocating 50 threads per target.
2020-04-02 05:05:53,488 [pool-55-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741831_1007 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,501 [pool-55-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741832_1008 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,508 [pool-56-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741831_1007 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,518 [pool-55-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741833_1009 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,522 [pool-56-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741832_1008 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,522 [pool-55-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741834_1010 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,522 [pool-56-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741833_1009 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,524 [pool-56-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741834_1010 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,530 [pool-55-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741835_1011 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,541 [pool-56-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741835_1011 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,587 [DataXceiver for client /127.0.0.1:52042 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007 from fc7da941-4cf8-40c2-bf9a-8dfcba457a18]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007 from /127.0.0.1:52042, delHint=fc7da941-4cf8-40c2-bf9a-8dfcba457a18
2020-04-02 05:05:53,589 [DataXceiver for client /127.0.0.1:56418 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741831_1007 to /127.0.0.1:56418
2020-04-02 05:05:53,591 [pool-56-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741831_1007 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,593 [DataXceiver for client /127.0.0.1:41302 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008 to /127.0.0.1:41302
2020-04-02 05:05:53,594 [DataXceiver for client /127.0.0.1:52048 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008 from fc7da941-4cf8-40c2-bf9a-8dfcba457a18]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741832_1008 from /127.0.0.1:52048, delHint=fc7da941-4cf8-40c2-bf9a-8dfcba457a18
2020-04-02 05:05:53,594 [pool-56-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741832_1008 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,640 [DataXceiver for client /127.0.0.1:56422 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011 to /127.0.0.1:56422
2020-04-02 05:05:53,641 [DataXceiver for client /127.0.0.1:52050 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011 from fc7da941-4cf8-40c2-bf9a-8dfcba457a18]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741835_1011 from /127.0.0.1:52050, delHint=fc7da941-4cf8-40c2-bf9a-8dfcba457a18
2020-04-02 05:05:53,654 [pool-56-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741835_1011 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,655 [pool-55-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741836_1012 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,658 [pool-55-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741837_1013 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,658 [pool-56-thread-6] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741836_1012 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,658 [pool-55-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741838_1014 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,658 [pool-56-thread-7] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741837_1013 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,659 [pool-55-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741839_1015 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,659 [pool-56-thread-8] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741838_1014 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,660 [pool-55-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,660 [pool-56-thread-9] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741839_1015 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,661 [pool-56-thread-10] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,696 [DataXceiver for client /127.0.0.1:56446 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015 to /127.0.0.1:56446
2020-04-02 05:05:53,697 [DataXceiver for client /127.0.0.1:41308 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010 to /127.0.0.1:41308
2020-04-02 05:05:53,698 [DataXceiver for client /127.0.0.1:52070 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015 from ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741839_1015 from /127.0.0.1:52070, delHint=ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b
2020-04-02 05:05:53,700 [DataXceiver for client /127.0.0.1:41306 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009 to /127.0.0.1:41306
2020-04-02 05:05:53,702 [pool-56-thread-9] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741839_1015 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
2020-04-02 05:05:53,702 [DataXceiver for client /127.0.0.1:41324 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014 to /127.0.0.1:41324
2020-04-02 05:05:53,704 [DataXceiver for client /127.0.0.1:41326 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013 to /127.0.0.1:41326
2020-04-02 05:05:53,705 [DataXceiver for client /127.0.0.1:41330 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001 to /127.0.0.1:41330
2020-04-02 05:05:53,707 [DataXceiver for client /127.0.0.1:52072 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001 from ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741825_1001 from /127.0.0.1:52072, delHint=ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b
2020-04-02 05:05:53,707 [DataXceiver for client /127.0.0.1:52046 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010 from fc7da941-4cf8-40c2-bf9a-8dfcba457a18]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741834_1010 from /127.0.0.1:52046, delHint=fc7da941-4cf8-40c2-bf9a-8dfcba457a18
2020-04-02 05:05:53,708 [pool-56-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741834_1010 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,726 [pool-56-thread-10] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,726 [DataXceiver for client /127.0.0.1:52044 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009 from fc7da941-4cf8-40c2-bf9a-8dfcba457a18]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741833_1009 from /127.0.0.1:52044, delHint=fc7da941-4cf8-40c2-bf9a-8dfcba457a18
2020-04-02 05:05:53,727 [pool-56-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741833_1009 with size=100 from 127.0.0.1:45226:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,727 [DataXceiver for client /127.0.0.1:52066 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013 from ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741837_1013 from /127.0.0.1:52066, delHint=ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b
2020-04-02 05:05:53,733 [DataXceiver for client /127.0.0.1:52068 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014 from ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741838_1014 from /127.0.0.1:52068, delHint=ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b
2020-04-02 05:05:53,735 [DataXceiver for client /127.0.0.1:56450 [Copying block BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012 to /127.0.0.1:56450
2020-04-02 05:05:53,737 [pool-56-thread-7] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741837_1013 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,742 [pool-56-thread-8] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741838_1014 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:37246
2020-04-02 05:05:53,742 [DataXceiver for client /127.0.0.1:52064 [Replacing block BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012 from ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-578793322-172.17.0.6-1585803949704:blk_1073741836_1012 from /127.0.0.1:52064, delHint=ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b
2020-04-02 05:05:53,743 [pool-56-thread-6] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741836_1012 with size=100 from 127.0.0.1:37246:DISK to 127.0.0.1:40671:DISK through 127.0.0.1:45226
Apr 2, 2020 5:05:54 AM            0               1000 B               500 B             1000 B
2020-04-02 05:05:57,662 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:05:57,663 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:05:57,663 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:05:57,663 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:05:57,663 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:05:57,663 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:05:57,664 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:57,664 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:57,664 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:05:57,664 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:05:57,666 [IPC Server handler 6 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:57,667 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack2/127.0.0.1:40671
2020-04-02 05:05:57,667 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack1/127.0.0.1:37246
2020-04-02 05:05:57,667 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:45226
2020-04-02 05:05:57,667 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:05:57,667 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 above-average: []
2020-04-02 05:05:57,668 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 3 below-average: [127.0.0.1:40671:DISK, 127.0.0.1:37246:DISK, 127.0.0.1:45226:DISK]
2020-04-02 05:05:57,668 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 underutilized: []
The cluster is balanced. Exiting...
Apr 2, 2020 5:05:57 AM            1               1000 B                 0 B                0 B
2020-04-02 05:05:57,670 [IPC Server handler 4 on 41168] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /system/balancer.id is closed by DFSClient_NONMAPREDUCE_933701597_1
2020-04-02 05:05:57,672 [IPC Server handler 1 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=delete	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:05:57,674 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(956)) -   .
2020-04-02 05:05:57,676 [IPC Server handler 0 on 41168] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:57,677 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:57,678 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:05:57,678 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35264 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:57,688 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@705202d1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:57,833 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@155d1021{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:57,839 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4bd2f0dc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:57,842 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62a8fd44{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:57,842 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f63c44f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:57,862 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35264
2020-04-02 05:05:57,901 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:57,902 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid 56bec9b3-171b-4ea0-ad58-615c3a9d27d2) service to localhost/127.0.0.1:41168
2020-04-02 05:05:57,902 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid 56bec9b3-171b-4ea0-ad58-615c3a9d27d2)
2020-04-02 05:05:57,905 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:57,906 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:57,906 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:05:57,906 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35361 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:57,906 [IPC Server listener on 35264] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35264
2020-04-02 05:05:57,988 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@60c16548] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:57,990 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7f9e1534{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:57,996 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@138a7441{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:57,996 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@534243e4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:57,997 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b56b654{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:58,014 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35361
2020-04-02 05:05:58,074 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:58,075 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:58,075 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b) service to localhost/127.0.0.1:41168
2020-04-02 05:05:58,075 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid ff6fa16c-82b7-4e2d-9cc3-5382fe00d26b)
2020-04-02 05:05:58,076 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:58,076 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:58,076 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41635 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:58,076 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1fd386c3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:58,078 [IPC Server listener on 35361] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35361
2020-04-02 05:05:58,079 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid fc7da941-4cf8-40c2-bf9a-8dfcba457a18) service to localhost/127.0.0.1:41168
2020-04-02 05:05:58,079 [BP-578793322-172.17.0.6-1585803949704 heartbeating to localhost/127.0.0.1:41168] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-578793322-172.17.0.6-1585803949704 (Datanode Uuid fc7da941-4cf8-40c2-bf9a-8dfcba457a18)
2020-04-02 05:05:58,172 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2bfeb1ef{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:58,174 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@778ca8ef{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:58,182 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@680362a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:58,183 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60e949e1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:58,199 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41635
2020-04-02 05:05:58,201 [IPC Server listener on 41635] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41635
2020-04-02 05:05:58,203 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:58,205 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:58,205 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:58,232 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 41168 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:58,232 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:58,233 [Thread[Thread-195,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:05:58,233 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 54
2020-04-02 05:05:58,233 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 55 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 30 Number of syncs: 26 SyncTimes(ms): 4 2 
2020-04-02 05:05:58,234 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:05:58,234 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4287d447] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:58,235 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3af37506] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:58,235 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:05:58,235 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:58,250 [CacheReplicationMonitor(1721346700)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:58,265 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41168
2020-04-02 05:05:58,265 [IPC Server listener on 41168] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41168
2020-04-02 05:05:58,286 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:58,293 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:58,294 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:58,306 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:58,306 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:58,310 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@49d98dc5{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:58,332 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@ec50f54{SSL,[ssl, http/1.1]}{localhost:39229}
2020-04-02 05:05:58,333 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1da6ee17{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:58,334 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1bdbf9be{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:58,342 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:05:58,364 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:05:58,365 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer#testBalancer0Integrity
[msx] writeFile testName = org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer#testBalancer0Integrity
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer#testBalancer0Authentication
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:58,482 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(819)) - capacities = [5000]
2020-04-02 05:05:58,482 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(820)) - racks      = [/rack0]
2020-04-02 05:05:58,482 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(821)) - newCapacity= 2500
2020-04-02 05:05:58,482 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(822)) - newRack    = /rack0
2020-04-02 05:05:58,483 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(823)) - useTool    = false
2020-04-02 05:05:58,483 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-04-02 05:05:58,497 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803958496,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:58,499 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:05:58,500 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:58,501 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:58,509 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:58,509 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:58,509 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:58,509 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:58,510 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:58,510 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:58,510 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:58,511 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:58,511 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:58,511 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:58,511 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:58,511 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:58,512 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:58,512 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:58
2020-04-02 05:05:58,512 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:58,512 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:58,513 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:58,513 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:58,554 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:58,555 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:58,555 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:58,555 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:58,556 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:05:58,562 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:58,562 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:58,562 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:58,562 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:58,563 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:58,563 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:05:58,563 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:58,563 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:58,563 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:58,563 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:05:58,563 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:58,563 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:58,564 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:58,564 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:58,564 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:58,565 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:58,577 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:58,577 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:58,577 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:58,578 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:58,578 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:58,578 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:58,578 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:58,578 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:58,579 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:58,579 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:58,581 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:58,581 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:58,581 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:58,582 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:58,582 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:58,582 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:58,582 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:58,582 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:58,582 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:58,584 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1975746625-172.17.0.6-1585803958584
2020-04-02 05:05:58,587 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:58,589 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:58,608 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:58,608 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:58,624 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:58,641 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:05:58,648 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:58,655 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:58,666 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:58,672 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:58,673 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:58,675 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:58,676 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:58,690 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803958689,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:58,693 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:58,743 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:58,744 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b6e8f77] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:58,744 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:05:58,744 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:58,746 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:58,754 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:58,754 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:58,756 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:58,757 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:58,757 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:58,757 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:58,760 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:58,760 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:58,761 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:05:58,761 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:05:58,761 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41096
2020-04-02 05:05:58,761 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:58,777 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27e32fe4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:58,778 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@17d238b1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:58,791 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:58,792 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:05:58,793 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@31ff1390{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:58,803 [main] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@759d81f3(server,h=[],w=[]) for SslContextFactory@781a9412(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:05:58,805 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5a4c638d{SSL,[ssl, http/1.1]}{localhost:41096}
2020-04-02 05:05:58,805 [main] INFO  server.Server (Server.java:doStart(419)) - Started @25120ms
2020-04-02 05:05:58,831 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:58,831 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:58,838 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:58,838 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:58,838 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:58,838 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:58,839 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:58,839 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:58,839 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:58,840 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:58,840 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:58,840 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:58,840 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:58,840 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:58,841 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:58,841 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:58
2020-04-02 05:05:58,841 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:58,846 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:58,846 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:58,846 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:59,006 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,006 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,006 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:05:59,007 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:05:59,007 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:05:59,007 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,008 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:59,008 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:59,008 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:59,008 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:59,008 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:05:59,008 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:59,008 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:59,008 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:59,009 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:05:59,009 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:59,009 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:59,009 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:59,009 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,010 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:59,010 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:59,013 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:59,013 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:59,014 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:59,014 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:59,014 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:59,014 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:59,014 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:59,014 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,015 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:59,015 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:59,017 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:59,017 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:59,018 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:59,018 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:59,018 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:59,018 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:59,031 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,035 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:59,035 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:59,046 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:05:59,047 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:05:59,059 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:59,074 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:59,075 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:59,075 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:59,076 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:59,077 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:59,084 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:59,085 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:59,085 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:59,097 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:59,098 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 61 msecs
2020-04-02 05:05:59,098 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:59,099 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:59,100 [Socket Reader #1 for port 43069] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43069
2020-04-02 05:05:59,104 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:43069 to access this namenode/service.
2020-04-02 05:05:59,143 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:59,226 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:59,239 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:59,241 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:59,241 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@267bbe1a] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:05:59,242 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:59,251 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:59,262 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:59,286 [Thread[Thread-422,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:05:59,286 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:59,286 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:59,286 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:59,286 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:59,286 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:59,286 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 45 msec
2020-04-02 05:05:59,290 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:59,337 [Thread[Thread-422,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:05:59,342 [IPC Server listener on 43069] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43069: starting
2020-04-02 05:05:59,365 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43069
2020-04-02 05:05:59,367 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:59,367 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:59,367 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:59,371 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43069 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:59,416 [CacheReplicationMonitor(1140143724)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:59,465 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803959464,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:59,527 [Socket Reader #1 for port 43069] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:59,564 [IPC Server handler 0 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,570 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:59,577 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:59,578 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 0 with hostname set to: host0.foo.com
2020-04-02 05:05:59,578 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host0.foo.com to rack /rack0
2020-04-02 05:05:59,584 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803959584,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:05:59,587 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:05:59,588 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:59,606 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:59,606 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:59,607 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:59,607 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:59,607 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host0.foo.com
2020-04-02 05:05:59,607 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:59,608 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,608 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,608 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:59,610 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38723
2020-04-02 05:05:59,610 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:59,610 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:59,611 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:59,613 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:59,626 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:59,626 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:59,628 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:59,642 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:59,642 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:59,643 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:59,644 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45412
2020-04-02 05:05:59,644 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:59,649 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6fe46b62{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:59,650 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61e45f87{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:59,659 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30feffc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:59,660 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@67207d8a{HTTP/1.1,[http/1.1]}{localhost:45412}
2020-04-02 05:05:59,660 [main] INFO  server.Server (Server.java:doStart(419)) - Started @25975ms
2020-04-02 05:05:59,693 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:37533
2020-04-02 05:05:59,694 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:59,695 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:59,695 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:59,696 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a619c2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:59,714 [Socket Reader #1 for port 45730] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45730
2020-04-02 05:05:59,745 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45730
2020-04-02 05:05:59,769 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:59,770 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:59,778 [Thread-452] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43069 starting to offer service
2020-04-02 05:05:59,782 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:38723 to rack /rack0
2020-04-02 05:05:59,786 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:59,786 [IPC Server listener on 45730] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45730: starting
2020-04-02 05:05:59,793 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45730 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:59,847 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803959844,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:05:59,909 [Socket Reader #1 for port 43069] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:59,910 [Socket Reader #1 for port 43069] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:05:59,950 [Thread-452] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43069
2020-04-02 05:05:59,957 [IPC Server handler 2 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,958 [Thread-452] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3828d896-221a-41b3-99aa-b8fcd6a5dbec
2020-04-02 05:05:59,959 [Thread-452] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:05:59,959 [Thread-452] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:59,960 [Thread-452] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@5abd6272
2020-04-02 05:05:59,974 [Thread-452] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@5abd6272
2020-04-02 05:05:59,974 [Thread-452] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:05:59,994 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:59,994 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:59,998 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1975746625-172.17.0.6-1585803958584 (Datanode Uuid 3828d896-221a-41b3-99aa-b8fcd6a5dbec) service to localhost/127.0.0.1:43069 beginning handshake with NN
2020-04-02 05:06:00,015 [IPC Server handler 3 on 43069] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38723, datanodeUuid=3828d896-221a-41b3-99aa-b8fcd6a5dbec, infoPort=0, infoSecurePort=37533, ipcPort=45730, storageInfo=lv=-57;cid=testClusterID;nsid=1442450675;c=1585803958584) storage 3828d896-221a-41b3-99aa-b8fcd6a5dbec
2020-04-02 05:06:00,016 [IPC Server handler 3 on 43069] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:38723
2020-04-02 05:06:00,017 [IPC Server handler 3 on 43069] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3828d896-221a-41b3-99aa-b8fcd6a5dbec (127.0.0.1:38723).
2020-04-02 05:06:00,034 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1975746625-172.17.0.6-1585803958584 (Datanode Uuid 3828d896-221a-41b3-99aa-b8fcd6a5dbec) service to localhost/127.0.0.1:43069 successfully registered with NN
2020-04-02 05:06:00,034 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1975746625-172.17.0.6-1585803958584 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:00,035 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:00,035 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43069 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:00,057 [IPC Server handler 4 on 43069] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-b95eba3d-234c-4e8a-ad47-ba68b6134161 for DN 127.0.0.1:38723
2020-04-02 05:06:00,067 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7ed56515a3b55a50: Processing first storage report for SimulatedStorage-DS-b95eba3d-234c-4e8a-ad47-ba68b6134161 from datanode 3828d896-221a-41b3-99aa-b8fcd6a5dbec
2020-04-02 05:06:00,068 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7ed56515a3b55a50: from storage SimulatedStorage-DS-b95eba3d-234c-4e8a-ad47-ba68b6134161 node DatanodeRegistration(127.0.0.1:38723, datanodeUuid=3828d896-221a-41b3-99aa-b8fcd6a5dbec, infoPort=0, infoSecurePort=37533, ipcPort=45730, storageInfo=lv=-57;cid=testClusterID;nsid=1442450675;c=1585803958584), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:00,068 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x7ed56515a3b55a50,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:00,069 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1975746625-172.17.0.6-1585803958584
2020-04-02 05:06:00,097 [IPC Server handler 6 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,108 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:00,115 [IPC Server handler 7 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,116 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:00,120 [IPC Server handler 8 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:00,122 [IPC Server handler 9 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/tmp.txt	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:00,143 [IPC Server handler 0 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,179 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45564 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741825_1001 src: /127.0.0.1:45564 dest: /127.0.0.1:38723
2020-04-02 05:06:00,214 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45564, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741825_1001, duration(ns): 24263807
2020-04-02 05:06:00,214 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,256 [IPC Server handler 3 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,284 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45568 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741826_1002 src: /127.0.0.1:45568 dest: /127.0.0.1:38723
2020-04-02 05:06:00,315 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45568, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741826_1002, duration(ns): 4073508
2020-04-02 05:06:00,315 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,318 [IPC Server handler 4 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,323 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45574 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741827_1003 src: /127.0.0.1:45574 dest: /127.0.0.1:38723
2020-04-02 05:06:00,331 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45574, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741827_1003, duration(ns): 5305009
2020-04-02 05:06:00,332 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,335 [IPC Server handler 6 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,343 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45576 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004 src: /127.0.0.1:45576 dest: /127.0.0.1:38723
2020-04-02 05:06:00,366 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45576, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004, duration(ns): 12228653
2020-04-02 05:06:00,367 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,375 [IPC Server handler 9 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,390 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45578 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005 src: /127.0.0.1:45578 dest: /127.0.0.1:38723
2020-04-02 05:06:00,406 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45578, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005, duration(ns): 15467181
2020-04-02 05:06:00,406 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,410 [IPC Server handler 0 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,417 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45580 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006 src: /127.0.0.1:45580 dest: /127.0.0.1:38723
2020-04-02 05:06:00,438 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45580, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006, duration(ns): 8793676
2020-04-02 05:06:00,439 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,447 [IPC Server handler 3 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,451 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45582 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007 src: /127.0.0.1:45582 dest: /127.0.0.1:38723
2020-04-02 05:06:00,454 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45582, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007, duration(ns): 1212886
2020-04-02 05:06:00,454 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,461 [IPC Server handler 5 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,466 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45584 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008 src: /127.0.0.1:45584 dest: /127.0.0.1:38723
2020-04-02 05:06:00,491 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45584, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008, duration(ns): 2352548
2020-04-02 05:06:00,492 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,499 [IPC Server handler 6 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,503 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45586 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741833_1009 src: /127.0.0.1:45586 dest: /127.0.0.1:38723
2020-04-02 05:06:00,510 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45586, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741833_1009, duration(ns): 5997925
2020-04-02 05:06:00,511 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,513 [IPC Server handler 8 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,519 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45588 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741834_1010 src: /127.0.0.1:45588 dest: /127.0.0.1:38723
2020-04-02 05:06:00,523 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45588, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741834_1010, duration(ns): 2007214
2020-04-02 05:06:00,525 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,530 [IPC Server handler 0 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,571 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45590 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741835_1011 src: /127.0.0.1:45590 dest: /127.0.0.1:38723
2020-04-02 05:06:00,575 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45590, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741835_1011, duration(ns): 3264958
2020-04-02 05:06:00,576 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,578 [IPC Server handler 2 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,589 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45594 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741836_1012 src: /127.0.0.1:45594 dest: /127.0.0.1:38723
2020-04-02 05:06:00,603 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45594, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741836_1012, duration(ns): 12372509
2020-04-02 05:06:00,603 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,607 [IPC Server handler 5 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,618 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45598 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741837_1013 src: /127.0.0.1:45598 dest: /127.0.0.1:38723
2020-04-02 05:06:00,623 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45598, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741837_1013, duration(ns): 2126657
2020-04-02 05:06:00,624 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,625 [IPC Server handler 6 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,630 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45600 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741838_1014 src: /127.0.0.1:45600 dest: /127.0.0.1:38723
2020-04-02 05:06:00,632 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45600, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741838_1014, duration(ns): 513641
2020-04-02 05:06:00,632 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,634 [IPC Server handler 8 on 43069] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:38723 for /tmp.txt
2020-04-02 05:06:00,640 [DataXceiver for client DFSClient_NONMAPREDUCE_-1575487137_1 at /127.0.0.1:45602 [Receiving block BP-1975746625-172.17.0.6-1585803958584:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1975746625-172.17.0.6-1585803958584:blk_1073741839_1015 src: /127.0.0.1:45602 dest: /127.0.0.1:38723
2020-04-02 05:06:00,661 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45602, dest: /127.0.0.1:38723, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1575487137_1, offset: 0, srvID: 3828d896-221a-41b3-99aa-b8fcd6a5dbec, blockid: BP-1975746625-172.17.0.6-1585803958584:blk_1073741839_1015, duration(ns): 19264438
2020-04-02 05:06:00,662 [PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1975746625-172.17.0.6-1585803958584:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:00,672 [IPC Server handler 1 on 43069] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp.txt is closed by DFSClient_NONMAPREDUCE_-1575487137_1
2020-04-02 05:06:00,674 [IPC Server handler 3 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp.txt	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,677 [IPC Server handler 2 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/tmp.txt	dst=null	perm=null	proto=rpc
All blocks of file /tmp.txt verified to have replication factor 1
2020-04-02 05:06:00,695 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:00,695 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 1 with hostname set to: host1.foo.com
2020-04-02 05:06:00,695 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host1.foo.com to rack /rack0
2020-04-02 05:06:00,701 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803960700,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:00,703 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:00,703 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:00,713 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:00,713 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:00,713 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:00,714 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:00,714 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1.foo.com
2020-04-02 05:06:00,714 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:00,714 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:00,714 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:00,715 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:00,715 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37514
2020-04-02 05:06:00,716 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:00,716 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:00,717 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:00,718 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:00,719 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:00,719 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:00,721 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:00,721 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:00,722 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:00,722 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:00,723 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41322
2020-04-02 05:06:00,723 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:00,742 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@72ba28ee{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:00,750 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4ebadd3d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:00,760 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@57bd802b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:00,761 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5cbb84b1{HTTP/1.1,[http/1.1]}{localhost:41322}
2020-04-02 05:06:00,761 [main] INFO  server.Server (Server.java:doStart(419)) - Started @27076ms
2020-04-02 05:06:00,816 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:33363
2020-04-02 05:06:00,817 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:00,817 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:00,817 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5183d589] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:00,818 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:00,823 [Socket Reader #1 for port 35747] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35747
2020-04-02 05:06:00,848 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35747
2020-04-02 05:06:00,853 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:00,853 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:00,857 [Thread-524] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43069 starting to offer service
2020-04-02 05:06:00,858 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:37514 to rack /rack0
2020-04-02 05:06:00,858 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:00,859 [IPC Server listener on 35747] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35747: starting
2020-04-02 05:06:00,860 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35747 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:00,943 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803960942,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:00,966 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803960965,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:00,987 [Socket Reader #1 for port 43069] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:00,988 [Socket Reader #1 for port 43069] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:01,006 [Thread-524] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43069
2020-04-02 05:06:01,007 [Thread-524] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 2fc17d65-d7d3-4de4-84c4-577ba07400d0
2020-04-02 05:06:01,008 [Thread-524] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:06:01,008 [Thread-524] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:01,010 [Thread-524] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@7f3d9cd6
2020-04-02 05:06:01,011 [Thread-524] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@7f3d9cd6
2020-04-02 05:06:01,011 [Thread-524] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:06:01,014 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1975746625-172.17.0.6-1585803958584 (Datanode Uuid 2fc17d65-d7d3-4de4-84c4-577ba07400d0) service to localhost/127.0.0.1:43069 beginning handshake with NN
2020-04-02 05:06:01,016 [IPC Server handler 7 on 43069] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37514, datanodeUuid=2fc17d65-d7d3-4de4-84c4-577ba07400d0, infoPort=0, infoSecurePort=33363, ipcPort=35747, storageInfo=lv=-57;cid=testClusterID;nsid=1442450675;c=1585803958584) storage 2fc17d65-d7d3-4de4-84c4-577ba07400d0
2020-04-02 05:06:01,016 [IPC Server handler 7 on 43069] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:37514
2020-04-02 05:06:01,016 [IPC Server handler 7 on 43069] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2fc17d65-d7d3-4de4-84c4-577ba07400d0 (127.0.0.1:37514).
2020-04-02 05:06:01,022 [IPC Server handler 5 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,024 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1975746625-172.17.0.6-1585803958584 (Datanode Uuid 2fc17d65-d7d3-4de4-84c4-577ba07400d0) service to localhost/127.0.0.1:43069 successfully registered with NN
2020-04-02 05:06:01,024 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1975746625-172.17.0.6-1585803958584 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:01,024 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:01,024 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43069 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:01,027 [IPC Server handler 6 on 43069] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-5dd2356c-3420-4a52-a0ce-eaf8e32fa2ff for DN 127.0.0.1:37514
2020-04-02 05:06:01,030 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc28a1c9ce8dba3a9: Processing first storage report for SimulatedStorage-DS-5dd2356c-3420-4a52-a0ce-eaf8e32fa2ff from datanode 2fc17d65-d7d3-4de4-84c4-577ba07400d0
2020-04-02 05:06:01,030 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc28a1c9ce8dba3a9: from storage SimulatedStorage-DS-5dd2356c-3420-4a52-a0ce-eaf8e32fa2ff node DatanodeRegistration(127.0.0.1:37514, datanodeUuid=2fc17d65-d7d3-4de4-84c4-577ba07400d0, infoPort=0, infoSecurePort=33363, ipcPort=35747, storageInfo=lv=-57;cid=testClusterID;nsid=1442450675;c=1585803958584), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:01,030 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc28a1c9ce8dba3a9,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:01,031 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1975746625-172.17.0.6-1585803958584
2020-04-02 05:06:01,058 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:01,058 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:01,160 [IPC Server handler 0 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,161 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:01,162 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(984)) - namenodes  = [hdfs://localhost:43069]
2020-04-02 05:06:01,163 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(985)) - parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]
2020-04-02 05:06:01,163 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(986)) - Print stack trace
java.lang.Throwable
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:986)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:945)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:921)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:793)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:787)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.oneNodeTest(TestBalancer.java:1093)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1208)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Authentication(TestBalancerWithSaslDataTransfer.java:29)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved
2020-04-02 05:06:01,174 [Socket Reader #1 for port 43069] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:01,184 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(75)) - Block token params received from NN: update interval=10hrs, 0sec, token lifetime=10hrs, 0sec
2020-04-02 05:06:01,185 [main] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:01,185 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(172)) - Update block keys every 2hrs, 30mins, 0sec
2020-04-02 05:06:01,190 [IPC Server handler 7 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,194 [IPC Server handler 5 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/system/balancer.id	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:01,197 [IPC Server handler 6 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,198 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:06:01,198 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:06:01,199 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:06:01,199 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:06:01,199 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:06:01,199 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:06:01,204 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:01,204 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:01,205 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:06:01,205 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:06:01,206 [IPC Server handler 8 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,208 [org.apache.hadoop.hdfs.server.balancer.KeyManager$BlockKeyUpdater@40021799] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:01,208 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:38723
2020-04-02 05:06:01,209 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:37514
2020-04-02 05:06:01,209 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:06:01,209 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 1 above-average: [127.0.0.1:38723:DISK]
2020-04-02 05:06:01,209 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 below-average: []
2020-04-02 05:06:01,209 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 1 underutilized: [127.0.0.1:37514:DISK]
2020-04-02 05:06:01,209 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(615)) - Need to move 250 B to make the cluster balanced.
2020-04-02 05:06:01,212 [IPC Server handler 1 on 43069] INFO  namenode.NameNode (NameNodeRpcServer.java:rollingUpgrade(1333)) - rollingUpgrade QUERY
2020-04-02 05:06:01,213 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for SAME_RACK: overUtilized => underUtilized
2020-04-02 05:06:01,213 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for SAME_RACK: overUtilized => belowAvgUtilized
2020-04-02 05:06:01,213 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for SAME_RACK: underUtilized => aboveAvgUtilized
2020-04-02 05:06:01,213 [main] INFO  balancer.Balancer (Balancer.java:matchSourceWithTargetToMove(537)) - Decided to move 500 B bytes from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK
2020-04-02 05:06:01,213 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for ANY_OTHER: overUtilized => underUtilized
2020-04-02 05:06:01,213 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for ANY_OTHER: overUtilized => belowAvgUtilized
2020-04-02 05:06:01,213 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for ANY_OTHER: underUtilized => aboveAvgUtilized
2020-04-02 05:06:01,213 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(639)) - Will move 500 B in this iteration
2020-04-02 05:06:01,214 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1189)) - Balancer allowed RPCs per sec = 20
2020-04-02 05:06:01,214 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1190)) - Balancer concurrent threads = 1
2020-04-02 05:06:01,214 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1191)) - Disperse Interval sec = 0
2020-04-02 05:06:01,214 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1207)) - Limiting threads per target to the specified max.
2020-04-02 05:06:01,214 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1210)) - Allocating 50 threads per target.
2020-04-02 05:06:01,218 [pool-76-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741828_1004 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,238 [pool-76-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741829_1005 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,238 [pool-77-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741828_1004 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,239 [pool-76-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741830_1006 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,240 [pool-77-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741829_1005 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,244 [pool-76-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741831_1007 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,244 [pool-76-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741832_1008 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,245 [pool-77-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741831_1007 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,244 [pool-77-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741830_1006 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,251 [pool-77-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741832_1008 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,309 [DataXceiver for client /127.0.0.1:45624 [Copying block BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006 to /127.0.0.1:45624
2020-04-02 05:06:01,319 [DataXceiver for client /127.0.0.1:52792 [Replacing block BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006 from 3828d896-221a-41b3-99aa-b8fcd6a5dbec]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1975746625-172.17.0.6-1585803958584:blk_1073741830_1006 from /127.0.0.1:52792, delHint=3828d896-221a-41b3-99aa-b8fcd6a5dbec
2020-04-02 05:06:01,319 [pool-77-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741830_1006 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,326 [DataXceiver for client /127.0.0.1:45626 [Copying block BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008 to /127.0.0.1:45626
2020-04-02 05:06:01,327 [DataXceiver for client /127.0.0.1:52794 [Replacing block BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008 from 3828d896-221a-41b3-99aa-b8fcd6a5dbec]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1975746625-172.17.0.6-1585803958584:blk_1073741832_1008 from /127.0.0.1:52794, delHint=3828d896-221a-41b3-99aa-b8fcd6a5dbec
2020-04-02 05:06:01,328 [pool-77-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741832_1008 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,333 [DataXceiver for client /127.0.0.1:45630 [Copying block BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007 to /127.0.0.1:45630
2020-04-02 05:06:01,333 [DataXceiver for client /127.0.0.1:52790 [Replacing block BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007 from 3828d896-221a-41b3-99aa-b8fcd6a5dbec]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1975746625-172.17.0.6-1585803958584:blk_1073741831_1007 from /127.0.0.1:52790, delHint=3828d896-221a-41b3-99aa-b8fcd6a5dbec
2020-04-02 05:06:01,334 [pool-77-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741831_1007 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,337 [DataXceiver for client /127.0.0.1:45632 [Copying block BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005 to /127.0.0.1:45632
2020-04-02 05:06:01,337 [DataXceiver for client /127.0.0.1:52788 [Replacing block BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005 from 3828d896-221a-41b3-99aa-b8fcd6a5dbec]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1975746625-172.17.0.6-1585803958584:blk_1073741829_1005 from /127.0.0.1:52788, delHint=3828d896-221a-41b3-99aa-b8fcd6a5dbec
2020-04-02 05:06:01,337 [pool-77-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741829_1005 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
2020-04-02 05:06:01,340 [DataXceiver for client /127.0.0.1:45628 [Copying block BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004 to /127.0.0.1:45628
2020-04-02 05:06:01,340 [DataXceiver for client /127.0.0.1:52786 [Replacing block BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004 from 3828d896-221a-41b3-99aa-b8fcd6a5dbec]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1975746625-172.17.0.6-1585803958584:blk_1073741828_1004 from /127.0.0.1:52786, delHint=3828d896-221a-41b3-99aa-b8fcd6a5dbec
2020-04-02 05:06:01,341 [pool-77-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741828_1004 with size=100 from 127.0.0.1:38723:DISK to 127.0.0.1:37514:DISK through 127.0.0.1:38723
Apr 2, 2020 5:06:02 AM            0                500 B               250 B              500 B
2020-04-02 05:06:05,270 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:06:05,270 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:06:05,270 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:06:05,271 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:06:05,271 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:06:05,271 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:06:05,272 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,272 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,272 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:06:05,272 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:06:05,273 [IPC Server handler 2 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,274 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:38723
2020-04-02 05:06:05,275 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:37514
2020-04-02 05:06:05,275 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:06:05,275 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 above-average: []
2020-04-02 05:06:05,275 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 2 below-average: [127.0.0.1:38723:DISK, 127.0.0.1:37514:DISK]
2020-04-02 05:06:05,275 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 underutilized: []
The cluster is balanced. Exiting...
Apr 2, 2020 5:06:05 AM            1                500 B                 0 B                0 B
2020-04-02 05:06:05,277 [IPC Server handler 4 on 43069] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /system/balancer.id is closed by DFSClient_NONMAPREDUCE_-1373840488_1
2020-04-02 05:06:05,283 [IPC Server handler 7 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=delete	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,284 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(956)) -   .
2020-04-02 05:06:05,285 [IPC Server handler 6 on 43069] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,286 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:05,286 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:05,287 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35747 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:05,321 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6d367020] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:05,439 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@57bd802b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:05,442 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5cbb84b1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:05,442 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4ebadd3d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:05,443 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@72ba28ee{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:05,445 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35747
2020-04-02 05:06:05,480 [IPC Server listener on 35747] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35747
2020-04-02 05:06:05,482 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:05,482 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1975746625-172.17.0.6-1585803958584 (Datanode Uuid 2fc17d65-d7d3-4de4-84c4-577ba07400d0) service to localhost/127.0.0.1:43069
2020-04-02 05:06:05,482 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1975746625-172.17.0.6-1585803958584 (Datanode Uuid 2fc17d65-d7d3-4de4-84c4-577ba07400d0)
2020-04-02 05:06:05,483 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:05,483 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:05,483 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45730 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:05,485 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:05,509 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@66908383] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:05,525 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30feffc{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:05,525 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@67207d8a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:05,526 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61e45f87{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:05,526 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6fe46b62{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:05,534 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45730
2020-04-02 05:06:05,536 [IPC Server listener on 45730] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45730
2020-04-02 05:06:05,559 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:05,559 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:05,559 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1975746625-172.17.0.6-1585803958584 (Datanode Uuid 3828d896-221a-41b3-99aa-b8fcd6a5dbec) service to localhost/127.0.0.1:43069
2020-04-02 05:06:05,559 [BP-1975746625-172.17.0.6-1585803958584 heartbeating to localhost/127.0.0.1:43069] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1975746625-172.17.0.6-1585803958584 (Datanode Uuid 3828d896-221a-41b3-99aa-b8fcd6a5dbec)
2020-04-02 05:06:05,576 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:05,585 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:05,589 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43069 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:05,589 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:05,590 [Thread[Thread-422,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:06:05,592 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 54
2020-04-02 05:06:05,592 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@779de014] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:05,594 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@757529a4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:05,594 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 55 Total time for transactions(ms): 32 Number of transactions batched in Syncs: 27 Number of syncs: 29 SyncTimes(ms): 4 2 
2020-04-02 05:06:05,595 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:06:05,596 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:06:05,599 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:05,600 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43069
2020-04-02 05:06:05,601 [CacheReplicationMonitor(1140143724)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:05,602 [IPC Server listener on 43069] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43069
2020-04-02 05:06:05,605 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:05,605 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:05,609 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:05,656 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:05,657 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:05,659 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@31ff1390{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:05,661 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5a4c638d{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:06:05,661 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@17d238b1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:05,678 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27e32fe4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:05,681 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:05,709 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:05,709 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:06:05,725 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(819)) - capacities = [5000, 5000]
2020-04-02 05:06:05,725 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(820)) - racks      = [/rack0, /rack1]
2020-04-02 05:06:05,726 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(821)) - newCapacity= 5000
2020-04-02 05:06:05,726 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(822)) - newRack    = /rack2
2020-04-02 05:06:05,735 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(823)) - useTool    = false
2020-04-02 05:06:05,736 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-04-02 05:06:05,748 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803965747,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:05,750 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:06:05,751 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:05,751 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:05,751 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:05,752 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:05,752 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:05,752 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:05,752 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:05,752 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:05,753 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:05,756 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,756 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:05,756 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:05,757 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,757 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:05,757 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:05,757 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:05
2020-04-02 05:06:05,757 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:05,758 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:05,758 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:05,758 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:05,762 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,763 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,763 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:06:05,763 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:06:05,763 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:05,764 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,764 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:05,764 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:05,764 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:05,764 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:05,764 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:06:05,765 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:05,765 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:05,765 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:05,765 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:05,765 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:05,765 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:05,767 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:05,768 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:05,768 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:05,768 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:05,770 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:05,770 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:05,771 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:05,771 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:05,771 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:05,771 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:05,771 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:05,771 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:05,772 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:05,772 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:05,773 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:05,773 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:05,773 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:05,773 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:05,773 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:05,774 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:05,774 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:05,774 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:05,774 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:05,775 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1715164147-172.17.0.6-1585803965775
2020-04-02 05:06:05,777 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:05,779 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:05,809 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:05,815 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:06:05,822 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:05,833 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:06:05,844 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:05,845 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:05,851 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:05,862 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:05,862 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:05,863 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:05,864 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:05,868 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803965867,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:05,875 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:05,882 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@67a056f1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:05,882 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:06:05,883 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:41096
2020-04-02 05:06:05,883 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:05,884 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:05,890 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:05,890 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:05,891 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:05,892 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:05,892 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:05,892 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:05,894 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:05,895 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:05,895 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:06:05,895 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:06:05,895 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41096
2020-04-02 05:06:05,895 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:05,911 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fedfe27{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:05,912 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d4664d7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:05,922 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:06:05,923 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:06:05,924 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27b22f74{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:05,925 [main] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@22fba58c(server,h=[],w=[]) for SslContextFactory@7e8a46b7(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:06:05,927 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2fe88a09{SSL,[ssl, http/1.1]}{localhost:41096}
2020-04-02 05:06:05,927 [main] INFO  server.Server (Server.java:doStart(419)) - Started @32242ms
2020-04-02 05:06:05,928 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:05,929 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:05,929 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:05,929 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:05,929 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:05,929 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:05,930 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:05,930 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:05,930 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:05,931 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,931 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:05,931 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:05,931 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,931 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:05,931 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:05,932 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:05
2020-04-02 05:06:05,932 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:05,932 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:05,932 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:05,932 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:05,936 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,937 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,937 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:06:05,950 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:06:05,950 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:05,951 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:05,951 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:05,951 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:05,951 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:05,952 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:05,952 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:06:05,952 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:05,952 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:05,952 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:05,953 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:05,953 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:05,953 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:05,953 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:05,970 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:05,970 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:05,970 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:05,972 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:05,972 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:05,972 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:05,973 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:05,973 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:05,973 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:05,973 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:05,974 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:05,974 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:05,974 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:05,975 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:05,975 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:05,975 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:05,975 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:05,975 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:05,976 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:05,976 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:05,976 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:05,976 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:05,979 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:06:05,987 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:06:05,989 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:05,994 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:05,995 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:05,995 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:05,996 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:05,997 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:05,997 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:05,997 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:05,998 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:06,036 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:06,036 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 59 msecs
2020-04-02 05:06:06,037 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:06,037 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:06,037 [Socket Reader #1 for port 34821] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34821
2020-04-02 05:06:06,056 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:34821 to access this namenode/service.
2020-04-02 05:06:06,057 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:06,143 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:06,150 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:06,151 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:06,151 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:06:06,151 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:06,194 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@4aac85fa] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:06:06,197 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:06:06,236 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:06,236 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:06,237 [IPC Server listener on 34821] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34821: starting
2020-04-02 05:06:06,236 [Thread[Thread-578,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:06:06,276 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:34821
2020-04-02 05:06:06,237 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:06,282 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:06,282 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:06,282 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:06,282 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 132 msec
2020-04-02 05:06:06,285 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:06,286 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:06,301 [Thread[Thread-578,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:06:06,306 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 20 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:06,322 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 34821 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:06,416 [CacheReplicationMonitor(1192458637)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:06,470 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803966470,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:06,505 [Socket Reader #1 for port 34821] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:06,559 [IPC Server handler 1 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,564 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:06,571 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:06,572 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 0 with hostname set to: host0.foo.com
2020-04-02 05:06:06,572 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host0.foo.com to rack /rack0
2020-04-02 05:06:06,603 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803966602,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:06,610 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:06,611 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:06,635 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:06,636 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:06,636 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:06,636 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:06,636 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host0.foo.com
2020-04-02 05:06:06,637 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:06,637 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,637 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,637 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:06,643 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39496
2020-04-02 05:06:06,643 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:06,644 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:06,646 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:06,648 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:06,648 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:06,649 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:06,650 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:06,650 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:06,651 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:06,651 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:06,651 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36034
2020-04-02 05:06:06,651 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:06,670 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d6aca33{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:06,674 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29314cc9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:06,685 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@273842a6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:06,686 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6a969fb8{HTTP/1.1,[http/1.1]}{localhost:36034}
2020-04-02 05:06:06,686 [main] INFO  server.Server (Server.java:doStart(419)) - Started @33002ms
2020-04-02 05:06:06,764 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:42888
2020-04-02 05:06:06,765 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:06,765 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:06,766 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:06,767 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5560bcdf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:06,767 [Socket Reader #1 for port 41393] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41393
2020-04-02 05:06:06,792 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41393
2020-04-02 05:06:06,810 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:06,811 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:06,814 [Thread-608] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34821 starting to offer service
2020-04-02 05:06:06,814 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:39496 to rack /rack0
2020-04-02 05:06:06,815 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:06,815 [IPC Server listener on 41393] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41393: starting
2020-04-02 05:06:06,850 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41393 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:06,851 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:06,851 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 1 with hostname set to: host1.foo.com
2020-04-02 05:06:06,851 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host1.foo.com to rack /rack1
2020-04-02 05:06:06,880 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803966880,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:06,891 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:06,892 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:06,923 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:06,923 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:06,924 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:06,925 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:06,926 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1.foo.com
2020-04-02 05:06:06,927 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:06,927 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,927 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,929 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:06,930 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45766
2020-04-02 05:06:06,930 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:06,931 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:06,956 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:06,958 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:06,968 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803966968,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:06,968 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:06,969 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:06,971 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:06,987 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:06,988 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:06,988 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:07,002 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40564
2020-04-02 05:06:07,009 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:07,004 [Socket Reader #1 for port 34821] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:07,054 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@73877e19{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:07,070 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bfc257{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:07,078 [Thread-608] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34821
2020-04-02 05:06:07,091 [Thread-608] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 15812ad8-a190-4f2d-9f34-dbb0e3ca2866
2020-04-02 05:06:07,092 [Thread-608] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:06:07,092 [Thread-608] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:07,128 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2cfbeac4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:07,129 [Thread-608] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@bb03d95
2020-04-02 05:06:07,129 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@12db3386{HTTP/1.1,[http/1.1]}{localhost:40564}
2020-04-02 05:06:07,129 [main] INFO  server.Server (Server.java:doStart(419)) - Started @33444ms
2020-04-02 05:06:07,131 [Thread-608] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@bb03d95
2020-04-02 05:06:07,131 [Thread-608] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:06:07,160 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid 15812ad8-a190-4f2d-9f34-dbb0e3ca2866) service to localhost/127.0.0.1:34821 beginning handshake with NN
2020-04-02 05:06:07,170 [IPC Server handler 2 on 34821] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39496, datanodeUuid=15812ad8-a190-4f2d-9f34-dbb0e3ca2866, infoPort=0, infoSecurePort=42888, ipcPort=41393, storageInfo=lv=-57;cid=testClusterID;nsid=1067543306;c=1585803965775) storage 15812ad8-a190-4f2d-9f34-dbb0e3ca2866
2020-04-02 05:06:07,171 [IPC Server handler 2 on 34821] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:39496
2020-04-02 05:06:07,172 [IPC Server handler 2 on 34821] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 15812ad8-a190-4f2d-9f34-dbb0e3ca2866 (127.0.0.1:39496).
2020-04-02 05:06:07,201 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid 15812ad8-a190-4f2d-9f34-dbb0e3ca2866) service to localhost/127.0.0.1:34821 successfully registered with NN
2020-04-02 05:06:07,201 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1715164147-172.17.0.6-1585803965775 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:07,201 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:07,201 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34821 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:07,203 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:39763
2020-04-02 05:06:07,204 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:07,204 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a7f0ab6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:07,204 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:07,204 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:07,206 [Socket Reader #1 for port 37064] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37064
2020-04-02 05:06:07,209 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37064
2020-04-02 05:06:07,220 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:07,221 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:07,221 [Thread-632] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34821 starting to offer service
2020-04-02 05:06:07,222 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:45766 to rack /rack1
2020-04-02 05:06:07,227 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:07,286 [IPC Server listener on 37064] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37064: starting
2020-04-02 05:06:07,287 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803967287,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:07,294 [Socket Reader #1 for port 34821] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:07,320 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37064 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:07,321 [IPC Server handler 1 on 34821] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-dc566cc9-ddb6-47d1-8ea3-78b251993c34 for DN 127.0.0.1:39496
2020-04-02 05:06:07,347 [Thread-632] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34821
2020-04-02 05:06:07,360 [Thread-632] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID f2605c05-73ac-437a-bb78-4f56f80aa161
2020-04-02 05:06:07,361 [Thread-632] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:06:07,361 [Thread-632] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:07,373 [Thread-632] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@f094bf3
2020-04-02 05:06:07,374 [Thread-632] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@f094bf3
2020-04-02 05:06:07,379 [Thread-632] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:06:07,384 [Socket Reader #1 for port 34821] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:07,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa58782a41ed9f199: Processing first storage report for SimulatedStorage-DS-dc566cc9-ddb6-47d1-8ea3-78b251993c34 from datanode 15812ad8-a190-4f2d-9f34-dbb0e3ca2866
2020-04-02 05:06:07,386 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa58782a41ed9f199: from storage SimulatedStorage-DS-dc566cc9-ddb6-47d1-8ea3-78b251993c34 node DatanodeRegistration(127.0.0.1:39496, datanodeUuid=15812ad8-a190-4f2d-9f34-dbb0e3ca2866, infoPort=0, infoSecurePort=42888, ipcPort=41393, storageInfo=lv=-57;cid=testClusterID;nsid=1067543306;c=1585803965775), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:07,386 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa58782a41ed9f199,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 27 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:07,387 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1715164147-172.17.0.6-1585803965775
2020-04-02 05:06:07,391 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid f2605c05-73ac-437a-bb78-4f56f80aa161) service to localhost/127.0.0.1:34821 beginning handshake with NN
2020-04-02 05:06:07,406 [IPC Server handler 5 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,408 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:07,408 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:07,408 [IPC Server handler 6 on 34821] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45766, datanodeUuid=f2605c05-73ac-437a-bb78-4f56f80aa161, infoPort=0, infoSecurePort=39763, ipcPort=37064, storageInfo=lv=-57;cid=testClusterID;nsid=1067543306;c=1585803965775) storage f2605c05-73ac-437a-bb78-4f56f80aa161
2020-04-02 05:06:07,409 [IPC Server handler 6 on 34821] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack1/127.0.0.1:45766
2020-04-02 05:06:07,409 [IPC Server handler 6 on 34821] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:checkIfClusterIsNowMultiRack(1386)) - DN 127.0.0.1:45766 joining cluster has expanded a formerly single-rack cluster to be multi-rack. Re-checking all blocks for replication, since they should now be replicated cross-rack
2020-04-02 05:06:07,419 [IPC Server handler 6 on 34821] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f2605c05-73ac-437a-bb78-4f56f80aa161 (127.0.0.1:45766).
2020-04-02 05:06:07,420 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid f2605c05-73ac-437a-bb78-4f56f80aa161) service to localhost/127.0.0.1:34821 successfully registered with NN
2020-04-02 05:06:07,420 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1715164147-172.17.0.6-1585803965775 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:07,421 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:07,421 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34821 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:07,437 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:07,437 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:07,438 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:07,438 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:07,438 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:07,438 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 17 msec
2020-04-02 05:06:07,455 [IPC Server handler 7 on 34821] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-e0cff080-7120-4efd-b84a-a9dd434461de for DN 127.0.0.1:45766
2020-04-02 05:06:07,486 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2dd0763418806fcd: Processing first storage report for SimulatedStorage-DS-e0cff080-7120-4efd-b84a-a9dd434461de from datanode f2605c05-73ac-437a-bb78-4f56f80aa161
2020-04-02 05:06:07,486 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2dd0763418806fcd: from storage SimulatedStorage-DS-e0cff080-7120-4efd-b84a-a9dd434461de node DatanodeRegistration(127.0.0.1:45766, datanodeUuid=f2605c05-73ac-437a-bb78-4f56f80aa161, infoPort=0, infoSecurePort=39763, ipcPort=37064, storageInfo=lv=-57;cid=testClusterID;nsid=1067543306;c=1585803965775), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:07,488 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2dd0763418806fcd,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 11 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:07,488 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1715164147-172.17.0.6-1585803965775
2020-04-02 05:06:07,510 [IPC Server handler 9 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,516 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:07,522 [IPC Server handler 3 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,530 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:07,534 [IPC Server handler 4 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:07,539 [IPC Server handler 0 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/tmp.txt	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:07,570 [IPC Server handler 1 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:45766, 127.0.0.1:39496 for /tmp.txt
2020-04-02 05:06:07,615 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59508 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001 src: /127.0.0.1:59508 dest: /127.0.0.1:45766
2020-04-02 05:06:07,659 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39476 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001 src: /127.0.0.1:39476 dest: /127.0.0.1:39496
2020-04-02 05:06:07,675 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39476, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001, duration(ns): 11823518
2020-04-02 05:06:07,676 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,676 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59508, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001, duration(ns): 14302259
2020-04-02 05:06:07,680 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496] terminating
2020-04-02 05:06:07,695 [IPC Server handler 7 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:45766, 127.0.0.1:39496 for /tmp.txt
2020-04-02 05:06:07,718 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59514 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002 src: /127.0.0.1:59514 dest: /127.0.0.1:45766
2020-04-02 05:06:07,757 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39482 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002 src: /127.0.0.1:39482 dest: /127.0.0.1:39496
2020-04-02 05:06:07,762 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39482, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002, duration(ns): 3638195
2020-04-02 05:06:07,762 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,774 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59514, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002, duration(ns): 13980387
2020-04-02 05:06:07,780 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496] terminating
2020-04-02 05:06:07,783 [IPC Server handler 3 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:45766, 127.0.0.1:39496 for /tmp.txt
2020-04-02 05:06:07,792 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59518 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003 src: /127.0.0.1:59518 dest: /127.0.0.1:45766
2020-04-02 05:06:07,806 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39486 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003 src: /127.0.0.1:39486 dest: /127.0.0.1:39496
2020-04-02 05:06:07,818 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39486, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003, duration(ns): 5091005
2020-04-02 05:06:07,818 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,819 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59518, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003, duration(ns): 6815232
2020-04-02 05:06:07,819 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496] terminating
2020-04-02 05:06:07,821 [IPC Server handler 4 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:39496, 127.0.0.1:45766 for /tmp.txt
2020-04-02 05:06:07,826 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39488 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004 src: /127.0.0.1:39488 dest: /127.0.0.1:39496
2020-04-02 05:06:07,829 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59524 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004 src: /127.0.0.1:59524 dest: /127.0.0.1:45766
2020-04-02 05:06:07,834 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59524, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004, duration(ns): 1300033
2020-04-02 05:06:07,834 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39488, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004, duration(ns): 1833472
2020-04-02 05:06:07,834 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766] terminating
2020-04-02 05:06:07,835 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,836 [IPC Server handler 6 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:45766, 127.0.0.1:39496 for /tmp.txt
2020-04-02 05:06:07,841 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59526 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005 src: /127.0.0.1:59526 dest: /127.0.0.1:45766
2020-04-02 05:06:07,845 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39494 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005 src: /127.0.0.1:39494 dest: /127.0.0.1:39496
2020-04-02 05:06:07,851 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39494, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005, duration(ns): 1063771
2020-04-02 05:06:07,851 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,854 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59526, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005, duration(ns): 6701596
2020-04-02 05:06:07,854 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496] terminating
2020-04-02 05:06:07,861 [IPC Server handler 8 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:39496, 127.0.0.1:45766 for /tmp.txt
2020-04-02 05:06:07,868 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39497 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006 src: /127.0.0.1:39497 dest: /127.0.0.1:39496
2020-04-02 05:06:07,871 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59532 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006 src: /127.0.0.1:59532 dest: /127.0.0.1:45766
2020-04-02 05:06:07,875 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59532, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006, duration(ns): 2941844
2020-04-02 05:06:07,875 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39497, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006, duration(ns): 3585159
2020-04-02 05:06:07,875 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766] terminating
2020-04-02 05:06:07,876 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,883 [IPC Server handler 1 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:45766, 127.0.0.1:39496 for /tmp.txt
2020-04-02 05:06:07,894 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59534 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007 src: /127.0.0.1:59534 dest: /127.0.0.1:45766
2020-04-02 05:06:07,900 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39502 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007 src: /127.0.0.1:39502 dest: /127.0.0.1:39496
2020-04-02 05:06:07,912 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39502, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007, duration(ns): 9763048
2020-04-02 05:06:07,912 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,914 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59534, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007, duration(ns): 7079634
2020-04-02 05:06:07,915 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496] terminating
2020-04-02 05:06:07,916 [IPC Server handler 6 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:39496, 127.0.0.1:45766 for /tmp.txt
2020-04-02 05:06:07,934 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39504 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008 src: /127.0.0.1:39504 dest: /127.0.0.1:39496
2020-04-02 05:06:07,937 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59540 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008 src: /127.0.0.1:59540 dest: /127.0.0.1:45766
2020-04-02 05:06:07,956 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59540, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008, duration(ns): 4424015
2020-04-02 05:06:07,958 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39504, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008, duration(ns): 13758721
2020-04-02 05:06:07,959 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766] terminating
2020-04-02 05:06:07,959 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,960 [IPC Server handler 3 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:45766, 127.0.0.1:39496 for /tmp.txt
2020-04-02 05:06:07,967 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59542 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009 src: /127.0.0.1:59542 dest: /127.0.0.1:45766
2020-04-02 05:06:07,970 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39510 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009 src: /127.0.0.1:39510 dest: /127.0.0.1:39496
2020-04-02 05:06:07,973 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39510, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009, duration(ns): 1548906
2020-04-02 05:06:07,974 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59542, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009, duration(ns): 2773871
2020-04-02 05:06:07,974 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496] terminating
2020-04-02 05:06:07,974 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,979 [IPC Server handler 0 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:45766, 127.0.0.1:39496 for /tmp.txt
2020-04-02 05:06:07,986 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59546 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010 src: /127.0.0.1:59546 dest: /127.0.0.1:45766
2020-04-02 05:06:08,017 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39514 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010 src: /127.0.0.1:39514 dest: /127.0.0.1:39496
2020-04-02 05:06:08,037 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39514, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010, duration(ns): 8699380
2020-04-02 05:06:08,037 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:08,037 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59546, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010, duration(ns): 9285564
2020-04-02 05:06:08,038 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496] terminating
2020-04-02 05:06:08,041 [IPC Server handler 5 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:39496, 127.0.0.1:45766 for /tmp.txt
2020-04-02 05:06:08,048 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39516 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011 src: /127.0.0.1:39516 dest: /127.0.0.1:39496
2020-04-02 05:06:08,066 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59552 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011 src: /127.0.0.1:59552 dest: /127.0.0.1:45766
2020-04-02 05:06:08,102 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59552, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011, duration(ns): 28444005
2020-04-02 05:06:08,103 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:08,110 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39516, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011, duration(ns): 16930411
2020-04-02 05:06:08,110 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766] terminating
2020-04-02 05:06:08,119 [IPC Server handler 3 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:45766, 127.0.0.1:39496 for /tmp.txt
2020-04-02 05:06:08,130 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59554 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012 src: /127.0.0.1:59554 dest: /127.0.0.1:45766
2020-04-02 05:06:08,145 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39522 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012 src: /127.0.0.1:39522 dest: /127.0.0.1:39496
2020-04-02 05:06:08,150 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39522, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012, duration(ns): 3043084
2020-04-02 05:06:08,150 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:08,154 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59554, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012, duration(ns): 5911344
2020-04-02 05:06:08,155 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:39496] terminating
2020-04-02 05:06:08,157 [IPC Server handler 0 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:39496, 127.0.0.1:45766 for /tmp.txt
2020-04-02 05:06:08,173 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39526 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013 src: /127.0.0.1:39526 dest: /127.0.0.1:39496
2020-04-02 05:06:08,223 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59562 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013 src: /127.0.0.1:59562 dest: /127.0.0.1:45766
2020-04-02 05:06:08,228 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59562, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013, duration(ns): 2980414
2020-04-02 05:06:08,228 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:08,229 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39526, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013, duration(ns): 4082500
2020-04-02 05:06:08,229 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766] terminating
2020-04-02 05:06:08,235 [IPC Server handler 6 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:39496, 127.0.0.1:45766 for /tmp.txt
2020-04-02 05:06:08,252 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39530 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014 src: /127.0.0.1:39530 dest: /127.0.0.1:39496
2020-04-02 05:06:08,270 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59566 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014 src: /127.0.0.1:59566 dest: /127.0.0.1:45766
2020-04-02 05:06:08,286 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59566, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014, duration(ns): 7472506
2020-04-02 05:06:08,286 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:08,287 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39530, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014, duration(ns): 4284667
2020-04-02 05:06:08,287 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766] terminating
2020-04-02 05:06:08,289 [IPC Server handler 8 on 34821] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:39496, 127.0.0.1:45766 for /tmp.txt
2020-04-02 05:06:08,297 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:39534 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015 src: /127.0.0.1:39534 dest: /127.0.0.1:39496
2020-04-02 05:06:08,301 [DataXceiver for client DFSClient_NONMAPREDUCE_-73843185_1 at /127.0.0.1:59570 [Receiving block BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015 src: /127.0.0.1:59570 dest: /127.0.0.1:45766
2020-04-02 05:06:08,306 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59570, dest: /127.0.0.1:45766, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: f2605c05-73ac-437a-bb78-4f56f80aa161, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015, duration(ns): 2552481
2020-04-02 05:06:08,306 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:08,307 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39534, dest: /127.0.0.1:39496, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-73843185_1, offset: 0, srvID: 15812ad8-a190-4f2d-9f34-dbb0e3ca2866, blockid: BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015, duration(ns): 2388314
2020-04-02 05:06:08,307 [PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45766] terminating
2020-04-02 05:06:08,308 [IPC Server handler 1 on 34821] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp.txt is closed by DFSClient_NONMAPREDUCE_-73843185_1
2020-04-02 05:06:08,310 [IPC Server handler 2 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp.txt	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,312 [IPC Server handler 5 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/tmp.txt	dst=null	perm=null	proto=rpc
All blocks of file /tmp.txt verified to have replication factor 2
2020-04-02 05:06:08,327 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:08,328 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 2 with hostname set to: host2.foo.com
2020-04-02 05:06:08,328 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host2.foo.com to rack /rack2
2020-04-02 05:06:08,335 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803968334,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:08,337 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:08,337 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:08,346 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:08,346 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:08,347 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:08,347 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:08,347 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host2.foo.com
2020-04-02 05:06:08,347 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:08,347 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:08,347 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:08,348 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:08,348 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39231
2020-04-02 05:06:08,349 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:08,349 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:08,350 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:08,351 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:08,352 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:08,353 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:08,354 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:08,354 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:08,354 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:08,354 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:08,355 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37067
2020-04-02 05:06:08,355 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:08,358 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f952d6c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:08,358 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d4a65c6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:08,363 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@878537d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:08,364 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4455f57d{HTTP/1.1,[http/1.1]}{localhost:37067}
2020-04-02 05:06:08,364 [main] INFO  server.Server (Server.java:doStart(419)) - Started @34679ms
2020-04-02 05:06:08,428 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:40095
2020-04-02 05:06:08,429 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:08,429 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:08,430 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:08,430 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c37bd27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:08,431 [Socket Reader #1 for port 37114] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37114
2020-04-02 05:06:08,434 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37114
2020-04-02 05:06:08,438 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:08,443 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:08,450 [Thread-735] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34821 starting to offer service
2020-04-02 05:06:08,450 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:39231 to rack /rack2
2020-04-02 05:06:08,451 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:08,451 [IPC Server listener on 37114] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37114: starting
2020-04-02 05:06:08,453 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37114 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:08,500 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803968500,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:08,506 [Socket Reader #1 for port 34821] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:08,572 [IPC Server handler 7 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,575 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803968575,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:08,581 [Socket Reader #1 for port 34821] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:08,587 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:08,588 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:08,602 [Thread-735] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34821
2020-04-02 05:06:08,603 [Thread-735] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 759806f4-878b-41b1-8bc5-e08ad492a3df
2020-04-02 05:06:08,604 [Thread-735] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:06:08,604 [Thread-735] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:08,605 [Thread-735] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@7029af7e
2020-04-02 05:06:08,612 [Thread-735] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@7029af7e
2020-04-02 05:06:08,613 [Thread-735] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:06:08,614 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid 759806f4-878b-41b1-8bc5-e08ad492a3df) service to localhost/127.0.0.1:34821 beginning handshake with NN
2020-04-02 05:06:08,618 [IPC Server handler 3 on 34821] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39231, datanodeUuid=759806f4-878b-41b1-8bc5-e08ad492a3df, infoPort=0, infoSecurePort=40095, ipcPort=37114, storageInfo=lv=-57;cid=testClusterID;nsid=1067543306;c=1585803965775) storage 759806f4-878b-41b1-8bc5-e08ad492a3df
2020-04-02 05:06:08,618 [IPC Server handler 3 on 34821] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack2/127.0.0.1:39231
2020-04-02 05:06:08,619 [IPC Server handler 3 on 34821] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 759806f4-878b-41b1-8bc5-e08ad492a3df (127.0.0.1:39231).
2020-04-02 05:06:08,626 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid 759806f4-878b-41b1-8bc5-e08ad492a3df) service to localhost/127.0.0.1:34821 successfully registered with NN
2020-04-02 05:06:08,626 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1715164147-172.17.0.6-1585803965775 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:08,626 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:08,627 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34821 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:08,630 [IPC Server handler 8 on 34821] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-e3d32523-ce8e-40d1-8ce3-0d18159ef00c for DN 127.0.0.1:39231
2020-04-02 05:06:08,647 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfb30d32dced949dd: Processing first storage report for SimulatedStorage-DS-e3d32523-ce8e-40d1-8ce3-0d18159ef00c from datanode 759806f4-878b-41b1-8bc5-e08ad492a3df
2020-04-02 05:06:08,647 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfb30d32dced949dd: from storage SimulatedStorage-DS-e3d32523-ce8e-40d1-8ce3-0d18159ef00c node DatanodeRegistration(127.0.0.1:39231, datanodeUuid=759806f4-878b-41b1-8bc5-e08ad492a3df, infoPort=0, infoSecurePort=40095, ipcPort=37114, storageInfo=lv=-57;cid=testClusterID;nsid=1067543306;c=1585803965775), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:08,652 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfb30d32dced949dd,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:08,652 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1715164147-172.17.0.6-1585803965775
2020-04-02 05:06:08,689 [IPC Server handler 0 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,691 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:09,308 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(984)) - namenodes  = [hdfs://localhost:34821]
2020-04-02 05:06:09,309 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(985)) - parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]
2020-04-02 05:06:09,309 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(986)) - Print stack trace
java.lang.Throwable
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:986)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:945)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:921)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:793)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:787)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.twoNodeTest(TestBalancer.java:1099)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1209)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Authentication(TestBalancerWithSaslDataTransfer.java:29)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved
2020-04-02 05:06:09,319 [Socket Reader #1 for port 34821] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:09,330 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(75)) - Block token params received from NN: update interval=10hrs, 0sec, token lifetime=10hrs, 0sec
2020-04-02 05:06:09,334 [main] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:09,334 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(172)) - Update block keys every 2hrs, 30mins, 0sec
2020-04-02 05:06:09,336 [IPC Server handler 2 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:09,338 [IPC Server handler 5 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/system/balancer.id	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:09,354 [IPC Server handler 6 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:09,356 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:06:09,360 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:06:09,360 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:06:09,360 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:06:09,360 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:06:09,361 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:06:09,361 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,361 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,362 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:06:09,362 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:06:09,366 [org.apache.hadoop.hdfs.server.balancer.KeyManager$BlockKeyUpdater@7ca0863b] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:09,368 [IPC Server handler 3 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:09,369 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack1/127.0.0.1:45766
2020-04-02 05:06:09,370 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack2/127.0.0.1:39231
2020-04-02 05:06:09,370 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:39496
2020-04-02 05:06:09,370 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:06:09,370 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 2 above-average: [127.0.0.1:45766:DISK, 127.0.0.1:39496:DISK]
2020-04-02 05:06:09,370 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 below-average: []
2020-04-02 05:06:09,370 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 1 underutilized: [127.0.0.1:39231:DISK]
2020-04-02 05:06:09,370 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(615)) - Need to move 500 B to make the cluster balanced.
2020-04-02 05:06:09,374 [IPC Server handler 8 on 34821] INFO  namenode.NameNode (NameNodeRpcServer.java:rollingUpgrade(1333)) - rollingUpgrade QUERY
2020-04-02 05:06:09,375 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for SAME_RACK: overUtilized => underUtilized
2020-04-02 05:06:09,375 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for SAME_RACK: overUtilized => belowAvgUtilized
2020-04-02 05:06:09,375 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for SAME_RACK: underUtilized => aboveAvgUtilized
2020-04-02 05:06:09,375 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for ANY_OTHER: overUtilized => underUtilized
2020-04-02 05:06:09,375 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for ANY_OTHER: overUtilized => belowAvgUtilized
2020-04-02 05:06:09,376 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for ANY_OTHER: underUtilized => aboveAvgUtilized
2020-04-02 05:06:09,376 [main] INFO  balancer.Balancer (Balancer.java:matchSourceWithTargetToMove(537)) - Decided to move 500 B bytes from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK
2020-04-02 05:06:09,376 [main] INFO  balancer.Balancer (Balancer.java:matchSourceWithTargetToMove(537)) - Decided to move 500 B bytes from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK
2020-04-02 05:06:09,376 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(639)) - Will move 1000 B in this iteration
2020-04-02 05:06:09,376 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1189)) - Balancer allowed RPCs per sec = 20
2020-04-02 05:06:09,376 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1190)) - Balancer concurrent threads = 2
2020-04-02 05:06:09,376 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1191)) - Disperse Interval sec = 0
2020-04-02 05:06:09,376 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1207)) - Limiting threads per target to the specified max.
2020-04-02 05:06:09,376 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1210)) - Allocating 50 threads per target.
2020-04-02 05:06:09,385 [pool-104-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741826_1002 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,394 [pool-104-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741827_1003 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,395 [pool-105-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741826_1002 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,396 [pool-104-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741828_1004 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:45766
2020-04-02 05:06:09,397 [pool-104-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741829_1005 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,398 [pool-105-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741827_1003 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,399 [pool-105-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741828_1004 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:45766
2020-04-02 05:06:09,400 [pool-104-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741830_1006 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,401 [pool-105-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741830_1006 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,401 [pool-105-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741829_1005 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,464 [DataXceiver for client /127.0.0.1:59598 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004 to /127.0.0.1:59598
2020-04-02 05:06:09,467 [DataXceiver for client /127.0.0.1:41222 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004 from f2605c05-73ac-437a-bb78-4f56f80aa161]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741828_1004 from /127.0.0.1:41222, delHint=f2605c05-73ac-437a-bb78-4f56f80aa161
2020-04-02 05:06:09,468 [pool-105-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741828_1004 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:45766
2020-04-02 05:06:09,476 [DataXceiver for client /127.0.0.1:39556 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003 to /127.0.0.1:39556
2020-04-02 05:06:09,491 [pool-104-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741837_1013 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,491 [pool-104-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741838_1014 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:45766
2020-04-02 05:06:09,492 [pool-105-thread-6] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741837_1013 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,493 [pool-104-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741839_1015 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:45766
2020-04-02 05:06:09,493 [pool-105-thread-7] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741838_1014 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:45766
2020-04-02 05:06:09,494 [pool-105-thread-8] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741839_1015 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:45766
2020-04-02 05:06:09,509 [DataXceiver for client /127.0.0.1:41220 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003 from f2605c05-73ac-437a-bb78-4f56f80aa161]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741827_1003 from /127.0.0.1:41220, delHint=f2605c05-73ac-437a-bb78-4f56f80aa161
2020-04-02 05:06:09,522 [pool-105-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741827_1003 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,518 [DataXceiver for client /127.0.0.1:39572 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006 to /127.0.0.1:39572
2020-04-02 05:06:09,519 [DataXceiver for client /127.0.0.1:41226 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006 from f2605c05-73ac-437a-bb78-4f56f80aa161]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741830_1006 from /127.0.0.1:41226, delHint=f2605c05-73ac-437a-bb78-4f56f80aa161
2020-04-02 05:06:09,530 [pool-105-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741830_1006 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,533 [pool-104-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741825_1001 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,536 [pool-104-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741831_1007 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,546 [pool-105-thread-9] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741825_1001 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,547 [pool-105-thread-10] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741831_1007 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,597 [DataXceiver for client /127.0.0.1:39570 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005 to /127.0.0.1:39570
2020-04-02 05:06:09,612 [DataXceiver for client /127.0.0.1:41234 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014 from 15812ad8-a190-4f2d-9f34-dbb0e3ca2866]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014 from /127.0.0.1:41234, delHint=15812ad8-a190-4f2d-9f34-dbb0e3ca2866
2020-04-02 05:06:09,612 [DataXceiver for client /127.0.0.1:59610 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741838_1014 to /127.0.0.1:59610
2020-04-02 05:06:09,613 [DataXceiver for client /127.0.0.1:41236 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015 from 15812ad8-a190-4f2d-9f34-dbb0e3ca2866]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015 from /127.0.0.1:41236, delHint=15812ad8-a190-4f2d-9f34-dbb0e3ca2866
2020-04-02 05:06:09,613 [DataXceiver for client /127.0.0.1:59612 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741839_1015 to /127.0.0.1:59612
2020-04-02 05:06:09,614 [pool-105-thread-7] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741838_1014 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:45766
2020-04-02 05:06:09,614 [DataXceiver for client /127.0.0.1:41228 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005 from f2605c05-73ac-437a-bb78-4f56f80aa161]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741829_1005 from /127.0.0.1:41228, delHint=f2605c05-73ac-437a-bb78-4f56f80aa161
2020-04-02 05:06:09,614 [pool-105-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741829_1005 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,615 [DataXceiver for client /127.0.0.1:41248 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001 from 15812ad8-a190-4f2d-9f34-dbb0e3ca2866]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001 from /127.0.0.1:41248, delHint=15812ad8-a190-4f2d-9f34-dbb0e3ca2866
2020-04-02 05:06:09,615 [DataXceiver for client /127.0.0.1:39586 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741825_1001 to /127.0.0.1:39586
2020-04-02 05:06:09,615 [pool-105-thread-9] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741825_1001 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,616 [pool-105-thread-8] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741839_1015 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:45766
2020-04-02 05:06:09,641 [DataXceiver for client /127.0.0.1:39584 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002 to /127.0.0.1:39584
2020-04-02 05:06:09,642 [DataXceiver for client /127.0.0.1:41218 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002 from f2605c05-73ac-437a-bb78-4f56f80aa161]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741826_1002 from /127.0.0.1:41218, delHint=f2605c05-73ac-437a-bb78-4f56f80aa161
2020-04-02 05:06:09,643 [DataXceiver for client /127.0.0.1:39590 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013 to /127.0.0.1:39590
2020-04-02 05:06:09,643 [DataXceiver for client /127.0.0.1:41242 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013 from 15812ad8-a190-4f2d-9f34-dbb0e3ca2866]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741837_1013 from /127.0.0.1:41242, delHint=15812ad8-a190-4f2d-9f34-dbb0e3ca2866
2020-04-02 05:06:09,644 [DataXceiver for client /127.0.0.1:39588 [Copying block BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007 to /127.0.0.1:39588
2020-04-02 05:06:09,645 [pool-105-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741826_1002 with size=100 from 127.0.0.1:45766:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,646 [pool-105-thread-6] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741837_1013 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
2020-04-02 05:06:09,652 [DataXceiver for client /127.0.0.1:41250 [Replacing block BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007 from 15812ad8-a190-4f2d-9f34-dbb0e3ca2866]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1715164147-172.17.0.6-1585803965775:blk_1073741831_1007 from /127.0.0.1:41250, delHint=15812ad8-a190-4f2d-9f34-dbb0e3ca2866
2020-04-02 05:06:09,658 [pool-105-thread-10] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741831_1007 with size=100 from 127.0.0.1:39496:DISK to 127.0.0.1:39231:DISK through 127.0.0.1:39496
Apr 2, 2020 5:06:10 AM            0               1000 B               500 B             1000 B
2020-04-02 05:06:13,537 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:06:13,538 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:06:13,538 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:06:13,538 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:06:13,538 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:06:13,538 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:06:13,539 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:13,540 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:13,540 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:06:13,540 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:06:13,552 [IPC Server handler 7 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,553 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack1/127.0.0.1:45766
2020-04-02 05:06:13,554 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:39496
2020-04-02 05:06:13,554 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack2/127.0.0.1:39231
2020-04-02 05:06:13,558 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:06:13,558 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 above-average: []
2020-04-02 05:06:13,558 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 3 below-average: [127.0.0.1:45766:DISK, 127.0.0.1:39496:DISK, 127.0.0.1:39231:DISK]
2020-04-02 05:06:13,558 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 underutilized: []
The cluster is balanced. Exiting...
Apr 2, 2020 5:06:13 AM            1               1000 B                 0 B                0 B
2020-04-02 05:06:13,561 [IPC Server handler 3 on 34821] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /system/balancer.id is closed by DFSClient_NONMAPREDUCE_1095295559_1
2020-04-02 05:06:13,562 [IPC Server handler 9 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=delete	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,566 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(956)) -   .
2020-04-02 05:06:13,567 [IPC Server handler 4 on 34821] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,570 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:13,574 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:06:13,574 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37114 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,575 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@56ba8773] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:13,638 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid 759806f4-878b-41b1-8bc5-e08ad492a3df) service to localhost/127.0.0.1:34821
2020-04-02 05:06:13,638 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid 759806f4-878b-41b1-8bc5-e08ad492a3df)
2020-04-02 05:06:13,692 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@878537d{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:13,693 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4455f57d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:13,693 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d4a65c6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:13,694 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f952d6c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:13,696 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37114
2020-04-02 05:06:13,702 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:13,702 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:13,702 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37064 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,705 [IPC Server listener on 37114] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37114
2020-04-02 05:06:13,837 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2cfbeac4{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:13,749 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:13,721 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@11a7ba62] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:13,845 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@12db3386{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:13,846 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bfc257{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:13,846 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@73877e19{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:13,849 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37064
2020-04-02 05:06:13,871 [IPC Server listener on 37064] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37064
2020-04-02 05:06:13,871 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:13,871 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid f2605c05-73ac-437a-bb78-4f56f80aa161) service to localhost/127.0.0.1:34821
2020-04-02 05:06:13,872 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid f2605c05-73ac-437a-bb78-4f56f80aa161)
2020-04-02 05:06:13,873 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:13,873 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:13,873 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:13,873 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41393 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,874 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@aced190] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:13,952 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@273842a6{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:13,954 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6a969fb8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:13,970 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29314cc9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:13,970 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d6aca33{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:13,995 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41393
2020-04-02 05:06:14,002 [IPC Server listener on 41393] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41393
2020-04-02 05:06:14,003 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:14,020 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid 15812ad8-a190-4f2d-9f34-dbb0e3ca2866) service to localhost/127.0.0.1:34821
2020-04-02 05:06:14,020 [BP-1715164147-172.17.0.6-1585803965775 heartbeating to localhost/127.0.0.1:34821] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1715164147-172.17.0.6-1585803965775 (Datanode Uuid 15812ad8-a190-4f2d-9f34-dbb0e3ca2866)
2020-04-02 05:06:14,003 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:14,023 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:14,024 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:14,024 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 34821 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:14,024 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:14,024 [Thread[Thread-578,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:06:14,025 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3241713e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:14,025 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5ecba515] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:14,025 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 54
2020-04-02 05:06:14,026 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 55 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 29 Number of syncs: 27 SyncTimes(ms): 6 3 
2020-04-02 05:06:14,027 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:06:14,027 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:06:14,028 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:14,028 [CacheReplicationMonitor(1192458637)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:14,028 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34821
2020-04-02 05:06:14,079 [IPC Server listener on 34821] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34821
2020-04-02 05:06:14,079 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:14,079 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:14,083 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:14,095 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:14,097 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:14,109 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@27b22f74{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:14,110 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2fe88a09{SSL,[ssl, http/1.1]}{localhost:41096}
2020-04-02 05:06:14,111 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d4664d7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:14,111 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fedfe27{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:14,115 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:14,120 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:14,120 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer#testBalancer0Authentication
[msx] writeFile testName = org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer#testBalancer0Authentication
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer#testBalancer0Privacy
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:14,207 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(819)) - capacities = [5000]
2020-04-02 05:06:14,207 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(820)) - racks      = [/rack0]
2020-04-02 05:06:14,208 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(821)) - newCapacity= 2500
2020-04-02 05:06:14,208 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(822)) - newRack    = /rack0
2020-04-02 05:06:14,208 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(823)) - useTool    = false
2020-04-02 05:06:14,208 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-04-02 05:06:14,219 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803974218,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:14,247 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:06:14,249 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:14,250 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:14,250 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:14,250 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:14,251 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:14,251 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:14,251 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:14,251 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:14,252 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:14,252 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,252 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:14,253 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:14,253 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,253 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:14,253 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:14,254 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:14
2020-04-02 05:06:14,254 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:14,254 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,254 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:14,254 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:14,277 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,277 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,278 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:06:14,278 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:06:14,278 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:14,279 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,279 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:14,279 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:14,279 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:14,280 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:14,280 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:06:14,280 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:14,280 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:14,280 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:14,280 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:14,280 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:14,281 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:14,281 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:14,281 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,282 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:14,282 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:14,295 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:14,295 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:14,295 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:14,296 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:14,296 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:14,296 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:14,296 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:14,296 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,297 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:14,297 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:14,300 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:14,300 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:14,300 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:14,301 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:14,301 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:14,301 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:14,306 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,307 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:14,307 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:14,309 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1377894298-172.17.0.6-1585803974309
2020-04-02 05:06:14,314 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:14,319 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:14,321 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:14,330 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:06:14,334 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:14,355 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:06:14,363 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:14,369 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:14,375 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:14,381 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:14,382 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:14,383 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:14,384 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:14,397 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803974397,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:14,401 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:14,418 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:06:14,419 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77a281fc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:14,419 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:06:14,420 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:14,422 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:14,423 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:14,423 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:14,424 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:14,425 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:14,426 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:14,428 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:14,438 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:14,439 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:14,439 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:06:14,439 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:06:14,440 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36741
2020-04-02 05:06:14,440 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:14,459 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27fde870{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:14,460 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ac7aa18{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:14,464 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:06:14,465 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:06:14,466 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@a64e035{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:14,469 [main] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@4d74c3ba(server,h=[],w=[]) for SslContextFactory@41c204a0(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:06:14,479 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@22d9c961{SSL,[ssl, http/1.1]}{localhost:36741}
2020-04-02 05:06:14,480 [main] INFO  server.Server (Server.java:doStart(419)) - Started @40795ms
2020-04-02 05:06:14,522 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:14,538 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:14,538 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:14,538 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:14,539 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:14,539 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:14,539 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:14,539 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:14,539 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:14,540 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,540 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:14,540 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:14,540 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,540 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:14,540 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:14,540 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:14
2020-04-02 05:06:14,540 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:14,541 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,547 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:14,547 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:14,563 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,564 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,564 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:06:14,564 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:06:14,564 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:14,565 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:14,565 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:14,565 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:14,565 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:14,565 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:14,565 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:06:14,565 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:14,570 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:14,570 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:14,571 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:14,571 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:14,571 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:14,571 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:14,571 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,571 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:14,571 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:14,577 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:14,577 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:14,577 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:14,577 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:14,577 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:14,581 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:14,581 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:14,582 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,582 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:14,582 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:14,583 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:14,584 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:14,584 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:14,584 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:14,584 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:14,584 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:14,584 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:14,584 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:14,584 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:14,618 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:06:14,633 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:06:14,635 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:14,635 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:14,635 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:14,635 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:14,637 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:14,637 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:14,641 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:14,642 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:14,643 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:14,679 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:14,680 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 91 msecs
2020-04-02 05:06:14,680 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:14,681 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:14,684 [Socket Reader #1 for port 36740] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36740
2020-04-02 05:06:14,690 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36740 to access this namenode/service.
2020-04-02 05:06:14,691 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:14,738 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:14,749 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@73ba6fe6] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:06:14,754 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:14,754 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:14,754 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:06:14,754 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:14,761 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:06:14,782 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:14,782 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:14,782 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:14,782 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:14,782 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:14,782 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 27 msec
2020-04-02 05:06:14,783 [Thread[Thread-801,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:06:14,808 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:14,814 [IPC Server listener on 36740] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36740: starting
2020-04-02 05:06:14,886 [Thread[Thread-801,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:06:14,901 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36740
2020-04-02 05:06:14,902 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:14,903 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:14,938 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 35 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:14,942 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36740 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:14,977 [CacheReplicationMonitor(2004244957)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:14,987 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803974986,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:15,036 [Socket Reader #1 for port 36740] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:15,070 [IPC Server handler 0 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,074 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:15,076 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:15,076 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 0 with hostname set to: host0.foo.com
2020-04-02 05:06:15,076 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host0.foo.com to rack /rack0
2020-04-02 05:06:15,087 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803975086,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:15,088 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:15,089 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:15,090 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:15,091 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:15,091 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,091 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:15,091 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host0.foo.com
2020-04-02 05:06:15,092 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,092 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,092 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,092 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:15,093 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38339
2020-04-02 05:06:15,093 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:15,106 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:15,107 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,112 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:15,113 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:15,113 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,115 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:15,116 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:15,116 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:15,116 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:15,117 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35159
2020-04-02 05:06:15,117 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:15,124 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56303475{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:15,124 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1dcca8d3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:15,130 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@260f2144{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:15,131 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3c017078{HTTP/1.1,[http/1.1]}{localhost:35159}
2020-04-02 05:06:15,131 [main] INFO  server.Server (Server.java:doStart(419)) - Started @41446ms
2020-04-02 05:06:15,181 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:44806
2020-04-02 05:06:15,182 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:15,182 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:15,183 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:15,184 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5c645b43] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:15,184 [Socket Reader #1 for port 44490] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44490
2020-04-02 05:06:15,216 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44490
2020-04-02 05:06:15,257 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:15,257 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:15,258 [Thread-831] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36740 starting to offer service
2020-04-02 05:06:15,259 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:38339 to rack /rack0
2020-04-02 05:06:15,259 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:15,259 [IPC Server listener on 44490] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44490: starting
2020-04-02 05:06:15,273 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44490 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:15,327 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803975327,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:15,378 [Socket Reader #1 for port 36740] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:15,378 [Socket Reader #1 for port 36740] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:15,383 [Thread-831] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36740
2020-04-02 05:06:15,386 [IPC Server handler 4 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,386 [Thread-831] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 33e55a24-2427-497e-8c33-9d1ce16084d1
2020-04-02 05:06:15,387 [Thread-831] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:06:15,387 [Thread-831] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,388 [Thread-831] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2b7e5398
2020-04-02 05:06:15,391 [Thread-831] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2b7e5398
2020-04-02 05:06:15,392 [Thread-831] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:06:15,402 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1377894298-172.17.0.6-1585803974309 (Datanode Uuid 33e55a24-2427-497e-8c33-9d1ce16084d1) service to localhost/127.0.0.1:36740 beginning handshake with NN
2020-04-02 05:06:15,412 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:15,418 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:15,432 [IPC Server handler 3 on 36740] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38339, datanodeUuid=33e55a24-2427-497e-8c33-9d1ce16084d1, infoPort=0, infoSecurePort=44806, ipcPort=44490, storageInfo=lv=-57;cid=testClusterID;nsid=614711164;c=1585803974309) storage 33e55a24-2427-497e-8c33-9d1ce16084d1
2020-04-02 05:06:15,432 [IPC Server handler 3 on 36740] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:38339
2020-04-02 05:06:15,432 [IPC Server handler 3 on 36740] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 33e55a24-2427-497e-8c33-9d1ce16084d1 (127.0.0.1:38339).
2020-04-02 05:06:15,446 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1377894298-172.17.0.6-1585803974309 (Datanode Uuid 33e55a24-2427-497e-8c33-9d1ce16084d1) service to localhost/127.0.0.1:36740 successfully registered with NN
2020-04-02 05:06:15,447 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1377894298-172.17.0.6-1585803974309 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:15,447 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:15,447 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36740 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:15,460 [IPC Server handler 1 on 36740] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-4d935bdd-b3c6-4936-9576-99b1d3d5e84e for DN 127.0.0.1:38339
2020-04-02 05:06:15,474 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x727790f3791f6454: Processing first storage report for SimulatedStorage-DS-4d935bdd-b3c6-4936-9576-99b1d3d5e84e from datanode 33e55a24-2427-497e-8c33-9d1ce16084d1
2020-04-02 05:06:15,474 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x727790f3791f6454: from storage SimulatedStorage-DS-4d935bdd-b3c6-4936-9576-99b1d3d5e84e node DatanodeRegistration(127.0.0.1:38339, datanodeUuid=33e55a24-2427-497e-8c33-9d1ce16084d1, infoPort=0, infoSecurePort=44806, ipcPort=44490, storageInfo=lv=-57;cid=testClusterID;nsid=614711164;c=1585803974309), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:15,482 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x727790f3791f6454,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:15,482 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1377894298-172.17.0.6-1585803974309
2020-04-02 05:06:15,522 [IPC Server handler 6 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,526 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:15,530 [IPC Server handler 7 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,534 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:15,538 [IPC Server handler 8 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:15,558 [IPC Server handler 9 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/tmp.txt	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:15,574 [IPC Server handler 0 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:15,611 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40618 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741825_1001 src: /127.0.0.1:40618 dest: /127.0.0.1:38339
2020-04-02 05:06:15,641 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40618, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741825_1001, duration(ns): 11951926
2020-04-02 05:06:15,641 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:15,682 [IPC Server handler 3 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:15,695 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40620 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741826_1002 src: /127.0.0.1:40620 dest: /127.0.0.1:38339
2020-04-02 05:06:15,710 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40620, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741826_1002, duration(ns): 13602777
2020-04-02 05:06:15,710 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:15,715 [IPC Server handler 1 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:15,723 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40622 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741827_1003 src: /127.0.0.1:40622 dest: /127.0.0.1:38339
2020-04-02 05:06:15,727 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40622, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741827_1003, duration(ns): 1707720
2020-04-02 05:06:15,727 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:15,729 [IPC Server handler 7 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:15,737 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40624 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741828_1004 src: /127.0.0.1:40624 dest: /127.0.0.1:38339
2020-04-02 05:06:15,755 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40624, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741828_1004, duration(ns): 12561819
2020-04-02 05:06:15,755 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:15,796 [IPC Server handler 9 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:15,824 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40628 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741829_1005 src: /127.0.0.1:40628 dest: /127.0.0.1:38339
2020-04-02 05:06:15,873 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40628, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741829_1005, duration(ns): 23063975
2020-04-02 05:06:15,873 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:15,886 [IPC Server handler 0 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:15,921 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40634 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741830_1006 src: /127.0.0.1:40634 dest: /127.0.0.1:38339
2020-04-02 05:06:15,937 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40634, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741830_1006, duration(ns): 14304084
2020-04-02 05:06:15,937 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:15,948 [IPC Server handler 3 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:15,967 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40640 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007 src: /127.0.0.1:40640 dest: /127.0.0.1:38339
2020-04-02 05:06:15,976 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40640, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007, duration(ns): 5650582
2020-04-02 05:06:15,977 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:15,985 [IPC Server handler 5 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:16,010 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40642 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008 src: /127.0.0.1:40642 dest: /127.0.0.1:38339
2020-04-02 05:06:16,017 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40642, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008, duration(ns): 1324868
2020-04-02 05:06:16,018 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:16,020 [IPC Server handler 7 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:16,041 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40644 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009 src: /127.0.0.1:40644 dest: /127.0.0.1:38339
2020-04-02 05:06:16,055 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40644, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009, duration(ns): 7100848
2020-04-02 05:06:16,056 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:16,059 [IPC Server handler 9 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:16,072 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40646 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010 src: /127.0.0.1:40646 dest: /127.0.0.1:38339
2020-04-02 05:06:16,079 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40646, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010, duration(ns): 2542732
2020-04-02 05:06:16,080 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:16,083 [IPC Server handler 0 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:16,089 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40648 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011 src: /127.0.0.1:40648 dest: /127.0.0.1:38339
2020-04-02 05:06:16,094 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40648, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011, duration(ns): 1706462
2020-04-02 05:06:16,094 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:16,097 [IPC Server handler 4 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:16,107 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40650 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741836_1012 src: /127.0.0.1:40650 dest: /127.0.0.1:38339
2020-04-02 05:06:16,138 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40650, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741836_1012, duration(ns): 22548795
2020-04-02 05:06:16,150 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:16,170 [IPC Server handler 5 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:16,199 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40654 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741837_1013 src: /127.0.0.1:40654 dest: /127.0.0.1:38339
2020-04-02 05:06:16,204 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40654, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741837_1013, duration(ns): 3113233
2020-04-02 05:06:16,204 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:16,206 [IPC Server handler 6 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:16,212 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40656 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741838_1014 src: /127.0.0.1:40656 dest: /127.0.0.1:38339
2020-04-02 05:06:16,241 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40656, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741838_1014, duration(ns): 6785058
2020-04-02 05:06:16,242 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:16,246 [IPC Server handler 9 on 36740] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:38339 for /tmp.txt
2020-04-02 05:06:16,263 [DataXceiver for client DFSClient_NONMAPREDUCE_1651312763_1 at /127.0.0.1:40658 [Receiving block BP-1377894298-172.17.0.6-1585803974309:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1377894298-172.17.0.6-1585803974309:blk_1073741839_1015 src: /127.0.0.1:40658 dest: /127.0.0.1:38339
2020-04-02 05:06:16,271 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40658, dest: /127.0.0.1:38339, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651312763_1, offset: 0, srvID: 33e55a24-2427-497e-8c33-9d1ce16084d1, blockid: BP-1377894298-172.17.0.6-1585803974309:blk_1073741839_1015, duration(ns): 1356969
2020-04-02 05:06:16,271 [PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1377894298-172.17.0.6-1585803974309:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:16,272 [IPC Server handler 2 on 36740] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741839_1015 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp.txt
2020-04-02 05:06:16,675 [IPC Server handler 3 on 36740] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp.txt is closed by DFSClient_NONMAPREDUCE_1651312763_1
2020-04-02 05:06:16,677 [IPC Server handler 1 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp.txt	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,679 [IPC Server handler 5 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/tmp.txt	dst=null	perm=null	proto=rpc
All blocks of file /tmp.txt verified to have replication factor 1
2020-04-02 05:06:16,684 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:16,684 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 1 with hostname set to: host1.foo.com
2020-04-02 05:06:16,684 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host1.foo.com to rack /rack0
2020-04-02 05:06:16,693 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803976692,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:16,694 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:16,694 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:16,701 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:16,702 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:16,702 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:16,702 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:16,702 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1.foo.com
2020-04-02 05:06:16,703 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:16,703 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:16,703 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:16,703 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:16,704 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38460
2020-04-02 05:06:16,704 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:16,704 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:16,708 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:16,710 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:16,711 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:16,712 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:16,713 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:16,714 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:16,714 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:16,714 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:16,715 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39956
2020-04-02 05:06:16,715 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:16,743 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@257cc1fc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:16,751 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57adfab0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:16,778 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@34dc85a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:16,778 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@67403656{HTTP/1.1,[http/1.1]}{localhost:39956}
2020-04-02 05:06:16,779 [main] INFO  server.Server (Server.java:doStart(419)) - Started @43094ms
2020-04-02 05:06:17,116 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:45163
2020-04-02 05:06:17,117 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:17,118 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:17,118 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:17,119 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@12f8b1d8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:17,131 [Socket Reader #1 for port 34170] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34170
2020-04-02 05:06:17,139 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34170
2020-04-02 05:06:17,143 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:17,143 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:17,146 [Thread-903] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36740 starting to offer service
2020-04-02 05:06:17,146 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:38460 to rack /rack0
2020-04-02 05:06:17,147 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:17,148 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34170 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:17,166 [IPC Server listener on 34170] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34170: starting
2020-04-02 05:06:17,200 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803977200,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:17,212 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803977211,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:17,214 [Socket Reader #1 for port 36740] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:17,229 [Socket Reader #1 for port 36740] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:17,250 [IPC Server handler 8 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,251 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:17,251 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:17,254 [Thread-903] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36740
2020-04-02 05:06:17,255 [Thread-903] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3a2fe354-c1c2-4d60-9b42-19f21a82e284
2020-04-02 05:06:17,256 [Thread-903] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:06:17,256 [Thread-903] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:17,257 [Thread-903] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@6871af1c
2020-04-02 05:06:17,258 [Thread-903] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@6871af1c
2020-04-02 05:06:17,258 [Thread-903] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:06:17,261 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1377894298-172.17.0.6-1585803974309 (Datanode Uuid 3a2fe354-c1c2-4d60-9b42-19f21a82e284) service to localhost/127.0.0.1:36740 beginning handshake with NN
2020-04-02 05:06:17,263 [IPC Server handler 2 on 36740] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38460, datanodeUuid=3a2fe354-c1c2-4d60-9b42-19f21a82e284, infoPort=0, infoSecurePort=45163, ipcPort=34170, storageInfo=lv=-57;cid=testClusterID;nsid=614711164;c=1585803974309) storage 3a2fe354-c1c2-4d60-9b42-19f21a82e284
2020-04-02 05:06:17,263 [IPC Server handler 2 on 36740] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:38460
2020-04-02 05:06:17,263 [IPC Server handler 2 on 36740] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3a2fe354-c1c2-4d60-9b42-19f21a82e284 (127.0.0.1:38460).
2020-04-02 05:06:17,264 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1377894298-172.17.0.6-1585803974309 (Datanode Uuid 3a2fe354-c1c2-4d60-9b42-19f21a82e284) service to localhost/127.0.0.1:36740 successfully registered with NN
2020-04-02 05:06:17,264 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1377894298-172.17.0.6-1585803974309 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:17,264 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:17,264 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36740 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:17,268 [IPC Server handler 4 on 36740] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-256ee2a1-4099-4caf-9a4e-bcdfb0afb2cb for DN 127.0.0.1:38460
2020-04-02 05:06:17,278 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xabd81cfc7ae2d8e6: Processing first storage report for SimulatedStorage-DS-256ee2a1-4099-4caf-9a4e-bcdfb0afb2cb from datanode 3a2fe354-c1c2-4d60-9b42-19f21a82e284
2020-04-02 05:06:17,278 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xabd81cfc7ae2d8e6: from storage SimulatedStorage-DS-256ee2a1-4099-4caf-9a4e-bcdfb0afb2cb node DatanodeRegistration(127.0.0.1:38460, datanodeUuid=3a2fe354-c1c2-4d60-9b42-19f21a82e284, infoPort=0, infoSecurePort=45163, ipcPort=34170, storageInfo=lv=-57;cid=testClusterID;nsid=614711164;c=1585803974309), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:17,286 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xabd81cfc7ae2d8e6,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:17,286 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1377894298-172.17.0.6-1585803974309
2020-04-02 05:06:17,353 [IPC Server handler 1 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,354 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:17,358 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(984)) - namenodes  = [hdfs://localhost:36740]
2020-04-02 05:06:17,358 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(985)) - parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]
2020-04-02 05:06:17,358 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(986)) - Print stack trace
java.lang.Throwable
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:986)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:945)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:921)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:793)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:787)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.oneNodeTest(TestBalancer.java:1093)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1208)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Privacy(TestBalancerWithSaslDataTransfer.java:39)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved
2020-04-02 05:06:17,366 [Socket Reader #1 for port 36740] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:17,373 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(75)) - Block token params received from NN: update interval=10hrs, 0sec, token lifetime=10hrs, 0sec
2020-04-02 05:06:17,373 [main] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:17,374 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(172)) - Update block keys every 2hrs, 30mins, 0sec
2020-04-02 05:06:17,378 [IPC Server handler 9 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,381 [IPC Server handler 8 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/system/balancer.id	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:17,398 [IPC Server handler 2 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,405 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:06:17,406 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:06:17,406 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:06:17,406 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:06:17,406 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:06:17,406 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:06:17,407 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:17,407 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:17,407 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:06:17,407 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:06:17,410 [IPC Server handler 4 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,418 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:38339
2020-04-02 05:06:17,418 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:38460
2020-04-02 05:06:17,418 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:06:17,418 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 1 above-average: [127.0.0.1:38339:DISK]
2020-04-02 05:06:17,419 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 below-average: []
2020-04-02 05:06:17,419 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 1 underutilized: [127.0.0.1:38460:DISK]
2020-04-02 05:06:17,419 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(615)) - Need to move 250 B to make the cluster balanced.
2020-04-02 05:06:17,421 [org.apache.hadoop.hdfs.server.balancer.KeyManager$BlockKeyUpdater@60e21209] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:17,422 [IPC Server handler 5 on 36740] INFO  namenode.NameNode (NameNodeRpcServer.java:rollingUpgrade(1333)) - rollingUpgrade QUERY
2020-04-02 05:06:17,422 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for SAME_RACK: overUtilized => underUtilized
2020-04-02 05:06:17,422 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for SAME_RACK: overUtilized => belowAvgUtilized
2020-04-02 05:06:17,423 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for SAME_RACK: underUtilized => aboveAvgUtilized
2020-04-02 05:06:17,423 [main] INFO  balancer.Balancer (Balancer.java:matchSourceWithTargetToMove(537)) - Decided to move 500 B bytes from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK
2020-04-02 05:06:17,423 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for ANY_OTHER: overUtilized => underUtilized
2020-04-02 05:06:17,423 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for ANY_OTHER: overUtilized => belowAvgUtilized
2020-04-02 05:06:17,423 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for ANY_OTHER: underUtilized => aboveAvgUtilized
2020-04-02 05:06:17,423 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(639)) - Will move 500 B in this iteration
2020-04-02 05:06:17,423 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1189)) - Balancer allowed RPCs per sec = 20
2020-04-02 05:06:17,423 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1190)) - Balancer concurrent threads = 1
2020-04-02 05:06:17,423 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1191)) - Disperse Interval sec = 0
2020-04-02 05:06:17,423 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1207)) - Limiting threads per target to the specified max.
2020-04-02 05:06:17,423 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1210)) - Allocating 50 threads per target.
2020-04-02 05:06:17,430 [pool-125-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741831_1007 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,431 [pool-125-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741832_1008 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,431 [pool-126-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741831_1007 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,432 [pool-125-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741833_1009 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,432 [pool-126-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741832_1008 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,433 [pool-125-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741834_1010 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,433 [pool-126-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741833_1009 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,434 [pool-125-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741835_1011 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,434 [pool-126-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741834_1010 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,443 [pool-126-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741835_1011 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,549 [DataXceiver for client /127.0.0.1:40716 [Copying block BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008 to /127.0.0.1:40716
2020-04-02 05:06:17,578 [DataXceiver for client /127.0.0.1:38002 [Replacing block BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008 from 33e55a24-2427-497e-8c33-9d1ce16084d1]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1377894298-172.17.0.6-1585803974309:blk_1073741832_1008 from /127.0.0.1:38002, delHint=33e55a24-2427-497e-8c33-9d1ce16084d1
2020-04-02 05:06:17,587 [DataXceiver for client /127.0.0.1:38008 [Replacing block BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011 from 33e55a24-2427-497e-8c33-9d1ce16084d1]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011 from /127.0.0.1:38008, delHint=33e55a24-2427-497e-8c33-9d1ce16084d1
2020-04-02 05:06:17,578 [DataXceiver for client /127.0.0.1:40718 [Copying block BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009 to /127.0.0.1:40718
2020-04-02 05:06:17,588 [pool-126-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741832_1008 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,585 [DataXceiver for client /127.0.0.1:40720 [Copying block BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007 to /127.0.0.1:40720
2020-04-02 05:06:17,584 [DataXceiver for client /127.0.0.1:38004 [Replacing block BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009 from 33e55a24-2427-497e-8c33-9d1ce16084d1]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1377894298-172.17.0.6-1585803974309:blk_1073741833_1009 from /127.0.0.1:38004, delHint=33e55a24-2427-497e-8c33-9d1ce16084d1
2020-04-02 05:06:17,583 [DataXceiver for client /127.0.0.1:40722 [Copying block BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1377894298-172.17.0.6-1585803974309:blk_1073741835_1011 to /127.0.0.1:40722
2020-04-02 05:06:17,583 [DataXceiver for client /127.0.0.1:40724 [Copying block BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010 to /127.0.0.1:40724
2020-04-02 05:06:17,583 [DataXceiver for client /127.0.0.1:38006 [Replacing block BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010 from 33e55a24-2427-497e-8c33-9d1ce16084d1]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1377894298-172.17.0.6-1585803974309:blk_1073741834_1010 from /127.0.0.1:38006, delHint=33e55a24-2427-497e-8c33-9d1ce16084d1
2020-04-02 05:06:17,582 [DataXceiver for client /127.0.0.1:38000 [Replacing block BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007 from 33e55a24-2427-497e-8c33-9d1ce16084d1]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1377894298-172.17.0.6-1585803974309:blk_1073741831_1007 from /127.0.0.1:38000, delHint=33e55a24-2427-497e-8c33-9d1ce16084d1
2020-04-02 05:06:17,599 [pool-126-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741831_1007 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,599 [pool-126-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741833_1009 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,600 [pool-126-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741834_1010 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
2020-04-02 05:06:17,602 [pool-126-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741835_1011 with size=100 from 127.0.0.1:38339:DISK to 127.0.0.1:38460:DISK through 127.0.0.1:38339
Apr 2, 2020 5:06:18 AM            0                500 B               250 B              500 B
2020-04-02 05:06:21,445 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:06:21,445 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:06:21,445 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:06:21,445 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:06:21,445 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:06:21,446 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:06:21,447 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:21,447 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:21,447 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:06:21,447 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:06:21,448 [IPC Server handler 7 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:21,449 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:38339
2020-04-02 05:06:21,449 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:38460
2020-04-02 05:06:21,449 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:06:21,449 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 above-average: []
2020-04-02 05:06:21,449 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 2 below-average: [127.0.0.1:38339:DISK, 127.0.0.1:38460:DISK]
2020-04-02 05:06:21,449 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 underutilized: []
The cluster is balanced. Exiting...
Apr 2, 2020 5:06:21 AM            1                500 B                 0 B                0 B
2020-04-02 05:06:21,450 [IPC Server handler 6 on 36740] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /system/balancer.id is closed by DFSClient_NONMAPREDUCE_19242530_1
2020-04-02 05:06:21,454 [IPC Server handler 9 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=delete	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:21,456 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(956)) -   .
2020-04-02 05:06:21,456 [IPC Server handler 4 on 36740] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:21,457 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:21,457 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:21,457 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34170 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:21,458 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1b005a0b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:21,508 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@34dc85a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:21,514 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@67403656{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:21,514 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57adfab0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:21,515 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@257cc1fc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:21,546 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34170
2020-04-02 05:06:21,559 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:21,559 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1377894298-172.17.0.6-1585803974309 (Datanode Uuid 3a2fe354-c1c2-4d60-9b42-19f21a82e284) service to localhost/127.0.0.1:36740
2020-04-02 05:06:21,559 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1377894298-172.17.0.6-1585803974309 (Datanode Uuid 3a2fe354-c1c2-4d60-9b42-19f21a82e284)
2020-04-02 05:06:21,561 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:21,562 [IPC Server listener on 34170] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34170
2020-04-02 05:06:21,564 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:21,564 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:21,564 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44490 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:21,565 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@10876a6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:21,669 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@260f2144{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:21,674 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3c017078{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:21,674 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1dcca8d3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:21,674 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56303475{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:21,690 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44490
2020-04-02 05:06:21,701 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:21,702 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:21,702 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1377894298-172.17.0.6-1585803974309 (Datanode Uuid 33e55a24-2427-497e-8c33-9d1ce16084d1) service to localhost/127.0.0.1:36740
2020-04-02 05:06:21,702 [BP-1377894298-172.17.0.6-1585803974309 heartbeating to localhost/127.0.0.1:36740] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1377894298-172.17.0.6-1585803974309 (Datanode Uuid 33e55a24-2427-497e-8c33-9d1ce16084d1)
2020-04-02 05:06:21,702 [IPC Server listener on 44490] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44490
2020-04-02 05:06:21,703 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:21,703 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:21,703 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36740 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:21,703 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:21,703 [Thread[Thread-801,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:06:21,703 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 54
2020-04-02 05:06:21,703 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@250b236d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:21,704 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@61f3fbb8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:21,704 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 55 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 26 Number of syncs: 30 SyncTimes(ms): 7 4 
2020-04-02 05:06:21,704 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:06:21,705 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:06:21,707 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:21,707 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36740
2020-04-02 05:06:21,708 [CacheReplicationMonitor(2004244957)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:21,743 [IPC Server listener on 36740] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36740
2020-04-02 05:06:21,744 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:21,745 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:21,755 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:21,778 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:21,778 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:21,779 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@a64e035{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:21,791 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@22d9c961{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:06:21,791 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ac7aa18{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:21,792 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27fde870{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:21,801 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:21,804 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:21,805 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:06:21,813 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(819)) - capacities = [5000, 5000]
2020-04-02 05:06:21,814 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(820)) - racks      = [/rack0, /rack1]
2020-04-02 05:06:21,814 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(821)) - newCapacity= 5000
2020-04-02 05:06:21,814 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(822)) - newRack    = /rack2
2020-04-02 05:06:21,814 [main] INFO  balancer.TestBalancer (TestBalancer.java:doTest(823)) - useTool    = false
2020-04-02 05:06:21,814 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=0
2020-04-02 05:06:21,830 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803981829,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:21,834 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:06:21,834 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:21,835 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:21,835 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:21,835 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:21,835 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:21,836 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:21,836 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:21,836 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:21,837 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:21,838 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:21,838 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:21,838 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:21,838 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:21,839 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:21,839 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:21,839 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:21
2020-04-02 05:06:21,839 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:21,839 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:21,840 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:21,840 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:21,856 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:21,856 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:21,857 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:06:21,857 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:06:21,857 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:21,858 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:21,858 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:21,858 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:21,859 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:21,859 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:21,859 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:06:21,859 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:21,859 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:21,860 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:21,860 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:21,860 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:21,860 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:21,860 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:21,861 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:21,861 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:21,861 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:21,874 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:21,874 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:21,874 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:21,874 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:21,874 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:21,875 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:21,875 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:21,875 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:21,875 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:21,875 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:21,878 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:21,879 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:21,879 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:21,879 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:21,879 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:21,879 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:21,879 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:21,880 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:21,880 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:21,884 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1564436493-172.17.0.6-1585803981884
2020-04-02 05:06:21,894 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:21,904 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:21,909 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:21,914 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:06:21,915 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:21,921 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 405 bytes saved in 0 seconds .
2020-04-02 05:06:21,925 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:21,927 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:21,933 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:21,942 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:21,942 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:21,945 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:21,945 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:21,952 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803981952,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:21,956 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:21,969 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:06:21,970 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7207cb51] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:21,971 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:36741
2020-04-02 05:06:21,971 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:21,972 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:21,973 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:21,974 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:21,975 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:21,975 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:21,975 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:21,975 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:21,977 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:21,977 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:21,978 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:06:21,978 [main] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:06:21,978 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36741
2020-04-02 05:06:21,978 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:21,993 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e2916c3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:21,994 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@ae7950d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:21,998 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:06:21,999 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:06:21,999 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@15bc339{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:22,001 [main] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@7e75bf2d(server,h=[],w=[]) for SslContextFactory@385ef531(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks)
2020-04-02 05:06:22,005 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@59d7d33a{SSL,[ssl, http/1.1]}{localhost:36741}
2020-04-02 05:06:22,009 [main] INFO  server.Server (Server.java:doStart(419)) - Started @48324ms
2020-04-02 05:06:22,014 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:22,014 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:22,015 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:22,015 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:22,015 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:22,015 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:22,015 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:22,016 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:22,016 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:22,016 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:22,017 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:22,017 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:22,017 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:22,017 [main] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:22,017 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:22,018 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:22
2020-04-02 05:06:22,018 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:22,025 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:22,026 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:22,026 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:22,047 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:22,047 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:22,047 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:06:22,048 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:06:22,048 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:22,048 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:22,049 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:22,049 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:22,049 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:22,049 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:22,050 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 0
2020-04-02 05:06:22,050 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:22,050 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:22,050 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:22,050 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:22,051 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:22,051 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:22,051 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:22,052 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:22,052 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:22,052 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:22,065 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:22,065 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:22,065 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:22,065 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:22,066 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:22,066 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:22,066 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:22,066 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:22,067 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:22,067 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:22,067 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:22,068 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:22,068 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:22,068 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:22,068 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:22,068 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:22,069 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:22,069 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:22,069 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:22,077 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:06:22,081 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8915@0d6e4bc4608e
2020-04-02 05:06:22,083 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:22,083 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:22,084 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:22,084 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:22,085 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:22,085 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:22,086 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:22,089 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:22,094 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:22,154 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:22,154 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 84 msecs
2020-04-02 05:06:22,154 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:22,155 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:22,161 [Socket Reader #1 for port 40831] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40831
2020-04-02 05:06:22,167 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:40831 to access this namenode/service.
2020-04-02 05:06:22,168 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:22,202 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:22,231 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@73044cdf] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:06:22,238 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:22,238 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:22,238 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:06:22,239 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:22,241 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:06:22,248 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:22,248 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:22,248 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:22,248 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:22,248 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:22,248 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-04-02 05:06:22,250 [Thread[Thread-963,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:06:22,250 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:22,250 [IPC Server listener on 40831] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40831: starting
2020-04-02 05:06:22,251 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:40831
2020-04-02 05:06:22,252 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:22,252 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:22,264 [Thread[Thread-963,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:06:22,264 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:22,276 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 40831 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:22,302 [CacheReplicationMonitor(1186774634)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:22,306 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803982305,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:22,336 [Socket Reader #1 for port 40831] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:22,344 [IPC Server handler 0 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,346 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:22,347 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:22,348 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 0 with hostname set to: host0.foo.com
2020-04-02 05:06:22,348 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host0.foo.com to rack /rack0
2020-04-02 05:06:22,359 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803982358,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:22,362 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:22,363 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:22,370 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:22,370 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:22,370 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:22,371 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:22,371 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host0.foo.com
2020-04-02 05:06:22,371 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:22,371 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:22,371 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:22,372 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:22,372 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41156
2020-04-02 05:06:22,372 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:22,372 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:22,374 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:22,375 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:22,376 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:22,376 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:22,377 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:22,377 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:22,377 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:22,377 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:22,382 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41532
2020-04-02 05:06:22,382 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:22,387 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@153d4abb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:22,387 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a67e962{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:22,391 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@105b693d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:22,392 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3fae596{HTTP/1.1,[http/1.1]}{localhost:41532}
2020-04-02 05:06:22,392 [main] INFO  server.Server (Server.java:doStart(419)) - Started @48707ms
2020-04-02 05:06:22,412 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:46145
2020-04-02 05:06:22,413 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:22,414 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:22,414 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:22,415 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5da7cee2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:22,415 [Socket Reader #1 for port 46692] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46692
2020-04-02 05:06:22,417 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46692
2020-04-02 05:06:22,436 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:22,436 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:22,450 [Thread-993] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40831 starting to offer service
2020-04-02 05:06:22,498 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:41156 to rack /rack0
2020-04-02 05:06:22,506 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:22,513 [IPC Server listener on 46692] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46692: starting
2020-04-02 05:06:22,554 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46692 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:22,560 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803982560,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:22,562 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:22,562 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 1 with hostname set to: host1.foo.com
2020-04-02 05:06:22,562 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host1.foo.com to rack /rack1
2020-04-02 05:06:22,579 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803982578,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:22,589 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:22,589 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:22,590 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:22,590 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:22,591 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:22,591 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:22,591 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1.foo.com
2020-04-02 05:06:22,591 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:22,591 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:22,591 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:22,592 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:22,592 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38987
2020-04-02 05:06:22,592 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:22,593 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:22,591 [Socket Reader #1 for port 40831] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:22,594 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:22,595 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:22,596 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:22,599 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:22,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:22,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:22,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:22,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:22,608 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39683
2020-04-02 05:06:22,608 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:22,597 [Thread-993] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40831
2020-04-02 05:06:22,616 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7965a51c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:22,617 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f63e3c7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:22,623 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44de0113{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:22,623 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@236134a1{HTTP/1.1,[http/1.1]}{localhost:39683}
2020-04-02 05:06:22,623 [main] INFO  server.Server (Server.java:doStart(419)) - Started @48938ms
2020-04-02 05:06:22,644 [Thread-993] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8edf1054-ed57-425c-97ff-2811821439b3
2020-04-02 05:06:22,644 [Thread-993] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:06:22,644 [Thread-993] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:22,645 [Thread-993] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2ca19b9e
2020-04-02 05:06:22,647 [Thread-993] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@2ca19b9e
2020-04-02 05:06:22,647 [Thread-993] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:06:22,653 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid 8edf1054-ed57-425c-97ff-2811821439b3) service to localhost/127.0.0.1:40831 beginning handshake with NN
2020-04-02 05:06:22,657 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:34364
2020-04-02 05:06:22,658 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:22,658 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:22,658 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:22,659 [Socket Reader #1 for port 43004] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43004
2020-04-02 05:06:22,668 [IPC Server handler 2 on 40831] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41156, datanodeUuid=8edf1054-ed57-425c-97ff-2811821439b3, infoPort=0, infoSecurePort=46145, ipcPort=46692, storageInfo=lv=-57;cid=testClusterID;nsid=269786207;c=1585803981884) storage 8edf1054-ed57-425c-97ff-2811821439b3
2020-04-02 05:06:22,668 [IPC Server handler 2 on 40831] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:41156
2020-04-02 05:06:22,668 [IPC Server handler 2 on 40831] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8edf1054-ed57-425c-97ff-2811821439b3 (127.0.0.1:41156).
2020-04-02 05:06:22,670 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@42b21d99] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:22,683 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43004
2020-04-02 05:06:22,685 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid 8edf1054-ed57-425c-97ff-2811821439b3) service to localhost/127.0.0.1:40831 successfully registered with NN
2020-04-02 05:06:22,685 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1564436493-172.17.0.6-1585803981884 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:22,685 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:22,686 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40831 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:22,718 [IPC Server handler 3 on 40831] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-abd85401-d230-4b1c-8183-28d87e6a7b80 for DN 127.0.0.1:41156
2020-04-02 05:06:22,726 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc6f69b472a453067: Processing first storage report for SimulatedStorage-DS-abd85401-d230-4b1c-8183-28d87e6a7b80 from datanode 8edf1054-ed57-425c-97ff-2811821439b3
2020-04-02 05:06:22,726 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc6f69b472a453067: from storage SimulatedStorage-DS-abd85401-d230-4b1c-8183-28d87e6a7b80 node DatanodeRegistration(127.0.0.1:41156, datanodeUuid=8edf1054-ed57-425c-97ff-2811821439b3, infoPort=0, infoSecurePort=46145, ipcPort=46692, storageInfo=lv=-57;cid=testClusterID;nsid=269786207;c=1585803981884), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:22,726 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:22,726 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:22,728 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc6f69b472a453067,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:22,736 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1564436493-172.17.0.6-1585803981884
2020-04-02 05:06:22,734 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:38987 to rack /rack1
2020-04-02 05:06:22,730 [Thread-1017] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40831 starting to offer service
2020-04-02 05:06:22,740 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:22,740 [IPC Server listener on 43004] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43004: starting
2020-04-02 05:06:22,761 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43004 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:22,781 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803982780,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:22,801 [Socket Reader #1 for port 40831] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:22,832 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803982821,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:22,833 [IPC Server handler 5 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,839 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:22,840 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:22,853 [Socket Reader #1 for port 40831] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:22,858 [Thread-1017] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40831
2020-04-02 05:06:22,860 [Thread-1017] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID c851c665-e533-484d-bd10-0c94efe1c406
2020-04-02 05:06:22,861 [Thread-1017] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:06:22,861 [Thread-1017] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:22,862 [Thread-1017] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@275495e1
2020-04-02 05:06:22,869 [Thread-1017] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@275495e1
2020-04-02 05:06:22,870 [Thread-1017] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:06:22,871 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid c851c665-e533-484d-bd10-0c94efe1c406) service to localhost/127.0.0.1:40831 beginning handshake with NN
2020-04-02 05:06:22,874 [IPC Server handler 7 on 40831] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38987, datanodeUuid=c851c665-e533-484d-bd10-0c94efe1c406, infoPort=0, infoSecurePort=34364, ipcPort=43004, storageInfo=lv=-57;cid=testClusterID;nsid=269786207;c=1585803981884) storage c851c665-e533-484d-bd10-0c94efe1c406
2020-04-02 05:06:22,874 [IPC Server handler 7 on 40831] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack1/127.0.0.1:38987
2020-04-02 05:06:22,874 [IPC Server handler 7 on 40831] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:checkIfClusterIsNowMultiRack(1386)) - DN 127.0.0.1:38987 joining cluster has expanded a formerly single-rack cluster to be multi-rack. Re-checking all blocks for replication, since they should now be replicated cross-rack
2020-04-02 05:06:22,881 [IPC Server handler 7 on 40831] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c851c665-e533-484d-bd10-0c94efe1c406 (127.0.0.1:38987).
2020-04-02 05:06:22,883 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid c851c665-e533-484d-bd10-0c94efe1c406) service to localhost/127.0.0.1:40831 successfully registered with NN
2020-04-02 05:06:22,883 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1564436493-172.17.0.6-1585803981884 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:22,884 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:22,884 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40831 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:22,891 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:22,891 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:22,891 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:22,891 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:22,891 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:22,891 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-04-02 05:06:22,898 [IPC Server handler 8 on 40831] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-139d74cb-4808-40cd-a72e-a00101e48831 for DN 127.0.0.1:38987
2020-04-02 05:06:22,910 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1c21d44abd8e9cef: Processing first storage report for SimulatedStorage-DS-139d74cb-4808-40cd-a72e-a00101e48831 from datanode c851c665-e533-484d-bd10-0c94efe1c406
2020-04-02 05:06:22,911 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1c21d44abd8e9cef: from storage SimulatedStorage-DS-139d74cb-4808-40cd-a72e-a00101e48831 node DatanodeRegistration(127.0.0.1:38987, datanodeUuid=c851c665-e533-484d-bd10-0c94efe1c406, infoPort=0, infoSecurePort=34364, ipcPort=43004, storageInfo=lv=-57;cid=testClusterID;nsid=269786207;c=1585803981884), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:22,911 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1c21d44abd8e9cef,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:22,911 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1564436493-172.17.0.6-1585803981884
2020-04-02 05:06:22,942 [IPC Server handler 0 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,950 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:22,957 [IPC Server handler 1 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,959 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:22,961 [IPC Server handler 2 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:22,971 [IPC Server handler 3 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/tmp.txt	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:22,995 [IPC Server handler 4 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,042 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:33984 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001 src: /127.0.0.1:33984 dest: /127.0.0.1:38987
2020-04-02 05:06:23,095 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43250 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001 src: /127.0.0.1:43250 dest: /127.0.0.1:41156
2020-04-02 05:06:23,130 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43250, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001, duration(ns): 23921575
2020-04-02 05:06:23,130 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,131 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33984, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001, duration(ns): 14703202
2020-04-02 05:06:23,131 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,153 [IPC Server handler 7 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,169 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:33992 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002 src: /127.0.0.1:33992 dest: /127.0.0.1:38987
2020-04-02 05:06:23,190 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43258 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002 src: /127.0.0.1:43258 dest: /127.0.0.1:41156
2020-04-02 05:06:23,208 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43258, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002, duration(ns): 12018652
2020-04-02 05:06:23,208 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,209 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33992, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002, duration(ns): 12952508
2020-04-02 05:06:23,209 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,214 [IPC Server handler 0 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,229 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:33996 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003 src: /127.0.0.1:33996 dest: /127.0.0.1:38987
2020-04-02 05:06:23,250 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43262 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003 src: /127.0.0.1:43262 dest: /127.0.0.1:41156
2020-04-02 05:06:23,262 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43262, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003, duration(ns): 10873531
2020-04-02 05:06:23,262 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,263 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33996, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003, duration(ns): 10182856
2020-04-02 05:06:23,263 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,268 [IPC Server handler 4 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,272 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34004 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004 src: /127.0.0.1:34004 dest: /127.0.0.1:38987
2020-04-02 05:06:23,291 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43270 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004 src: /127.0.0.1:43270 dest: /127.0.0.1:41156
2020-04-02 05:06:23,301 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43270, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004, duration(ns): 6132374
2020-04-02 05:06:23,301 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,302 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34004, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004, duration(ns): 2300947
2020-04-02 05:06:23,302 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,307 [IPC Server handler 5 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:41156, 127.0.0.1:38987 for /tmp.txt
2020-04-02 05:06:23,315 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43272 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005 src: /127.0.0.1:43272 dest: /127.0.0.1:41156
2020-04-02 05:06:23,347 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34010 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005 src: /127.0.0.1:34010 dest: /127.0.0.1:38987
2020-04-02 05:06:23,376 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34010, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005, duration(ns): 21298662
2020-04-02 05:06:23,376 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,376 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43272, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005, duration(ns): 2658110
2020-04-02 05:06:23,376 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987] terminating
2020-04-02 05:06:23,383 [IPC Server handler 1 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,398 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34014 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006 src: /127.0.0.1:34014 dest: /127.0.0.1:38987
2020-04-02 05:06:23,408 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43280 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006 src: /127.0.0.1:43280 dest: /127.0.0.1:41156
2020-04-02 05:06:23,442 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43280, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006, duration(ns): 17604348
2020-04-02 05:06:23,445 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,445 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34014, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006, duration(ns): 31261617
2020-04-02 05:06:23,449 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,452 [IPC Server handler 3 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,459 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34018 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007 src: /127.0.0.1:34018 dest: /127.0.0.1:38987
2020-04-02 05:06:23,465 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43284 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007 src: /127.0.0.1:43284 dest: /127.0.0.1:41156
2020-04-02 05:06:23,475 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43284, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007, duration(ns): 9330532
2020-04-02 05:06:23,475 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,476 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34018, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007, duration(ns): 9689418
2020-04-02 05:06:23,477 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,478 [IPC Server handler 4 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,484 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34022 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008 src: /127.0.0.1:34022 dest: /127.0.0.1:38987
2020-04-02 05:06:23,494 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43288 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008 src: /127.0.0.1:43288 dest: /127.0.0.1:41156
2020-04-02 05:06:23,502 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43288, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008, duration(ns): 5784441
2020-04-02 05:06:23,502 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,506 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34022, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008, duration(ns): 7898099
2020-04-02 05:06:23,506 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,514 [IPC Server handler 9 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:41156, 127.0.0.1:38987 for /tmp.txt
2020-04-02 05:06:23,520 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43290 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009 src: /127.0.0.1:43290 dest: /127.0.0.1:41156
2020-04-02 05:06:23,530 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34028 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009 src: /127.0.0.1:34028 dest: /127.0.0.1:38987
2020-04-02 05:06:23,540 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34028, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009, duration(ns): 4389760
2020-04-02 05:06:23,540 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,540 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43290, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009, duration(ns): 2653929
2020-04-02 05:06:23,541 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987] terminating
2020-04-02 05:06:23,542 [IPC Server handler 1 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:41156, 127.0.0.1:38987 for /tmp.txt
2020-04-02 05:06:23,553 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43294 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010 src: /127.0.0.1:43294 dest: /127.0.0.1:41156
2020-04-02 05:06:23,558 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34032 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010 src: /127.0.0.1:34032 dest: /127.0.0.1:38987
2020-04-02 05:06:23,563 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34032, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010, duration(ns): 3570313
2020-04-02 05:06:23,563 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,566 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43294, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010, duration(ns): 6450020
2020-04-02 05:06:23,566 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987] terminating
2020-04-02 05:06:23,568 [IPC Server handler 3 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,574 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34034 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011 src: /127.0.0.1:34034 dest: /127.0.0.1:38987
2020-04-02 05:06:23,581 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43300 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011 src: /127.0.0.1:43300 dest: /127.0.0.1:41156
2020-04-02 05:06:23,589 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43300, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011, duration(ns): 6895189
2020-04-02 05:06:23,590 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,590 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34034, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011, duration(ns): 7819378
2020-04-02 05:06:23,590 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,593 [IPC Server handler 8 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,598 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34040 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012 src: /127.0.0.1:34040 dest: /127.0.0.1:38987
2020-04-02 05:06:23,602 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43306 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012 src: /127.0.0.1:43306 dest: /127.0.0.1:41156
2020-04-02 05:06:23,615 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43306, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012, duration(ns): 8184514
2020-04-02 05:06:23,616 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,616 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34040, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012, duration(ns): 8368256
2020-04-02 05:06:23,616 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,630 [IPC Server handler 0 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:41156, 127.0.0.1:38987 for /tmp.txt
2020-04-02 05:06:23,635 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43312 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013 src: /127.0.0.1:43312 dest: /127.0.0.1:41156
2020-04-02 05:06:23,643 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34050 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013 src: /127.0.0.1:34050 dest: /127.0.0.1:38987
2020-04-02 05:06:23,646 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34050, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013, duration(ns): 2032297
2020-04-02 05:06:23,646 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,647 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43312, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013, duration(ns): 2042527
2020-04-02 05:06:23,647 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:38987] terminating
2020-04-02 05:06:23,651 [IPC Server handler 3 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,656 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34052 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014 src: /127.0.0.1:34052 dest: /127.0.0.1:38987
2020-04-02 05:06:23,672 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43318 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014 src: /127.0.0.1:43318 dest: /127.0.0.1:41156
2020-04-02 05:06:23,682 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43318, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014, duration(ns): 8401096
2020-04-02 05:06:23,682 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,683 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34052, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014, duration(ns): 3832543
2020-04-02 05:06:23,684 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,715 [IPC Server handler 8 on 40831] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:38987, 127.0.0.1:41156 for /tmp.txt
2020-04-02 05:06:23,846 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:34060 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015 src: /127.0.0.1:34060 dest: /127.0.0.1:38987
2020-04-02 05:06:23,866 [DataXceiver for client DFSClient_NONMAPREDUCE_-270074273_1 at /127.0.0.1:43332 [Receiving block BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015 src: /127.0.0.1:43332 dest: /127.0.0.1:41156
2020-04-02 05:06:23,882 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43332, dest: /127.0.0.1:41156, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: 8edf1054-ed57-425c-97ff-2811821439b3, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015, duration(ns): 14927488
2020-04-02 05:06:23,882 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:23,886 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34060, dest: /127.0.0.1:38987, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-270074273_1, offset: 0, srvID: c851c665-e533-484d-bd10-0c94efe1c406, blockid: BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015, duration(ns): 11873534
2020-04-02 05:06:23,886 [PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:41156] terminating
2020-04-02 05:06:23,904 [IPC Server handler 0 on 40831] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp.txt is closed by DFSClient_NONMAPREDUCE_-270074273_1
2020-04-02 05:06:23,908 [IPC Server handler 3 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp.txt	dst=null	perm=null	proto=rpc
2020-04-02 05:06:23,911 [IPC Server handler 5 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=open	src=/tmp.txt	dst=null	perm=null	proto=rpc
All blocks of file /tmp.txt verified to have replication factor 2
2020-04-02 05:06:23,914 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:23,915 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 2 with hostname set to: host2.foo.com
2020-04-02 05:06:23,915 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host2.foo.com to rack /rack2
2020-04-02 05:06:23,923 [pool-1-thread-2] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585803983922,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:06:23,924 [main] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/hdfs.keytab
2020-04-02 05:06:23,925 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:23,927 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:23,927 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:23,928 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:23,928 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:23,928 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host2.foo.com
2020-04-02 05:06:23,928 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:23,928 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:23,928 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:23,929 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:23,929 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42280
2020-04-02 05:06:23,929 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:23,929 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:23,934 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:23,938 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:23,939 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:23,939 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:23,940 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:23,940 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:23,941 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:23,941 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:23,941 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38532
2020-04-02 05:06:23,941 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:23,957 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@640dc4c6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:23,957 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7bb35cc6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:23,963 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@64c4c01{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:23,968 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1aa99005{HTTP/1.1,[http/1.1]}{localhost:38532}
2020-04-02 05:06:23,968 [main] INFO  server.Server (Server.java:doStart(419)) - Started @50284ms
2020-04-02 05:06:24,004 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:46782
2020-04-02 05:06:24,006 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:24,006 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:24,007 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:24,006 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5cdf39b2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:24,014 [Socket Reader #1 for port 40590] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40590
2020-04-02 05:06:24,027 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40590
2020-04-02 05:06:24,029 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:24,029 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:24,037 [Thread-1120] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40831 starting to offer service
2020-04-02 05:06:24,039 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:42280 to rack /rack2
2020-04-02 05:06:24,049 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:24,049 [IPC Server listener on 40590] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40590: starting
2020-04-02 05:06:24,074 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40590 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:24,089 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803984089,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:24,097 [Socket Reader #1 for port 40831] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:24,108 [IPC Server handler 6 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:24,109 [pool-1-thread-2] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585803984109,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:06:24,125 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:24,126 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:24,128 [Socket Reader #1 for port 40831] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:24,143 [Thread-1120] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40831
2020-04-02 05:06:24,144 [Thread-1120] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 9d3a0e23-5972-4931-8e39-c6e38bd4a7cd
2020-04-02 05:06:24,145 [Thread-1120] INFO  datanode.DataNode (SimulatedFSDataset.java:registerMBean(1350)) - Registered FSDatasetState MBean
2020-04-02 05:06:24,145 [Thread-1120] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,146 [Thread-1120] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@14ff4f6
2020-04-02 05:06:24,150 [Thread-1120] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume org.apache.hadoop.hdfs.server.datanode.SimulatedFSDataset$SimulatedVolume@14ff4f6
2020-04-02 05:06:24,156 [Thread-1120] INFO  datanode.DataNode (DataNode.java:initDirectoryScanner(1103)) - Periodic Directory Tree Verification scan is disabled because verifcation is not supported by SimulatedFSDataset
2020-04-02 05:06:24,157 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid 9d3a0e23-5972-4931-8e39-c6e38bd4a7cd) service to localhost/127.0.0.1:40831 beginning handshake with NN
2020-04-02 05:06:24,162 [IPC Server handler 8 on 40831] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42280, datanodeUuid=9d3a0e23-5972-4931-8e39-c6e38bd4a7cd, infoPort=0, infoSecurePort=46782, ipcPort=40590, storageInfo=lv=-57;cid=testClusterID;nsid=269786207;c=1585803981884) storage 9d3a0e23-5972-4931-8e39-c6e38bd4a7cd
2020-04-02 05:06:24,162 [IPC Server handler 8 on 40831] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack2/127.0.0.1:42280
2020-04-02 05:06:24,163 [IPC Server handler 8 on 40831] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9d3a0e23-5972-4931-8e39-c6e38bd4a7cd (127.0.0.1:42280).
2020-04-02 05:06:24,163 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid 9d3a0e23-5972-4931-8e39-c6e38bd4a7cd) service to localhost/127.0.0.1:40831 successfully registered with NN
2020-04-02 05:06:24,163 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1564436493-172.17.0.6-1585803981884 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:06:24,163 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:24,163 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40831 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:24,172 [IPC Server handler 7 on 40831] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID SimulatedStorage-DS-6a6e9646-ca5c-48b8-bd3b-afbf30462377 for DN 127.0.0.1:42280
2020-04-02 05:06:24,174 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe51c0cdab3f2dd2b: Processing first storage report for SimulatedStorage-DS-6a6e9646-ca5c-48b8-bd3b-afbf30462377 from datanode 9d3a0e23-5972-4931-8e39-c6e38bd4a7cd
2020-04-02 05:06:24,174 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe51c0cdab3f2dd2b: from storage SimulatedStorage-DS-6a6e9646-ca5c-48b8-bd3b-afbf30462377 node DatanodeRegistration(127.0.0.1:42280, datanodeUuid=9d3a0e23-5972-4931-8e39-c6e38bd4a7cd, infoPort=0, infoSecurePort=46782, ipcPort=40590, storageInfo=lv=-57;cid=testClusterID;nsid=269786207;c=1585803981884), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:24,175 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe51c0cdab3f2dd2b,  containing 1 storage report(s), of which we sent 1. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:24,175 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1564436493-172.17.0.6-1585803981884
2020-04-02 05:06:24,230 [IPC Server handler 9 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:24,234 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:24,743 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(984)) - namenodes  = [hdfs://localhost:40831]
2020-04-02 05:06:24,743 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(985)) - parameters = Balancer.BalancerParameters [BalancingPolicy.Node, threshold = 10.0, max idle iteration = 5, #excluded nodes = 0, #included nodes = 0, #source nodes = 0, #blockpools = 0, run during upgrade = false]
2020-04-02 05:06:24,743 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(986)) - Print stack trace
java.lang.Throwable
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:986)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.runBalancer(TestBalancer.java:945)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:921)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:793)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.doTest(TestBalancer.java:787)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.twoNodeTest(TestBalancer.java:1099)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancer.testBalancer0Internal(TestBalancer.java:1209)
	at org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer.testBalancer0Privacy(TestBalancerWithSaslDataTransfer.java:39)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Time Stamp               Iteration#  Bytes Already Moved  Bytes Left To Move  Bytes Being Moved
2020-04-02 05:06:24,752 [Socket Reader #1 for port 40831] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:06:24,764 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(75)) - Block token params received from NN: update interval=10hrs, 0sec, token lifetime=10hrs, 0sec
2020-04-02 05:06:24,764 [main] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:24,765 [main] INFO  balancer.KeyManager (KeyManager.java:<init>(172)) - Update block keys every 2hrs, 30mins, 0sec
2020-04-02 05:06:24,765 [IPC Server handler 2 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:24,768 [IPC Server handler 0 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/system/balancer.id	dst=null	perm=hdfs:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:24,776 [IPC Server handler 3 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getfileinfo	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:24,785 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:06:24,786 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:06:24,786 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:06:24,786 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:06:24,786 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:06:24,786 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:06:24,787 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:24,787 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:24,787 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:06:24,787 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:06:24,788 [IPC Server handler 5 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:24,789 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:41156
2020-04-02 05:06:24,789 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack1/127.0.0.1:38987
2020-04-02 05:06:24,789 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack2/127.0.0.1:42280
2020-04-02 05:06:24,795 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:06:24,796 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 2 above-average: [127.0.0.1:41156:DISK, 127.0.0.1:38987:DISK]
2020-04-02 05:06:24,796 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 below-average: []
2020-04-02 05:06:24,796 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 1 underutilized: [127.0.0.1:42280:DISK]
2020-04-02 05:06:24,796 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(615)) - Need to move 500 B to make the cluster balanced.
2020-04-02 05:06:24,800 [org.apache.hadoop.hdfs.server.balancer.KeyManager$BlockKeyUpdater@a52ca2e] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:06:24,802 [IPC Server handler 8 on 40831] INFO  namenode.NameNode (NameNodeRpcServer.java:rollingUpgrade(1333)) - rollingUpgrade QUERY
2020-04-02 05:06:24,805 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for SAME_RACK: overUtilized => underUtilized
2020-04-02 05:06:24,806 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for SAME_RACK: overUtilized => belowAvgUtilized
2020-04-02 05:06:24,806 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for SAME_RACK: underUtilized => aboveAvgUtilized
2020-04-02 05:06:24,806 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(471)) - chooseStorageGroups for ANY_OTHER: overUtilized => underUtilized
2020-04-02 05:06:24,806 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(479)) - chooseStorageGroups for ANY_OTHER: overUtilized => belowAvgUtilized
2020-04-02 05:06:24,806 [main] INFO  balancer.Balancer (Balancer.java:chooseStorageGroups(487)) - chooseStorageGroups for ANY_OTHER: underUtilized => aboveAvgUtilized
2020-04-02 05:06:24,806 [main] INFO  balancer.Balancer (Balancer.java:matchSourceWithTargetToMove(537)) - Decided to move 500 B bytes from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK
2020-04-02 05:06:24,807 [main] INFO  balancer.Balancer (Balancer.java:matchSourceWithTargetToMove(537)) - Decided to move 500 B bytes from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK
2020-04-02 05:06:24,807 [main] INFO  balancer.Balancer (Balancer.java:runOneIteration(639)) - Will move 1000 B in this iteration
2020-04-02 05:06:24,807 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1189)) - Balancer allowed RPCs per sec = 20
2020-04-02 05:06:24,807 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1190)) - Balancer concurrent threads = 2
2020-04-02 05:06:24,807 [main] DEBUG balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1191)) - Disperse Interval sec = 0
2020-04-02 05:06:24,807 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1207)) - Limiting threads per target to the specified max.
2020-04-02 05:06:24,807 [main] INFO  balancer.Dispatcher (Dispatcher.java:dispatchBlockMoves(1210)) - Allocating 50 threads per target.
2020-04-02 05:06:24,819 [pool-153-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741834_1010 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:38987
2020-04-02 05:06:24,827 [pool-153-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741835_1011 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,830 [pool-154-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741834_1010 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:38987
2020-04-02 05:06:24,834 [pool-153-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741836_1012 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,840 [pool-154-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741835_1011 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,844 [pool-153-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741837_1013 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,845 [pool-154-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741836_1012 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,849 [pool-153-thread-1] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741838_1014 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:38987
2020-04-02 05:06:24,850 [pool-154-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741837_1013 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,859 [pool-154-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741838_1014 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:38987
2020-04-02 05:06:24,916 [DataXceiver for client /127.0.0.1:34124 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010 to /127.0.0.1:34124
2020-04-02 05:06:24,935 [DataXceiver for client /127.0.0.1:43392 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012 to /127.0.0.1:43392
2020-04-02 05:06:24,946 [pool-153-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741830_1006 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,946 [pool-153-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741831_1007 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,947 [pool-154-thread-6] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741830_1006 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,946 [DataXceiver for client /127.0.0.1:43396 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011 to /127.0.0.1:43396
2020-04-02 05:06:24,947 [pool-153-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741832_1008 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,947 [pool-154-thread-7] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741831_1007 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,947 [pool-153-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741833_1009 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,947 [pool-154-thread-8] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741832_1008 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,947 [pool-153-thread-2] DEBUG balancer.Dispatcher (Dispatcher.java:markMovedIfGoodBlock(294)) - Decided to move blk_1073741839_1015 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,947 [pool-154-thread-9] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741833_1009 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,947 [pool-154-thread-10] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(361)) - Start moving blk_1073741839_1015 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,950 [DataXceiver for client /127.0.0.1:43400 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013 to /127.0.0.1:43400
2020-04-02 05:06:24,951 [DataXceiver for client /127.0.0.1:34130 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014 to /127.0.0.1:34130
2020-04-02 05:06:24,992 [DataXceiver for client /127.0.0.1:43414 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008 to /127.0.0.1:43414
2020-04-02 05:06:24,994 [DataXceiver for client /127.0.0.1:60646 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011 from 8edf1054-ed57-425c-97ff-2811821439b3]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741835_1011 from /127.0.0.1:60646, delHint=8edf1054-ed57-425c-97ff-2811821439b3
2020-04-02 05:06:24,994 [pool-154-thread-2] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741835_1011 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,995 [DataXceiver for client /127.0.0.1:60672 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008 from c851c665-e533-484d-bd10-0c94efe1c406]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741832_1008 from /127.0.0.1:60672, delHint=c851c665-e533-484d-bd10-0c94efe1c406
2020-04-02 05:06:24,995 [DataXceiver for client /127.0.0.1:60644 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010 from 8edf1054-ed57-425c-97ff-2811821439b3]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741834_1010 from /127.0.0.1:60644, delHint=8edf1054-ed57-425c-97ff-2811821439b3
2020-04-02 05:06:24,995 [pool-154-thread-8] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741832_1008 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,995 [DataXceiver for client /127.0.0.1:60648 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012 from 8edf1054-ed57-425c-97ff-2811821439b3]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741836_1012 from /127.0.0.1:60648, delHint=8edf1054-ed57-425c-97ff-2811821439b3
2020-04-02 05:06:24,997 [pool-154-thread-3] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741836_1012 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:24,998 [pool-154-thread-1] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741834_1010 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:38987
2020-04-02 05:06:24,999 [DataXceiver for client /127.0.0.1:43412 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006 to /127.0.0.1:43412
2020-04-02 05:06:25,018 [DataXceiver for client /127.0.0.1:43418 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009 to /127.0.0.1:43418
2020-04-02 05:06:25,019 [DataXceiver for client /127.0.0.1:60652 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014 from 8edf1054-ed57-425c-97ff-2811821439b3]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741838_1014 from /127.0.0.1:60652, delHint=8edf1054-ed57-425c-97ff-2811821439b3
2020-04-02 05:06:25,020 [DataXceiver for client /127.0.0.1:60674 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009 from c851c665-e533-484d-bd10-0c94efe1c406]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741833_1009 from /127.0.0.1:60674, delHint=c851c665-e533-484d-bd10-0c94efe1c406
2020-04-02 05:06:25,020 [pool-154-thread-9] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741833_1009 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:25,021 [DataXceiver for client /127.0.0.1:43416 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007 to /127.0.0.1:43416
2020-04-02 05:06:25,021 [pool-154-thread-5] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741838_1014 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:38987
2020-04-02 05:06:25,022 [DataXceiver for client /127.0.0.1:60670 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007 from c851c665-e533-484d-bd10-0c94efe1c406]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741831_1007 from /127.0.0.1:60670, delHint=c851c665-e533-484d-bd10-0c94efe1c406
2020-04-02 05:06:25,022 [pool-154-thread-7] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741831_1007 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:25,023 [DataXceiver for client /127.0.0.1:60668 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006 from c851c665-e533-484d-bd10-0c94efe1c406]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741830_1006 from /127.0.0.1:60668, delHint=c851c665-e533-484d-bd10-0c94efe1c406
2020-04-02 05:06:25,024 [pool-154-thread-6] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741830_1006 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:25,032 [DataXceiver for client /127.0.0.1:60650 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013 from 8edf1054-ed57-425c-97ff-2811821439b3]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741837_1013 from /127.0.0.1:60650, delHint=8edf1054-ed57-425c-97ff-2811821439b3
2020-04-02 05:06:25,032 [pool-154-thread-4] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741837_1013 with size=100 from 127.0.0.1:41156:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
2020-04-02 05:06:25,036 [DataXceiver for client /127.0.0.1:43420 [Copying block BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:copyBlock(1105)) - Copied BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015 to /127.0.0.1:43420
2020-04-02 05:06:25,037 [DataXceiver for client /127.0.0.1:60676 [Replacing block BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015 from c851c665-e533-484d-bd10-0c94efe1c406]] INFO  datanode.DataNode (DataXceiver.java:replaceBlock(1227)) - Moved BP-1564436493-172.17.0.6-1585803981884:blk_1073741839_1015 from /127.0.0.1:60676, delHint=c851c665-e533-484d-bd10-0c94efe1c406
2020-04-02 05:06:25,040 [pool-154-thread-10] INFO  balancer.Dispatcher (Dispatcher.java:dispatch(396)) - Successfully moved blk_1073741839_1015 with size=100 from 127.0.0.1:38987:DISK to 127.0.0.1:42280:DISK through 127.0.0.1:41156
Apr 2, 2020 5:06:25 AM            0               1000 B               500 B             1000 B
2020-04-02 05:06:28,948 [main] INFO  balancer.Balancer (Balancer.java:getLong(233)) - dfs.balancer.movedWinWidth = 2000 (default=5400000)
2020-04-02 05:06:28,949 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.moverThreads = 1000 (default=1000)
2020-04-02 05:06:28,949 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.balancer.dispatcherThreads = 200 (default=200)
2020-04-02 05:06:28,949 [main] INFO  balancer.Balancer (Balancer.java:getInt(251)) - dfs.datanode.balance.max.concurrent.moves = 50 (default=50)
2020-04-02 05:06:28,949 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.size = 2147483648 (default=2147483648)
2020-04-02 05:06:28,949 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.getBlocks.min-block-size = 1 (default=10485760)
2020-04-02 05:06:28,950 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:28,950 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:28,950 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.balancer.max-size-to-move = 10737418240 (default=10737418240)
2020-04-02 05:06:28,950 [main] INFO  balancer.Balancer (Balancer.java:getLongBytes(242)) - dfs.blocksize = 100 (default=134217728)
2020-04-02 05:06:28,951 [IPC Server handler 0 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=getDatanodeStorageReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:28,952 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack2/127.0.0.1:42280
2020-04-02 05:06:28,952 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack0/127.0.0.1:41156
2020-04-02 05:06:28,952 [main] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /rack1/127.0.0.1:38987
2020-04-02 05:06:28,952 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 over-utilized: []
2020-04-02 05:06:28,952 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 above-average: []
2020-04-02 05:06:28,952 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 3 below-average: [127.0.0.1:42280:DISK, 127.0.0.1:41156:DISK, 127.0.0.1:38987:DISK]
2020-04-02 05:06:28,953 [main] INFO  balancer.Balancer (Balancer.java:logUtilizationCollection(442)) - 0 underutilized: []
The cluster is balanced. Exiting...
Apr 2, 2020 5:06:28 AM            1               1000 B                 0 B                0 B
2020-04-02 05:06:28,954 [IPC Server handler 3 on 40831] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /system/balancer.id is closed by DFSClient_NONMAPREDUCE_-1684751235_1
2020-04-02 05:06:28,956 [IPC Server handler 5 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=delete	src=/system/balancer.id	dst=null	perm=null	proto=rpc
2020-04-02 05:06:28,956 [main] INFO  balancer.TestBalancer (TestBalancer.java:runBalancer(956)) -   .
2020-04-02 05:06:28,958 [IPC Server handler 4 on 40831] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:28,958 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:28,959 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:06:28,959 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40590 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:28,960 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6a9b0a6f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:28,983 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@64c4c01{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:28,984 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1aa99005{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:28,984 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7bb35cc6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:28,984 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@640dc4c6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:28,987 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40590
2020-04-02 05:06:28,988 [IPC Server listener on 40590] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40590
2020-04-02 05:06:28,990 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:28,990 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:28,990 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid 9d3a0e23-5972-4931-8e39-c6e38bd4a7cd) service to localhost/127.0.0.1:40831
2020-04-02 05:06:28,990 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid 9d3a0e23-5972-4931-8e39-c6e38bd4a7cd)
2020-04-02 05:06:28,990 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:28,990 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:28,991 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43004 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:28,992 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2ff95fc6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:29,015 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@44de0113{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:29,015 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@236134a1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:29,016 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f63e3c7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:29,016 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7965a51c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:29,017 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43004
2020-04-02 05:06:29,021 [IPC Server listener on 43004] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43004
2020-04-02 05:06:29,021 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:29,021 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:29,024 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid c851c665-e533-484d-bd10-0c94efe1c406) service to localhost/127.0.0.1:40831
2020-04-02 05:06:29,024 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid c851c665-e533-484d-bd10-0c94efe1c406)
2020-04-02 05:06:29,024 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:29,025 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:29,025 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46692 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:29,026 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@8ed9cf] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:29,040 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@105b693d{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:29,041 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3fae596{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:29,041 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a67e962{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:29,041 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@153d4abb{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:29,043 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46692
2020-04-02 05:06:29,045 [IPC Server listener on 46692] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46692
2020-04-02 05:06:29,045 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:29,047 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:29,048 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid 8edf1054-ed57-425c-97ff-2811821439b3) service to localhost/127.0.0.1:40831
2020-04-02 05:06:29,048 [BP-1564436493-172.17.0.6-1585803981884 heartbeating to localhost/127.0.0.1:40831] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1564436493-172.17.0.6-1585803981884 (Datanode Uuid 8edf1054-ed57-425c-97ff-2811821439b3)
2020-04-02 05:06:29,048 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:29,048 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:29,048 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 40831 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:29,048 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:29,049 [Thread[Thread-963,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:06:29,049 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@2679311f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:29,049 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 54
2020-04-02 05:06:29,049 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 55 Total time for transactions(ms): 30 Number of transactions batched in Syncs: 30 Number of syncs: 26 SyncTimes(ms): 6 14 
2020-04-02 05:06:29,050 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:06:29,051 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5327a06e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:29,051 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:06:29,051 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:29,051 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40831
2020-04-02 05:06:29,052 [IPC Server listener on 40831] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40831
2020-04-02 05:06:29,052 [CacheReplicationMonitor(1186774634)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:29,069 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:29,069 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:29,069 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:29,078 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:29,079 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:29,085 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@15bc339{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:29,086 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@59d7d33a{SSL,[ssl, http/1.1]}{localhost:36741}
2020-04-02 05:06:29,086 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@ae7950d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:29,087 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e2916c3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:29,088 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:29,093 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:29,093 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer#testBalancer0Privacy
[msx] writeFile testName = org.apache.hadoop.hdfs.server.balancer.TestBalancerWithSaslDataTransfer#testBalancer0Privacy
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:29,098 [main] INFO  impl.DefaultInternalKdcServerImpl (DefaultInternalKdcServerImpl.java:doStop(102)) - Default Internal kdc server stopped.
2020-04-02 05:06:30,099 [main] INFO  minikdc.MiniKdc (MiniKdc.java:stop(359)) - MiniKdc stopped.
[msx] all testRunFinished
2020-04-02 05:06:30,126 [Truststore reloader thread] WARN  ssl.ReloadingX509TrustManager (ReloadingX509TrustManager.java:run(203)) - Could not load truststore (keep using existing one) : java.io.FileNotFoundException: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks (No such file or directory)
java.io.FileNotFoundException: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/SaslDataTransferTestCase/trustKS.jks (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.hadoop.security.ssl.ReloadingX509TrustManager.loadTrustManager(ReloadingX509TrustManager.java:169)
	at org.apache.hadoop.security.ssl.ReloadingX509TrustManager.run(ReloadingX509TrustManager.java:201)
	at java.lang.Thread.run(Thread.java:748)

[msx] before_class
[msx] test Started org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testScrBlockFileCorruption
[msx] unitTestCounterInClass = 0
2020-04-02 05:05:49,120 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:05:49,565 [Thread-1] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
Formatting using clusterid: testClusterID
2020-04-02 05:05:49,587 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:49,601 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:49,603 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:49,605 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:49,606 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:49,607 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:49,607 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:49,608 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:49,649 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:49,654 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:05:49,655 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,658 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:49,658 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:49,658 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,660 [Thread-1] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:49,664 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:49,665 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:49
2020-04-02 05:05:49,667 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:49,668 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,671 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:49,671 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:49,689 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,690 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,693 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:49,696 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:49,700 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:49,701 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:49,701 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:05:49,701 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:49,701 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:49,701 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:49,702 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:49,702 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:49,702 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:49,702 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:49,702 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:49,742 [Thread-1] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:05:49,759 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:49,760 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,760 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:49,761 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:49,768 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:49,768 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:49,769 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:49,769 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:49,775 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:49,777 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:49,782 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:49,783 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,783 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:49,783 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:49,794 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:49,795 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:49,795 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:49,800 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:49,801 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:49,804 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:49,804 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:49,805 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:49,805 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:49,841 [Thread-1] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:49,857 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:49,860 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:49,880 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:49,882 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:50,028 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:50,030 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:50,062 [Thread-1] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:50,067 [Thread-1] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:50,330 [Thread-1] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:05:50,823 [Thread-1] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:50,910 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:50,910 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:50,917 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:50,944 [Thread-1] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:50,947 [Thread-1] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
2020-04-02 05:05:50,998 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@13af63bb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:51,018 [Thread-1] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:05:51,025 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:51,040 [Thread-1] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3911ms
2020-04-02 05:05:51,157 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:51,161 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:51,162 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:51,175 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:51,181 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:51,182 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:51,182 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:51,216 [Thread-1] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:51,216 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:51,225 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40388
2020-04-02 05:05:51,228 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:51,334 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6c49b39{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:51,340 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37cd3398{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:51,393 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3664b7de{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:51,409 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@413cb321{HTTP/1.1,[http/1.1]}{localhost:40388}
2020-04-02 05:05:51,410 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @4281ms
2020-04-02 05:05:51,442 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:51,443 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:51,444 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:51,444 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:51,444 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:51,444 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:51,444 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:51,445 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:51,446 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:51,446 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:51,446 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:51,447 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:51,447 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:51,447 [Thread-1] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:51,448 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:51,448 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:51
2020-04-02 05:05:51,448 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:51,448 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:51,449 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:51,449 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:51,470 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:51,471 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:51,471 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:51,472 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:51,472 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:51,472 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:51,472 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:05:51,472 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:51,473 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:51,473 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:51,473 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:51,473 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:51,473 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:51,473 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:51,474 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:51,474 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:51,474 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:51,475 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:51,475 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:51,486 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:51,486 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:51,486 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:51,486 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:51,487 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:51,487 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:51,487 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:51,487 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:51,487 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:51,488 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:51,489 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:51,489 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:51,490 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:51,490 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:51,490 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:51,490 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:51,490 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:51,491 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:51,491 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:51,499 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:05:51,502 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:05:51,506 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:51,506 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:51,507 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:51,507 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:51,561 [Thread-1] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:51,576 [Thread-1] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:51,577 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:51,583 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:51,584 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:51,639 [Thread-1] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:51,639 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 145 msecs
2020-04-02 05:05:51,846 [Thread-1] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:51,858 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:51,872 [Socket Reader #1 for port 45899] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45899
2020-04-02 05:05:52,277 [Thread-1] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:45899 to access this namenode/service.
2020-04-02 05:05:52,281 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:52,320 [Thread-1] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:52,352 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@208270fa] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:05:52,368 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:52,389 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(607)) - STATE* Safe mode ON. 
The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1 live datanodes to reach the minimum number 1.
Safe mode will be turned off automatically once the thresholds have been reached.
2020-04-02 05:05:52,390 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:52,391 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:52,391 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:52,391 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:52,391 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:52,391 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-04-02 05:05:52,534 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:52,540 [IPC Server listener on 45899] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45899: starting
2020-04-02 05:05:52,591 [Thread-1] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:45899
2020-04-02 05:05:52,596 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:52,597 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:52,603 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 6 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:52,607 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6bf69f26] DEBUG namenode.FSNamesystem (FSNamesystem.java:run(4098)) - Namenode is in safemode, skipping scrubbing of corrupted lazy-persist files.
2020-04-02 05:05:52,609 [Thread-1] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 45899 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:52,614 [CacheReplicationMonitor(882307902)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:52,618 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:52,698 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:52,727 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:52,729 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:52,748 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:52,755 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,760 [Thread-1] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:52,763 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:05:52,764 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:52,766 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,766 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:52,766 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:52,771 [Thread-1] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:verifyCanMlock(348)) - LazyPersistTestCase: fake return true
2020-04-02 05:05:52,782 [Thread-1] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:getMemlockLimit(342)) - LazyPersistTestCase: fake return 9223372036854775807
2020-04-02 05:05:52,782 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 9223372036854775807
2020-04-02 05:05:52,797 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42947
2020-04-02 05:05:52,804 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:52,804 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:52,812 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:52,812 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:52,812 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585803949092.-1264300450/TestScrLazyPersistFiles.42947.sock
2020-04-02 05:05:52,833 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,836 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:52,837 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:52,838 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,840 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:52,841 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:52,841 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:52,841 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:52,845 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40470
2020-04-02 05:05:52,845 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:52,856 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b83f627{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:52,857 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4029cde4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:52,865 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@32e29ce1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:52,867 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@71aee1{HTTP/1.1,[http/1.1]}{localhost:40470}
2020-04-02 05:05:52,868 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @5739ms
2020-04-02 05:05:53,353 [Thread-1] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44007
2020-04-02 05:05:53,355 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:53,356 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:53,362 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1b092156] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:53,918 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:53,938 [Socket Reader #1 for port 43122] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43122
2020-04-02 05:05:53,947 [Thread-1] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43122
2020-04-02 05:05:53,960 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:53,963 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:53,977 [Thread-61] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45899 starting to offer service
2020-04-02 05:05:54,030 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:54,035 [IPC Server listener on 43122] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43122: starting
2020-04-02 05:05:54,060 [Thread-1] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43122 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:54,483 [Thread-61] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45899
2020-04-02 05:05:54,486 [Thread-61] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:54,490 [Thread-61] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:05:54,491 [Thread-61] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 280961669. Formatting...
2020-04-02 05:05:54,492 [Thread-61] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4811cb78-c71b-4a4b-90cb-3b597a52f304 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:54,499 [Thread-61] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:05:54,500 [Thread-61] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 280961669. Formatting...
2020-04-02 05:05:54,500 [Thread-61] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-02ce2cb3-90b4-489a-909a-7c09fb093623 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:54,516 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:54,516 [Thread-61] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:54,517 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-490424955-172.17.0.14-1585803949824 is not formatted. Formatting ...
2020-04-02 05:05:54,517 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-490424955-172.17.0.14-1585803949824 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-490424955-172.17.0.14-1585803949824/current
2020-04-02 05:05:54,531 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:54,532 [Thread-61] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:54,532 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-490424955-172.17.0.14-1585803949824 is not formatted. Formatting ...
2020-04-02 05:05:54,532 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-490424955-172.17.0.14-1585803949824 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current
2020-04-02 05:05:54,535 [Thread-61] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=280961669;bpid=BP-490424955-172.17.0.14-1585803949824;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=280961669;c=1585803949824;bpid=BP-490424955-172.17.0.14-1585803949824;dnuuid=null
2020-04-02 05:05:54,537 [Thread-61] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 05bd5c45-ff48-4524-a05c-1e4fe644e8c7
2020-04-02 05:05:54,794 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-4811cb78-c71b-4a4b-90cb-3b597a52f304
2020-04-02 05:05:54,794 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: RAM_DISK
2020-04-02 05:05:54,815 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-02ce2cb3-90b4-489a-909a-7c09fb093623
2020-04-02 05:05:54,815 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:54,850 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:54,857 [Thread-61] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:54,887 [Thread-61] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:54,888 [Thread-61] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:54,889 [Thread-61] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:54,904 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:54,910 [IPC Server handler 4 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:54,911 [Thread-80] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-490424955-172.17.0.14-1585803949824 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:54,914 [Thread-81] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-490424955-172.17.0.14-1585803949824 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:54,922 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:54,923 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:54,961 [Thread-80] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-490424955-172.17.0.14-1585803949824 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 50ms
2020-04-02 05:05:54,963 [Thread-81] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-490424955-172.17.0.14-1585803949824 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 49ms
2020-04-02 05:05:54,963 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-490424955-172.17.0.14-1585803949824: 59ms
2020-04-02 05:05:54,966 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-490424955-172.17.0.14-1585803949824 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:54,966 [Thread-85] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-490424955-172.17.0.14-1585803949824 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:54,966 [Thread-84] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-490424955-172.17.0.14-1585803949824/current/replicas doesn't exist 
2020-04-02 05:05:54,966 [Thread-85] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current/replicas doesn't exist 
2020-04-02 05:05:54,968 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-490424955-172.17.0.14-1585803949824 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-04-02 05:05:54,968 [Thread-85] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-490424955-172.17.0.14-1585803949824 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:05:54,968 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-490424955-172.17.0.14-1585803949824: 3ms
2020-04-02 05:05:54,972 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-490424955-172.17.0.14-1585803949824 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:54,974 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-4811cb78-c71b-4a4b-90cb-3b597a52f304): finished scanning block pool BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:54,981 [Thread-61] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:02 AM with interval of 21600000ms
2020-04-02 05:05:54,973 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-490424955-172.17.0.14-1585803949824 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:55,008 [BP-490424955-172.17.0.14-1585803949824 heartbeating to localhost/127.0.0.1:45899] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-490424955-172.17.0.14-1585803949824 (Datanode Uuid 05bd5c45-ff48-4524-a05c-1e4fe644e8c7) service to localhost/127.0.0.1:45899 beginning handshake with NN
2020-04-02 05:05:55,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-02ce2cb3-90b4-489a-909a-7c09fb093623): finished scanning block pool BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:55,044 [IPC Server handler 0 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:55,046 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:55,046 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:55,049 [IPC Server handler 5 on 45899] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42947, datanodeUuid=05bd5c45-ff48-4524-a05c-1e4fe644e8c7, infoPort=44007, infoSecurePort=0, ipcPort=43122, storageInfo=lv=-57;cid=testClusterID;nsid=280961669;c=1585803949824) storage 05bd5c45-ff48-4524-a05c-1e4fe644e8c7
2020-04-02 05:05:55,052 [IPC Server handler 5 on 45899] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42947
2020-04-02 05:05:55,053 [IPC Server handler 5 on 45899] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 05bd5c45-ff48-4524-a05c-1e4fe644e8c7 (127.0.0.1:42947).
2020-04-02 05:05:55,055 [IPC Server handler 5 on 45899] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(391)) - STATE* Safe mode is OFF
2020-04-02 05:05:55,055 [IPC Server handler 5 on 45899] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 2 secs
2020-04-02 05:05:55,055 [IPC Server handler 5 on 45899] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 1 datanodes
2020-04-02 05:05:55,056 [IPC Server handler 5 on 45899] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:55,064 [BP-490424955-172.17.0.14-1585803949824 heartbeating to localhost/127.0.0.1:45899] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-490424955-172.17.0.14-1585803949824 (Datanode Uuid 05bd5c45-ff48-4524-a05c-1e4fe644e8c7) service to localhost/127.0.0.1:45899 successfully registered with NN
2020-04-02 05:05:55,064 [BP-490424955-172.17.0.14-1585803949824 heartbeating to localhost/127.0.0.1:45899] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:45899 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:05:55,091 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-02ce2cb3-90b4-489a-909a-7c09fb093623): no suitable block pools found to scan.  Waiting 1814399879 ms.
2020-04-02 05:05:55,097 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-4811cb78-c71b-4a4b-90cb-3b597a52f304): no suitable block pools found to scan.  Waiting 1814399873 ms.
2020-04-02 05:05:55,100 [IPC Server handler 3 on 45899] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4811cb78-c71b-4a4b-90cb-3b597a52f304 for DN 127.0.0.1:42947
2020-04-02 05:05:55,101 [IPC Server handler 3 on 45899] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-02ce2cb3-90b4-489a-909a-7c09fb093623 for DN 127.0.0.1:42947
2020-04-02 05:05:55,138 [IPC Server handler 8 on 45899] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42947, datanodeUuid=05bd5c45-ff48-4524-a05c-1e4fe644e8c7, infoPort=44007, infoSecurePort=0, ipcPort=43122, storageInfo=lv=-57;cid=testClusterID;nsid=280961669;c=1585803949824), reports.length=2
2020-04-02 05:05:55,140 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe7fabb8a43f85c78: Processing first storage report for DS-4811cb78-c71b-4a4b-90cb-3b597a52f304 from datanode 05bd5c45-ff48-4524-a05c-1e4fe644e8c7
2020-04-02 05:05:55,142 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe7fabb8a43f85c78: from storage DS-4811cb78-c71b-4a4b-90cb-3b597a52f304 node DatanodeRegistration(127.0.0.1:42947, datanodeUuid=05bd5c45-ff48-4524-a05c-1e4fe644e8c7, infoPort=44007, infoSecurePort=0, ipcPort=43122, storageInfo=lv=-57;cid=testClusterID;nsid=280961669;c=1585803949824), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:05:55,146 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe7fabb8a43f85c78: Processing first storage report for DS-02ce2cb3-90b4-489a-909a-7c09fb093623 from datanode 05bd5c45-ff48-4524-a05c-1e4fe644e8c7
2020-04-02 05:05:55,146 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe7fabb8a43f85c78: from storage DS-02ce2cb3-90b4-489a-909a-7c09fb093623 node DatanodeRegistration(127.0.0.1:42947, datanodeUuid=05bd5c45-ff48-4524-a05c-1e4fe644e8c7, infoPort=44007, infoSecurePort=0, ipcPort=43122, storageInfo=lv=-57;cid=testClusterID;nsid=280961669;c=1585803949824), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:55,146 [IPC Server handler 8 on 45899] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xe7fabb8a43f85c78
2020-04-02 05:05:55,149 [IPC Server handler 9 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:55,157 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:55,158 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [RAM_DISK]DS-4811cb78-c71b-4a4b-90cb-3b597a52f304
2020-04-02 05:05:55,158 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [DISK]DS-02ce2cb3-90b4-489a-909a-7c09fb093623
2020-04-02 05:05:55,182 [BP-490424955-172.17.0.14-1585803949824 heartbeating to localhost/127.0.0.1:45899] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe7fabb8a43f85c78,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 3 msec to generate and 61 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:55,183 [BP-490424955-172.17.0.14-1585803949824 heartbeating to localhost/127.0.0.1:45899] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:55,187 [IPC Server handler 1 on 45899] DEBUG BlockStateChange (NameNodeRpcServer.java:cacheReport(1559)) - *BLOCK* NameNode.cacheReport: from DatanodeRegistration(127.0.0.1:42947, datanodeUuid=05bd5c45-ff48-4524-a05c-1e4fe644e8c7, infoPort=44007, infoSecurePort=0, ipcPort=43122, storageInfo=lv=-57;cid=testClusterID;nsid=280961669;c=1585803949824) 0 blocks
2020-04-02 05:05:55,274 [IPC Server handler 2 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:55,282 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
init: server=localhost;port=;service=DataNode;localVMUrl=null

Domains:
	Domain = Hadoop
	Domain = JMImplementation
	Domain = com.sun.management
	Domain = java.lang
	Domain = java.nio
	Domain = java.util.logging

MBeanServer default domain = DefaultDomain

MBean count = 50

Query MBeanServer MBeans:
Hadoop service: Hadoop:service=DataNode,name=DataNodeActivity-127.0.0.1-42947
Hadoop service: Hadoop:service=DataNode,name=DataNodeInfo
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState-05bd5c45-ff48-4524-a05c-1e4fe644e8c7
Hadoop service: Hadoop:service=DataNode,name=JvmMetrics-1
Hadoop service: Hadoop:service=DataNode,name=RpcActivityForPort43122
Hadoop service: Hadoop:service=DataNode,name=RpcDetailedActivityForPort43122
2020-04-02 05:05:55,293 [Thread-1] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:startUpCluster(326)) - Cluster startup complete
2020-04-02 05:05:55,312 [IPC Server handler 7 on 45899] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /doShortCircuitReadBlockFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_1823711492_25 at 127.0.0.1
2020-04-02 05:05:55,313 [IPC Server handler 7 on 45899] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/doShortCircuitReadBlockFileCorruptionTest.01.dat, holder=DFSClient_NONMAPREDUCE_1823711492_25, clientMachine=127.0.0.1, createParent=true, replication=1, createFlag=[CREATE, LAZY_PERSIST], blockSize=5242880, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:05:55,329 [IPC Server handler 7 on 45899] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: doShortCircuitReadBlockFileCorruptionTest.01.dat is added
2020-04-02 05:05:55,334 [IPC Server handler 7 on 45899] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /doShortCircuitReadBlockFileCorruptionTest.01.dat inode 16386 DFSClient_NONMAPREDUCE_1823711492_25
2020-04-02 05:05:55,374 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:55,380 [IPC Server handler 7 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:55,446 [IPC Server handler 4 on 45899] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /doShortCircuitReadBlockFileCorruptionTest.01.dat  inodeId 16386 for DFSClient_NONMAPREDUCE_1823711492_25
2020-04-02 05:05:55,461 [IPC Server handler 4 on 45899] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /doShortCircuitReadBlockFileCorruptionTest.01.dat with blk_1073741825_1001 block is added to the in-memory file system
2020-04-02 05:05:55,461 [IPC Server handler 4 on 45899] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:42947 for /doShortCircuitReadBlockFileCorruptionTest.01.dat
2020-04-02 05:05:55,461 [IPC Server handler 4 on 45899] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /doShortCircuitReadBlockFileCorruptionTest.01.dat with new block blk_1073741825_1001, current total block count is 1
2020-04-02 05:05:55,606 [DataXceiver for client DFSClient_NONMAPREDUCE_1823711492_25 at /127.0.0.1:42410 [Receiving block BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001 src: /127.0.0.1:42410 dest: /127.0.0.1:42947
2020-04-02 05:05:55,820 [PacketResponder: BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:moveBlockFiles(885)) - addFinalizedBlock: Moved file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-490424955-172.17.0.14-1585803949824/current/rbw/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-490424955-172.17.0.14-1585803949824/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta and file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-490424955-172.17.0.14-1585803949824/current/rbw/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-490424955-172.17.0.14-1585803949824/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:05:55,826 [PacketResponder: BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42410, dest: /127.0.0.1:42947, bytes: 5242880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1823711492_25, offset: 0, srvID: 05bd5c45-ff48-4524-a05c-1e4fe644e8c7, blockid: BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001, duration(ns): 127341983
2020-04-02 05:05:55,826 [PacketResponder: BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:55,853 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@24e3dea2] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:saveNextReplica(3108)) - LazyWriter: Start persisting RamDisk block: block pool Id: BP-490424955-172.17.0.14-1585803949824 block id: 1073741825 on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:55,862 [IPC Server handler 5 on 45899] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42947, datanodeUuid=05bd5c45-ff48-4524-a05c-1e4fe644e8c7, infoPort=44007, infoSecurePort=0, ipcPort=43122, storageInfo=lv=-57;cid=testClusterID;nsid=280961669;c=1585803949824) 1 blocks.
2020-04-02 05:05:55,864 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:42947 size 5242880 replicaState = FINALIZED
2020-04-02 05:05:55,871 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:55,884 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42947 is added to blk_1073741825_1001 (size=0)
2020-04-02 05:05:55,906 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:42947
2020-04-02 05:05:55,906 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42947 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:55,907 [IPC Server handler 3 on 45899] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3274)) - BLOCK* fsync: /doShortCircuitReadBlockFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_1823711492_25
2020-04-02 05:05:55,908 [IPC Server handler 3 on 45899] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistBlocks(112)) - persistBlocks: /doShortCircuitReadBlockFileCorruptionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:05:55,920 [IPC Server handler 9 on 45899] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /doShortCircuitReadBlockFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_1823711492_25
2020-04-02 05:05:55,926 [IPC Server handler 9 on 45899] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /doShortCircuitReadBlockFileCorruptionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:05:55,928 [IPC Server handler 9 on 45899] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /doShortCircuitReadBlockFileCorruptionTest.01.dat is closed by DFSClient_NONMAPREDUCE_1823711492_25
2020-04-02 05:05:55,934 [Thread-1] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadBlockFileCorruptionTest.01.dat is on StorageType: RAM_DISK
2020-04-02 05:05:55,938 [IPC Server handler 8 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:55,940 [Async RamDisk lazy persist worker  for volume with id DS-02ce2cb3-90b4-489a-909a-7c09fb093623] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:copyBlockFiles(931)) - Copied file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-490424955-172.17.0.14-1585803949824/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta and calculated checksum
2020-04-02 05:05:55,941 [Async RamDisk lazy persist worker  for volume with id DS-02ce2cb3-90b4-489a-909a-7c09fb093623] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:onCompleteLazyPersist(2969)) - LazyWriter: Finish persisting RamDisk block:  block pool Id: BP-490424955-172.17.0.14-1585803949824 block id: 1073741825 to block file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current/lazypersist/subdir0/subdir0/blk_1073741825 and meta file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:55,942 [IPC Server handler 1 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:55,952 [IPC Server handler 6 on 45899] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:05:55,959 [IPC Server handler 6 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:55,977 [IPC Server handler 2 on 45899] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:05:55,978 [IPC Server handler 2 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:1
2020-04-02 05:05:55,984 [Thread-1] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 1
2020-04-02 05:05:55,984 [Thread-1] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:evictBlocks(3151)) - Evicting block [BlockPoolID=BP-490424955-172.17.0.14-1585803949824; BlockId=1073741825]
2020-04-02 05:05:56,001 [Thread-1] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(382)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current/lazypersist/subdir0/subdir0/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:05:56,001 [Thread-1] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(384)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta
2020-04-02 05:05:56,006 [Thread-1] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadBlockFileCorruptionTest.01.dat is on StorageType: DISK
2020-04-02 05:05:56,025 [IPC Server handler 4 on 45899] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42947, datanodeUuid=05bd5c45-ff48-4524-a05c-1e4fe644e8c7, infoPort=44007, infoSecurePort=0, ipcPort=43122, storageInfo=lv=-57;cid=testClusterID;nsid=280961669;c=1585803949824) 1 blocks.
2020-04-02 05:05:56,026 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:42947 size 5242880 replicaState = FINALIZED
2020-04-02 05:05:56,026 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:05:56,026 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3248)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:42947
2020-04-02 05:05:56,025 [IPC Server handler 7 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:56,026 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:42947
2020-04-02 05:05:56,027 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42947 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:56,034 [IPC Server handler 0 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:56,043 [IPC Server handler 5 on 45899] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:05:56,043 [IPC Server handler 5 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:56,051 [IPC Server handler 3 on 45899] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:05:56,052 [IPC Server handler 3 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:56,058 [IPC Server handler 9 on 45899] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:05:56,059 [IPC Server handler 9 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:56,153 [DataXceiver for client unix:/tmp/socks.1585803949092.-1264300450/TestScrLazyPersistFiles.42947.sock [Passing file descriptors for block BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 05bd5c45-ff48-4524-a05c-1e4fe644e8c7, success: true
2020-04-02 05:05:56,153 [DataXceiver for client unix:/tmp/socks.1585803949092.-1264300450/TestScrLazyPersistFiles.42947.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_1823711492_25, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: 645891987b1ed315d407e8a0b6c3d399, srvID: 05bd5c45-ff48-4524-a05c-1e4fe644e8c7, success: true
2020-04-02 05:05:56,178 [Thread-1] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:05:56,183 [IPC Server handler 8 on 45899] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:05:56,183 [IPC Server handler 8 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:56,188 [Thread-1] WARN  hdfs.DFSClient (DFSInputStream.java:readBuffer(706)) - Found Checksum error for BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001 from DatanodeInfoWithStorage[127.0.0.1:42947,DS-02ce2cb3-90b4-489a-909a-7c09fb093623,DISK] at 0
2020-04-02 05:05:56,190 [Thread-1] WARN  hdfs.DFSClient (DFSInputStream.java:reportLostBlock(959)) - No live nodes contain block BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:42947,DS-02ce2cb3-90b4-489a-909a-7c09fb093623,DISK]], ignoredNodes = null
2020-04-02 05:05:56,213 [Thread-1] INFO  hdfs.DFSClient (DFSInputStream.java:refetchLocations(882)) - Could not obtain BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:42947,DS-02ce2cb3-90b4-489a-909a-7c09fb093623,DISK] Dead nodes:  DatanodeInfoWithStorage[127.0.0.1:42947,DS-02ce2cb3-90b4-489a-909a-7c09fb093623,DISK]. Will get new block locations from namenode and retry...
2020-04-02 05:05:56,214 [Thread-1] WARN  hdfs.DFSClient (DFSInputStream.java:refetchLocations(901)) - DFS chooseDataNode: got # 1 IOException, will wait for 2432.3990927217797 msec.
2020-04-02 05:05:58,375 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:58,651 [IPC Server handler 6 on 45899] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:05:58,651 [IPC Server handler 6 on 45899] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:05:58,658 [IPC Server handler 2 on 45899] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-490424955-172.17.0.14-1585803949824:blk_1073741825_1001 on datanode: 127.0.0.1:42947
2020-04-02 05:05:58,660 [IPC Server handler 2 on 45899] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_1073741825_1001 added as corrupt on 127.0.0.1:42947 by /127.0.0.1  because client machine reported it
2020-04-02 05:05:58,660 [IPC Server handler 2 on 45899] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741825_1001 curReplicas 0 curExpectedReplicas 1 oldReplicas 1 oldExpectedReplicas  1 curPri  4 oldPri  3
2020-04-02 05:05:58,660 [IPC Server handler 2 on 45899] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_1073741825_1001 has only 0 replicas and needs 1 replicas so is added to neededReconstructions at priority level 4
List of the keys matching ^RamDisk :
>>>>>>>>jmx name: name=DataNodeActivity-127.0.0.1-42947,service=DataNode
RamDiskBlocksWrite=1
RamDiskBlocksWriteFallback=0
RamDiskBytesWrite=5242880
RamDiskBlocksReadHits=0
RamDiskBlocksEvicted=1
RamDiskBlocksEvictedWithoutRead=1
RamDiskBlocksEvictionWindowMsNumOps=1
RamDiskBlocksEvictionWindowMsAvgTime=180.0
RamDiskBlocksLazyPersisted=1
RamDiskBlocksDeletedBeforeLazyPersisted=0
RamDiskBytesLazyPersisted=5242880
RamDiskBlocksLazyPersistWindowMsNumOps=1
RamDiskBlocksLazyPersistWindowMsAvgTime=119.0
>>>>>>>>jmx name: name=DataNodeInfo,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState-05bd5c45-ff48-4524-a05c-1e4fe644e8c7,service=DataNode
>>>>>>>>jmx name: name=JvmMetrics-1,service=DataNode
>>>>>>>>jmx name: name=RpcActivityForPort43122,service=DataNode
>>>>>>>>jmx name: name=RpcDetailedActivityForPort43122,service=DataNode
2020-04-02 05:05:58,685 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:05:58,685 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43122 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:58,686 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@32b69be4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:58,686 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@797256c1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:58,697 [Thread-1] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:58,699 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-4811cb78-c71b-4a4b-90cb-3b597a52f304) exiting.
2020-04-02 05:05:58,700 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-02ce2cb3-90b4-489a-909a-7c09fb093623) exiting.
2020-04-02 05:05:58,855 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@32e29ce1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:58,875 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@71aee1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:58,876 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4029cde4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:58,879 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b83f627{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:58,966 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43122
2020-04-02 05:05:58,969 [IPC Server listener on 43122] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43122
2020-04-02 05:05:58,992 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:58,993 [BP-490424955-172.17.0.14-1585803949824 heartbeating to localhost/127.0.0.1:45899] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:58,993 [BP-490424955-172.17.0.14-1585803949824 heartbeating to localhost/127.0.0.1:45899] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-490424955-172.17.0.14-1585803949824 (Datanode Uuid 05bd5c45-ff48-4524-a05c-1e4fe644e8c7) service to localhost/127.0.0.1:45899
2020-04-02 05:05:58,997 [BP-490424955-172.17.0.14-1585803949824 heartbeating to localhost/127.0.0.1:45899] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-490424955-172.17.0.14-1585803949824 (Datanode Uuid 05bd5c45-ff48-4524-a05c-1e4fe644e8c7)
2020-04-02 05:05:58,998 [BP-490424955-172.17.0.14-1585803949824 heartbeating to localhost/127.0.0.1:45899] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-490424955-172.17.0.14-1585803949824
2020-04-02 05:05:59,010 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-490424955-172.17.0.14-1585803949824] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:59,025 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-490424955-172.17.0.14-1585803949824] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:59,057 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@24e3dea2] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(3203)) - LazyWriter was interrupted, exiting
2020-04-02 05:05:59,074 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:59,075 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:59,078 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:59,079 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:59,095 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:59,095 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:05:59,096 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:05:59,096 [Thread-1] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 45899 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:59,096 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:59,099 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@6734f1fc] DEBUG namenode.LeaseManager (LeaseManager.java:run(536)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:59,101 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6bf69f26] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:05:59,101 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:05:59,102 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5f8ebee3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:05:59,109 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 60 Number of transactions batched in Syncs: 2 Number of syncs: 7 SyncTimes(ms): 1 23 
2020-04-02 05:05:59,116 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:05:59,117 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:05:59,117 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:05:59,124 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45899
2020-04-02 05:05:59,124 [CacheReplicationMonitor(882307902)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:05:59,145 [IPC Server listener on 45899] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45899
2020-04-02 05:05:59,142 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:05:59,138 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:05:59,139 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:59,152 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@208270fa] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:59,203 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:05:59,204 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:05:59,222 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3664b7de{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:05:59,234 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@413cb321{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:59,235 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37cd3398{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:59,235 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6c49b39{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:59,238 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:05:59,239 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:05:59,239 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testScrBlockFileCorruption
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testScrBlockFileCorruption
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testRamDiskShortCircuitRead
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:05:59,281 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:05:59,284 [Thread-98] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
Formatting using clusterid: testClusterID
2020-04-02 05:05:59,285 [Thread-98] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:59,286 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:59,286 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:59,286 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:59,286 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:59,286 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:59,286 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:59,287 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:59,287 [Thread-98] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:59,287 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,287 [Thread-98] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:59,288 [Thread-98] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:59,288 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,288 [Thread-98] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:59,288 [Thread-98] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:59,288 [Thread-98] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:59
2020-04-02 05:05:59,289 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:59,289 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,289 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:59,289 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:59,302 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,302 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,302 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:59,302 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,303 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:59,303 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:59,304 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:59,304 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,304 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:59,304 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:59,312 [Thread-98] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:59,312 [Thread-98] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:59,312 [Thread-98] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:59,312 [Thread-98] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:59,313 [Thread-98] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:59,313 [Thread-98] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:59,313 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:59,313 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,313 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:59,314 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:59,315 [Thread-98] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:59,317 [Thread-98] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:59,317 [Thread-98] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:59,317 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:59,317 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:59,318 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:59,318 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,318 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:59,319 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:59,321 [Thread-98] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:05:59,327 [Thread-98] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:59,336 [Thread-98] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:59,352 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:59,354 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:59,359 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:05:59,362 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:05:59,373 [Thread-98] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:59,376 [Thread-98] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:59,382 [Thread-98] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:59,384 [Thread-98] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:59,384 [Thread-98] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:59,385 [Thread-98] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:59,386 [Thread-98] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:59,386 [Thread-98] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
2020-04-02 05:05:59,393 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@67515c5f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:59,394 [Thread-98] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:05:59,394 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:59,397 [Thread-98] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:59,398 [Thread-98] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:59,399 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:59,401 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:59,404 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:59,404 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:59,404 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:59,426 [Thread-98] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:59,427 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:59,431 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43821
2020-04-02 05:05:59,431 [Thread-98] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:59,435 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@590cfcb4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:59,436 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@443b7aee{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:59,443 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@ce5f767{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:59,454 [Thread-98] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@51714653{HTTP/1.1,[http/1.1]}{localhost:43821}
2020-04-02 05:05:59,454 [Thread-98] INFO  server.Server (Server.java:doStart(419)) - Started @12325ms
2020-04-02 05:05:59,458 [Thread-98] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:59,458 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:59,458 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:59,462 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:59,462 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:59,463 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:59,463 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:59,463 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:59,463 [Thread-98] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:59,466 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,466 [Thread-98] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:05:59,466 [Thread-98] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:59,466 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,466 [Thread-98] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:05:59,467 [Thread-98] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:59,467 [Thread-98] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:59
2020-04-02 05:05:59,467 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:59,467 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,467 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:59,467 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:59,496 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,496 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,496 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:59,497 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,497 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:59,497 [Thread-98] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:59,497 [Thread-98] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:05:59,497 [Thread-98] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:59,497 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:05:59,497 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:59,498 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:59,498 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:59,498 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:05:59,498 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:59,498 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:59,498 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:59,498 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,499 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:59,499 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:59,513 [Thread-98] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:59,513 [Thread-98] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:59,513 [Thread-98] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:59,513 [Thread-98] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:59,522 [Thread-98] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:59,522 [Thread-98] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:59,522 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:59,522 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,523 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:59,523 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:59,525 [Thread-98] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:59,525 [Thread-98] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:59,525 [Thread-98] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:59,532 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:59,532 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:59,533 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:59,533 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:59,533 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:59,533 [Thread-98] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:59,545 [Thread-98] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:05:59,554 [Thread-98] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:05:59,556 [Thread-98] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:59,557 [Thread-98] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:59,557 [Thread-98] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:59,557 [Thread-98] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:59,559 [Thread-98] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:59,561 [Thread-98] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:59,561 [Thread-98] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:59,566 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:59,574 [Thread-98] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:59,589 [Thread-98] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:59,589 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 54 msecs
2020-04-02 05:05:59,590 [Thread-98] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:59,590 [Thread-98] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:59,628 [Socket Reader #1 for port 35635] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35635
2020-04-02 05:05:59,664 [Thread-98] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:35635 to access this namenode/service.
2020-04-02 05:05:59,664 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:59,759 [Thread-98] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:59,762 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@60ea93dd] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:05:59,775 [Thread-98] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:59,776 [Thread-98] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(607)) - STATE* Safe mode ON. 
The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1 live datanodes to reach the minimum number 1.
Safe mode will be turned off automatically once the thresholds have been reached.
2020-04-02 05:05:59,791 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:59,810 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:59,811 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:59,811 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:59,811 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:59,811 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 25 msec
2020-04-02 05:05:59,814 [IPC Server listener on 35635] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35635: starting
2020-04-02 05:05:59,819 [Thread-98] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:35635
2020-04-02 05:05:59,821 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:59,822 [Thread-98] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:59,814 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:59,839 [Thread-98] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 17 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:59,854 [Thread-98] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 35635 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:59,867 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3fe1fd92] DEBUG namenode.FSNamesystem (FSNamesystem.java:run(4098)) - Namenode is in safemode, skipping scrubbing of corrupted lazy-persist files.
2020-04-02 05:05:59,883 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:59,885 [Thread-98] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:59,886 [Thread-98] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:59,885 [CacheReplicationMonitor(1774276678)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:59,949 [Thread-98] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:59,950 [Thread-98] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:59,950 [Thread-98] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:59,950 [Thread-98] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:59,958 [Thread-98] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:05:59,958 [Thread-98] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:05:59,958 [Thread-98] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:59,958 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,958 [Thread-98] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:05:59,958 [Thread-98] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:verifyCanMlock(348)) - LazyPersistTestCase: fake return true
2020-04-02 05:05:59,959 [Thread-98] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:getMemlockLimit(342)) - LazyPersistTestCase: fake return 9223372036854775807
2020-04-02 05:05:59,959 [Thread-98] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 9223372036854775807
2020-04-02 05:05:59,959 [Thread-98] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44051
2020-04-02 05:05:59,960 [Thread-98] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:59,960 [Thread-98] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:59,960 [Thread-98] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:59,960 [Thread-98] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:59,960 [Thread-98] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585803959280.1375503368/TestScrLazyPersistFiles.44051.sock
2020-04-02 05:05:59,962 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:59,964 [Thread-98] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:59,970 [Thread-98] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:59,971 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:59,974 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:59,975 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:59,975 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:59,975 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:59,978 [Thread-98] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 32845
2020-04-02 05:05:59,979 [Thread-98] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:59,982 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@100f0cc1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:59,993 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e662b9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:00,011 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30c40fa2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:00,012 [Thread-98] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7e9e0285{HTTP/1.1,[http/1.1]}{localhost:32845}
2020-04-02 05:06:00,012 [Thread-98] INFO  server.Server (Server.java:doStart(419)) - Started @12883ms
2020-04-02 05:06:00,174 [Thread-98] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33030
2020-04-02 05:06:00,179 [Thread-98] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:00,179 [Thread-98] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:00,179 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bb2b394] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:00,179 [Thread-98] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:00,183 [Socket Reader #1 for port 42840] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42840
2020-04-02 05:06:00,187 [Thread-98] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42840
2020-04-02 05:06:00,219 [Thread-98] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:00,219 [Thread-98] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:00,221 [Thread-154] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35635 starting to offer service
2020-04-02 05:06:00,233 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:00,234 [IPC Server listener on 42840] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42840: starting
2020-04-02 05:06:00,254 [Thread-98] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42840 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:00,365 [IPC Server handler 2 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,366 [Thread-154] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35635
2020-04-02 05:06:00,366 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:00,366 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:00,370 [Thread-154] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:00,372 [Thread-154] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:00,372 [Thread-154] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1358963891. Formatting...
2020-04-02 05:06:00,372 [Thread-154] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0d0a0e80-4caf-43c1-899f-e0953727b25c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:00,376 [Thread-154] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:00,377 [Thread-154] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1358963891. Formatting...
2020-04-02 05:06:00,377 [Thread-154] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0892d977-93cf-4430-910e-63575fa8cdbf for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:00,412 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:06:00,412 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:06:00,413 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-2041880392-172.17.0.14-1585803959321 is not formatted. Formatting ...
2020-04-02 05:06:00,413 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2041880392-172.17.0.14-1585803959321 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2041880392-172.17.0.14-1585803959321/current
2020-04-02 05:06:00,437 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:06:00,438 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:06:00,438 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-2041880392-172.17.0.14-1585803959321 is not formatted. Formatting ...
2020-04-02 05:06:00,438 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2041880392-172.17.0.14-1585803959321 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2041880392-172.17.0.14-1585803959321/current
2020-04-02 05:06:00,440 [Thread-154] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1358963891;bpid=BP-2041880392-172.17.0.14-1585803959321;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1358963891;c=1585803959321;bpid=BP-2041880392-172.17.0.14-1585803959321;dnuuid=null
2020-04-02 05:06:00,445 [Thread-154] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID c0fdc82a-1a0f-480d-8a31-e8aeff13d214
2020-04-02 05:06:00,447 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0d0a0e80-4caf-43c1-899f-e0953727b25c
2020-04-02 05:06:00,448 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: RAM_DISK
2020-04-02 05:06:00,451 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0892d977-93cf-4430-910e-63575fa8cdbf
2020-04-02 05:06:00,451 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:00,467 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:00,469 [Thread-154] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:00,480 [IPC Server handler 3 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,490 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:00,490 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:00,498 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:00,499 [Thread-154] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:00,499 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:00,507 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:06:00,509 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2041880392-172.17.0.14-1585803959321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:00,509 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2041880392-172.17.0.14-1585803959321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:00,550 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2041880392-172.17.0.14-1585803959321 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 41ms
2020-04-02 05:06:00,579 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2041880392-172.17.0.14-1585803959321 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 69ms
2020-04-02 05:06:00,579 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2041880392-172.17.0.14-1585803959321: 71ms
2020-04-02 05:06:00,580 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2041880392-172.17.0.14-1585803959321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:00,580 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2041880392-172.17.0.14-1585803959321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:00,580 [Thread-175] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2041880392-172.17.0.14-1585803959321/current/replicas doesn't exist 
2020-04-02 05:06:00,580 [Thread-176] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2041880392-172.17.0.14-1585803959321/current/replicas doesn't exist 
2020-04-02 05:06:00,580 [Thread-175] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2041880392-172.17.0.14-1585803959321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:06:00,590 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2041880392-172.17.0.14-1585803959321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 10ms
2020-04-02 05:06:00,590 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2041880392-172.17.0.14-1585803959321: 11ms
2020-04-02 05:06:00,590 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2041880392-172.17.0.14-1585803959321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:00,591 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2041880392-172.17.0.14-1585803959321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:00,591 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0892d977-93cf-4430-910e-63575fa8cdbf): finished scanning block pool BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:06:00,591 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0d0a0e80-4caf-43c1-899f-e0953727b25c): finished scanning block pool BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:06:00,591 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0892d977-93cf-4430-910e-63575fa8cdbf): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:00,592 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0d0a0e80-4caf-43c1-899f-e0953727b25c): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:00,595 [Thread-154] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:01 AM with interval of 21600000ms
2020-04-02 05:06:00,595 [IPC Server handler 4 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,596 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:00,596 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:00,600 [BP-2041880392-172.17.0.14-1585803959321 heartbeating to localhost/127.0.0.1:35635] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2041880392-172.17.0.14-1585803959321 (Datanode Uuid c0fdc82a-1a0f-480d-8a31-e8aeff13d214) service to localhost/127.0.0.1:35635 beginning handshake with NN
2020-04-02 05:06:00,606 [IPC Server handler 1 on 35635] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44051, datanodeUuid=c0fdc82a-1a0f-480d-8a31-e8aeff13d214, infoPort=33030, infoSecurePort=0, ipcPort=42840, storageInfo=lv=-57;cid=testClusterID;nsid=1358963891;c=1585803959321) storage c0fdc82a-1a0f-480d-8a31-e8aeff13d214
2020-04-02 05:06:00,607 [IPC Server handler 1 on 35635] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44051
2020-04-02 05:06:00,607 [IPC Server handler 1 on 35635] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c0fdc82a-1a0f-480d-8a31-e8aeff13d214 (127.0.0.1:44051).
2020-04-02 05:06:00,611 [IPC Server handler 1 on 35635] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(391)) - STATE* Safe mode is OFF
2020-04-02 05:06:00,611 [IPC Server handler 1 on 35635] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:00,611 [IPC Server handler 1 on 35635] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 1 datanodes
2020-04-02 05:06:00,612 [IPC Server handler 1 on 35635] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:00,614 [BP-2041880392-172.17.0.14-1585803959321 heartbeating to localhost/127.0.0.1:35635] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2041880392-172.17.0.14-1585803959321 (Datanode Uuid c0fdc82a-1a0f-480d-8a31-e8aeff13d214) service to localhost/127.0.0.1:35635 successfully registered with NN
2020-04-02 05:06:00,614 [BP-2041880392-172.17.0.14-1585803959321 heartbeating to localhost/127.0.0.1:35635] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35635 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:00,620 [IPC Server handler 5 on 35635] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0d0a0e80-4caf-43c1-899f-e0953727b25c for DN 127.0.0.1:44051
2020-04-02 05:06:00,621 [IPC Server handler 5 on 35635] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0892d977-93cf-4430-910e-63575fa8cdbf for DN 127.0.0.1:44051
2020-04-02 05:06:00,630 [IPC Server handler 6 on 35635] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:44051, datanodeUuid=c0fdc82a-1a0f-480d-8a31-e8aeff13d214, infoPort=33030, infoSecurePort=0, ipcPort=42840, storageInfo=lv=-57;cid=testClusterID;nsid=1358963891;c=1585803959321), reports.length=2
2020-04-02 05:06:00,630 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c6a3d3f6570aee: Processing first storage report for DS-0d0a0e80-4caf-43c1-899f-e0953727b25c from datanode c0fdc82a-1a0f-480d-8a31-e8aeff13d214
2020-04-02 05:06:00,638 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c6a3d3f6570aee: from storage DS-0d0a0e80-4caf-43c1-899f-e0953727b25c node DatanodeRegistration(127.0.0.1:44051, datanodeUuid=c0fdc82a-1a0f-480d-8a31-e8aeff13d214, infoPort=33030, infoSecurePort=0, ipcPort=42840, storageInfo=lv=-57;cid=testClusterID;nsid=1358963891;c=1585803959321), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:00,638 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c6a3d3f6570aee: Processing first storage report for DS-0892d977-93cf-4430-910e-63575fa8cdbf from datanode c0fdc82a-1a0f-480d-8a31-e8aeff13d214
2020-04-02 05:06:00,638 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c6a3d3f6570aee: from storage DS-0892d977-93cf-4430-910e-63575fa8cdbf node DatanodeRegistration(127.0.0.1:44051, datanodeUuid=c0fdc82a-1a0f-480d-8a31-e8aeff13d214, infoPort=33030, infoSecurePort=0, ipcPort=42840, storageInfo=lv=-57;cid=testClusterID;nsid=1358963891;c=1585803959321), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:00,641 [IPC Server handler 6 on 35635] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x9c6a3d3f6570aee
2020-04-02 05:06:00,643 [BP-2041880392-172.17.0.14-1585803959321 heartbeating to localhost/127.0.0.1:35635] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9c6a3d3f6570aee,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 16 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:00,644 [BP-2041880392-172.17.0.14-1585803959321 heartbeating to localhost/127.0.0.1:35635] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:06:00,652 [IPC Server handler 7 on 35635] DEBUG BlockStateChange (NameNodeRpcServer.java:cacheReport(1559)) - *BLOCK* NameNode.cacheReport: from DatanodeRegistration(127.0.0.1:44051, datanodeUuid=c0fdc82a-1a0f-480d-8a31-e8aeff13d214, infoPort=33030, infoSecurePort=0, ipcPort=42840, storageInfo=lv=-57;cid=testClusterID;nsid=1358963891;c=1585803959321) 0 blocks
2020-04-02 05:06:00,702 [IPC Server handler 8 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,705 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:00,705 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [RAM_DISK]DS-0d0a0e80-4caf-43c1-899f-e0953727b25c
2020-04-02 05:06:00,705 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [DISK]DS-0892d977-93cf-4430-910e-63575fa8cdbf
2020-04-02 05:06:00,809 [IPC Server handler 0 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,813 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
init: server=localhost;port=;service=DataNode;localVMUrl=null

Domains:
	Domain = Hadoop
	Domain = JMImplementation
	Domain = com.sun.management
	Domain = java.lang
	Domain = java.nio
	Domain = java.util.logging

MBeanServer default domain = DefaultDomain

MBean count = 49

Query MBeanServer MBeans:
Hadoop service: Hadoop:service=DataNode,name=DataNodeActivity-127.0.0.1-44051
Hadoop service: Hadoop:service=DataNode,name=DataNodeInfo
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState-c0fdc82a-1a0f-480d-8a31-e8aeff13d214
Hadoop service: Hadoop:service=DataNode,name=JvmMetrics-1
Hadoop service: Hadoop:service=DataNode,name=RpcActivityForPort42840
Hadoop service: Hadoop:service=DataNode,name=RpcDetailedActivityForPort42840
2020-04-02 05:06:00,835 [Thread-98] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:startUpCluster(326)) - Cluster startup complete
2020-04-02 05:06:00,846 [IPC Server handler 2 on 35635] DEBUG hdfs.StateChange (NameNodeRpcServer.java:mkdirs(1120)) - *DIR* NameNode.mkdirs: /
2020-04-02 05:06:00,847 [IPC Server handler 2 on 35635] DEBUG hdfs.StateChange (FSDirMkdirOp.java:mkdirs(46)) - DIR* NameSystem.mkdirs: /
2020-04-02 05:06:00,847 [IPC Server handler 2 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:00,852 [IPC Server handler 3 on 35635] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /testRamDiskShortCircuitRead.dat for DFSClient_NONMAPREDUCE_-1817247680_314 at 127.0.0.1
2020-04-02 05:06:00,853 [IPC Server handler 3 on 35635] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/testRamDiskShortCircuitRead.dat, holder=DFSClient_NONMAPREDUCE_-1817247680_314, clientMachine=127.0.0.1, createParent=true, replication=1, createFlag=[CREATE, OVERWRITE, LAZY_PERSIST], blockSize=5242880, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:06:00,853 [IPC Server handler 3 on 35635] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: testRamDiskShortCircuitRead.dat is added
2020-04-02 05:06:00,855 [IPC Server handler 3 on 35635] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /testRamDiskShortCircuitRead.dat inode 16386 DFSClient_NONMAPREDUCE_-1817247680_314
2020-04-02 05:06:00,855 [IPC Server handler 3 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/testRamDiskShortCircuitRead.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:00,918 [IPC Server handler 4 on 35635] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /testRamDiskShortCircuitRead.dat  inodeId 16386 for DFSClient_NONMAPREDUCE_-1817247680_314
2020-04-02 05:06:00,919 [IPC Server handler 4 on 35635] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /testRamDiskShortCircuitRead.dat with blk_1073741825_1001 block is added to the in-memory file system
2020-04-02 05:06:00,919 [IPC Server handler 4 on 35635] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:44051 for /testRamDiskShortCircuitRead.dat
2020-04-02 05:06:00,920 [IPC Server handler 4 on 35635] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /testRamDiskShortCircuitRead.dat with new block blk_1073741825_1001, current total block count is 1
2020-04-02 05:06:00,971 [DataXceiver for client DFSClient_NONMAPREDUCE_-1817247680_314 at /127.0.0.1:57904 [Receiving block BP-2041880392-172.17.0.14-1585803959321:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2041880392-172.17.0.14-1585803959321:blk_1073741825_1001 src: /127.0.0.1:57904 dest: /127.0.0.1:44051
2020-04-02 05:06:01,103 [PacketResponder: BP-2041880392-172.17.0.14-1585803959321:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:moveBlockFiles(885)) - addFinalizedBlock: Moved file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2041880392-172.17.0.14-1585803959321/current/rbw/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2041880392-172.17.0.14-1585803959321/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta and file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2041880392-172.17.0.14-1585803959321/current/rbw/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2041880392-172.17.0.14-1585803959321/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:01,104 [PacketResponder: BP-2041880392-172.17.0.14-1585803959321:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57904, dest: /127.0.0.1:44051, bytes: 5242880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1817247680_314, offset: 0, srvID: c0fdc82a-1a0f-480d-8a31-e8aeff13d214, blockid: BP-2041880392-172.17.0.14-1585803959321:blk_1073741825_1001, duration(ns): 98059263
2020-04-02 05:06:01,104 [PacketResponder: BP-2041880392-172.17.0.14-1585803959321:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2041880392-172.17.0.14-1585803959321:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:01,105 [IPC Server handler 5 on 35635] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:44051, datanodeUuid=c0fdc82a-1a0f-480d-8a31-e8aeff13d214, infoPort=33030, infoSecurePort=0, ipcPort=42840, storageInfo=lv=-57;cid=testClusterID;nsid=1358963891;c=1585803959321) 1 blocks.
2020-04-02 05:06:01,106 [IPC Server handler 6 on 35635] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3274)) - BLOCK* fsync: /testRamDiskShortCircuitRead.dat for DFSClient_NONMAPREDUCE_-1817247680_314
2020-04-02 05:06:01,107 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:44051 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:01,108 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:01,108 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:44051 is added to blk_1073741825_1001 (size=0)
2020-04-02 05:06:01,108 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:44051
2020-04-02 05:06:01,108 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:44051 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:01,109 [IPC Server handler 6 on 35635] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistBlocks(112)) - persistBlocks: /testRamDiskShortCircuitRead.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:01,113 [IPC Server handler 7 on 35635] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /testRamDiskShortCircuitRead.dat for DFSClient_NONMAPREDUCE_-1817247680_314
2020-04-02 05:06:01,117 [IPC Server handler 7 on 35635] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /testRamDiskShortCircuitRead.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:01,117 [IPC Server handler 7 on 35635] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /testRamDiskShortCircuitRead.dat is closed by DFSClient_NONMAPREDUCE_-1817247680_314
2020-04-02 05:06:01,119 [Thread-98] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /testRamDiskShortCircuitRead.dat is on StorageType: RAM_DISK
2020-04-02 05:06:01,120 [IPC Server handler 8 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testRamDiskShortCircuitRead.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,122 [IPC Server handler 9 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/testRamDiskShortCircuitRead.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,124 [IPC Server handler 0 on 35635] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:01,125 [IPC Server handler 0 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testRamDiskShortCircuitRead.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,131 [IPC Server handler 2 on 35635] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:01,132 [IPC Server handler 2 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testRamDiskShortCircuitRead.dat	dst=null	perm=null	proto=rpc
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:0
2020-04-02 05:06:01,134 [Thread-98] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 0
2020-04-02 05:06:01,475 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@295295e4] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:saveNextReplica(3108)) - LazyWriter: Start persisting RamDisk block: block pool Id: BP-2041880392-172.17.0.14-1585803959321 block id: 1073741825 on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:01,486 [Async RamDisk lazy persist worker  for volume with id DS-0892d977-93cf-4430-910e-63575fa8cdbf] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:copyBlockFiles(931)) - Copied file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2041880392-172.17.0.14-1585803959321/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2041880392-172.17.0.14-1585803959321/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta and calculated checksum
2020-04-02 05:06:01,486 [Async RamDisk lazy persist worker  for volume with id DS-0892d977-93cf-4430-910e-63575fa8cdbf] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:onCompleteLazyPersist(2969)) - LazyWriter: Finish persisting RamDisk block:  block pool Id: BP-2041880392-172.17.0.14-1585803959321 block id: 1073741825 to block file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2041880392-172.17.0.14-1585803959321/current/lazypersist/subdir0/subdir0/blk_1073741825 and meta file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2041880392-172.17.0.14-1585803959321/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:1
2020-04-02 05:06:02,136 [Thread-98] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 1
2020-04-02 05:06:02,138 [IPC Server handler 3 on 35635] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:02,139 [IPC Server handler 3 on 35635] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/testRamDiskShortCircuitRead.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,144 [DataXceiver for client unix:/tmp/socks.1585803959280.1375503368/TestScrLazyPersistFiles.44051.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-1817247680_314, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: acff1b090f51eaf52be4fe48acd95c57, srvID: c0fdc82a-1a0f-480d-8a31-e8aeff13d214, success: true
2020-04-02 05:06:02,148 [DataXceiver for client unix:/tmp/socks.1585803959280.1375503368/TestScrLazyPersistFiles.44051.sock [Passing file descriptors for block BP-2041880392-172.17.0.14-1585803959321:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: c0fdc82a-1a0f-480d-8a31-e8aeff13d214, success: true
List of the keys matching ^RamDisk :
>>>>>>>>jmx name: name=DataNodeActivity-127.0.0.1-44051,service=DataNode
RamDiskBlocksWrite=1
RamDiskBlocksWriteFallback=0
RamDiskBytesWrite=5242880
RamDiskBlocksReadHits=0
RamDiskBlocksEvicted=0
RamDiskBlocksEvictedWithoutRead=0
RamDiskBlocksEvictionWindowMsNumOps=0
RamDiskBlocksEvictionWindowMsAvgTime=0.0
RamDiskBlocksLazyPersisted=1
RamDiskBlocksDeletedBeforeLazyPersisted=0
RamDiskBytesLazyPersisted=5242880
RamDiskBlocksLazyPersistWindowMsNumOps=1
RamDiskBlocksLazyPersistWindowMsAvgTime=382.0
>>>>>>>>jmx name: name=DataNodeInfo,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState-c0fdc82a-1a0f-480d-8a31-e8aeff13d214,service=DataNode
>>>>>>>>jmx name: name=JvmMetrics-1,service=DataNode
>>>>>>>>jmx name: name=RpcActivityForPort42840,service=DataNode
>>>>>>>>jmx name: name=RpcDetailedActivityForPort42840,service=DataNode
2020-04-02 05:06:02,164 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:02,164 [Thread-98] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42840 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:02,165 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@157f5995] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:02,166 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@51055148] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:02,175 [Thread-98] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:02,177 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0892d977-93cf-4430-910e-63575fa8cdbf) exiting.
2020-04-02 05:06:02,178 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0d0a0e80-4caf-43c1-899f-e0953727b25c) exiting.
2020-04-02 05:06:02,515 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30c40fa2{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:02,532 [Thread-98] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7e9e0285{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:02,532 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e662b9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:02,533 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@100f0cc1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:02,537 [Thread-98] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42840
2020-04-02 05:06:02,541 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:02,541 [IPC Server listener on 42840] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42840
2020-04-02 05:06:02,541 [BP-2041880392-172.17.0.14-1585803959321 heartbeating to localhost/127.0.0.1:35635] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:02,543 [BP-2041880392-172.17.0.14-1585803959321 heartbeating to localhost/127.0.0.1:35635] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2041880392-172.17.0.14-1585803959321 (Datanode Uuid c0fdc82a-1a0f-480d-8a31-e8aeff13d214) service to localhost/127.0.0.1:35635
2020-04-02 05:06:02,650 [BP-2041880392-172.17.0.14-1585803959321 heartbeating to localhost/127.0.0.1:35635] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2041880392-172.17.0.14-1585803959321 (Datanode Uuid c0fdc82a-1a0f-480d-8a31-e8aeff13d214)
2020-04-02 05:06:02,650 [BP-2041880392-172.17.0.14-1585803959321 heartbeating to localhost/127.0.0.1:35635] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2041880392-172.17.0.14-1585803959321
2020-04-02 05:06:02,665 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2041880392-172.17.0.14-1585803959321] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:02,686 [Thread-98] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:02,689 [Thread-98] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:02,689 [Thread-98] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:02,689 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2041880392-172.17.0.14-1585803959321] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:02,689 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@295295e4] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(3203)) - LazyWriter was interrupted, exiting
2020-04-02 05:06:02,689 [Thread-98] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:02,695 [Thread-98] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:02,695 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:02,695 [Thread-98] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:02,695 [Thread-98] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 35635 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:02,695 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:02,695 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@58b6dd88] DEBUG namenode.LeaseManager (LeaseManager.java:run(536)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:02,696 [Thread-98] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:06:02,697 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3fe1fd92] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:02,697 [Thread-98] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 1 Number of syncs: 8 SyncTimes(ms): 2 2 
2020-04-02 05:06:02,697 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@78ef5d4c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:02,698 [Thread-98] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:02,699 [Thread-98] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:02,699 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:02,700 [CacheReplicationMonitor(1774276678)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:02,702 [Thread-98] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35635
2020-04-02 05:06:02,721 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:02,721 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:02,722 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:02,724 [IPC Server listener on 35635] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35635
2020-04-02 05:06:02,725 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@60ea93dd] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:02,731 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:02,731 [Thread-98] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:02,733 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@ce5f767{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:02,738 [Thread-98] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@51714653{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:02,739 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@443b7aee{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:02,740 [Thread-98] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@590cfcb4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:02,751 [Thread-98] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:02,752 [Thread-98] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:02,753 [Thread-98] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testRamDiskShortCircuitRead
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testRamDiskShortCircuitRead
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testLegacyScrMetaFileCorruption
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:02,786 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:06:02,789 [Thread-190] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
Formatting using clusterid: testClusterID
2020-04-02 05:06:02,790 [Thread-190] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:02,791 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:02,791 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:02,791 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:02,791 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:02,791 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:02,791 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:02,792 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:02,792 [Thread-190] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:02,792 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:02,792 [Thread-190] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:02,792 [Thread-190] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:02,793 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:02,793 [Thread-190] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:02,793 [Thread-190] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:02,793 [Thread-190] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:02
2020-04-02 05:06:02,793 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:02,793 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:02,794 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:02,794 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:02,798 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:02,798 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:02,798 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:02,798 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:02,798 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:02,799 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:02,800 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:02,800 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:02,800 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:02,800 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:02,805 [Thread-190] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:02,805 [Thread-190] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:02,805 [Thread-190] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:02,805 [Thread-190] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:02,805 [Thread-190] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:02,805 [Thread-190] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:02,806 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:02,806 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:02,806 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:02,806 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:02,807 [Thread-190] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:02,807 [Thread-190] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:02,807 [Thread-190] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:02,807 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:02,807 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:02,807 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:02,808 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:02,808 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:02,808 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:02,810 [Thread-190] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:02,812 [Thread-190] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:02,826 [Thread-190] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:02,842 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:02,842 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:02,847 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:02,860 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:02,871 [Thread-190] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:02,873 [Thread-190] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:02,877 [Thread-190] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:02,889 [Thread-190] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:02,890 [Thread-190] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:02,891 [Thread-190] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:02,892 [Thread-190] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:02,892 [Thread-190] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
2020-04-02 05:06:02,897 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1265d0ef] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:02,902 [Thread-190] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:02,902 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:02,904 [Thread-190] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:02,906 [Thread-190] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:02,906 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:02,907 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:02,908 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:02,908 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:02,908 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:02,910 [Thread-190] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:02,910 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:02,910 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43519
2020-04-02 05:06:02,910 [Thread-190] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:02,916 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1858ca94{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:02,928 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@56cda63e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:02,941 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@33c8e4a5{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:02,942 [Thread-190] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6e72ef02{HTTP/1.1,[http/1.1]}{localhost:43519}
2020-04-02 05:06:02,942 [Thread-190] INFO  server.Server (Server.java:doStart(419)) - Started @15813ms
2020-04-02 05:06:02,944 [Thread-190] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:02,944 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:02,944 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:02,944 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:02,945 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:02,945 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:02,945 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:02,945 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:02,956 [Thread-190] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:02,956 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:02,956 [Thread-190] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:02,957 [Thread-190] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:02,957 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:02,957 [Thread-190] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:02,969 [Thread-190] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:02,970 [Thread-190] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:02
2020-04-02 05:06:02,986 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:02,986 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:02,986 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:02,986 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:03,000 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:03,001 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:03,001 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:03,001 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:03,001 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:03,002 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:03,003 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:03,003 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:03,004 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:03,004 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:03,006 [Thread-190] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:03,007 [Thread-190] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:03,007 [Thread-190] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:03,007 [Thread-190] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:03,007 [Thread-190] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:03,007 [Thread-190] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:03,007 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:03,007 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:03,008 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:03,008 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:03,009 [Thread-190] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:03,009 [Thread-190] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:03,009 [Thread-190] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:03,009 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:03,009 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:03,009 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:03,009 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:03,010 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:03,010 [Thread-190] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:03,012 [Thread-190] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:03,014 [Thread-190] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:03,015 [Thread-190] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:03,016 [Thread-190] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:03,016 [Thread-190] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:03,016 [Thread-190] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:03,019 [Thread-190] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:03,019 [Thread-190] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:03,020 [Thread-190] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:03,020 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:03,020 [Thread-190] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:03,031 [Thread-190] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:03,032 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 21 msecs
2020-04-02 05:06:03,032 [Thread-190] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:03,033 [Thread-190] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:03,033 [Socket Reader #1 for port 34057] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34057
2020-04-02 05:06:03,046 [Thread-190] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:34057 to access this namenode/service.
2020-04-02 05:06:03,047 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:03,105 [Thread-190] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:03,108 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@3087d47d] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:06:03,114 [Thread-190] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:03,117 [Thread-190] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(607)) - STATE* Safe mode ON. 
The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1 live datanodes to reach the minimum number 1.
Safe mode will be turned off automatically once the thresholds have been reached.
2020-04-02 05:06:03,145 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:03,151 [Thread-190] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:34057
2020-04-02 05:06:03,175 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:03,176 [IPC Server listener on 34057] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34057: starting
2020-04-02 05:06:03,176 [Thread-190] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:03,204 [Thread-190] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 2 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:03,206 [Thread-190] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 34057 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:03,221 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@605b1c18] DEBUG namenode.FSNamesystem (FSNamesystem.java:run(4098)) - Namenode is in safemode, skipping scrubbing of corrupted lazy-persist files.
2020-04-02 05:06:03,226 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:03,226 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:03,226 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:03,226 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:03,226 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:03,226 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:03,226 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 30 msec
2020-04-02 05:06:03,229 [Thread-190] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:03,232 [Thread-190] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:03,244 [CacheReplicationMonitor(643697546)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:03,250 [Thread-190] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:03,251 [Thread-190] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:03,251 [Thread-190] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:03,251 [Thread-190] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:03,252 [Thread-190] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:06:03,252 [Thread-190] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:03,252 [Thread-190] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:03,252 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:03,252 [Thread-190] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:03,252 [Thread-190] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:verifyCanMlock(348)) - LazyPersistTestCase: fake return true
2020-04-02 05:06:03,252 [Thread-190] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:getMemlockLimit(342)) - LazyPersistTestCase: fake return 9223372036854775807
2020-04-02 05:06:03,253 [Thread-190] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 9223372036854775807
2020-04-02 05:06:03,253 [Thread-190] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43303
2020-04-02 05:06:03,262 [Thread-190] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:03,262 [Thread-190] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:03,267 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:03,269 [Thread-190] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:03,274 [Thread-190] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:03,274 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:03,275 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:03,276 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:03,276 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:03,276 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:03,277 [Thread-190] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45785
2020-04-02 05:06:03,277 [Thread-190] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:03,295 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2bd81fbd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:03,296 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68d12127{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:03,302 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@606d9371{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:03,311 [Thread-190] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42d6462b{HTTP/1.1,[http/1.1]}{localhost:45785}
2020-04-02 05:06:03,311 [Thread-190] INFO  server.Server (Server.java:doStart(419)) - Started @16182ms
2020-04-02 05:06:03,382 [Thread-190] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38030
2020-04-02 05:06:03,386 [Thread-190] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:03,386 [Thread-190] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:03,386 [Thread-190] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:03,387 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@52d8f457] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:03,387 [Socket Reader #1 for port 34044] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34044
2020-04-02 05:06:03,399 [Thread-190] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34044
2020-04-02 05:06:03,419 [Thread-190] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:03,420 [Thread-190] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:03,425 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:03,425 [IPC Server listener on 34044] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34044: starting
2020-04-02 05:06:03,426 [Thread-190] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34044 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:03,428 [Thread-245] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34057 starting to offer service
2020-04-02 05:06:03,486 [Thread-245] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34057
2020-04-02 05:06:03,486 [IPC Server handler 3 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,487 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:03,487 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:03,489 [Thread-245] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:03,496 [Thread-245] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:03,497 [Thread-245] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 498836141. Formatting...
2020-04-02 05:06:03,497 [Thread-245] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e6365d8f-2aea-46de-b8ac-e288589e8d52 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:03,500 [Thread-245] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:03,500 [Thread-245] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 498836141. Formatting...
2020-04-02 05:06:03,501 [Thread-245] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-50b69733-d617-40f3-8b9b-b13062ca8efd for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:03,543 [Thread-245] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:03,546 [Thread-245] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:03,547 [Thread-245] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-3045270-172.17.0.14-1585803962810 is not formatted. Formatting ...
2020-04-02 05:06:03,547 [Thread-245] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-3045270-172.17.0.14-1585803962810 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-3045270-172.17.0.14-1585803962810/current
2020-04-02 05:06:03,583 [Thread-245] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:03,583 [Thread-245] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:03,583 [Thread-245] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-3045270-172.17.0.14-1585803962810 is not formatted. Formatting ...
2020-04-02 05:06:03,583 [Thread-245] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-3045270-172.17.0.14-1585803962810 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current
2020-04-02 05:06:03,590 [IPC Server handler 7 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,595 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:03,595 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:03,598 [Thread-245] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=498836141;bpid=BP-3045270-172.17.0.14-1585803962810;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=498836141;c=1585803962810;bpid=BP-3045270-172.17.0.14-1585803962810;dnuuid=null
2020-04-02 05:06:03,600 [Thread-245] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID d4ccd24f-2fb0-44d1-9e07-855ff8d4a126
2020-04-02 05:06:03,602 [Thread-245] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e6365d8f-2aea-46de-b8ac-e288589e8d52
2020-04-02 05:06:03,602 [Thread-245] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: RAM_DISK
2020-04-02 05:06:03,611 [Thread-245] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-50b69733-d617-40f3-8b9b-b13062ca8efd
2020-04-02 05:06:03,613 [Thread-245] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:03,614 [Thread-245] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:03,615 [Thread-245] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:03,623 [Thread-245] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:03,623 [Thread-245] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:03,624 [Thread-245] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:03,626 [Thread-245] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:03,648 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-3045270-172.17.0.14-1585803962810 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:03,650 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-3045270-172.17.0.14-1585803962810 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:03,700 [IPC Server handler 1 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,701 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:03,701 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:03,715 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-3045270-172.17.0.14-1585803962810 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 65ms
2020-04-02 05:06:03,729 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-3045270-172.17.0.14-1585803962810 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 81ms
2020-04-02 05:06:03,731 [Thread-245] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-3045270-172.17.0.14-1585803962810: 105ms
2020-04-02 05:06:03,737 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-3045270-172.17.0.14-1585803962810 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:03,737 [Thread-266] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-3045270-172.17.0.14-1585803962810/current/replicas doesn't exist 
2020-04-02 05:06:03,746 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-3045270-172.17.0.14-1585803962810 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:03,746 [Thread-267] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current/replicas doesn't exist 
2020-04-02 05:06:03,750 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-3045270-172.17.0.14-1585803962810 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-04-02 05:06:03,750 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-3045270-172.17.0.14-1585803962810 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 13ms
2020-04-02 05:06:03,761 [Thread-245] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-3045270-172.17.0.14-1585803962810: 31ms
2020-04-02 05:06:03,762 [Thread-245] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:41 AM with interval of 21600000ms
2020-04-02 05:06:03,764 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-3045270-172.17.0.14-1585803962810 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:03,764 [BP-3045270-172.17.0.14-1585803962810 heartbeating to localhost/127.0.0.1:34057] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-3045270-172.17.0.14-1585803962810 (Datanode Uuid d4ccd24f-2fb0-44d1-9e07-855ff8d4a126) service to localhost/127.0.0.1:34057 beginning handshake with NN
2020-04-02 05:06:03,765 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-3045270-172.17.0.14-1585803962810 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:03,766 [IPC Server handler 2 on 34057] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43303, datanodeUuid=d4ccd24f-2fb0-44d1-9e07-855ff8d4a126, infoPort=38030, infoSecurePort=0, ipcPort=34044, storageInfo=lv=-57;cid=testClusterID;nsid=498836141;c=1585803962810) storage d4ccd24f-2fb0-44d1-9e07-855ff8d4a126
2020-04-02 05:06:03,766 [IPC Server handler 2 on 34057] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43303
2020-04-02 05:06:03,767 [IPC Server handler 2 on 34057] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d4ccd24f-2fb0-44d1-9e07-855ff8d4a126 (127.0.0.1:43303).
2020-04-02 05:06:03,768 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e6365d8f-2aea-46de-b8ac-e288589e8d52): finished scanning block pool BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:03,769 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e6365d8f-2aea-46de-b8ac-e288589e8d52): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:06:03,771 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-50b69733-d617-40f3-8b9b-b13062ca8efd): finished scanning block pool BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:03,772 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-50b69733-d617-40f3-8b9b-b13062ca8efd): no suitable block pools found to scan.  Waiting 1814399990 ms.
2020-04-02 05:06:03,774 [IPC Server handler 2 on 34057] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(391)) - STATE* Safe mode is OFF
2020-04-02 05:06:03,775 [IPC Server handler 2 on 34057] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:03,775 [IPC Server handler 2 on 34057] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 1 datanodes
2020-04-02 05:06:03,776 [IPC Server handler 2 on 34057] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:03,782 [BP-3045270-172.17.0.14-1585803962810 heartbeating to localhost/127.0.0.1:34057] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-3045270-172.17.0.14-1585803962810 (Datanode Uuid d4ccd24f-2fb0-44d1-9e07-855ff8d4a126) service to localhost/127.0.0.1:34057 successfully registered with NN
2020-04-02 05:06:03,782 [BP-3045270-172.17.0.14-1585803962810 heartbeating to localhost/127.0.0.1:34057] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34057 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:03,791 [IPC Server handler 6 on 34057] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e6365d8f-2aea-46de-b8ac-e288589e8d52 for DN 127.0.0.1:43303
2020-04-02 05:06:03,791 [IPC Server handler 6 on 34057] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-50b69733-d617-40f3-8b9b-b13062ca8efd for DN 127.0.0.1:43303
2020-04-02 05:06:03,798 [IPC Server handler 8 on 34057] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43303, datanodeUuid=d4ccd24f-2fb0-44d1-9e07-855ff8d4a126, infoPort=38030, infoSecurePort=0, ipcPort=34044, storageInfo=lv=-57;cid=testClusterID;nsid=498836141;c=1585803962810), reports.length=2
2020-04-02 05:06:03,799 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x891121dfe24e8079: Processing first storage report for DS-50b69733-d617-40f3-8b9b-b13062ca8efd from datanode d4ccd24f-2fb0-44d1-9e07-855ff8d4a126
2020-04-02 05:06:03,799 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x891121dfe24e8079: from storage DS-50b69733-d617-40f3-8b9b-b13062ca8efd node DatanodeRegistration(127.0.0.1:43303, datanodeUuid=d4ccd24f-2fb0-44d1-9e07-855ff8d4a126, infoPort=38030, infoSecurePort=0, ipcPort=34044, storageInfo=lv=-57;cid=testClusterID;nsid=498836141;c=1585803962810), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:03,799 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x891121dfe24e8079: Processing first storage report for DS-e6365d8f-2aea-46de-b8ac-e288589e8d52 from datanode d4ccd24f-2fb0-44d1-9e07-855ff8d4a126
2020-04-02 05:06:03,799 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x891121dfe24e8079: from storage DS-e6365d8f-2aea-46de-b8ac-e288589e8d52 node DatanodeRegistration(127.0.0.1:43303, datanodeUuid=d4ccd24f-2fb0-44d1-9e07-855ff8d4a126, infoPort=38030, infoSecurePort=0, ipcPort=34044, storageInfo=lv=-57;cid=testClusterID;nsid=498836141;c=1585803962810), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:03,799 [IPC Server handler 8 on 34057] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x891121dfe24e8079
2020-04-02 05:06:03,802 [BP-3045270-172.17.0.14-1585803962810 heartbeating to localhost/127.0.0.1:34057] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x891121dfe24e8079,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 2 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:03,802 [BP-3045270-172.17.0.14-1585803962810 heartbeating to localhost/127.0.0.1:34057] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:03,804 [IPC Server handler 5 on 34057] DEBUG BlockStateChange (NameNodeRpcServer.java:cacheReport(1559)) - *BLOCK* NameNode.cacheReport: from DatanodeRegistration(127.0.0.1:43303, datanodeUuid=d4ccd24f-2fb0-44d1-9e07-855ff8d4a126, infoPort=38030, infoSecurePort=0, ipcPort=34044, storageInfo=lv=-57;cid=testClusterID;nsid=498836141;c=1585803962810) 0 blocks
2020-04-02 05:06:03,804 [IPC Server handler 9 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,815 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:03,815 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [RAM_DISK]DS-e6365d8f-2aea-46de-b8ac-e288589e8d52
2020-04-02 05:06:03,815 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [DISK]DS-50b69733-d617-40f3-8b9b-b13062ca8efd
2020-04-02 05:06:03,922 [IPC Server handler 0 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,925 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
init: server=localhost;port=;service=DataNode;localVMUrl=null

Domains:
	Domain = Hadoop
	Domain = JMImplementation
	Domain = com.sun.management
	Domain = java.lang
	Domain = java.nio
	Domain = java.util.logging

MBeanServer default domain = DefaultDomain

MBean count = 49

Query MBeanServer MBeans:
Hadoop service: Hadoop:service=DataNode,name=DataNodeActivity-127.0.0.1-43303
Hadoop service: Hadoop:service=DataNode,name=DataNodeInfo
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState-d4ccd24f-2fb0-44d1-9e07-855ff8d4a126
Hadoop service: Hadoop:service=DataNode,name=JvmMetrics-1
Hadoop service: Hadoop:service=DataNode,name=RpcActivityForPort34044
Hadoop service: Hadoop:service=DataNode,name=RpcDetailedActivityForPort34044
2020-04-02 05:06:03,928 [Thread-190] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:startUpCluster(326)) - Cluster startup complete
2020-04-02 05:06:03,930 [IPC Server handler 3 on 34057] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /doShortCircuitReadMetaFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_1694075288_598 at 127.0.0.1
2020-04-02 05:06:03,930 [IPC Server handler 3 on 34057] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/doShortCircuitReadMetaFileCorruptionTest.01.dat, holder=DFSClient_NONMAPREDUCE_1694075288_598, clientMachine=127.0.0.1, createParent=true, replication=1, createFlag=[CREATE, LAZY_PERSIST], blockSize=5242880, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:06:03,931 [IPC Server handler 3 on 34057] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: doShortCircuitReadMetaFileCorruptionTest.01.dat is added
2020-04-02 05:06:03,932 [IPC Server handler 3 on 34057] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /doShortCircuitReadMetaFileCorruptionTest.01.dat inode 16386 DFSClient_NONMAPREDUCE_1694075288_598
2020-04-02 05:06:03,933 [IPC Server handler 3 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:03,943 [IPC Server handler 7 on 34057] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /doShortCircuitReadMetaFileCorruptionTest.01.dat  inodeId 16386 for DFSClient_NONMAPREDUCE_1694075288_598
2020-04-02 05:06:03,944 [IPC Server handler 7 on 34057] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /doShortCircuitReadMetaFileCorruptionTest.01.dat with blk_1073741825_1001 block is added to the in-memory file system
2020-04-02 05:06:03,944 [IPC Server handler 7 on 34057] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:43303 for /doShortCircuitReadMetaFileCorruptionTest.01.dat
2020-04-02 05:06:03,944 [IPC Server handler 7 on 34057] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /doShortCircuitReadMetaFileCorruptionTest.01.dat with new block blk_1073741825_1001, current total block count is 1
2020-04-02 05:06:03,967 [DataXceiver for client DFSClient_NONMAPREDUCE_1694075288_598 at /127.0.0.1:55992 [Receiving block BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001 src: /127.0.0.1:55992 dest: /127.0.0.1:43303
2020-04-02 05:06:04,060 [PacketResponder: BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:moveBlockFiles(885)) - addFinalizedBlock: Moved file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-3045270-172.17.0.14-1585803962810/current/rbw/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-3045270-172.17.0.14-1585803962810/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta and file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-3045270-172.17.0.14-1585803962810/current/rbw/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-3045270-172.17.0.14-1585803962810/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:04,062 [PacketResponder: BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55992, dest: /127.0.0.1:43303, bytes: 5242880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1694075288_598, offset: 0, srvID: d4ccd24f-2fb0-44d1-9e07-855ff8d4a126, blockid: BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001, duration(ns): 81987383
2020-04-02 05:06:04,062 [PacketResponder: BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:04,066 [IPC Server handler 2 on 34057] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3274)) - BLOCK* fsync: /doShortCircuitReadMetaFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_1694075288_598
2020-04-02 05:06:04,070 [IPC Server handler 2 on 34057] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistBlocks(112)) - persistBlocks: /doShortCircuitReadMetaFileCorruptionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:04,071 [IPC Server handler 2 on 34057] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43303, datanodeUuid=d4ccd24f-2fb0-44d1-9e07-855ff8d4a126, infoPort=38030, infoSecurePort=0, ipcPort=34044, storageInfo=lv=-57;cid=testClusterID;nsid=498836141;c=1585803962810) 1 blocks.
2020-04-02 05:06:04,076 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:43303 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:04,076 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:04,080 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:43303 is added to blk_1073741825_1001 (size=5242880)
2020-04-02 05:06:04,080 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:43303
2020-04-02 05:06:04,080 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43303 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:04,085 [IPC Server handler 6 on 34057] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /doShortCircuitReadMetaFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_1694075288_598
2020-04-02 05:06:04,088 [IPC Server handler 6 on 34057] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /doShortCircuitReadMetaFileCorruptionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:04,088 [IPC Server handler 6 on 34057] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /doShortCircuitReadMetaFileCorruptionTest.01.dat is closed by DFSClient_NONMAPREDUCE_1694075288_598
2020-04-02 05:06:04,094 [Thread-190] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadMetaFileCorruptionTest.01.dat is on StorageType: RAM_DISK
2020-04-02 05:06:04,095 [IPC Server handler 5 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,098 [IPC Server handler 9 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,099 [IPC Server handler 4 on 34057] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:04,100 [IPC Server handler 4 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,102 [IPC Server handler 9 on 34057] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:04,103 [IPC Server handler 9 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:0
2020-04-02 05:06:04,105 [Thread-190] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 0
2020-04-02 05:06:04,617 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@12109ccb] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:saveNextReplica(3108)) - LazyWriter: Start persisting RamDisk block: block pool Id: BP-3045270-172.17.0.14-1585803962810 block id: 1073741825 on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:04,629 [Async RamDisk lazy persist worker  for volume with id DS-50b69733-d617-40f3-8b9b-b13062ca8efd] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:copyBlockFiles(931)) - Copied file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-3045270-172.17.0.14-1585803962810/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta and calculated checksum
2020-04-02 05:06:04,630 [Async RamDisk lazy persist worker  for volume with id DS-50b69733-d617-40f3-8b9b-b13062ca8efd] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:onCompleteLazyPersist(2969)) - LazyWriter: Finish persisting RamDisk block:  block pool Id: BP-3045270-172.17.0.14-1585803962810 block id: 1073741825 to block file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current/lazypersist/subdir0/subdir0/blk_1073741825 and meta file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:1
2020-04-02 05:06:05,106 [Thread-190] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 1
2020-04-02 05:06:05,107 [Thread-190] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:evictBlocks(3151)) - Evicting block [BlockPoolID=BP-3045270-172.17.0.14-1585803962810; BlockId=1073741825]
2020-04-02 05:06:05,115 [Thread-190] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(382)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current/lazypersist/subdir0/subdir0/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:05,116 [Thread-190] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(384)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta
2020-04-02 05:06:05,117 [IPC Server handler 8 on 34057] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43303, datanodeUuid=d4ccd24f-2fb0-44d1-9e07-855ff8d4a126, infoPort=38030, infoSecurePort=0, ipcPort=34044, storageInfo=lv=-57;cid=testClusterID;nsid=498836141;c=1585803962810) 1 blocks.
2020-04-02 05:06:05,122 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:43303 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:05,118 [Thread-190] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadMetaFileCorruptionTest.01.dat is on StorageType: DISK
2020-04-02 05:06:05,122 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:05,123 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3248)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:43303
2020-04-02 05:06:05,124 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:43303
2020-04-02 05:06:05,124 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43303 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:05,124 [IPC Server handler 3 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,126 [IPC Server handler 0 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,143 [IPC Server handler 7 on 34057] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:05,144 [IPC Server handler 7 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,148 [IPC Server handler 1 on 34057] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:05,148 [IPC Server handler 1 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,151 [IPC Server handler 2 on 34057] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:05,151 [IPC Server handler 2 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,256 [Thread-190] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptMeta(160)) - Corrupting meta file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta
2020-04-02 05:06:05,258 [IPC Server handler 6 on 34057] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:05,259 [IPC Server handler 6 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,265 [Thread-190] WARN  hdfs.DFSClient (DFSInputStream.java:readBuffer(706)) - Found Checksum error for BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001 from DatanodeInfoWithStorage[127.0.0.1:43303,DS-50b69733-d617-40f3-8b9b-b13062ca8efd,DISK] at 192512
2020-04-02 05:06:05,265 [Thread-190] WARN  hdfs.DFSClient (DFSInputStream.java:reportLostBlock(959)) - No live nodes contain block BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:43303,DS-50b69733-d617-40f3-8b9b-b13062ca8efd,DISK]], ignoredNodes = null
2020-04-02 05:06:05,266 [Thread-190] INFO  hdfs.DFSClient (DFSInputStream.java:refetchLocations(882)) - Could not obtain BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:43303,DS-50b69733-d617-40f3-8b9b-b13062ca8efd,DISK] Dead nodes:  DatanodeInfoWithStorage[127.0.0.1:43303,DS-50b69733-d617-40f3-8b9b-b13062ca8efd,DISK]. Will get new block locations from namenode and retry...
2020-04-02 05:06:05,266 [Thread-190] WARN  hdfs.DFSClient (DFSInputStream.java:refetchLocations(901)) - DFS chooseDataNode: got # 1 IOException, will wait for 443.99565765238924 msec.
2020-04-02 05:06:05,710 [IPC Server handler 5 on 34057] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:05,711 [IPC Server handler 5 on 34057] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,717 [IPC Server handler 4 on 34057] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-3045270-172.17.0.14-1585803962810:blk_1073741825_1001 on datanode: 127.0.0.1:43303
2020-04-02 05:06:05,717 [IPC Server handler 4 on 34057] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_1073741825_1001 added as corrupt on 127.0.0.1:43303 by /127.0.0.1  because client machine reported it
2020-04-02 05:06:05,717 [IPC Server handler 4 on 34057] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741825_1001 curReplicas 0 curExpectedReplicas 1 oldReplicas 1 oldExpectedReplicas  1 curPri  4 oldPri  3
2020-04-02 05:06:05,717 [IPC Server handler 4 on 34057] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_1073741825_1001 has only 0 replicas and needs 1 replicas so is added to neededReconstructions at priority level 4
List of the keys matching ^RamDisk :
>>>>>>>>jmx name: name=DataNodeActivity-127.0.0.1-43303,service=DataNode
RamDiskBlocksWrite=1
RamDiskBlocksWriteFallback=0
RamDiskBytesWrite=5242880
RamDiskBlocksReadHits=0
RamDiskBlocksEvicted=1
RamDiskBlocksEvictedWithoutRead=1
RamDiskBlocksEvictionWindowMsNumOps=1
RamDiskBlocksEvictionWindowMsAvgTime=1055.0
RamDiskBlocksLazyPersisted=1
RamDiskBlocksDeletedBeforeLazyPersisted=0
RamDiskBytesLazyPersisted=5242880
RamDiskBlocksLazyPersistWindowMsNumOps=1
RamDiskBlocksLazyPersistWindowMsAvgTime=569.0
>>>>>>>>jmx name: name=DataNodeInfo,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState-d4ccd24f-2fb0-44d1-9e07-855ff8d4a126,service=DataNode
>>>>>>>>jmx name: name=JvmMetrics-1,service=DataNode
>>>>>>>>jmx name: name=RpcActivityForPort34044,service=DataNode
>>>>>>>>jmx name: name=RpcDetailedActivityForPort34044,service=DataNode
2020-04-02 05:06:05,801 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:05,802 [Thread-190] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34044 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:05,802 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@185cb01a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:05,803 [Thread-190] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:05,810 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-50b69733-d617-40f3-8b9b-b13062ca8efd) exiting.
2020-04-02 05:06:05,811 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e6365d8f-2aea-46de-b8ac-e288589e8d52) exiting.
2020-04-02 05:06:05,818 [BP-3045270-172.17.0.14-1585803962810 heartbeating to localhost/127.0.0.1:34057] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-3045270-172.17.0.14-1585803962810 (Datanode Uuid d4ccd24f-2fb0-44d1-9e07-855ff8d4a126) service to localhost/127.0.0.1:34057
2020-04-02 05:06:05,818 [BP-3045270-172.17.0.14-1585803962810 heartbeating to localhost/127.0.0.1:34057] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-3045270-172.17.0.14-1585803962810 (Datanode Uuid d4ccd24f-2fb0-44d1-9e07-855ff8d4a126)
2020-04-02 05:06:05,818 [BP-3045270-172.17.0.14-1585803962810 heartbeating to localhost/127.0.0.1:34057] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-3045270-172.17.0.14-1585803962810
2020-04-02 05:06:05,940 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@606d9371{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:05,951 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-3045270-172.17.0.14-1585803962810] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:05,965 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-3045270-172.17.0.14-1585803962810] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:05,970 [Thread-190] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42d6462b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:05,971 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68d12127{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:05,971 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2bd81fbd{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:05,972 [Thread-190] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34044
2020-04-02 05:06:05,994 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:05,997 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@12109ccb] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(3203)) - LazyWriter was interrupted, exiting
2020-04-02 05:06:05,997 [Thread-190] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:05,998 [Thread-190] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:05,998 [Thread-190] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:05,998 [Thread-190] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:06,010 [Thread-190] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:06,010 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:06,010 [Thread-190] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:06,010 [Thread-190] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 34057 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:06,011 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:06,011 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@55854048] DEBUG namenode.LeaseManager (LeaseManager.java:run(536)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:06,017 [IPC Server listener on 34044] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34044
2020-04-02 05:06:06,022 [Thread-190] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:06:06,022 [Thread-190] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 5 Number of transactions batched in Syncs: 2 Number of syncs: 7 SyncTimes(ms): 2 3 
2020-04-02 05:06:06,023 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@605b1c18] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:06,022 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@214aba5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:06,032 [Thread-190] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:06,032 [Thread-190] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:06,033 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:06,039 [Thread-190] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34057
2020-04-02 05:06:06,041 [IPC Server listener on 34057] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34057
2020-04-02 05:06:06,041 [CacheReplicationMonitor(643697546)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:06,048 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:06,049 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:06,049 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:06,057 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@3087d47d] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:06,079 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:06,079 [Thread-190] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:06,082 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@33c8e4a5{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:06,107 [Thread-190] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6e72ef02{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:06,108 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@56cda63e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:06,108 [Thread-190] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1858ca94{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:06,121 [Thread-190] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:06,126 [Thread-190] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:06,128 [Thread-190] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testLegacyScrMetaFileCorruption
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testLegacyScrMetaFileCorruption
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testScrAfterEviction
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:06,166 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:06:06,169 [Thread-279] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
Formatting using clusterid: testClusterID
2020-04-02 05:06:06,179 [Thread-279] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:06,180 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:06,180 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:06,181 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:06,181 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:06,181 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:06,181 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:06,182 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:06,182 [Thread-279] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:06,182 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,183 [Thread-279] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:06,183 [Thread-279] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:06,183 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,183 [Thread-279] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:06,184 [Thread-279] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:06,184 [Thread-279] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:06
2020-04-02 05:06:06,184 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:06,184 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:06,185 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:06,185 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:06,214 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,221 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,221 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:06,222 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,222 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:06,222 [Thread-279] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:06,222 [Thread-279] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:06,223 [Thread-279] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:06,223 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:06,223 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:06,223 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:06,223 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:06,223 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:06,223 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:06,223 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:06,223 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:06,224 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:06,224 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:06,224 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:06,226 [Thread-279] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:06,226 [Thread-279] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:06,226 [Thread-279] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:06,226 [Thread-279] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:06,226 [Thread-279] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:06,226 [Thread-279] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:06,227 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:06,227 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:06,227 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:06,227 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:06,229 [Thread-279] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:06,229 [Thread-279] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:06,229 [Thread-279] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:06,230 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:06,230 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:06,230 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:06,230 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:06,230 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:06,231 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:06,232 [Thread-279] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:06,235 [Thread-279] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:06,237 [Thread-279] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:06,265 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:06,265 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:06,273 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:06,278 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:06,280 [Thread-279] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:06,288 [Thread-279] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:06,294 [Thread-279] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:06,298 [Thread-279] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:06,298 [Thread-279] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:06,299 [Thread-279] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:06,300 [Thread-279] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:06,300 [Thread-279] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
2020-04-02 05:06:06,309 [Thread-279] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:06,310 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:06,311 [Thread-279] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:06,312 [Thread-279] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:06,313 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:06,316 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:06,317 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:06,317 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:06,317 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:06,321 [Thread-279] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:06,321 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:06,321 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37722
2020-04-02 05:06:06,322 [Thread-279] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:06,322 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@14892bf0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:06,327 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53716199{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:06,338 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55deced4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:06,365 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7305cbf6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:06,373 [Thread-279] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@16721edf{HTTP/1.1,[http/1.1]}{localhost:37722}
2020-04-02 05:06:06,374 [Thread-279] INFO  server.Server (Server.java:doStart(419)) - Started @19245ms
2020-04-02 05:06:06,375 [Thread-279] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:06,375 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:06,376 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:06,376 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:06,376 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:06,376 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:06,376 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:06,377 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:06,377 [Thread-279] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:06,377 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,385 [Thread-279] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:06,388 [Thread-279] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:06,390 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,391 [Thread-279] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:06,392 [Thread-279] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:06,394 [Thread-279] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:06
2020-04-02 05:06:06,396 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:06,397 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:06,399 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:06,401 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:06,428 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,434 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,436 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:06,441 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,441 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:06,441 [Thread-279] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:06,441 [Thread-279] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:06,442 [Thread-279] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:06,442 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:06,442 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:06,442 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:06,442 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:06,442 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:06,442 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:06,442 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:06,443 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:06,443 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:06,443 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:06,443 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:06,463 [Thread-279] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:06,463 [Thread-279] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:06,463 [Thread-279] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:06,463 [Thread-279] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:06,463 [Thread-279] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:06,463 [Thread-279] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:06,463 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:06,464 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:06,464 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:06,464 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:06,468 [Thread-279] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:06,469 [Thread-279] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:06,470 [Thread-279] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:06,470 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:06,470 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:06,471 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:06,471 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:06,471 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:06,471 [Thread-279] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:06,481 [Thread-279] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:06,483 [Thread-279] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:06,486 [Thread-279] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:06,487 [Thread-279] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:06,488 [Thread-279] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:06,488 [Thread-279] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:06,489 [Thread-279] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:06,492 [Thread-279] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:06,494 [Thread-279] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:06,494 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:06,495 [Thread-279] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:06,532 [Thread-279] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:06,532 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 59 msecs
2020-04-02 05:06:06,533 [Thread-279] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:06,533 [Thread-279] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:06,538 [Socket Reader #1 for port 43110] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43110
2020-04-02 05:06:06,606 [Thread-279] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:43110 to access this namenode/service.
2020-04-02 05:06:06,607 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:06,659 [Thread-279] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:06,663 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@21368a80] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:06:06,664 [Thread-279] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:06,665 [Thread-279] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(607)) - STATE* Safe mode ON. 
The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1 live datanodes to reach the minimum number 1.
Safe mode will be turned off automatically once the thresholds have been reached.
2020-04-02 05:06:06,710 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:06,710 [IPC Server listener on 43110] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43110: starting
2020-04-02 05:06:06,711 [Thread-279] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43110
2020-04-02 05:06:06,712 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:06,712 [Thread-279] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:06,713 [Thread-279] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:06,723 [Thread-279] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43110 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:06,726 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:06,726 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:06,726 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:06,726 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:06,726 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:06,726 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 61 msec
2020-04-02 05:06:06,730 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:06,732 [Thread-279] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:06,735 [Thread-279] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:06,762 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3f30c5ea] DEBUG namenode.FSNamesystem (FSNamesystem.java:run(4098)) - Namenode is in safemode, skipping scrubbing of corrupted lazy-persist files.
2020-04-02 05:06:06,763 [CacheReplicationMonitor(335510677)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:06,778 [Thread-279] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:06,790 [Thread-279] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:06,790 [Thread-279] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:06,790 [Thread-279] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:06,791 [Thread-279] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:06:06,791 [Thread-279] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:06,791 [Thread-279] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:06,791 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,791 [Thread-279] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:06,791 [Thread-279] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:verifyCanMlock(348)) - LazyPersistTestCase: fake return true
2020-04-02 05:06:06,791 [Thread-279] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:getMemlockLimit(342)) - LazyPersistTestCase: fake return 9223372036854775807
2020-04-02 05:06:06,791 [Thread-279] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 9223372036854775807
2020-04-02 05:06:06,792 [Thread-279] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36056
2020-04-02 05:06:06,792 [Thread-279] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:06,792 [Thread-279] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:06,793 [Thread-279] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:06,793 [Thread-279] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:06,793 [Thread-279] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585803966166.-2030442735/TestScrLazyPersistFiles.36056.sock
2020-04-02 05:06:06,800 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:06,803 [Thread-279] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:06,807 [Thread-279] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:06,807 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:06,813 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:06,823 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:06,823 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:06,824 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:06,825 [Thread-279] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42940
2020-04-02 05:06:06,826 [Thread-279] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:06,839 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@48e6bf2d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:06,840 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4fc1e737{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:06,851 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30d5518b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:06,852 [Thread-279] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4fb38c6c{HTTP/1.1,[http/1.1]}{localhost:42940}
2020-04-02 05:06:06,852 [Thread-279] INFO  server.Server (Server.java:doStart(419)) - Started @19723ms
2020-04-02 05:06:06,963 [Thread-279] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45361
2020-04-02 05:06:06,964 [Thread-279] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:06,964 [Thread-279] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:06,965 [Thread-279] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:06,965 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7400dafe] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:06,966 [Socket Reader #1 for port 41572] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41572
2020-04-02 05:06:06,985 [Thread-279] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41572
2020-04-02 05:06:06,993 [Thread-279] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:06,993 [Thread-279] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:06,998 [Thread-335] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43110 starting to offer service
2020-04-02 05:06:06,999 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:07,000 [IPC Server listener on 41572] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41572: starting
2020-04-02 05:06:07,001 [Thread-279] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41572 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:07,054 [Thread-335] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43110
2020-04-02 05:06:07,055 [IPC Server handler 0 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,056 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:07,056 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:07,057 [Thread-335] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:07,062 [Thread-335] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:07,063 [Thread-335] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 288644598. Formatting...
2020-04-02 05:06:07,063 [Thread-335] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-78446729-48d4-4d71-b7e2-4764b67bffa7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:07,070 [Thread-335] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:07,070 [Thread-335] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 288644598. Formatting...
2020-04-02 05:06:07,071 [Thread-335] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-485ee963-abaa-44ae-af0e-6b4c83c18198 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:07,104 [Thread-335] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:07,105 [Thread-335] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:07,105 [Thread-335] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-431206537-172.17.0.14-1585803966232 is not formatted. Formatting ...
2020-04-02 05:06:07,105 [Thread-335] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-431206537-172.17.0.14-1585803966232 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-431206537-172.17.0.14-1585803966232/current
2020-04-02 05:06:07,141 [Thread-335] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:07,141 [Thread-335] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:07,142 [Thread-335] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-431206537-172.17.0.14-1585803966232 is not formatted. Formatting ...
2020-04-02 05:06:07,142 [Thread-335] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-431206537-172.17.0.14-1585803966232 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232/current
2020-04-02 05:06:07,154 [Thread-335] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=288644598;bpid=BP-431206537-172.17.0.14-1585803966232;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=288644598;c=1585803966232;bpid=BP-431206537-172.17.0.14-1585803966232;dnuuid=null
2020-04-02 05:06:07,165 [Thread-335] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID eed67f08-05c9-4337-be24-6b4ae00f586e
2020-04-02 05:06:07,172 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-78446729-48d4-4d71-b7e2-4764b67bffa7
2020-04-02 05:06:07,173 [Thread-335] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: RAM_DISK
2020-04-02 05:06:07,179 [IPC Server handler 2 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,182 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:07,182 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:07,201 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-485ee963-abaa-44ae-af0e-6b4c83c18198
2020-04-02 05:06:07,202 [Thread-335] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:07,210 [Thread-335] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:07,214 [Thread-335] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:07,226 [Thread-335] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:07,226 [Thread-335] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:07,226 [Thread-335] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:07,229 [Thread-335] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:07,229 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-431206537-172.17.0.14-1585803966232 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:07,229 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-431206537-172.17.0.14-1585803966232 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:07,281 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-431206537-172.17.0.14-1585803966232 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 52ms
2020-04-02 05:06:07,294 [IPC Server handler 3 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,295 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:07,295 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:07,308 [Thread-353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-431206537-172.17.0.14-1585803966232 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 79ms
2020-04-02 05:06:07,309 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-431206537-172.17.0.14-1585803966232: 80ms
2020-04-02 05:06:07,314 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-431206537-172.17.0.14-1585803966232 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:07,314 [Thread-357] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232/current/replicas doesn't exist 
2020-04-02 05:06:07,317 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-431206537-172.17.0.14-1585803966232 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:07,317 [Thread-356] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-431206537-172.17.0.14-1585803966232/current/replicas doesn't exist 
2020-04-02 05:06:07,318 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-431206537-172.17.0.14-1585803966232 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-04-02 05:06:07,318 [Thread-356] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-431206537-172.17.0.14-1585803966232 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:06:07,322 [Thread-335] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-431206537-172.17.0.14-1585803966232: 14ms
2020-04-02 05:06:07,323 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-431206537-172.17.0.14-1585803966232 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:07,323 [Thread-335] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:44 AM with interval of 21600000ms
2020-04-02 05:06:07,324 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-78446729-48d4-4d71-b7e2-4764b67bffa7): finished scanning block pool BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:07,324 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-431206537-172.17.0.14-1585803966232 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:07,336 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-485ee963-abaa-44ae-af0e-6b4c83c18198): finished scanning block pool BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:07,336 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-485ee963-abaa-44ae-af0e-6b4c83c18198): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-04-02 05:06:07,334 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-78446729-48d4-4d71-b7e2-4764b67bffa7): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-04-02 05:06:07,333 [BP-431206537-172.17.0.14-1585803966232 heartbeating to localhost/127.0.0.1:43110] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-431206537-172.17.0.14-1585803966232 (Datanode Uuid eed67f08-05c9-4337-be24-6b4ae00f586e) service to localhost/127.0.0.1:43110 beginning handshake with NN
2020-04-02 05:06:07,338 [IPC Server handler 4 on 43110] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36056, datanodeUuid=eed67f08-05c9-4337-be24-6b4ae00f586e, infoPort=45361, infoSecurePort=0, ipcPort=41572, storageInfo=lv=-57;cid=testClusterID;nsid=288644598;c=1585803966232) storage eed67f08-05c9-4337-be24-6b4ae00f586e
2020-04-02 05:06:07,339 [IPC Server handler 4 on 43110] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36056
2020-04-02 05:06:07,339 [IPC Server handler 4 on 43110] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN eed67f08-05c9-4337-be24-6b4ae00f586e (127.0.0.1:36056).
2020-04-02 05:06:07,341 [IPC Server handler 4 on 43110] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(391)) - STATE* Safe mode is OFF
2020-04-02 05:06:07,341 [IPC Server handler 4 on 43110] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:07,341 [IPC Server handler 4 on 43110] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 1 datanodes
2020-04-02 05:06:07,344 [IPC Server handler 4 on 43110] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:07,346 [BP-431206537-172.17.0.14-1585803966232 heartbeating to localhost/127.0.0.1:43110] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-431206537-172.17.0.14-1585803966232 (Datanode Uuid eed67f08-05c9-4337-be24-6b4ae00f586e) service to localhost/127.0.0.1:43110 successfully registered with NN
2020-04-02 05:06:07,346 [BP-431206537-172.17.0.14-1585803966232 heartbeating to localhost/127.0.0.1:43110] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43110 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:07,359 [IPC Server handler 5 on 43110] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-78446729-48d4-4d71-b7e2-4764b67bffa7 for DN 127.0.0.1:36056
2020-04-02 05:06:07,359 [IPC Server handler 5 on 43110] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-485ee963-abaa-44ae-af0e-6b4c83c18198 for DN 127.0.0.1:36056
2020-04-02 05:06:07,379 [IPC Server handler 6 on 43110] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36056, datanodeUuid=eed67f08-05c9-4337-be24-6b4ae00f586e, infoPort=45361, infoSecurePort=0, ipcPort=41572, storageInfo=lv=-57;cid=testClusterID;nsid=288644598;c=1585803966232), reports.length=2
2020-04-02 05:06:07,382 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x86cb42e475f9ec6f: Processing first storage report for DS-78446729-48d4-4d71-b7e2-4764b67bffa7 from datanode eed67f08-05c9-4337-be24-6b4ae00f586e
2020-04-02 05:06:07,382 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x86cb42e475f9ec6f: from storage DS-78446729-48d4-4d71-b7e2-4764b67bffa7 node DatanodeRegistration(127.0.0.1:36056, datanodeUuid=eed67f08-05c9-4337-be24-6b4ae00f586e, infoPort=45361, infoSecurePort=0, ipcPort=41572, storageInfo=lv=-57;cid=testClusterID;nsid=288644598;c=1585803966232), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:07,382 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x86cb42e475f9ec6f: Processing first storage report for DS-485ee963-abaa-44ae-af0e-6b4c83c18198 from datanode eed67f08-05c9-4337-be24-6b4ae00f586e
2020-04-02 05:06:07,382 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x86cb42e475f9ec6f: from storage DS-485ee963-abaa-44ae-af0e-6b4c83c18198 node DatanodeRegistration(127.0.0.1:36056, datanodeUuid=eed67f08-05c9-4337-be24-6b4ae00f586e, infoPort=45361, infoSecurePort=0, ipcPort=41572, storageInfo=lv=-57;cid=testClusterID;nsid=288644598;c=1585803966232), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:07,382 [IPC Server handler 6 on 43110] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x86cb42e475f9ec6f
2020-04-02 05:06:07,386 [BP-431206537-172.17.0.14-1585803966232 heartbeating to localhost/127.0.0.1:43110] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x86cb42e475f9ec6f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 20 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:07,386 [BP-431206537-172.17.0.14-1585803966232 heartbeating to localhost/127.0.0.1:43110] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:07,388 [IPC Server handler 7 on 43110] DEBUG BlockStateChange (NameNodeRpcServer.java:cacheReport(1559)) - *BLOCK* NameNode.cacheReport: from DatanodeRegistration(127.0.0.1:36056, datanodeUuid=eed67f08-05c9-4337-be24-6b4ae00f586e, infoPort=45361, infoSecurePort=0, ipcPort=41572, storageInfo=lv=-57;cid=testClusterID;nsid=288644598;c=1585803966232) 0 blocks
2020-04-02 05:06:07,396 [IPC Server handler 8 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,400 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:07,400 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [RAM_DISK]DS-78446729-48d4-4d71-b7e2-4764b67bffa7
2020-04-02 05:06:07,401 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [DISK]DS-485ee963-abaa-44ae-af0e-6b4c83c18198
2020-04-02 05:06:07,505 [IPC Server handler 1 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,506 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
init: server=localhost;port=;service=DataNode;localVMUrl=null

Domains:
	Domain = Hadoop
	Domain = JMImplementation
	Domain = com.sun.management
	Domain = java.lang
	Domain = java.nio
	Domain = java.util.logging

MBeanServer default domain = DefaultDomain

MBean count = 49

Query MBeanServer MBeans:
Hadoop service: Hadoop:service=DataNode,name=DataNodeActivity-127.0.0.1-36056
Hadoop service: Hadoop:service=DataNode,name=DataNodeInfo
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState-eed67f08-05c9-4337-be24-6b4ae00f586e
Hadoop service: Hadoop:service=DataNode,name=JvmMetrics-1
Hadoop service: Hadoop:service=DataNode,name=RpcActivityForPort41572
Hadoop service: Hadoop:service=DataNode,name=RpcDetailedActivityForPort41572
2020-04-02 05:06:07,508 [Thread-279] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:startUpCluster(326)) - Cluster startup complete
2020-04-02 05:06:07,511 [IPC Server handler 0 on 43110] DEBUG hdfs.StateChange (NameNodeRpcServer.java:mkdirs(1120)) - *DIR* NameNode.mkdirs: /
2020-04-02 05:06:07,511 [IPC Server handler 0 on 43110] DEBUG hdfs.StateChange (FSDirMkdirOp.java:mkdirs(46)) - DIR* NameSystem.mkdirs: /
2020-04-02 05:06:07,511 [IPC Server handler 0 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:07,513 [IPC Server handler 2 on 43110] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /doShortCircuitReadAfterEvictionTest.01.dat for DFSClient_NONMAPREDUCE_702345733_875 at 127.0.0.1
2020-04-02 05:06:07,513 [IPC Server handler 2 on 43110] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/doShortCircuitReadAfterEvictionTest.01.dat, holder=DFSClient_NONMAPREDUCE_702345733_875, clientMachine=127.0.0.1, createParent=true, replication=1, createFlag=[CREATE, OVERWRITE, LAZY_PERSIST], blockSize=5242880, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:06:07,514 [IPC Server handler 2 on 43110] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: doShortCircuitReadAfterEvictionTest.01.dat is added
2020-04-02 05:06:07,516 [IPC Server handler 2 on 43110] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /doShortCircuitReadAfterEvictionTest.01.dat inode 16386 DFSClient_NONMAPREDUCE_702345733_875
2020-04-02 05:06:07,517 [IPC Server handler 2 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:07,542 [IPC Server handler 3 on 43110] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /doShortCircuitReadAfterEvictionTest.01.dat  inodeId 16386 for DFSClient_NONMAPREDUCE_702345733_875
2020-04-02 05:06:07,543 [IPC Server handler 3 on 43110] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /doShortCircuitReadAfterEvictionTest.01.dat with blk_1073741825_1001 block is added to the in-memory file system
2020-04-02 05:06:07,543 [IPC Server handler 3 on 43110] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:36056 for /doShortCircuitReadAfterEvictionTest.01.dat
2020-04-02 05:06:07,543 [IPC Server handler 3 on 43110] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /doShortCircuitReadAfterEvictionTest.01.dat with new block blk_1073741825_1001, current total block count is 1
2020-04-02 05:06:07,578 [DataXceiver for client DFSClient_NONMAPREDUCE_702345733_875 at /127.0.0.1:57162 [Receiving block BP-431206537-172.17.0.14-1585803966232:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-431206537-172.17.0.14-1585803966232:blk_1073741825_1001 src: /127.0.0.1:57162 dest: /127.0.0.1:36056
2020-04-02 05:06:07,655 [PacketResponder: BP-431206537-172.17.0.14-1585803966232:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:moveBlockFiles(885)) - addFinalizedBlock: Moved file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-431206537-172.17.0.14-1585803966232/current/rbw/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-431206537-172.17.0.14-1585803966232/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta and file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-431206537-172.17.0.14-1585803966232/current/rbw/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-431206537-172.17.0.14-1585803966232/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:07,656 [PacketResponder: BP-431206537-172.17.0.14-1585803966232:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57162, dest: /127.0.0.1:36056, bytes: 5242880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_702345733_875, offset: 0, srvID: eed67f08-05c9-4337-be24-6b4ae00f586e, blockid: BP-431206537-172.17.0.14-1585803966232:blk_1073741825_1001, duration(ns): 75069512
2020-04-02 05:06:07,657 [PacketResponder: BP-431206537-172.17.0.14-1585803966232:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-431206537-172.17.0.14-1585803966232:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:07,662 [IPC Server handler 5 on 43110] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3274)) - BLOCK* fsync: /doShortCircuitReadAfterEvictionTest.01.dat for DFSClient_NONMAPREDUCE_702345733_875
2020-04-02 05:06:07,663 [IPC Server handler 5 on 43110] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistBlocks(112)) - persistBlocks: /doShortCircuitReadAfterEvictionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:07,664 [IPC Server handler 5 on 43110] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36056, datanodeUuid=eed67f08-05c9-4337-be24-6b4ae00f586e, infoPort=45361, infoSecurePort=0, ipcPort=41572, storageInfo=lv=-57;cid=testClusterID;nsid=288644598;c=1585803966232) 1 blocks.
2020-04-02 05:06:07,669 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:36056 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:07,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:07,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36056 is added to blk_1073741825_1001 (size=5242880)
2020-04-02 05:06:07,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:36056
2020-04-02 05:06:07,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36056 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:07,670 [IPC Server handler 7 on 43110] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /doShortCircuitReadAfterEvictionTest.01.dat for DFSClient_NONMAPREDUCE_702345733_875
2020-04-02 05:06:07,676 [IPC Server handler 7 on 43110] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /doShortCircuitReadAfterEvictionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:07,676 [IPC Server handler 7 on 43110] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /doShortCircuitReadAfterEvictionTest.01.dat is closed by DFSClient_NONMAPREDUCE_702345733_875
2020-04-02 05:06:07,682 [Thread-279] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadAfterEvictionTest.01.dat is on StorageType: RAM_DISK
2020-04-02 05:06:07,686 [IPC Server handler 8 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,688 [IPC Server handler 9 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,690 [IPC Server handler 1 on 43110] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:07,691 [IPC Server handler 1 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,693 [IPC Server handler 0 on 43110] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:07,697 [IPC Server handler 0 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:0
2020-04-02 05:06:07,703 [Thread-279] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 0
2020-04-02 05:06:08,214 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@1d3e4682] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:saveNextReplica(3108)) - LazyWriter: Start persisting RamDisk block: block pool Id: BP-431206537-172.17.0.14-1585803966232 block id: 1073741825 on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:08,224 [Async RamDisk lazy persist worker  for volume with id DS-485ee963-abaa-44ae-af0e-6b4c83c18198] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:copyBlockFiles(931)) - Copied file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-431206537-172.17.0.14-1585803966232/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta and calculated checksum
2020-04-02 05:06:08,225 [Async RamDisk lazy persist worker  for volume with id DS-485ee963-abaa-44ae-af0e-6b4c83c18198] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:onCompleteLazyPersist(2969)) - LazyWriter: Finish persisting RamDisk block:  block pool Id: BP-431206537-172.17.0.14-1585803966232 block id: 1073741825 to block file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232/current/lazypersist/subdir0/subdir0/blk_1073741825 and meta file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:1
2020-04-02 05:06:08,704 [Thread-279] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 1
2020-04-02 05:06:08,707 [IPC Server handler 6 on 43110] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:08,707 [IPC Server handler 6 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,710 [DataXceiver for client unix:/tmp/socks.1585803966166.-2030442735/TestScrLazyPersistFiles.36056.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_702345733_875, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: 7a5c4fd28bfb365a77272db2745db24f, srvID: eed67f08-05c9-4337-be24-6b4ae00f586e, success: true
2020-04-02 05:06:08,726 [DataXceiver for client unix:/tmp/socks.1585803966166.-2030442735/TestScrLazyPersistFiles.36056.sock [Passing file descriptors for block BP-431206537-172.17.0.14-1585803966232:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: eed67f08-05c9-4337-be24-6b4ae00f586e, success: true
2020-04-02 05:06:08,733 [IPC Server handler 2 on 43110] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:08,734 [IPC Server handler 2 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,858 [Thread-279] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:evictBlocks(3151)) - Evicting block [BlockPoolID=BP-431206537-172.17.0.14-1585803966232; BlockId=1073741825]
2020-04-02 05:06:08,867 [Thread-279] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(382)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232/current/lazypersist/subdir0/subdir0/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:08,868 [Thread-279] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(384)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta
2020-04-02 05:06:08,870 [Thread-279] INFO  datanode.ShortCircuitRegistry (ShortCircuitRegistry.java:processBlockInvalidation(252)) - Block 1073741825_BP-431206537-172.17.0.14-1585803966232 has been invalidated.  Marking short-circuit slots as invalid: Slot(slotIdx=0, shm=RegisteredShm(7a5c4fd28bfb365a77272db2745db24f))
2020-04-02 05:06:08,871 [Thread-279] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadAfterEvictionTest.01.dat is on StorageType: DISK
2020-04-02 05:06:08,871 [IPC Server handler 3 on 43110] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36056, datanodeUuid=eed67f08-05c9-4337-be24-6b4ae00f586e, infoPort=45361, infoSecurePort=0, ipcPort=41572, storageInfo=lv=-57;cid=testClusterID;nsid=288644598;c=1585803966232) 1 blocks.
2020-04-02 05:06:08,872 [IPC Server handler 3 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,873 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:36056 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:08,873 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:08,873 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3248)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:36056
2020-04-02 05:06:08,873 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:36056
2020-04-02 05:06:08,873 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36056 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:08,890 [IPC Server handler 5 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,894 [IPC Server handler 7 on 43110] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:08,894 [IPC Server handler 7 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,897 [IPC Server handler 8 on 43110] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:08,897 [IPC Server handler 8 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,902 [IPC Server handler 9 on 43110] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:08,902 [IPC Server handler 9 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,904 [Thread-279] INFO  shortcircuit.ShortCircuitCache (ShortCircuitCache.java:fetch(754)) - ShortCircuitCache(0x7977971a): got stale replica ShortCircuitReplica{key=1073741825_BP-431206537-172.17.0.14-1585803966232, metaHeader.version=1, metaHeader.checksum=DataChecksum(type=CRC32C, chunkSize=512), ident=0x5647d917, creationTimeMs=689138104}.  Removing this replica from the replicaInfoMap and retrying.
2020-04-02 05:06:08,912 [DataXceiver for client unix:/tmp/socks.1585803966166.-2030442735/TestScrLazyPersistFiles.36056.sock [Passing file descriptors for block BP-431206537-172.17.0.14-1585803966232:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: eed67f08-05c9-4337-be24-6b4ae00f586e, success: true
2020-04-02 05:06:08,915 [IPC Server handler 1 on 43110] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:08,916 [IPC Server handler 1 on 43110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,924 [DataXceiver for client unix:/tmp/socks.1585803966166.-2030442735/TestScrLazyPersistFiles.36056.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:releaseShortCircuitFds(463)) - src: 127.0.0.1, dest: 127.0.0.1, op: RELEASE_SHORT_CIRCUIT_FDS, shmId: 7a5c4fd28bfb365a77272db2745db24f, slotIdx: 0, srvID: eed67f08-05c9-4337-be24-6b4ae00f586e, success: true
List of the keys matching ^RamDisk :
>>>>>>>>jmx name: name=DataNodeActivity-127.0.0.1-36056,service=DataNode
RamDiskBlocksWrite=1
RamDiskBlocksWriteFallback=0
RamDiskBytesWrite=5242880
RamDiskBlocksReadHits=1
RamDiskBlocksEvicted=1
RamDiskBlocksEvictedWithoutRead=0
RamDiskBlocksEvictionWindowMsNumOps=1
RamDiskBlocksEvictionWindowMsAvgTime=1212.0
RamDiskBlocksLazyPersisted=1
RamDiskBlocksDeletedBeforeLazyPersisted=0
RamDiskBytesLazyPersisted=5242880
RamDiskBlocksLazyPersistWindowMsNumOps=1
RamDiskBlocksLazyPersistWindowMsAvgTime=569.0
>>>>>>>>jmx name: name=DataNodeInfo,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState-eed67f08-05c9-4337-be24-6b4ae00f586e,service=DataNode
>>>>>>>>jmx name: name=JvmMetrics-1,service=DataNode
>>>>>>>>jmx name: name=RpcActivityForPort41572,service=DataNode
>>>>>>>>jmx name: name=RpcDetailedActivityForPort41572,service=DataNode
2020-04-02 05:06:09,060 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:09,060 [Thread-279] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41572 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:09,062 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@32952b3c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:09,066 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1ca6f340] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:09,071 [Thread-279] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:09,074 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-485ee963-abaa-44ae-af0e-6b4c83c18198) exiting.
2020-04-02 05:06:09,075 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-78446729-48d4-4d71-b7e2-4764b67bffa7) exiting.
2020-04-02 05:06:09,247 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30d5518b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:09,249 [Thread-279] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4fb38c6c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:09,250 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4fc1e737{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:09,250 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@48e6bf2d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:09,286 [Thread-279] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41572
2020-04-02 05:06:09,322 [BP-431206537-172.17.0.14-1585803966232 heartbeating to localhost/127.0.0.1:43110] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:09,322 [BP-431206537-172.17.0.14-1585803966232 heartbeating to localhost/127.0.0.1:43110] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-431206537-172.17.0.14-1585803966232 (Datanode Uuid eed67f08-05c9-4337-be24-6b4ae00f586e) service to localhost/127.0.0.1:43110
2020-04-02 05:06:09,322 [BP-431206537-172.17.0.14-1585803966232 heartbeating to localhost/127.0.0.1:43110] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-431206537-172.17.0.14-1585803966232 (Datanode Uuid eed67f08-05c9-4337-be24-6b4ae00f586e)
2020-04-02 05:06:09,323 [BP-431206537-172.17.0.14-1585803966232 heartbeating to localhost/127.0.0.1:43110] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-431206537-172.17.0.14-1585803966232
2020-04-02 05:06:09,324 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:09,334 [IPC Server listener on 41572] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41572
2020-04-02 05:06:09,353 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-431206537-172.17.0.14-1585803966232] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,366 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-431206537-172.17.0.14-1585803966232] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,382 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@1d3e4682] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(3203)) - LazyWriter was interrupted, exiting
2020-04-02 05:06:09,384 [Thread-279] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:09,384 [Thread-279] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:09,385 [Thread-279] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:09,385 [Thread-279] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:09,398 [Thread-279] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:09,398 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:09,398 [Thread-279] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:09,399 [Thread-279] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43110 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:09,399 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:09,399 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@166ef95e] DEBUG namenode.LeaseManager (LeaseManager.java:run(536)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:09,400 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@54befce] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:09,400 [Thread-279] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:06:09,401 [Thread-279] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 27 Number of transactions batched in Syncs: 2 Number of syncs: 7 SyncTimes(ms): 1 2 
2020-04-02 05:06:09,402 [Thread-279] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:09,414 [Thread-279] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:09,417 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:09,417 [CacheReplicationMonitor(335510677)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:09,401 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@3f30c5ea] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:09,419 [Thread-279] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43110
2020-04-02 05:06:09,421 [IPC Server listener on 43110] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43110
2020-04-02 05:06:09,433 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:09,434 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:09,434 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@21368a80] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:09,437 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:09,471 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:09,471 [Thread-279] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:09,475 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7305cbf6{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:09,477 [Thread-279] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@16721edf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:09,477 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55deced4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:09,478 [Thread-279] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53716199{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:09,497 [Thread-279] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:09,498 [Thread-279] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:09,499 [Thread-279] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testScrAfterEviction
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testScrAfterEviction
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#tesScrDuringEviction
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:09,523 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:06:09,526 [Thread-372] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
Formatting using clusterid: testClusterID
2020-04-02 05:06:09,528 [Thread-372] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:09,528 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:09,528 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:09,529 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:09,529 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:09,529 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:09,529 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:09,529 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:09,529 [Thread-372] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:09,530 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,530 [Thread-372] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:09,530 [Thread-372] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:09,530 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,530 [Thread-372] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:09,530 [Thread-372] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:09,531 [Thread-372] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:09
2020-04-02 05:06:09,531 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:09,531 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:09,531 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:09,531 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:09,552 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,552 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,553 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:09,554 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,554 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:09,554 [Thread-372] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:09,555 [Thread-372] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:09,555 [Thread-372] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:09,555 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:09,555 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:09,555 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:09,555 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:09,555 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:09,556 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:09,556 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:09,556 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:09,556 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:09,557 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:09,557 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:09,561 [Thread-372] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:09,562 [Thread-372] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:09,562 [Thread-372] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:09,562 [Thread-372] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:09,563 [Thread-372] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:09,563 [Thread-372] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:09,563 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:09,563 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:09,563 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:09,563 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:09,566 [Thread-372] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:09,566 [Thread-372] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:09,566 [Thread-372] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:09,566 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:09,567 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:09,567 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:09,567 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:09,567 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:09,567 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:09,569 [Thread-372] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:09,574 [Thread-372] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:09,582 [Thread-372] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:09,599 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:09,602 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:09,605 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:09,609 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:09,615 [Thread-372] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:09,616 [Thread-372] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:09,621 [Thread-372] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:09,633 [Thread-372] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:09,634 [Thread-372] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:09,643 [Thread-372] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:09,644 [Thread-372] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:09,644 [Thread-372] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
2020-04-02 05:06:09,649 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f30a322] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:09,649 [Thread-372] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:09,650 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:09,651 [Thread-372] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:09,652 [Thread-372] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:09,652 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:09,654 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:09,655 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:09,655 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:09,655 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:09,657 [Thread-372] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:09,657 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:09,658 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42167
2020-04-02 05:06:09,658 [Thread-372] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:09,666 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14cfc875{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:09,667 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@521d4f4f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:09,674 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@627abeb5{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:09,675 [Thread-372] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@20a1a3a4{HTTP/1.1,[http/1.1]}{localhost:42167}
2020-04-02 05:06:09,675 [Thread-372] INFO  server.Server (Server.java:doStart(419)) - Started @22546ms
2020-04-02 05:06:09,676 [Thread-372] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:09,677 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:09,677 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:09,677 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:09,677 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:09,677 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:09,684 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:09,684 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:09,684 [Thread-372] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:09,685 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,685 [Thread-372] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:09,685 [Thread-372] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:09,685 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,685 [Thread-372] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:09,685 [Thread-372] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:09,686 [Thread-372] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:09
2020-04-02 05:06:09,686 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:09,686 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:09,686 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:09,686 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:09,699 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,699 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,700 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:09,700 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:09,700 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:09,700 [Thread-372] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:09,701 [Thread-372] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:09,701 [Thread-372] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:09,701 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:09,701 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:09,701 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:09,701 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:09,701 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:09,701 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:09,701 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:09,702 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:09,702 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:09,702 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:09,702 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:09,708 [Thread-372] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:09,711 [Thread-372] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:09,711 [Thread-372] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:09,711 [Thread-372] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:09,712 [Thread-372] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:09,712 [Thread-372] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:09,712 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:09,712 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:09,713 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:09,713 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:09,715 [Thread-372] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:09,715 [Thread-372] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:09,715 [Thread-372] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:09,715 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:09,716 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:09,716 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:09,716 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:09,716 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:09,716 [Thread-372] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:09,720 [Thread-372] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:09,722 [Thread-372] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:09,723 [Thread-372] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:09,724 [Thread-372] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:09,724 [Thread-372] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:09,724 [Thread-372] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:09,726 [Thread-372] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:09,726 [Thread-372] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:09,726 [Thread-372] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:09,726 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:09,728 [Thread-372] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:09,738 [Thread-372] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:09,738 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 19 msecs
2020-04-02 05:06:09,738 [Thread-372] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:09,739 [Thread-372] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:09,739 [Socket Reader #1 for port 43007] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43007
2020-04-02 05:06:09,781 [Thread-372] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:43007 to access this namenode/service.
2020-04-02 05:06:09,781 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:09,816 [Thread-372] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:09,817 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@60a42a94] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:06:09,818 [Thread-372] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:09,819 [Thread-372] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(607)) - STATE* Safe mode ON. 
The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1 live datanodes to reach the minimum number 1.
Safe mode will be turned off automatically once the thresholds have been reached.
2020-04-02 05:06:09,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:09,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:09,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:09,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:09,826 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:09,826 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-04-02 05:06:09,832 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:09,832 [IPC Server listener on 43007] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43007: starting
2020-04-02 05:06:10,167 [Thread-372] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43007
2020-04-02 05:06:10,190 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:10,190 [Thread-372] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:10,204 [Thread-372] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 14 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:10,207 [Thread-372] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43007 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:10,238 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5e665930] DEBUG namenode.FSNamesystem (FSNamesystem.java:run(4098)) - Namenode is in safemode, skipping scrubbing of corrupted lazy-persist files.
2020-04-02 05:06:10,247 [CacheReplicationMonitor(799937499)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:10,247 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:10,249 [Thread-372] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:10,250 [Thread-372] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:10,298 [Thread-372] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:10,299 [Thread-372] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:10,299 [Thread-372] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:10,299 [Thread-372] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:10,300 [Thread-372] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:06:10,300 [Thread-372] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:10,300 [Thread-372] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:10,301 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:10,301 [Thread-372] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:10,301 [Thread-372] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:verifyCanMlock(348)) - LazyPersistTestCase: fake return true
2020-04-02 05:06:10,301 [Thread-372] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:getMemlockLimit(342)) - LazyPersistTestCase: fake return 9223372036854775807
2020-04-02 05:06:10,302 [Thread-372] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 9223372036854775807
2020-04-02 05:06:10,302 [Thread-372] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37038
2020-04-02 05:06:10,303 [Thread-372] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:10,303 [Thread-372] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:10,303 [Thread-372] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:10,303 [Thread-372] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:10,304 [Thread-372] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585803969523.-635823204/TestScrLazyPersistFiles.37038.sock
2020-04-02 05:06:10,305 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:10,307 [Thread-372] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:10,308 [Thread-372] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:10,309 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:10,320 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:10,321 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:10,321 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:10,323 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:10,324 [Thread-372] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39696
2020-04-02 05:06:10,324 [Thread-372] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:10,353 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77c6e531{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:10,357 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6dd3719d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:10,380 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b0a4fe6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:10,380 [Thread-372] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@10bd46d0{HTTP/1.1,[http/1.1]}{localhost:39696}
2020-04-02 05:06:10,381 [Thread-372] INFO  server.Server (Server.java:doStart(419)) - Started @23252ms
2020-04-02 05:06:10,444 [Thread-372] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41785
2020-04-02 05:06:10,444 [Thread-372] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:10,445 [Thread-372] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:10,445 [Thread-372] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:10,447 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d60246a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:10,447 [Socket Reader #1 for port 39723] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39723
2020-04-02 05:06:10,451 [Thread-372] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39723
2020-04-02 05:06:10,478 [Thread-372] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:10,482 [Thread-372] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:10,484 [Thread-428] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43007 starting to offer service
2020-04-02 05:06:10,502 [IPC Server listener on 39723] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39723: starting
2020-04-02 05:06:10,535 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:10,590 [Thread-372] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39723 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:10,652 [IPC Server handler 0 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:10,653 [Thread-428] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43007
2020-04-02 05:06:10,654 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:10,654 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:10,662 [Thread-428] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:10,666 [Thread-428] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:10,666 [Thread-428] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 956492744. Formatting...
2020-04-02 05:06:10,667 [Thread-428] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d9cdb869-a9ab-4c67-a87c-465a108eb262 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:10,675 [Thread-428] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:10,676 [Thread-428] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 956492744. Formatting...
2020-04-02 05:06:10,676 [Thread-428] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:10,694 [Thread-428] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:10,695 [Thread-428] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:10,695 [Thread-428] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-560778292-172.17.0.14-1585803969569 is not formatted. Formatting ...
2020-04-02 05:06:10,695 [Thread-428] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-560778292-172.17.0.14-1585803969569 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-560778292-172.17.0.14-1585803969569/current
2020-04-02 05:06:10,706 [Thread-428] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:10,707 [Thread-428] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:10,707 [Thread-428] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-560778292-172.17.0.14-1585803969569 is not formatted. Formatting ...
2020-04-02 05:06:10,707 [Thread-428] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-560778292-172.17.0.14-1585803969569 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569/current
2020-04-02 05:06:10,718 [Thread-428] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=956492744;bpid=BP-560778292-172.17.0.14-1585803969569;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=956492744;c=1585803969569;bpid=BP-560778292-172.17.0.14-1585803969569;dnuuid=null
2020-04-02 05:06:10,726 [Thread-428] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 534c8a79-23f2-4c73-98d0-aef8a0c1083d
2020-04-02 05:06:10,737 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d9cdb869-a9ab-4c67-a87c-465a108eb262
2020-04-02 05:06:10,738 [Thread-428] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: RAM_DISK
2020-04-02 05:06:10,741 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1
2020-04-02 05:06:10,749 [Thread-428] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:10,754 [Thread-428] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:10,764 [IPC Server handler 2 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:10,776 [Thread-428] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:10,778 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:10,794 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:10,793 [Thread-428] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:10,794 [Thread-428] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:10,794 [Thread-428] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:10,819 [Thread-428] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:10,822 [Thread-445] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-560778292-172.17.0.14-1585803969569 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:10,824 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-560778292-172.17.0.14-1585803969569 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:10,900 [IPC Server handler 4 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:10,901 [Thread-445] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-560778292-172.17.0.14-1585803969569 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 79ms
2020-04-02 05:06:10,901 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:10,902 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:10,910 [Thread-446] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-560778292-172.17.0.14-1585803969569 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 86ms
2020-04-02 05:06:10,911 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-560778292-172.17.0.14-1585803969569: 91ms
2020-04-02 05:06:10,914 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-560778292-172.17.0.14-1585803969569 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:10,914 [Thread-449] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-560778292-172.17.0.14-1585803969569/current/replicas doesn't exist 
2020-04-02 05:06:10,914 [Thread-450] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-560778292-172.17.0.14-1585803969569 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:10,914 [Thread-450] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569/current/replicas doesn't exist 
2020-04-02 05:06:10,918 [Thread-450] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-560778292-172.17.0.14-1585803969569 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-04-02 05:06:10,918 [Thread-449] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-560778292-172.17.0.14-1585803969569 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 4ms
2020-04-02 05:06:10,919 [Thread-428] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-560778292-172.17.0.14-1585803969569: 8ms
2020-04-02 05:06:10,920 [Thread-428] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:23 AM with interval of 21600000ms
2020-04-02 05:06:10,920 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-560778292-172.17.0.14-1585803969569 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:10,938 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1): finished scanning block pool BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:10,938 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-04-02 05:06:10,942 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-560778292-172.17.0.14-1585803969569 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:10,942 [BP-560778292-172.17.0.14-1585803969569 heartbeating to localhost/127.0.0.1:43007] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-560778292-172.17.0.14-1585803969569 (Datanode Uuid 534c8a79-23f2-4c73-98d0-aef8a0c1083d) service to localhost/127.0.0.1:43007 beginning handshake with NN
2020-04-02 05:06:10,942 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d9cdb869-a9ab-4c67-a87c-465a108eb262): finished scanning block pool BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:10,943 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d9cdb869-a9ab-4c67-a87c-465a108eb262): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-04-02 05:06:10,945 [IPC Server handler 5 on 43007] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37038, datanodeUuid=534c8a79-23f2-4c73-98d0-aef8a0c1083d, infoPort=41785, infoSecurePort=0, ipcPort=39723, storageInfo=lv=-57;cid=testClusterID;nsid=956492744;c=1585803969569) storage 534c8a79-23f2-4c73-98d0-aef8a0c1083d
2020-04-02 05:06:10,945 [IPC Server handler 5 on 43007] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37038
2020-04-02 05:06:10,946 [IPC Server handler 5 on 43007] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 534c8a79-23f2-4c73-98d0-aef8a0c1083d (127.0.0.1:37038).
2020-04-02 05:06:10,948 [IPC Server handler 5 on 43007] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(391)) - STATE* Safe mode is OFF
2020-04-02 05:06:10,948 [IPC Server handler 5 on 43007] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 1 secs
2020-04-02 05:06:10,948 [IPC Server handler 5 on 43007] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 1 datanodes
2020-04-02 05:06:10,956 [IPC Server handler 5 on 43007] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:10,959 [BP-560778292-172.17.0.14-1585803969569 heartbeating to localhost/127.0.0.1:43007] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-560778292-172.17.0.14-1585803969569 (Datanode Uuid 534c8a79-23f2-4c73-98d0-aef8a0c1083d) service to localhost/127.0.0.1:43007 successfully registered with NN
2020-04-02 05:06:10,960 [BP-560778292-172.17.0.14-1585803969569 heartbeating to localhost/127.0.0.1:43007] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43007 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:10,975 [IPC Server handler 6 on 43007] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d9cdb869-a9ab-4c67-a87c-465a108eb262 for DN 127.0.0.1:37038
2020-04-02 05:06:10,975 [IPC Server handler 6 on 43007] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1 for DN 127.0.0.1:37038
2020-04-02 05:06:10,982 [IPC Server handler 7 on 43007] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37038, datanodeUuid=534c8a79-23f2-4c73-98d0-aef8a0c1083d, infoPort=41785, infoSecurePort=0, ipcPort=39723, storageInfo=lv=-57;cid=testClusterID;nsid=956492744;c=1585803969569), reports.length=2
2020-04-02 05:06:10,982 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5ce7bdcc051f3124: Processing first storage report for DS-d9cdb869-a9ab-4c67-a87c-465a108eb262 from datanode 534c8a79-23f2-4c73-98d0-aef8a0c1083d
2020-04-02 05:06:10,982 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5ce7bdcc051f3124: from storage DS-d9cdb869-a9ab-4c67-a87c-465a108eb262 node DatanodeRegistration(127.0.0.1:37038, datanodeUuid=534c8a79-23f2-4c73-98d0-aef8a0c1083d, infoPort=41785, infoSecurePort=0, ipcPort=39723, storageInfo=lv=-57;cid=testClusterID;nsid=956492744;c=1585803969569), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:10,982 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5ce7bdcc051f3124: Processing first storage report for DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1 from datanode 534c8a79-23f2-4c73-98d0-aef8a0c1083d
2020-04-02 05:06:10,982 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5ce7bdcc051f3124: from storage DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1 node DatanodeRegistration(127.0.0.1:37038, datanodeUuid=534c8a79-23f2-4c73-98d0-aef8a0c1083d, infoPort=41785, infoSecurePort=0, ipcPort=39723, storageInfo=lv=-57;cid=testClusterID;nsid=956492744;c=1585803969569), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:10,982 [IPC Server handler 7 on 43007] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x5ce7bdcc051f3124
2020-04-02 05:06:10,983 [BP-560778292-172.17.0.14-1585803969569 heartbeating to localhost/127.0.0.1:43007] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5ce7bdcc051f3124,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:10,983 [BP-560778292-172.17.0.14-1585803969569 heartbeating to localhost/127.0.0.1:43007] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:10,984 [IPC Server handler 8 on 43007] DEBUG BlockStateChange (NameNodeRpcServer.java:cacheReport(1559)) - *BLOCK* NameNode.cacheReport: from DatanodeRegistration(127.0.0.1:37038, datanodeUuid=534c8a79-23f2-4c73-98d0-aef8a0c1083d, infoPort=41785, infoSecurePort=0, ipcPort=39723, storageInfo=lv=-57;cid=testClusterID;nsid=956492744;c=1585803969569) 0 blocks
2020-04-02 05:06:11,007 [IPC Server handler 9 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:11,010 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:11,011 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [RAM_DISK]DS-d9cdb869-a9ab-4c67-a87c-465a108eb262
2020-04-02 05:06:11,011 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [DISK]DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1
2020-04-02 05:06:11,114 [IPC Server handler 1 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:11,117 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
init: server=localhost;port=;service=DataNode;localVMUrl=null

Domains:
	Domain = Hadoop
	Domain = JMImplementation
	Domain = com.sun.management
	Domain = java.lang
	Domain = java.nio
	Domain = java.util.logging

MBeanServer default domain = DefaultDomain

MBean count = 49

Query MBeanServer MBeans:
Hadoop service: Hadoop:service=DataNode,name=DataNodeActivity-127.0.0.1-37038
Hadoop service: Hadoop:service=DataNode,name=DataNodeInfo
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState-534c8a79-23f2-4c73-98d0-aef8a0c1083d
Hadoop service: Hadoop:service=DataNode,name=JvmMetrics-1
Hadoop service: Hadoop:service=DataNode,name=RpcActivityForPort39723
Hadoop service: Hadoop:service=DataNode,name=RpcDetailedActivityForPort39723
2020-04-02 05:06:11,119 [Thread-372] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:startUpCluster(326)) - Cluster startup complete
2020-04-02 05:06:11,120 [IPC Server handler 0 on 43007] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /tesScrDuringEviction.01.dat for DFSClient_NONMAPREDUCE_-1863106212_1157 at 127.0.0.1
2020-04-02 05:06:11,120 [IPC Server handler 0 on 43007] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/tesScrDuringEviction.01.dat, holder=DFSClient_NONMAPREDUCE_-1863106212_1157, clientMachine=127.0.0.1, createParent=true, replication=1, createFlag=[CREATE, LAZY_PERSIST], blockSize=5242880, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:06:11,121 [IPC Server handler 0 on 43007] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: tesScrDuringEviction.01.dat is added
2020-04-02 05:06:11,123 [IPC Server handler 0 on 43007] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /tesScrDuringEviction.01.dat inode 16386 DFSClient_NONMAPREDUCE_-1863106212_1157
2020-04-02 05:06:11,124 [IPC Server handler 0 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tesScrDuringEviction.01.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:11,162 [IPC Server handler 2 on 43007] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /tesScrDuringEviction.01.dat  inodeId 16386 for DFSClient_NONMAPREDUCE_-1863106212_1157
2020-04-02 05:06:11,163 [IPC Server handler 2 on 43007] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /tesScrDuringEviction.01.dat with blk_1073741825_1001 block is added to the in-memory file system
2020-04-02 05:06:11,163 [IPC Server handler 2 on 43007] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:37038 for /tesScrDuringEviction.01.dat
2020-04-02 05:06:11,163 [IPC Server handler 2 on 43007] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /tesScrDuringEviction.01.dat with new block blk_1073741825_1001, current total block count is 1
2020-04-02 05:06:11,186 [DataXceiver for client DFSClient_NONMAPREDUCE_-1863106212_1157 at /127.0.0.1:39398 [Receiving block BP-560778292-172.17.0.14-1585803969569:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-560778292-172.17.0.14-1585803969569:blk_1073741825_1001 src: /127.0.0.1:39398 dest: /127.0.0.1:37038
2020-04-02 05:06:11,299 [PacketResponder: BP-560778292-172.17.0.14-1585803969569:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:moveBlockFiles(885)) - addFinalizedBlock: Moved file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-560778292-172.17.0.14-1585803969569/current/rbw/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-560778292-172.17.0.14-1585803969569/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta and file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-560778292-172.17.0.14-1585803969569/current/rbw/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-560778292-172.17.0.14-1585803969569/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:11,300 [PacketResponder: BP-560778292-172.17.0.14-1585803969569:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39398, dest: /127.0.0.1:37038, bytes: 5242880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1863106212_1157, offset: 0, srvID: 534c8a79-23f2-4c73-98d0-aef8a0c1083d, blockid: BP-560778292-172.17.0.14-1585803969569:blk_1073741825_1001, duration(ns): 82146239
2020-04-02 05:06:11,300 [PacketResponder: BP-560778292-172.17.0.14-1585803969569:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-560778292-172.17.0.14-1585803969569:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:11,306 [IPC Server handler 5 on 43007] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37038, datanodeUuid=534c8a79-23f2-4c73-98d0-aef8a0c1083d, infoPort=41785, infoSecurePort=0, ipcPort=39723, storageInfo=lv=-57;cid=testClusterID;nsid=956492744;c=1585803969569) 1 blocks.
2020-04-02 05:06:11,318 [IPC Server handler 6 on 43007] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3274)) - BLOCK* fsync: /tesScrDuringEviction.01.dat for DFSClient_NONMAPREDUCE_-1863106212_1157
2020-04-02 05:06:11,319 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:37038 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:11,319 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:11,319 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37038 is added to blk_1073741825_1001 (size=0)
2020-04-02 05:06:11,319 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:37038
2020-04-02 05:06:11,319 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37038 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:11,320 [IPC Server handler 6 on 43007] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistBlocks(112)) - persistBlocks: /tesScrDuringEviction.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:11,326 [IPC Server handler 7 on 43007] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /tesScrDuringEviction.01.dat for DFSClient_NONMAPREDUCE_-1863106212_1157
2020-04-02 05:06:11,328 [IPC Server handler 7 on 43007] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /tesScrDuringEviction.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:11,328 [IPC Server handler 7 on 43007] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tesScrDuringEviction.01.dat is closed by DFSClient_NONMAPREDUCE_-1863106212_1157
2020-04-02 05:06:11,329 [Thread-372] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /tesScrDuringEviction.01.dat is on StorageType: RAM_DISK
2020-04-02 05:06:11,331 [IPC Server handler 8 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tesScrDuringEviction.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:11,339 [IPC Server handler 9 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tesScrDuringEviction.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:11,343 [IPC Server handler 3 on 43007] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:11,343 [IPC Server handler 3 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tesScrDuringEviction.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:11,346 [IPC Server handler 1 on 43007] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:11,346 [IPC Server handler 1 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tesScrDuringEviction.01.dat	dst=null	perm=null	proto=rpc
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:0
2020-04-02 05:06:11,353 [Thread-372] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 0
2020-04-02 05:06:11,755 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@325c6094] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:saveNextReplica(3108)) - LazyWriter: Start persisting RamDisk block: block pool Id: BP-560778292-172.17.0.14-1585803969569 block id: 1073741825 on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:11,765 [Async RamDisk lazy persist worker  for volume with id DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:copyBlockFiles(931)) - Copied file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-560778292-172.17.0.14-1585803969569/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta and calculated checksum
2020-04-02 05:06:11,765 [Async RamDisk lazy persist worker  for volume with id DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:onCompleteLazyPersist(2969)) - LazyWriter: Finish persisting RamDisk block:  block pool Id: BP-560778292-172.17.0.14-1585803969569 block id: 1073741825 to block file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569/current/lazypersist/subdir0/subdir0/blk_1073741825 and meta file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:1
2020-04-02 05:06:12,354 [Thread-372] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 1
2020-04-02 05:06:12,356 [IPC Server handler 0 on 43007] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:12,357 [IPC Server handler 0 on 43007] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tesScrDuringEviction.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:12,359 [DataXceiver for client unix:/tmp/socks.1585803969523.-635823204/TestScrLazyPersistFiles.37038.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-1863106212_1157, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: f365c1d8746c2ee67e57a205a40b85f5, srvID: 534c8a79-23f2-4c73-98d0-aef8a0c1083d, success: true
2020-04-02 05:06:12,362 [DataXceiver for client unix:/tmp/socks.1585803969523.-635823204/TestScrLazyPersistFiles.37038.sock [Passing file descriptors for block BP-560778292-172.17.0.14-1585803969569:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 534c8a79-23f2-4c73-98d0-aef8a0c1083d, success: true
2020-04-02 05:06:12,367 [Thread-372] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:evictBlocks(3151)) - Evicting block [BlockPoolID=BP-560778292-172.17.0.14-1585803969569; BlockId=1073741825]
2020-04-02 05:06:12,375 [Thread-372] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(382)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569/current/lazypersist/subdir0/subdir0/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:12,375 [Thread-372] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(384)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta
2020-04-02 05:06:12,380 [Thread-372] INFO  datanode.ShortCircuitRegistry (ShortCircuitRegistry.java:processBlockInvalidation(252)) - Block 1073741825_BP-560778292-172.17.0.14-1585803969569 has been invalidated.  Marking short-circuit slots as invalid: Slot(slotIdx=0, shm=RegisteredShm(f365c1d8746c2ee67e57a205a40b85f5))
2020-04-02 05:06:12,381 [Thread-372] INFO  shortcircuit.ShortCircuitCache (ShortCircuitCache.java:fetch(754)) - ShortCircuitCache(0x245f881c): got stale replica ShortCircuitReplica{key=1073741825_BP-560778292-172.17.0.14-1585803969569, metaHeader.version=1, metaHeader.checksum=DataChecksum(type=CRC32C, chunkSize=512), ident=0x35d02110, creationTimeMs=689141740}.  Removing this replica from the replicaInfoMap and retrying.
2020-04-02 05:06:12,385 [DataXceiver for client unix:/tmp/socks.1585803969523.-635823204/TestScrLazyPersistFiles.37038.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:releaseShortCircuitFds(463)) - src: 127.0.0.1, dest: 127.0.0.1, op: RELEASE_SHORT_CIRCUIT_FDS, shmId: f365c1d8746c2ee67e57a205a40b85f5, slotIdx: 0, srvID: 534c8a79-23f2-4c73-98d0-aef8a0c1083d, success: true
2020-04-02 05:06:12,389 [IPC Server handler 2 on 43007] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37038, datanodeUuid=534c8a79-23f2-4c73-98d0-aef8a0c1083d, infoPort=41785, infoSecurePort=0, ipcPort=39723, storageInfo=lv=-57;cid=testClusterID;nsid=956492744;c=1585803969569) 1 blocks.
2020-04-02 05:06:12,389 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:37038 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:12,389 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:12,389 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3248)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:37038
2020-04-02 05:06:12,390 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:37038
2020-04-02 05:06:12,390 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37038 receiving: 0, received: 1, deleted: 0
List of the keys matching ^RamDisk :
>>>>>>>>jmx name: name=DataNodeActivity-127.0.0.1-37038,service=DataNode
RamDiskBlocksWrite=1
RamDiskBlocksWriteFallback=0
RamDiskBytesWrite=5242880
RamDiskBlocksReadHits=0
RamDiskBlocksEvicted=0
RamDiskBlocksEvictedWithoutRead=0
RamDiskBlocksEvictionWindowMsNumOps=0
RamDiskBlocksEvictionWindowMsAvgTime=0.0
RamDiskBlocksLazyPersisted=1
RamDiskBlocksDeletedBeforeLazyPersisted=0
RamDiskBytesLazyPersisted=5242880
RamDiskBlocksLazyPersistWindowMsNumOps=1
RamDiskBlocksLazyPersistWindowMsAvgTime=465.0
>>>>>>>>jmx name: name=DataNodeInfo,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,service=DataNode
2020-04-02 05:06:12,397 [DataXceiver for client unix:/tmp/socks.1585803969523.-635823204/TestScrLazyPersistFiles.37038.sock [Passing file descriptors for block BP-560778292-172.17.0.14-1585803969569:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 534c8a79-23f2-4c73-98d0-aef8a0c1083d, success: true
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState-534c8a79-23f2-4c73-98d0-aef8a0c1083d,service=DataNode
>>>>>>>>jmx name: name=JvmMetrics-1,service=DataNode
>>>>>>>>jmx name: name=RpcActivityForPort39723,service=DataNode
>>>>>>>>jmx name: name=RpcDetailedActivityForPort39723,service=DataNode
2020-04-02 05:06:12,406 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:12,406 [Thread-372] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39723 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:12,407 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@247e0db3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:12,407 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@73cae018] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:12,417 [Thread-372] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:12,418 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d9cdb869-a9ab-4c67-a87c-465a108eb262) exiting.
2020-04-02 05:06:12,425 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e8bd18c0-f85f-411c-b776-b3ebd8bf8dd1) exiting.
2020-04-02 05:06:12,480 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b0a4fe6{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:12,482 [Thread-372] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@10bd46d0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:12,483 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6dd3719d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:12,483 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77c6e531{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:12,497 [Thread-372] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39723
2020-04-02 05:06:12,531 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:12,531 [BP-560778292-172.17.0.14-1585803969569 heartbeating to localhost/127.0.0.1:43007] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:12,531 [BP-560778292-172.17.0.14-1585803969569 heartbeating to localhost/127.0.0.1:43007] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-560778292-172.17.0.14-1585803969569 (Datanode Uuid 534c8a79-23f2-4c73-98d0-aef8a0c1083d) service to localhost/127.0.0.1:43007
2020-04-02 05:06:12,531 [BP-560778292-172.17.0.14-1585803969569 heartbeating to localhost/127.0.0.1:43007] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-560778292-172.17.0.14-1585803969569 (Datanode Uuid 534c8a79-23f2-4c73-98d0-aef8a0c1083d)
2020-04-02 05:06:12,531 [BP-560778292-172.17.0.14-1585803969569 heartbeating to localhost/127.0.0.1:43007] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-560778292-172.17.0.14-1585803969569
2020-04-02 05:06:12,538 [IPC Server listener on 39723] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39723
2020-04-02 05:06:12,574 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-560778292-172.17.0.14-1585803969569] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:12,649 [Thread-372] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:12,649 [Thread-372] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:12,649 [Thread-372] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:12,649 [Thread-372] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:12,654 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-560778292-172.17.0.14-1585803969569] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:12,654 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@325c6094] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(3203)) - LazyWriter was interrupted, exiting
2020-04-02 05:06:12,657 [Thread-372] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:12,666 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:12,666 [Thread-372] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:12,666 [Thread-372] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43007 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:12,666 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:12,669 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@7aeaccc0] DEBUG namenode.LeaseManager (LeaseManager.java:run(536)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:12,682 [Thread-372] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:06:12,682 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@112cc6ab] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:12,683 [Thread-372] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 2 Number of syncs: 7 SyncTimes(ms): 2 1 
2020-04-02 05:06:12,684 [Thread-372] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:12,684 [Thread-372] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:12,684 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:12,685 [CacheReplicationMonitor(799937499)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:12,689 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5e665930] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:12,686 [Thread-372] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43007
2020-04-02 05:06:12,692 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:12,696 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:12,693 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:12,693 [IPC Server listener on 43007] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43007
2020-04-02 05:06:12,701 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@60a42a94] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:12,722 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:12,723 [Thread-372] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:12,724 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@627abeb5{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:12,734 [Thread-372] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@20a1a3a4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:12,735 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@521d4f4f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:12,735 [Thread-372] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14cfc875{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:12,749 [Thread-372] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:12,751 [Thread-372] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:12,751 [Thread-372] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#tesScrDuringEviction
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#tesScrDuringEviction
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testLegacyScrAfterEviction
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:12,793 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:06:12,798 [Thread-468] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
Formatting using clusterid: testClusterID
2020-04-02 05:06:12,807 [Thread-468] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:12,807 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:12,808 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:12,808 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:12,808 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:12,808 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:12,808 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:12,808 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:12,808 [Thread-468] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:12,809 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,809 [Thread-468] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:12,809 [Thread-468] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:12,809 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,809 [Thread-468] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:12,809 [Thread-468] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:12,809 [Thread-468] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:12
2020-04-02 05:06:12,810 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:12,810 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,810 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:12,810 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:12,816 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,816 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,816 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:12,816 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,817 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:12,817 [Thread-468] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:12,817 [Thread-468] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:12,817 [Thread-468] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:12,817 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:12,817 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:12,817 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:12,817 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:12,817 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:12,817 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:12,818 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:12,834 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:12,835 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,838 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:12,838 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:12,840 [Thread-468] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:12,840 [Thread-468] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:12,840 [Thread-468] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:12,840 [Thread-468] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:12,841 [Thread-468] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:12,841 [Thread-468] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:12,841 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:12,841 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,841 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:12,841 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:12,846 [Thread-468] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:12,846 [Thread-468] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:12,847 [Thread-468] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:12,847 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:12,847 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:12,847 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:12,847 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,848 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:12,848 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:12,849 [Thread-468] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:12,857 [Thread-468] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:12,860 [Thread-468] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:12,875 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:12,875 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:12,882 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:12,892 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:12,904 [Thread-468] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:12,905 [Thread-468] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:12,912 [Thread-468] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:12,915 [Thread-468] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:12,915 [Thread-468] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:12,916 [Thread-468] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:12,916 [Thread-468] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:12,917 [Thread-468] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
2020-04-02 05:06:12,922 [Thread-468] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:12,922 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:12,922 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@26240b8b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:12,924 [Thread-468] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:12,925 [Thread-468] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:12,926 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:12,927 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:12,927 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:12,928 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:12,932 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:12,935 [Thread-468] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:12,935 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:12,936 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40364
2020-04-02 05:06:12,937 [Thread-468] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:12,945 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3861ee3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:12,954 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@747859e8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:12,967 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7e401eac{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:12,968 [Thread-468] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@163ac09f{HTTP/1.1,[http/1.1]}{localhost:40364}
2020-04-02 05:06:12,968 [Thread-468] INFO  server.Server (Server.java:doStart(419)) - Started @25839ms
2020-04-02 05:06:12,973 [Thread-468] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:12,977 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:12,977 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:12,977 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:12,977 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:12,977 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:12,977 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:12,978 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:12,990 [Thread-468] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:12,990 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,991 [Thread-468] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:12,991 [Thread-468] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:12,991 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,991 [Thread-468] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:12,992 [Thread-468] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:12,993 [Thread-468] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:12
2020-04-02 05:06:12,993 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:12,993 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,993 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:12,994 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:12,998 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,999 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,999 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:12,999 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:12,999 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:13,000 [Thread-468] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:13,000 [Thread-468] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:13,000 [Thread-468] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:13,000 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:13,000 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:13,001 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:13,001 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:13,001 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:13,001 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:13,001 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:13,022 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:13,022 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:13,022 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:13,022 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:13,024 [Thread-468] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:13,024 [Thread-468] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:13,024 [Thread-468] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:13,024 [Thread-468] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:13,024 [Thread-468] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:13,025 [Thread-468] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:13,025 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:13,025 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:13,025 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:13,025 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:13,030 [Thread-468] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:13,030 [Thread-468] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:13,030 [Thread-468] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:13,030 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:13,030 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:13,031 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:13,031 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:13,031 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:13,031 [Thread-468] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:13,039 [Thread-468] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:13,049 [Thread-468] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:13,051 [Thread-468] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:13,052 [Thread-468] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:13,052 [Thread-468] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:13,052 [Thread-468] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:13,053 [Thread-468] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:13,054 [Thread-468] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:13,054 [Thread-468] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:13,054 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:13,064 [Thread-468] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:13,090 [Thread-468] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:13,090 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 59 msecs
2020-04-02 05:06:13,092 [Thread-468] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:13,092 [Thread-468] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:13,093 [Socket Reader #1 for port 36329] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36329
2020-04-02 05:06:13,102 [Thread-468] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36329 to access this namenode/service.
2020-04-02 05:06:13,103 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:13,129 [Thread-468] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:13,131 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@1cd25551] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:06:13,135 [Thread-468] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:13,137 [Thread-468] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(607)) - STATE* Safe mode ON. 
The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1 live datanodes to reach the minimum number 1.
Safe mode will be turned off automatically once the thresholds have been reached.
2020-04-02 05:06:13,153 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:13,153 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:13,153 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:13,153 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:13,154 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:13,154 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-02 05:06:13,161 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:13,174 [IPC Server listener on 36329] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36329: starting
2020-04-02 05:06:13,190 [Thread-468] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36329
2020-04-02 05:06:13,191 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:13,191 [Thread-468] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:13,192 [Thread-468] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:13,193 [Thread-468] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36329 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,194 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@70311882] DEBUG namenode.FSNamesystem (FSNamesystem.java:run(4098)) - Namenode is in safemode, skipping scrubbing of corrupted lazy-persist files.
2020-04-02 05:06:13,197 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:13,199 [Thread-468] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:13,205 [Thread-468] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:13,232 [CacheReplicationMonitor(1726883190)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:13,234 [Thread-468] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:13,234 [Thread-468] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:13,234 [Thread-468] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,234 [Thread-468] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:13,235 [Thread-468] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:06:13,235 [Thread-468] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:13,235 [Thread-468] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,235 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:13,235 [Thread-468] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:13,235 [Thread-468] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:verifyCanMlock(348)) - LazyPersistTestCase: fake return true
2020-04-02 05:06:13,235 [Thread-468] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:getMemlockLimit(342)) - LazyPersistTestCase: fake return 9223372036854775807
2020-04-02 05:06:13,235 [Thread-468] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 9223372036854775807
2020-04-02 05:06:13,236 [Thread-468] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35573
2020-04-02 05:06:13,236 [Thread-468] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:13,236 [Thread-468] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:13,241 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,242 [Thread-468] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:13,243 [Thread-468] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:13,243 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,244 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:13,245 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:13,245 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:13,245 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:13,246 [Thread-468] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38879
2020-04-02 05:06:13,246 [Thread-468] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:13,247 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6546284e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:13,248 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53081e98{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:13,277 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b67fccd{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:13,277 [Thread-468] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@66eeef58{HTTP/1.1,[http/1.1]}{localhost:38879}
2020-04-02 05:06:13,277 [Thread-468] INFO  server.Server (Server.java:doStart(419)) - Started @26148ms
2020-04-02 05:06:13,308 [Thread-468] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46818
2020-04-02 05:06:13,312 [Thread-468] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:13,312 [Thread-468] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:13,313 [Thread-468] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:13,313 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@312ccca1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:13,314 [Socket Reader #1 for port 39848] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39848
2020-04-02 05:06:13,317 [Thread-468] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39848
2020-04-02 05:06:13,321 [Thread-468] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:13,325 [Thread-468] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:13,326 [Thread-523] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36329 starting to offer service
2020-04-02 05:06:13,327 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:13,327 [IPC Server listener on 39848] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39848: starting
2020-04-02 05:06:13,329 [Thread-468] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39848 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,403 [Thread-523] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36329
2020-04-02 05:06:13,404 [IPC Server handler 0 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,405 [Thread-523] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:13,406 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:13,406 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:13,407 [Thread-523] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:13,407 [Thread-523] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 516705746. Formatting...
2020-04-02 05:06:13,407 [Thread-523] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-15386d3e-2b1a-40fc-9dbd-b3923cfe2de0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:13,413 [Thread-523] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:13,414 [Thread-523] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 516705746. Formatting...
2020-04-02 05:06:13,414 [Thread-523] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-56549336-0ec7-4099-a31d-d89a732ed947 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:13,442 [Thread-523] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:13,443 [Thread-523] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:13,443 [Thread-523] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1967904765-172.17.0.14-1585803972849 is not formatted. Formatting ...
2020-04-02 05:06:13,443 [Thread-523] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1967904765-172.17.0.14-1585803972849 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1967904765-172.17.0.14-1585803972849/current
2020-04-02 05:06:13,478 [Thread-523] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:13,479 [Thread-523] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:13,480 [Thread-523] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1967904765-172.17.0.14-1585803972849 is not formatted. Formatting ...
2020-04-02 05:06:13,481 [Thread-523] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1967904765-172.17.0.14-1585803972849 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849/current
2020-04-02 05:06:13,488 [Thread-523] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=516705746;bpid=BP-1967904765-172.17.0.14-1585803972849;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=516705746;c=1585803972849;bpid=BP-1967904765-172.17.0.14-1585803972849;dnuuid=null
2020-04-02 05:06:13,490 [Thread-523] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 6ae325e8-eec1-436e-8a16-79dbd320027f
2020-04-02 05:06:13,497 [Thread-523] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-15386d3e-2b1a-40fc-9dbd-b3923cfe2de0
2020-04-02 05:06:13,498 [Thread-523] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: RAM_DISK
2020-04-02 05:06:13,499 [Thread-523] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-56549336-0ec7-4099-a31d-d89a732ed947
2020-04-02 05:06:13,499 [Thread-523] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:13,502 [Thread-523] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:13,503 [Thread-523] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:13,503 [Thread-523] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:13,503 [Thread-523] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:13,504 [Thread-523] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:13,522 [Thread-523] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:13,523 [Thread-540] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1967904765-172.17.0.14-1585803972849 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:13,523 [Thread-541] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1967904765-172.17.0.14-1585803972849 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:13,535 [IPC Server handler 3 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,535 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:13,536 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:13,568 [Thread-540] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1967904765-172.17.0.14-1585803972849 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 45ms
2020-04-02 05:06:13,594 [Thread-541] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1967904765-172.17.0.14-1585803972849 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 70ms
2020-04-02 05:06:13,596 [Thread-523] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1967904765-172.17.0.14-1585803972849: 73ms
2020-04-02 05:06:13,597 [Thread-544] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1967904765-172.17.0.14-1585803972849 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:13,597 [Thread-544] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1967904765-172.17.0.14-1585803972849/current/replicas doesn't exist 
2020-04-02 05:06:13,598 [Thread-545] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1967904765-172.17.0.14-1585803972849 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:13,598 [Thread-545] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849/current/replicas doesn't exist 
2020-04-02 05:06:13,601 [Thread-544] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1967904765-172.17.0.14-1585803972849 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 5ms
2020-04-02 05:06:13,602 [Thread-545] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1967904765-172.17.0.14-1585803972849 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-04-02 05:06:13,602 [Thread-523] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1967904765-172.17.0.14-1585803972849: 5ms
2020-04-02 05:06:13,603 [Thread-523] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:33 AM with interval of 21600000ms
2020-04-02 05:06:13,603 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1967904765-172.17.0.14-1585803972849 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:13,603 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1967904765-172.17.0.14-1585803972849 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:13,603 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-56549336-0ec7-4099-a31d-d89a732ed947): finished scanning block pool BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:13,603 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-15386d3e-2b1a-40fc-9dbd-b3923cfe2de0): finished scanning block pool BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:13,604 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-56549336-0ec7-4099-a31d-d89a732ed947): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:06:13,605 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-15386d3e-2b1a-40fc-9dbd-b3923cfe2de0): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:06:13,608 [BP-1967904765-172.17.0.14-1585803972849 heartbeating to localhost/127.0.0.1:36329] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1967904765-172.17.0.14-1585803972849 (Datanode Uuid 6ae325e8-eec1-436e-8a16-79dbd320027f) service to localhost/127.0.0.1:36329 beginning handshake with NN
2020-04-02 05:06:13,609 [IPC Server handler 4 on 36329] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35573, datanodeUuid=6ae325e8-eec1-436e-8a16-79dbd320027f, infoPort=46818, infoSecurePort=0, ipcPort=39848, storageInfo=lv=-57;cid=testClusterID;nsid=516705746;c=1585803972849) storage 6ae325e8-eec1-436e-8a16-79dbd320027f
2020-04-02 05:06:13,609 [IPC Server handler 4 on 36329] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35573
2020-04-02 05:06:13,610 [IPC Server handler 4 on 36329] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6ae325e8-eec1-436e-8a16-79dbd320027f (127.0.0.1:35573).
2020-04-02 05:06:13,614 [IPC Server handler 4 on 36329] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(391)) - STATE* Safe mode is OFF
2020-04-02 05:06:13,614 [IPC Server handler 4 on 36329] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:13,620 [IPC Server handler 4 on 36329] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 1 datanodes
2020-04-02 05:06:13,621 [IPC Server handler 4 on 36329] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:13,626 [BP-1967904765-172.17.0.14-1585803972849 heartbeating to localhost/127.0.0.1:36329] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1967904765-172.17.0.14-1585803972849 (Datanode Uuid 6ae325e8-eec1-436e-8a16-79dbd320027f) service to localhost/127.0.0.1:36329 successfully registered with NN
2020-04-02 05:06:13,626 [BP-1967904765-172.17.0.14-1585803972849 heartbeating to localhost/127.0.0.1:36329] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36329 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:13,635 [IPC Server handler 5 on 36329] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-15386d3e-2b1a-40fc-9dbd-b3923cfe2de0 for DN 127.0.0.1:35573
2020-04-02 05:06:13,635 [IPC Server handler 5 on 36329] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-56549336-0ec7-4099-a31d-d89a732ed947 for DN 127.0.0.1:35573
2020-04-02 05:06:13,637 [IPC Server handler 6 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,637 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:13,638 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [RAM_DISK]DS-15386d3e-2b1a-40fc-9dbd-b3923cfe2de0
2020-04-02 05:06:13,638 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [DISK]DS-56549336-0ec7-4099-a31d-d89a732ed947
2020-04-02 05:06:13,651 [IPC Server handler 7 on 36329] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35573, datanodeUuid=6ae325e8-eec1-436e-8a16-79dbd320027f, infoPort=46818, infoSecurePort=0, ipcPort=39848, storageInfo=lv=-57;cid=testClusterID;nsid=516705746;c=1585803972849), reports.length=2
2020-04-02 05:06:13,651 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xdd22f7ffdc75e745: Processing first storage report for DS-15386d3e-2b1a-40fc-9dbd-b3923cfe2de0 from datanode 6ae325e8-eec1-436e-8a16-79dbd320027f
2020-04-02 05:06:13,651 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xdd22f7ffdc75e745: from storage DS-15386d3e-2b1a-40fc-9dbd-b3923cfe2de0 node DatanodeRegistration(127.0.0.1:35573, datanodeUuid=6ae325e8-eec1-436e-8a16-79dbd320027f, infoPort=46818, infoSecurePort=0, ipcPort=39848, storageInfo=lv=-57;cid=testClusterID;nsid=516705746;c=1585803972849), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:13,651 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xdd22f7ffdc75e745: Processing first storage report for DS-56549336-0ec7-4099-a31d-d89a732ed947 from datanode 6ae325e8-eec1-436e-8a16-79dbd320027f
2020-04-02 05:06:13,651 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xdd22f7ffdc75e745: from storage DS-56549336-0ec7-4099-a31d-d89a732ed947 node DatanodeRegistration(127.0.0.1:35573, datanodeUuid=6ae325e8-eec1-436e-8a16-79dbd320027f, infoPort=46818, infoSecurePort=0, ipcPort=39848, storageInfo=lv=-57;cid=testClusterID;nsid=516705746;c=1585803972849), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:13,652 [IPC Server handler 7 on 36329] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xdd22f7ffdc75e745
2020-04-02 05:06:13,654 [BP-1967904765-172.17.0.14-1585803972849 heartbeating to localhost/127.0.0.1:36329] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xdd22f7ffdc75e745,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 14 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:13,654 [BP-1967904765-172.17.0.14-1585803972849 heartbeating to localhost/127.0.0.1:36329] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:13,655 [IPC Server handler 8 on 36329] DEBUG BlockStateChange (NameNodeRpcServer.java:cacheReport(1559)) - *BLOCK* NameNode.cacheReport: from DatanodeRegistration(127.0.0.1:35573, datanodeUuid=6ae325e8-eec1-436e-8a16-79dbd320027f, infoPort=46818, infoSecurePort=0, ipcPort=39848, storageInfo=lv=-57;cid=testClusterID;nsid=516705746;c=1585803972849) 0 blocks
2020-04-02 05:06:13,742 [IPC Server handler 1 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,746 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
init: server=localhost;port=;service=DataNode;localVMUrl=null

Domains:
	Domain = Hadoop
	Domain = JMImplementation
	Domain = com.sun.management
	Domain = java.lang
	Domain = java.nio
	Domain = java.util.logging

MBeanServer default domain = DefaultDomain

MBean count = 49

Query MBeanServer MBeans:
Hadoop service: Hadoop:service=DataNode,name=DataNodeActivity-127.0.0.1-35573
Hadoop service: Hadoop:service=DataNode,name=DataNodeInfo
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState-6ae325e8-eec1-436e-8a16-79dbd320027f
Hadoop service: Hadoop:service=DataNode,name=JvmMetrics-1
Hadoop service: Hadoop:service=DataNode,name=RpcActivityForPort39848
Hadoop service: Hadoop:service=DataNode,name=RpcDetailedActivityForPort39848
2020-04-02 05:06:13,748 [Thread-468] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:startUpCluster(326)) - Cluster startup complete
2020-04-02 05:06:13,749 [IPC Server handler 2 on 36329] DEBUG hdfs.StateChange (NameNodeRpcServer.java:mkdirs(1120)) - *DIR* NameNode.mkdirs: /
2020-04-02 05:06:13,749 [IPC Server handler 2 on 36329] DEBUG hdfs.StateChange (FSDirMkdirOp.java:mkdirs(46)) - DIR* NameSystem.mkdirs: /
2020-04-02 05:06:13,750 [IPC Server handler 2 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:13,751 [IPC Server handler 0 on 36329] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /doShortCircuitReadAfterEvictionTest.01.dat for DFSClient_NONMAPREDUCE_1887932022_1443 at 127.0.0.1
2020-04-02 05:06:13,751 [IPC Server handler 0 on 36329] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/doShortCircuitReadAfterEvictionTest.01.dat, holder=DFSClient_NONMAPREDUCE_1887932022_1443, clientMachine=127.0.0.1, createParent=true, replication=1, createFlag=[CREATE, OVERWRITE, LAZY_PERSIST], blockSize=5242880, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:06:13,752 [IPC Server handler 0 on 36329] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: doShortCircuitReadAfterEvictionTest.01.dat is added
2020-04-02 05:06:13,753 [IPC Server handler 0 on 36329] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /doShortCircuitReadAfterEvictionTest.01.dat inode 16386 DFSClient_NONMAPREDUCE_1887932022_1443
2020-04-02 05:06:13,754 [IPC Server handler 0 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:13,816 [IPC Server handler 3 on 36329] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /doShortCircuitReadAfterEvictionTest.01.dat  inodeId 16386 for DFSClient_NONMAPREDUCE_1887932022_1443
2020-04-02 05:06:13,817 [IPC Server handler 3 on 36329] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /doShortCircuitReadAfterEvictionTest.01.dat with blk_1073741825_1001 block is added to the in-memory file system
2020-04-02 05:06:13,818 [IPC Server handler 3 on 36329] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:35573 for /doShortCircuitReadAfterEvictionTest.01.dat
2020-04-02 05:06:13,818 [IPC Server handler 3 on 36329] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /doShortCircuitReadAfterEvictionTest.01.dat with new block blk_1073741825_1001, current total block count is 1
2020-04-02 05:06:13,835 [DataXceiver for client DFSClient_NONMAPREDUCE_1887932022_1443 at /127.0.0.1:48570 [Receiving block BP-1967904765-172.17.0.14-1585803972849:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1967904765-172.17.0.14-1585803972849:blk_1073741825_1001 src: /127.0.0.1:48570 dest: /127.0.0.1:35573
2020-04-02 05:06:13,884 [PacketResponder: BP-1967904765-172.17.0.14-1585803972849:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:moveBlockFiles(885)) - addFinalizedBlock: Moved file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1967904765-172.17.0.14-1585803972849/current/rbw/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1967904765-172.17.0.14-1585803972849/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta and file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1967904765-172.17.0.14-1585803972849/current/rbw/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1967904765-172.17.0.14-1585803972849/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:13,886 [PacketResponder: BP-1967904765-172.17.0.14-1585803972849:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48570, dest: /127.0.0.1:35573, bytes: 5242880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1887932022_1443, offset: 0, srvID: 6ae325e8-eec1-436e-8a16-79dbd320027f, blockid: BP-1967904765-172.17.0.14-1585803972849:blk_1073741825_1001, duration(ns): 29418964
2020-04-02 05:06:13,887 [PacketResponder: BP-1967904765-172.17.0.14-1585803972849:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1967904765-172.17.0.14-1585803972849:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:13,888 [IPC Server handler 6 on 36329] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35573, datanodeUuid=6ae325e8-eec1-436e-8a16-79dbd320027f, infoPort=46818, infoSecurePort=0, ipcPort=39848, storageInfo=lv=-57;cid=testClusterID;nsid=516705746;c=1585803972849) 1 blocks.
2020-04-02 05:06:13,891 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:35573 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:13,891 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:13,891 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:35573 is added to blk_1073741825_1001 (size=0)
2020-04-02 05:06:13,891 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:35573
2020-04-02 05:06:13,891 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35573 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:13,893 [IPC Server handler 5 on 36329] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3274)) - BLOCK* fsync: /doShortCircuitReadAfterEvictionTest.01.dat for DFSClient_NONMAPREDUCE_1887932022_1443
2020-04-02 05:06:13,894 [IPC Server handler 5 on 36329] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistBlocks(112)) - persistBlocks: /doShortCircuitReadAfterEvictionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:13,896 [IPC Server handler 7 on 36329] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /doShortCircuitReadAfterEvictionTest.01.dat for DFSClient_NONMAPREDUCE_1887932022_1443
2020-04-02 05:06:13,897 [IPC Server handler 7 on 36329] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /doShortCircuitReadAfterEvictionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:13,897 [IPC Server handler 7 on 36329] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /doShortCircuitReadAfterEvictionTest.01.dat is closed by DFSClient_NONMAPREDUCE_1887932022_1443
2020-04-02 05:06:13,902 [Thread-468] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadAfterEvictionTest.01.dat is on StorageType: RAM_DISK
2020-04-02 05:06:13,903 [IPC Server handler 8 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,907 [IPC Server handler 9 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,910 [IPC Server handler 1 on 36329] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:13,910 [IPC Server handler 1 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:13,912 [IPC Server handler 2 on 36329] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:13,913 [IPC Server handler 2 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:0
2020-04-02 05:06:13,914 [Thread-468] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 0
2020-04-02 05:06:14,512 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@5476c623] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:saveNextReplica(3108)) - LazyWriter: Start persisting RamDisk block: block pool Id: BP-1967904765-172.17.0.14-1585803972849 block id: 1073741825 on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:14,523 [Async RamDisk lazy persist worker  for volume with id DS-56549336-0ec7-4099-a31d-d89a732ed947] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:copyBlockFiles(931)) - Copied file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1967904765-172.17.0.14-1585803972849/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta and calculated checksum
2020-04-02 05:06:14,523 [Async RamDisk lazy persist worker  for volume with id DS-56549336-0ec7-4099-a31d-d89a732ed947] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:onCompleteLazyPersist(2969)) - LazyWriter: Finish persisting RamDisk block:  block pool Id: BP-1967904765-172.17.0.14-1585803972849 block id: 1073741825 to block file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849/current/lazypersist/subdir0/subdir0/blk_1073741825 and meta file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:1
2020-04-02 05:06:14,915 [Thread-468] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 1
2020-04-02 05:06:14,917 [IPC Server handler 0 on 36329] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:14,918 [IPC Server handler 0 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:14,937 [IPC Server handler 3 on 36329] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:14,937 [IPC Server handler 3 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,036 [Thread-468] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:evictBlocks(3151)) - Evicting block [BlockPoolID=BP-1967904765-172.17.0.14-1585803972849; BlockId=1073741825]
2020-04-02 05:06:15,044 [Thread-468] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(382)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849/current/lazypersist/subdir0/subdir0/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:15,049 [Thread-468] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(384)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta
2020-04-02 05:06:15,051 [Thread-468] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadAfterEvictionTest.01.dat is on StorageType: DISK
2020-04-02 05:06:15,053 [IPC Server handler 4 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,054 [IPC Server handler 4 on 36329] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35573, datanodeUuid=6ae325e8-eec1-436e-8a16-79dbd320027f, infoPort=46818, infoSecurePort=0, ipcPort=39848, storageInfo=lv=-57;cid=testClusterID;nsid=516705746;c=1585803972849) 1 blocks.
2020-04-02 05:06:15,054 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:35573 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:15,054 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:15,054 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3248)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:35573
2020-04-02 05:06:15,054 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:35573
2020-04-02 05:06:15,054 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35573 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:15,056 [IPC Server handler 5 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,057 [IPC Server handler 7 on 36329] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:15,058 [IPC Server handler 7 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,060 [IPC Server handler 8 on 36329] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:15,061 [IPC Server handler 8 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,066 [IPC Server handler 9 on 36329] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:15,066 [IPC Server handler 9 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,086 [IPC Server handler 1 on 36329] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:15,086 [IPC Server handler 1 on 36329] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadAfterEvictionTest.01.dat	dst=null	perm=null	proto=rpc
List of the keys matching ^RamDisk :
>>>>>>>>jmx name: name=DataNodeActivity-127.0.0.1-35573,service=DataNode
RamDiskBlocksWrite=1
RamDiskBlocksWriteFallback=0
RamDiskBytesWrite=5242880
RamDiskBlocksReadHits=0
RamDiskBlocksEvicted=1
RamDiskBlocksEvictedWithoutRead=1
RamDiskBlocksEvictionWindowMsNumOps=1
RamDiskBlocksEvictionWindowMsAvgTime=1164.0
RamDiskBlocksLazyPersisted=1
RamDiskBlocksDeletedBeforeLazyPersisted=0
RamDiskBytesLazyPersisted=5242880
RamDiskBlocksLazyPersistWindowMsNumOps=1
RamDiskBlocksLazyPersistWindowMsAvgTime=637.0
>>>>>>>>jmx name: name=DataNodeInfo,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState-6ae325e8-eec1-436e-8a16-79dbd320027f,service=DataNode
>>>>>>>>jmx name: name=JvmMetrics-1,service=DataNode
>>>>>>>>jmx name: name=RpcActivityForPort39848,service=DataNode
>>>>>>>>jmx name: name=RpcDetailedActivityForPort39848,service=DataNode
2020-04-02 05:06:15,220 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:15,220 [Thread-468] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39848 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:15,221 [Thread-468] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:15,221 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7542a1dc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:15,223 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-15386d3e-2b1a-40fc-9dbd-b3923cfe2de0) exiting.
2020-04-02 05:06:15,224 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-56549336-0ec7-4099-a31d-d89a732ed947) exiting.
2020-04-02 05:06:15,262 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b67fccd{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:15,263 [Thread-468] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@66eeef58{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:15,263 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53081e98{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:15,263 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6546284e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:15,274 [Thread-468] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39848
2020-04-02 05:06:15,280 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:15,281 [BP-1967904765-172.17.0.14-1585803972849 heartbeating to localhost/127.0.0.1:36329] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:15,281 [BP-1967904765-172.17.0.14-1585803972849 heartbeating to localhost/127.0.0.1:36329] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1967904765-172.17.0.14-1585803972849 (Datanode Uuid 6ae325e8-eec1-436e-8a16-79dbd320027f) service to localhost/127.0.0.1:36329
2020-04-02 05:06:15,281 [BP-1967904765-172.17.0.14-1585803972849 heartbeating to localhost/127.0.0.1:36329] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1967904765-172.17.0.14-1585803972849 (Datanode Uuid 6ae325e8-eec1-436e-8a16-79dbd320027f)
2020-04-02 05:06:15,281 [BP-1967904765-172.17.0.14-1585803972849 heartbeating to localhost/127.0.0.1:36329] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1967904765-172.17.0.14-1585803972849
2020-04-02 05:06:15,293 [IPC Server listener on 39848] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39848
2020-04-02 05:06:15,353 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1967904765-172.17.0.14-1585803972849] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:15,357 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1967904765-172.17.0.14-1585803972849] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:15,363 [Thread-468] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:15,364 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@5476c623] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(3203)) - LazyWriter was interrupted, exiting
2020-04-02 05:06:15,364 [Thread-468] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:15,364 [Thread-468] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:15,364 [Thread-468] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:15,373 [Thread-468] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:15,373 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:15,373 [Thread-468] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:15,373 [Thread-468] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36329 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:15,374 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:15,374 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@3c034281] DEBUG namenode.LeaseManager (LeaseManager.java:run(536)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:15,378 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@70311882] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:15,379 [Thread-468] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:06:15,382 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4309d6d1] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:15,383 [Thread-468] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 2 Number of syncs: 7 SyncTimes(ms): 1 2 
2020-04-02 05:06:15,383 [Thread-468] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:15,384 [Thread-468] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:15,384 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:15,385 [CacheReplicationMonitor(1726883190)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:15,386 [Thread-468] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36329
2020-04-02 05:06:15,388 [IPC Server listener on 36329] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36329
2020-04-02 05:06:15,391 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:15,391 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:15,391 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:15,394 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@1cd25551] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:15,420 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:15,427 [Thread-468] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:15,428 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7e401eac{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:15,432 [Thread-468] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@163ac09f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:15,433 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@747859e8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:15,433 [Thread-468] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3861ee3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:15,442 [Thread-468] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:15,443 [Thread-468] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:15,443 [Thread-468] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testLegacyScrAfterEviction
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testLegacyScrAfterEviction
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testLegacyScrBlockFileCorruption
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:15,467 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:06:15,470 [Thread-556] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
Formatting using clusterid: testClusterID
2020-04-02 05:06:15,470 [Thread-556] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:15,471 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:15,471 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:15,471 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:15,472 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:15,472 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:15,472 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:15,472 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:15,473 [Thread-556] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,473 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,473 [Thread-556] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:15,473 [Thread-556] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:15,473 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,474 [Thread-556] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:15,474 [Thread-556] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:15,482 [Thread-556] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:15
2020-04-02 05:06:15,482 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:15,482 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:15,482 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:15,483 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:15,486 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,486 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,486 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:15,487 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,487 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:15,487 [Thread-556] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:15,487 [Thread-556] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:15,487 [Thread-556] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:15,487 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:15,487 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:15,488 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:15,488 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:15,488 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:15,488 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:15,488 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:15,488 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:15,489 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:15,489 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:15,489 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:15,490 [Thread-556] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:15,491 [Thread-556] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:15,491 [Thread-556] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:15,491 [Thread-556] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:15,491 [Thread-556] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:15,491 [Thread-556] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:15,491 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:15,491 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:15,492 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:15,492 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:15,493 [Thread-556] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:15,493 [Thread-556] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:15,493 [Thread-556] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:15,493 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:15,493 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:15,494 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:15,494 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:15,494 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:15,494 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:15,495 [Thread-556] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:15,505 [Thread-556] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:15,511 [Thread-556] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:15,512 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:15,513 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:15,519 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:15,523 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:15,526 [Thread-556] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:15,527 [Thread-556] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:15,531 [Thread-556] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:15,537 [Thread-556] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:15,538 [Thread-556] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:15,539 [Thread-556] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:15,539 [Thread-556] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:15,540 [Thread-556] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
2020-04-02 05:06:15,545 [Thread-556] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:15,545 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,546 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@13ca1cce] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:15,547 [Thread-556] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:15,548 [Thread-556] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:15,548 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,549 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:15,550 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:15,550 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:15,550 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:15,551 [Thread-556] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:15,552 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:15,552 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39309
2020-04-02 05:06:15,552 [Thread-556] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:15,560 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@463973ae{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:15,561 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f53f787{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:15,571 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30bad8e3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:15,572 [Thread-556] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3afc9130{HTTP/1.1,[http/1.1]}{localhost:39309}
2020-04-02 05:06:15,572 [Thread-556] INFO  server.Server (Server.java:doStart(419)) - Started @28443ms
2020-04-02 05:06:15,573 [Thread-556] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:15,573 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:15,574 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:15,574 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:15,574 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:15,574 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:15,574 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:15,575 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:15,575 [Thread-556] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,581 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,586 [Thread-556] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:15,586 [Thread-556] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:15,586 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,586 [Thread-556] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:15,587 [Thread-556] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:15,587 [Thread-556] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:15
2020-04-02 05:06:15,587 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:15,587 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:15,587 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:15,588 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:15,595 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,602 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,602 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:15,602 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,602 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:15,603 [Thread-556] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:15,603 [Thread-556] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:15,603 [Thread-556] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:15,603 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:15,603 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:15,603 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:15,603 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:15,603 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:15,604 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:15,604 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:15,604 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:15,604 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:15,604 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:15,605 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:15,619 [Thread-556] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:15,619 [Thread-556] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:15,619 [Thread-556] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:15,619 [Thread-556] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:15,619 [Thread-556] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:15,620 [Thread-556] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:15,620 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:15,626 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:15,627 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:15,627 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:15,629 [Thread-556] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:15,629 [Thread-556] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:15,629 [Thread-556] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:15,630 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:15,630 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:15,630 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:15,630 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:15,630 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:15,631 [Thread-556] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:15,638 [Thread-556] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:15,641 [Thread-556] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:15,643 [Thread-556] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:15,644 [Thread-556] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:15,644 [Thread-556] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:15,644 [Thread-556] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:15,647 [Thread-556] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:15,648 [Thread-556] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:15,648 [Thread-556] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:15,649 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:15,650 [Thread-556] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:15,664 [Thread-556] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:15,664 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 32 msecs
2020-04-02 05:06:15,665 [Thread-556] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:15,666 [Thread-556] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:15,667 [Socket Reader #1 for port 37976] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37976
2020-04-02 05:06:15,676 [Thread-556] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:37976 to access this namenode/service.
2020-04-02 05:06:15,677 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:15,706 [Thread-556] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:15,712 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@50af4010] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:06:15,719 [Thread-556] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:15,722 [Thread-556] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(607)) - STATE* Safe mode ON. 
The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1 live datanodes to reach the minimum number 1.
Safe mode will be turned off automatically once the thresholds have been reached.
2020-04-02 05:06:15,758 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:15,759 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:15,759 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:15,759 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:15,759 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:15,759 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 35 msec
2020-04-02 05:06:15,764 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:15,765 [IPC Server listener on 37976] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37976: starting
2020-04-02 05:06:15,770 [Thread-556] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:37976
2020-04-02 05:06:15,771 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:15,771 [Thread-556] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:15,771 [Thread-556] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:15,772 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@81823bd] DEBUG namenode.FSNamesystem (FSNamesystem.java:run(4098)) - Namenode is in safemode, skipping scrubbing of corrupted lazy-persist files.
2020-04-02 05:06:15,772 [Thread-556] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 37976 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:15,800 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:15,806 [Thread-556] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:15,813 [CacheReplicationMonitor(321197391)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:15,813 [Thread-556] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:15,816 [Thread-556] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:15,816 [Thread-556] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:15,817 [Thread-556] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,817 [Thread-556] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:15,817 [Thread-556] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:06:15,817 [Thread-556] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:15,817 [Thread-556] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,817 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,818 [Thread-556] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:15,818 [Thread-556] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:verifyCanMlock(348)) - LazyPersistTestCase: fake return true
2020-04-02 05:06:15,818 [Thread-556] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:getMemlockLimit(342)) - LazyPersistTestCase: fake return 9223372036854775807
2020-04-02 05:06:15,818 [Thread-556] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 9223372036854775807
2020-04-02 05:06:15,819 [Thread-556] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40894
2020-04-02 05:06:15,819 [Thread-556] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:15,819 [Thread-556] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:15,821 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,823 [Thread-556] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:15,824 [Thread-556] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:15,824 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,825 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:15,826 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:15,826 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:15,826 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:15,826 [Thread-556] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45646
2020-04-02 05:06:15,827 [Thread-556] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:15,842 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b023f05{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:15,843 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@39b7444f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:15,848 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7464c0d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:15,849 [Thread-556] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@21fc4761{HTTP/1.1,[http/1.1]}{localhost:45646}
2020-04-02 05:06:15,849 [Thread-556] INFO  server.Server (Server.java:doStart(419)) - Started @28720ms
2020-04-02 05:06:15,874 [Thread-556] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39515
2020-04-02 05:06:15,875 [Thread-556] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:15,875 [Thread-556] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:15,875 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6ba7bcac] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:15,876 [Thread-556] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:15,877 [Socket Reader #1 for port 37208] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37208
2020-04-02 05:06:15,907 [Thread-556] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37208
2020-04-02 05:06:15,910 [Thread-556] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:15,911 [Thread-556] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:15,912 [Thread-611] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37976 starting to offer service
2020-04-02 05:06:15,913 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:15,914 [IPC Server listener on 37208] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37208: starting
2020-04-02 05:06:15,915 [Thread-556] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37208 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:15,957 [IPC Server handler 0 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:15,958 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:15,958 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:15,959 [Thread-611] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37976
2020-04-02 05:06:15,960 [Thread-611] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:15,962 [Thread-611] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:15,962 [Thread-611] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1901237744. Formatting...
2020-04-02 05:06:15,962 [Thread-611] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f825f990-cf15-4ec6-af33-f418795fa0ad for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:15,966 [Thread-611] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:15,966 [Thread-611] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1901237744. Formatting...
2020-04-02 05:06:15,966 [Thread-611] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-83606040-669b-40f8-83d7-a6dc1b506734 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:16,000 [Thread-611] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:16,001 [Thread-611] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:16,001 [Thread-611] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1983427623-172.17.0.14-1585803975495 is not formatted. Formatting ...
2020-04-02 05:06:16,001 [Thread-611] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1983427623-172.17.0.14-1585803975495 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1983427623-172.17.0.14-1585803975495/current
2020-04-02 05:06:16,029 [Thread-611] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:16,030 [Thread-611] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:16,030 [Thread-611] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1983427623-172.17.0.14-1585803975495 is not formatted. Formatting ...
2020-04-02 05:06:16,031 [Thread-611] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1983427623-172.17.0.14-1585803975495 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current
2020-04-02 05:06:16,036 [Thread-611] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1901237744;bpid=BP-1983427623-172.17.0.14-1585803975495;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1901237744;c=1585803975495;bpid=BP-1983427623-172.17.0.14-1585803975495;dnuuid=null
2020-04-02 05:06:16,040 [Thread-611] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 099cdcb3-c4c8-450e-89f7-75bc92708fbc
2020-04-02 05:06:16,065 [Thread-611] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f825f990-cf15-4ec6-af33-f418795fa0ad
2020-04-02 05:06:16,066 [Thread-611] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: RAM_DISK
2020-04-02 05:06:16,068 [Thread-611] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-83606040-669b-40f8-83d7-a6dc1b506734
2020-04-02 05:06:16,068 [Thread-611] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:16,070 [Thread-611] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:16,073 [IPC Server handler 2 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,077 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:16,077 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:16,077 [Thread-611] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:16,090 [Thread-611] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:16,090 [Thread-611] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:16,090 [Thread-611] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:16,093 [Thread-611] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:16,094 [Thread-628] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1983427623-172.17.0.14-1585803975495 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:16,124 [Thread-629] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1983427623-172.17.0.14-1585803975495 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:16,132 [Thread-628] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1983427623-172.17.0.14-1585803975495 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 38ms
2020-04-02 05:06:16,155 [Thread-629] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1983427623-172.17.0.14-1585803975495 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 31ms
2020-04-02 05:06:16,155 [Thread-611] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1983427623-172.17.0.14-1585803975495: 62ms
2020-04-02 05:06:16,166 [Thread-632] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1983427623-172.17.0.14-1585803975495 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:16,166 [Thread-632] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1983427623-172.17.0.14-1585803975495/current/replicas doesn't exist 
2020-04-02 05:06:16,167 [Thread-632] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1983427623-172.17.0.14-1585803975495 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:06:16,174 [Thread-633] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1983427623-172.17.0.14-1585803975495 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:16,174 [Thread-633] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current/replicas doesn't exist 
2020-04-02 05:06:16,174 [Thread-633] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1983427623-172.17.0.14-1585803975495 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:06:16,178 [Thread-611] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1983427623-172.17.0.14-1585803975495: 23ms
2020-04-02 05:06:16,178 [Thread-611] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:51 AM with interval of 21600000ms
2020-04-02 05:06:16,179 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1983427623-172.17.0.14-1585803975495 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:16,179 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-83606040-669b-40f8-83d7-a6dc1b506734): finished scanning block pool BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:16,180 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-83606040-669b-40f8-83d7-a6dc1b506734): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:06:16,180 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1983427623-172.17.0.14-1585803975495 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:16,180 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f825f990-cf15-4ec6-af33-f418795fa0ad): finished scanning block pool BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:16,181 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f825f990-cf15-4ec6-af33-f418795fa0ad): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:06:16,191 [BP-1983427623-172.17.0.14-1585803975495 heartbeating to localhost/127.0.0.1:37976] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1983427623-172.17.0.14-1585803975495 (Datanode Uuid 099cdcb3-c4c8-450e-89f7-75bc92708fbc) service to localhost/127.0.0.1:37976 beginning handshake with NN
2020-04-02 05:06:16,194 [IPC Server handler 3 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,195 [IPC Server handler 3 on 37976] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40894, datanodeUuid=099cdcb3-c4c8-450e-89f7-75bc92708fbc, infoPort=39515, infoSecurePort=0, ipcPort=37208, storageInfo=lv=-57;cid=testClusterID;nsid=1901237744;c=1585803975495) storage 099cdcb3-c4c8-450e-89f7-75bc92708fbc
2020-04-02 05:06:16,195 [IPC Server handler 3 on 37976] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40894
2020-04-02 05:06:16,195 [IPC Server handler 3 on 37976] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 099cdcb3-c4c8-450e-89f7-75bc92708fbc (127.0.0.1:40894).
2020-04-02 05:06:16,195 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:16,195 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:16,203 [IPC Server handler 3 on 37976] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(391)) - STATE* Safe mode is OFF
2020-04-02 05:06:16,203 [IPC Server handler 3 on 37976] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:16,203 [IPC Server handler 3 on 37976] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 1 datanodes
2020-04-02 05:06:16,204 [IPC Server handler 3 on 37976] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:16,208 [BP-1983427623-172.17.0.14-1585803975495 heartbeating to localhost/127.0.0.1:37976] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1983427623-172.17.0.14-1585803975495 (Datanode Uuid 099cdcb3-c4c8-450e-89f7-75bc92708fbc) service to localhost/127.0.0.1:37976 successfully registered with NN
2020-04-02 05:06:16,208 [BP-1983427623-172.17.0.14-1585803975495 heartbeating to localhost/127.0.0.1:37976] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37976 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:16,221 [IPC Server handler 6 on 37976] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f825f990-cf15-4ec6-af33-f418795fa0ad for DN 127.0.0.1:40894
2020-04-02 05:06:16,221 [IPC Server handler 6 on 37976] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-83606040-669b-40f8-83d7-a6dc1b506734 for DN 127.0.0.1:40894
2020-04-02 05:06:16,224 [IPC Server handler 7 on 37976] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40894, datanodeUuid=099cdcb3-c4c8-450e-89f7-75bc92708fbc, infoPort=39515, infoSecurePort=0, ipcPort=37208, storageInfo=lv=-57;cid=testClusterID;nsid=1901237744;c=1585803975495), reports.length=2
2020-04-02 05:06:16,225 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa4166a60f956576e: Processing first storage report for DS-f825f990-cf15-4ec6-af33-f418795fa0ad from datanode 099cdcb3-c4c8-450e-89f7-75bc92708fbc
2020-04-02 05:06:16,225 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa4166a60f956576e: from storage DS-f825f990-cf15-4ec6-af33-f418795fa0ad node DatanodeRegistration(127.0.0.1:40894, datanodeUuid=099cdcb3-c4c8-450e-89f7-75bc92708fbc, infoPort=39515, infoSecurePort=0, ipcPort=37208, storageInfo=lv=-57;cid=testClusterID;nsid=1901237744;c=1585803975495), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:16,229 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa4166a60f956576e: Processing first storage report for DS-83606040-669b-40f8-83d7-a6dc1b506734 from datanode 099cdcb3-c4c8-450e-89f7-75bc92708fbc
2020-04-02 05:06:16,230 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa4166a60f956576e: from storage DS-83606040-669b-40f8-83d7-a6dc1b506734 node DatanodeRegistration(127.0.0.1:40894, datanodeUuid=099cdcb3-c4c8-450e-89f7-75bc92708fbc, infoPort=39515, infoSecurePort=0, ipcPort=37208, storageInfo=lv=-57;cid=testClusterID;nsid=1901237744;c=1585803975495), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:16,230 [IPC Server handler 7 on 37976] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xa4166a60f956576e
2020-04-02 05:06:16,231 [BP-1983427623-172.17.0.14-1585803975495 heartbeating to localhost/127.0.0.1:37976] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa4166a60f956576e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:16,231 [BP-1983427623-172.17.0.14-1585803975495 heartbeating to localhost/127.0.0.1:37976] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:16,234 [IPC Server handler 8 on 37976] DEBUG BlockStateChange (NameNodeRpcServer.java:cacheReport(1559)) - *BLOCK* NameNode.cacheReport: from DatanodeRegistration(127.0.0.1:40894, datanodeUuid=099cdcb3-c4c8-450e-89f7-75bc92708fbc, infoPort=39515, infoSecurePort=0, ipcPort=37208, storageInfo=lv=-57;cid=testClusterID;nsid=1901237744;c=1585803975495) 0 blocks
2020-04-02 05:06:16,297 [IPC Server handler 9 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,298 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:16,298 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [RAM_DISK]DS-f825f990-cf15-4ec6-af33-f418795fa0ad
2020-04-02 05:06:16,298 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [DISK]DS-83606040-669b-40f8-83d7-a6dc1b506734
2020-04-02 05:06:16,401 [IPC Server handler 1 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,404 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
init: server=localhost;port=;service=DataNode;localVMUrl=null

Domains:
	Domain = Hadoop
	Domain = JMImplementation
	Domain = com.sun.management
	Domain = java.lang
	Domain = java.nio
	Domain = java.util.logging

MBeanServer default domain = DefaultDomain

MBean count = 49

Query MBeanServer MBeans:
Hadoop service: Hadoop:service=DataNode,name=DataNodeActivity-127.0.0.1-40894
Hadoop service: Hadoop:service=DataNode,name=DataNodeInfo
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState-099cdcb3-c4c8-450e-89f7-75bc92708fbc
Hadoop service: Hadoop:service=DataNode,name=JvmMetrics-1
Hadoop service: Hadoop:service=DataNode,name=RpcActivityForPort37208
Hadoop service: Hadoop:service=DataNode,name=RpcDetailedActivityForPort37208
2020-04-02 05:06:16,406 [Thread-556] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:startUpCluster(326)) - Cluster startup complete
2020-04-02 05:06:16,407 [IPC Server handler 0 on 37976] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /doShortCircuitReadBlockFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_802917146_1718 at 127.0.0.1
2020-04-02 05:06:16,407 [IPC Server handler 0 on 37976] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/doShortCircuitReadBlockFileCorruptionTest.01.dat, holder=DFSClient_NONMAPREDUCE_802917146_1718, clientMachine=127.0.0.1, createParent=true, replication=1, createFlag=[CREATE, LAZY_PERSIST], blockSize=5242880, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:06:16,407 [IPC Server handler 0 on 37976] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: doShortCircuitReadBlockFileCorruptionTest.01.dat is added
2020-04-02 05:06:16,418 [IPC Server handler 0 on 37976] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /doShortCircuitReadBlockFileCorruptionTest.01.dat inode 16386 DFSClient_NONMAPREDUCE_802917146_1718
2020-04-02 05:06:16,418 [IPC Server handler 0 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:16,432 [IPC Server handler 2 on 37976] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /doShortCircuitReadBlockFileCorruptionTest.01.dat  inodeId 16386 for DFSClient_NONMAPREDUCE_802917146_1718
2020-04-02 05:06:16,433 [IPC Server handler 2 on 37976] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /doShortCircuitReadBlockFileCorruptionTest.01.dat with blk_1073741825_1001 block is added to the in-memory file system
2020-04-02 05:06:16,433 [IPC Server handler 2 on 37976] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40894 for /doShortCircuitReadBlockFileCorruptionTest.01.dat
2020-04-02 05:06:16,434 [IPC Server handler 2 on 37976] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /doShortCircuitReadBlockFileCorruptionTest.01.dat with new block blk_1073741825_1001, current total block count is 1
2020-04-02 05:06:16,443 [DataXceiver for client DFSClient_NONMAPREDUCE_802917146_1718 at /127.0.0.1:35964 [Receiving block BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001 src: /127.0.0.1:35964 dest: /127.0.0.1:40894
2020-04-02 05:06:16,522 [PacketResponder: BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:moveBlockFiles(885)) - addFinalizedBlock: Moved file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1983427623-172.17.0.14-1585803975495/current/rbw/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1983427623-172.17.0.14-1585803975495/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta and file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1983427623-172.17.0.14-1585803975495/current/rbw/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1983427623-172.17.0.14-1585803975495/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:16,523 [PacketResponder: BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35964, dest: /127.0.0.1:40894, bytes: 5242880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_802917146_1718, offset: 0, srvID: 099cdcb3-c4c8-450e-89f7-75bc92708fbc, blockid: BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001, duration(ns): 76355676
2020-04-02 05:06:16,523 [PacketResponder: BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:16,524 [IPC Server handler 3 on 37976] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40894, datanodeUuid=099cdcb3-c4c8-450e-89f7-75bc92708fbc, infoPort=39515, infoSecurePort=0, ipcPort=37208, storageInfo=lv=-57;cid=testClusterID;nsid=1901237744;c=1585803975495) 1 blocks.
2020-04-02 05:06:16,526 [IPC Server handler 6 on 37976] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3274)) - BLOCK* fsync: /doShortCircuitReadBlockFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_802917146_1718
2020-04-02 05:06:16,533 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:40894 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:16,534 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:16,534 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40894 is added to blk_1073741825_1001 (size=0)
2020-04-02 05:06:16,534 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:40894
2020-04-02 05:06:16,534 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40894 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:16,535 [IPC Server handler 6 on 37976] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistBlocks(112)) - persistBlocks: /doShortCircuitReadBlockFileCorruptionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:16,538 [IPC Server handler 7 on 37976] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /doShortCircuitReadBlockFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_802917146_1718
2020-04-02 05:06:16,540 [IPC Server handler 7 on 37976] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /doShortCircuitReadBlockFileCorruptionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:16,540 [IPC Server handler 7 on 37976] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /doShortCircuitReadBlockFileCorruptionTest.01.dat is closed by DFSClient_NONMAPREDUCE_802917146_1718
2020-04-02 05:06:16,546 [Thread-556] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadBlockFileCorruptionTest.01.dat is on StorageType: RAM_DISK
2020-04-02 05:06:16,547 [IPC Server handler 8 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,549 [IPC Server handler 9 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,550 [IPC Server handler 4 on 37976] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:16,550 [IPC Server handler 4 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,552 [IPC Server handler 1 on 37976] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:16,552 [IPC Server handler 1 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:0
2020-04-02 05:06:16,553 [Thread-556] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 0
2020-04-02 05:06:17,074 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@10534d53] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:saveNextReplica(3108)) - LazyWriter: Start persisting RamDisk block: block pool Id: BP-1983427623-172.17.0.14-1585803975495 block id: 1073741825 on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:17,085 [Async RamDisk lazy persist worker  for volume with id DS-83606040-669b-40f8-83d7-a6dc1b506734] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:copyBlockFiles(931)) - Copied file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1983427623-172.17.0.14-1585803975495/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta and calculated checksum
2020-04-02 05:06:17,085 [Async RamDisk lazy persist worker  for volume with id DS-83606040-669b-40f8-83d7-a6dc1b506734] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:onCompleteLazyPersist(2969)) - LazyWriter: Finish persisting RamDisk block:  block pool Id: BP-1983427623-172.17.0.14-1585803975495 block id: 1073741825 to block file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current/lazypersist/subdir0/subdir0/blk_1073741825 and meta file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:1
2020-04-02 05:06:17,554 [Thread-556] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 1
2020-04-02 05:06:17,556 [Thread-556] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:evictBlocks(3151)) - Evicting block [BlockPoolID=BP-1983427623-172.17.0.14-1585803975495; BlockId=1073741825]
2020-04-02 05:06:17,562 [Thread-556] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(382)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current/lazypersist/subdir0/subdir0/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:17,563 [Thread-556] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(384)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta
2020-04-02 05:06:17,564 [IPC Server handler 0 on 37976] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40894, datanodeUuid=099cdcb3-c4c8-450e-89f7-75bc92708fbc, infoPort=39515, infoSecurePort=0, ipcPort=37208, storageInfo=lv=-57;cid=testClusterID;nsid=1901237744;c=1585803975495) 1 blocks.
2020-04-02 05:06:17,566 [Thread-556] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadBlockFileCorruptionTest.01.dat is on StorageType: DISK
2020-04-02 05:06:17,566 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:40894 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:17,566 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:17,566 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3248)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:40894
2020-04-02 05:06:17,567 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:40894
2020-04-02 05:06:17,567 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40894 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,567 [IPC Server handler 2 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,569 [IPC Server handler 5 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,570 [IPC Server handler 3 on 37976] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:17,571 [IPC Server handler 3 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,577 [IPC Server handler 6 on 37976] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:17,577 [IPC Server handler 6 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,580 [IPC Server handler 7 on 37976] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:17,580 [IPC Server handler 7 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,592 [Thread-556] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:17,598 [IPC Server handler 8 on 37976] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:17,598 [IPC Server handler 8 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,601 [Thread-556] WARN  hdfs.DFSClient (DFSInputStream.java:readBuffer(706)) - Found Checksum error for BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001 from DatanodeInfoWithStorage[127.0.0.1:40894,DS-83606040-669b-40f8-83d7-a6dc1b506734,DISK] at 0
2020-04-02 05:06:17,602 [Thread-556] WARN  hdfs.DFSClient (DFSInputStream.java:reportLostBlock(959)) - No live nodes contain block BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:40894,DS-83606040-669b-40f8-83d7-a6dc1b506734,DISK]], ignoredNodes = null
2020-04-02 05:06:17,602 [Thread-556] INFO  hdfs.DFSClient (DFSInputStream.java:refetchLocations(882)) - Could not obtain BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:40894,DS-83606040-669b-40f8-83d7-a6dc1b506734,DISK] Dead nodes:  DatanodeInfoWithStorage[127.0.0.1:40894,DS-83606040-669b-40f8-83d7-a6dc1b506734,DISK]. Will get new block locations from namenode and retry...
2020-04-02 05:06:17,602 [Thread-556] WARN  hdfs.DFSClient (DFSInputStream.java:refetchLocations(901)) - DFS chooseDataNode: got # 1 IOException, will wait for 2398.502441270143 msec.
2020-04-02 05:06:18,718 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:20,002 [IPC Server handler 9 on 37976] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:20,002 [IPC Server handler 9 on 37976] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadBlockFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:20,006 [IPC Server handler 4 on 37976] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1983427623-172.17.0.14-1585803975495:blk_1073741825_1001 on datanode: 127.0.0.1:40894
2020-04-02 05:06:20,006 [IPC Server handler 4 on 37976] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_1073741825_1001 added as corrupt on 127.0.0.1:40894 by /127.0.0.1  because client machine reported it
2020-04-02 05:06:20,006 [IPC Server handler 4 on 37976] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741825_1001 curReplicas 0 curExpectedReplicas 1 oldReplicas 1 oldExpectedReplicas  1 curPri  4 oldPri  3
2020-04-02 05:06:20,006 [IPC Server handler 4 on 37976] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_1073741825_1001 has only 0 replicas and needs 1 replicas so is added to neededReconstructions at priority level 4
List of the keys matching ^RamDisk :
>>>>>>>>jmx name: name=DataNodeActivity-127.0.0.1-40894,service=DataNode
RamDiskBlocksWrite=1
RamDiskBlocksWriteFallback=0
RamDiskBytesWrite=5242880
RamDiskBlocksReadHits=0
RamDiskBlocksEvicted=1
RamDiskBlocksEvictedWithoutRead=1
RamDiskBlocksEvictionWindowMsNumOps=1
RamDiskBlocksEvictionWindowMsAvgTime=1040.0
RamDiskBlocksLazyPersisted=1
RamDiskBlocksDeletedBeforeLazyPersisted=0
RamDiskBytesLazyPersisted=5242880
RamDiskBlocksLazyPersistWindowMsNumOps=1
RamDiskBlocksLazyPersistWindowMsAvgTime=562.0
>>>>>>>>jmx name: name=DataNodeInfo,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState-099cdcb3-c4c8-450e-89f7-75bc92708fbc,service=DataNode
>>>>>>>>jmx name: name=JvmMetrics-1,service=DataNode
>>>>>>>>jmx name: name=RpcActivityForPort37208,service=DataNode
>>>>>>>>jmx name: name=RpcDetailedActivityForPort37208,service=DataNode
2020-04-02 05:06:20,019 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:20,019 [Thread-556] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37208 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:20,020 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6eacec2a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:20,020 [Thread-556] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:20,021 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f825f990-cf15-4ec6-af33-f418795fa0ad) exiting.
2020-04-02 05:06:20,021 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-83606040-669b-40f8-83d7-a6dc1b506734) exiting.
2020-04-02 05:06:20,036 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7464c0d{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:20,045 [Thread-556] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@21fc4761{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:20,046 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@39b7444f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:20,046 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b023f05{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:20,047 [Thread-556] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37208
2020-04-02 05:06:20,054 [IPC Server listener on 37208] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37208
2020-04-02 05:06:20,055 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:20,056 [BP-1983427623-172.17.0.14-1585803975495 heartbeating to localhost/127.0.0.1:37976] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:20,056 [BP-1983427623-172.17.0.14-1585803975495 heartbeating to localhost/127.0.0.1:37976] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1983427623-172.17.0.14-1585803975495 (Datanode Uuid 099cdcb3-c4c8-450e-89f7-75bc92708fbc) service to localhost/127.0.0.1:37976
2020-04-02 05:06:20,056 [BP-1983427623-172.17.0.14-1585803975495 heartbeating to localhost/127.0.0.1:37976] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1983427623-172.17.0.14-1585803975495 (Datanode Uuid 099cdcb3-c4c8-450e-89f7-75bc92708fbc)
2020-04-02 05:06:20,056 [BP-1983427623-172.17.0.14-1585803975495 heartbeating to localhost/127.0.0.1:37976] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1983427623-172.17.0.14-1585803975495
2020-04-02 05:06:20,065 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1983427623-172.17.0.14-1585803975495] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:20,070 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1983427623-172.17.0.14-1585803975495] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:20,088 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@10534d53] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(3203)) - LazyWriter was interrupted, exiting
2020-04-02 05:06:20,090 [Thread-556] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:20,100 [Thread-556] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:20,101 [Thread-556] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:20,108 [Thread-556] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:20,110 [Thread-556] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:20,110 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:20,110 [Thread-556] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:20,110 [Thread-556] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 37976 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:20,110 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:20,118 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@61debde5] DEBUG namenode.LeaseManager (LeaseManager.java:run(536)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:20,124 [Thread-556] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:06:20,124 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@81823bd] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:20,125 [Thread-556] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 2 Number of syncs: 7 SyncTimes(ms): 2 2 
2020-04-02 05:06:20,125 [Thread-556] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:20,126 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@4c38c044] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:20,126 [Thread-556] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:20,133 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:20,138 [CacheReplicationMonitor(321197391)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:20,138 [Thread-556] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37976
2020-04-02 05:06:20,147 [IPC Server listener on 37976] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37976
2020-04-02 05:06:20,163 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:20,164 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:20,164 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:20,174 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@50af4010] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:20,181 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:20,181 [Thread-556] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:20,187 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30bad8e3{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:20,206 [Thread-556] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3afc9130{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:20,207 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f53f787{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:20,207 [Thread-556] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@463973ae{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:20,214 [Thread-556] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:20,216 [Thread-556] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:20,216 [Thread-556] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testLegacyScrBlockFileCorruption
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testLegacyScrBlockFileCorruption
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testScrMetaFileCorruption
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:20,235 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:06:20,237 [Thread-645] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
Formatting using clusterid: testClusterID
2020-04-02 05:06:20,237 [Thread-645] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:20,238 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:20,238 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:20,238 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:20,238 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:20,238 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:20,238 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:20,238 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:20,239 [Thread-645] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:20,239 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,239 [Thread-645] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:20,239 [Thread-645] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:20,239 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,239 [Thread-645] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:20,240 [Thread-645] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:20,240 [Thread-645] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:20
2020-04-02 05:06:20,240 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:20,240 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:20,240 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:20,240 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:20,245 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,245 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,245 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:20,245 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,245 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:20,246 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:20,246 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:20,247 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:20,247 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:20,247 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:20,258 [Thread-645] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:20,258 [Thread-645] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:20,258 [Thread-645] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:20,258 [Thread-645] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:20,258 [Thread-645] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:20,258 [Thread-645] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:20,259 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:20,259 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:20,259 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:20,259 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:20,260 [Thread-645] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:20,260 [Thread-645] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:20,260 [Thread-645] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:20,262 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:20,262 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:20,262 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:20,262 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:20,263 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:20,263 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:20,264 [Thread-645] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:20,267 [Thread-645] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:20,287 [Thread-645] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:20,291 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:20,291 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:20,297 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:20,299 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:06:20,307 [Thread-645] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:20,308 [Thread-645] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:20,313 [Thread-645] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:20,315 [Thread-645] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:20,315 [Thread-645] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:20,316 [Thread-645] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:20,317 [Thread-645] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:20,317 [Thread-645] DEBUG namenode.NameNode (NameNode.java:initializeGenericKeys(1718)) - Setting fs.defaultFS to hdfs://127.0.0.1:0
2020-04-02 05:06:20,321 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ac6ee0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:20,321 [Thread-645] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:20,321 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:20,323 [Thread-645] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:20,327 [Thread-645] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:20,327 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:20,328 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:20,329 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:20,329 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:20,329 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:20,331 [Thread-645] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:20,331 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:20,332 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42155
2020-04-02 05:06:20,332 [Thread-645] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:20,343 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d8625de{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:20,344 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30b88784{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:20,359 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@39133f03{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:20,361 [Thread-645] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c9b49ab{HTTP/1.1,[http/1.1]}{localhost:42155}
2020-04-02 05:06:20,361 [Thread-645] INFO  server.Server (Server.java:doStart(419)) - Started @33232ms
2020-04-02 05:06:20,372 [Thread-645] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:20,373 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:20,373 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:20,373 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:20,373 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:20,373 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:20,373 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:20,373 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:20,374 [Thread-645] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:20,375 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,375 [Thread-645] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=20, effected=1000
2020-04-02 05:06:20,375 [Thread-645] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:20,375 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,376 [Thread-645] WARN  blockmanagement.DatanodeManager (DatanodeManager.java:getStaleIntervalFromConf(366)) - The given interval for marking stale datanode = 30000, which is larger than heartbeat expire interval 11000.
2020-04-02 05:06:20,376 [Thread-645] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:20,376 [Thread-645] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:20
2020-04-02 05:06:20,376 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:20,376 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:20,377 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:20,377 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:20,395 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,395 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,395 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:20,395 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,396 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 1
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:20,396 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:20,397 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:20,397 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:20,397 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:20,397 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:20,402 [Thread-645] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:20,402 [Thread-645] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:20,402 [Thread-645] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:20,402 [Thread-645] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:20,402 [Thread-645] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:20,403 [Thread-645] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:20,403 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:20,403 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:20,403 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:20,403 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:20,404 [Thread-645] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:20,404 [Thread-645] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:20,404 [Thread-645] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:20,405 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:20,405 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:20,405 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:20,405 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:20,405 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:20,406 [Thread-645] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:20,429 [Thread-645] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:20,431 [Thread-645] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:20,433 [Thread-645] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:20,433 [Thread-645] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:20,434 [Thread-645] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:20,434 [Thread-645] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:20,435 [Thread-645] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:20,435 [Thread-645] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:20,435 [Thread-645] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:20,435 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:20,436 [Thread-645] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:20,446 [Thread-645] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:20,446 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 39 msecs
2020-04-02 05:06:20,446 [Thread-645] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:20,446 [Thread-645] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:20,447 [Socket Reader #1 for port 32856] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 32856
2020-04-02 05:06:20,451 [Thread-645] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:32856 to access this namenode/service.
2020-04-02 05:06:20,451 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:20,469 [Thread-645] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:20,480 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@662ebb23] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:06:20,482 [Thread-645] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:20,483 [Thread-645] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(607)) - STATE* Safe mode ON. 
The reported blocks 0 has reached the threshold 0.9990 of total blocks 0. The number of live datanodes 0 needs an additional 1 live datanodes to reach the minimum number 1.
Safe mode will be turned off automatically once the thresholds have been reached.
2020-04-02 05:06:20,486 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:20,486 [IPC Server listener on 32856] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 32856: starting
2020-04-02 05:06:20,486 [Thread-645] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:32856
2020-04-02 05:06:20,486 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:20,486 [Thread-645] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:20,487 [Thread-645] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:20,487 [Thread-645] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 32856 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:20,494 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7487801b] DEBUG namenode.FSNamesystem (FSNamesystem.java:run(4098)) - Namenode is in safemode, skipping scrubbing of corrupted lazy-persist files.
2020-04-02 05:06:20,499 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:20,500 [Thread-645] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:20,500 [CacheReplicationMonitor(1498994006)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:20,500 [Thread-645] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:20,500 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:20,501 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:20,501 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:20,501 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:20,501 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:20,501 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 18 msec
2020-04-02 05:06:20,504 [Thread-645] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:20,505 [Thread-645] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:20,505 [Thread-645] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:20,505 [Thread-645] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:20,506 [Thread-645] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:06:20,506 [Thread-645] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:06:20,506 [Thread-645] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:20,506 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,506 [Thread-645] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.heartbeat.interval(1) assuming SECONDS
2020-04-02 05:06:20,506 [Thread-645] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:verifyCanMlock(348)) - LazyPersistTestCase: fake return true
2020-04-02 05:06:20,507 [Thread-645] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:getMemlockLimit(342)) - LazyPersistTestCase: fake return 9223372036854775807
2020-04-02 05:06:20,507 [Thread-645] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 9223372036854775807
2020-04-02 05:06:20,507 [Thread-645] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41701
2020-04-02 05:06:20,507 [Thread-645] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:20,508 [Thread-645] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:20,508 [Thread-645] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:20,508 [Thread-645] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:20,508 [Thread-645] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585803980235.1965697671/TestScrLazyPersistFiles.41701.sock
2020-04-02 05:06:20,509 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:20,512 [Thread-645] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:20,538 [Thread-645] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:20,539 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:20,540 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:20,541 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:20,541 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:20,541 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:20,542 [Thread-645] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37579
2020-04-02 05:06:20,542 [Thread-645] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:20,555 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@557e5287{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:20,556 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2162ee32{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:20,571 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44044b4c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:20,571 [Thread-645] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7e92cb4a{HTTP/1.1,[http/1.1]}{localhost:37579}
2020-04-02 05:06:20,572 [Thread-645] INFO  server.Server (Server.java:doStart(419)) - Started @33443ms
2020-04-02 05:06:20,607 [Thread-645] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40282
2020-04-02 05:06:20,608 [Thread-645] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:20,608 [Thread-645] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:20,609 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6bc13482] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:20,610 [Thread-645] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:20,612 [Socket Reader #1 for port 38981] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38981
2020-04-02 05:06:20,617 [Thread-645] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38981
2020-04-02 05:06:20,658 [Thread-645] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:20,660 [Thread-645] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:20,671 [Thread-701] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32856 starting to offer service
2020-04-02 05:06:20,672 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:20,672 [IPC Server listener on 38981] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38981: starting
2020-04-02 05:06:20,673 [Thread-645] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38981 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:20,692 [Thread-701] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:32856
2020-04-02 05:06:20,699 [Thread-701] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:20,702 [Thread-701] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:20,702 [Thread-701] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1481251138. Formatting...
2020-04-02 05:06:20,702 [Thread-701] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f8b9c5df-a486-4f50-bdf8-9e246244e231 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:20,713 [IPC Server handler 1 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:20,715 [Thread-701] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 8980@8480ff0b2e43
2020-04-02 05:06:20,715 [Thread-701] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1481251138. Formatting...
2020-04-02 05:06:20,715 [Thread-701] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:20,720 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:20,720 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:20,739 [Thread-701] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:20,744 [Thread-701] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:20,744 [Thread-701] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-2049781868-172.17.0.14-1585803980264 is not formatted. Formatting ...
2020-04-02 05:06:20,744 [Thread-701] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049781868-172.17.0.14-1585803980264 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049781868-172.17.0.14-1585803980264/current
2020-04-02 05:06:20,767 [Thread-701] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:20,768 [Thread-701] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:20,768 [Thread-701] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-2049781868-172.17.0.14-1585803980264 is not formatted. Formatting ...
2020-04-02 05:06:20,768 [Thread-701] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2049781868-172.17.0.14-1585803980264 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current
2020-04-02 05:06:20,773 [Thread-701] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1481251138;bpid=BP-2049781868-172.17.0.14-1585803980264;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1481251138;c=1585803980264;bpid=BP-2049781868-172.17.0.14-1585803980264;dnuuid=null
2020-04-02 05:06:20,777 [Thread-701] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 59b30d45-b02b-42c4-9ad4-3f56f5d14926
2020-04-02 05:06:20,778 [Thread-701] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f8b9c5df-a486-4f50-bdf8-9e246244e231
2020-04-02 05:06:20,778 [Thread-701] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [RAM_DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: RAM_DISK
2020-04-02 05:06:20,780 [Thread-701] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d
2020-04-02 05:06:20,780 [Thread-701] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:20,781 [Thread-701] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:20,781 [Thread-701] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:20,784 [Thread-701] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:20,784 [Thread-701] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:20,785 [Thread-701] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:20,799 [Thread-701] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:20,802 [Thread-718] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2049781868-172.17.0.14-1585803980264 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:20,824 [Thread-719] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2049781868-172.17.0.14-1585803980264 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:20,842 [Thread-718] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2049781868-172.17.0.14-1585803980264 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 40ms
2020-04-02 05:06:20,842 [IPC Server handler 2 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:20,846 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:20,846 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:20,857 [Thread-719] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2049781868-172.17.0.14-1585803980264 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 33ms
2020-04-02 05:06:20,857 [Thread-701] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2049781868-172.17.0.14-1585803980264: 59ms
2020-04-02 05:06:20,862 [Thread-722] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2049781868-172.17.0.14-1585803980264 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:20,862 [Thread-722] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049781868-172.17.0.14-1585803980264/current/replicas doesn't exist 
2020-04-02 05:06:20,862 [Thread-723] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2049781868-172.17.0.14-1585803980264 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:20,862 [Thread-723] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current/replicas doesn't exist 
2020-04-02 05:06:20,862 [Thread-722] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2049781868-172.17.0.14-1585803980264 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:06:20,864 [Thread-723] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2049781868-172.17.0.14-1585803980264 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:06:20,864 [Thread-701] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2049781868-172.17.0.14-1585803980264: 6ms
2020-04-02 05:06:20,864 [Thread-701] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:23 AM with interval of 21600000ms
2020-04-02 05:06:20,865 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2049781868-172.17.0.14-1585803980264 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:20,865 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d): finished scanning block pool BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:20,865 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:20,873 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2049781868-172.17.0.14-1585803980264 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:20,874 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f8b9c5df-a486-4f50-bdf8-9e246244e231): finished scanning block pool BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:20,874 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f8b9c5df-a486-4f50-bdf8-9e246244e231): no suitable block pools found to scan.  Waiting 1814399990 ms.
2020-04-02 05:06:20,875 [BP-2049781868-172.17.0.14-1585803980264 heartbeating to localhost/127.0.0.1:32856] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2049781868-172.17.0.14-1585803980264 (Datanode Uuid 59b30d45-b02b-42c4-9ad4-3f56f5d14926) service to localhost/127.0.0.1:32856 beginning handshake with NN
2020-04-02 05:06:20,877 [IPC Server handler 3 on 32856] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41701, datanodeUuid=59b30d45-b02b-42c4-9ad4-3f56f5d14926, infoPort=40282, infoSecurePort=0, ipcPort=38981, storageInfo=lv=-57;cid=testClusterID;nsid=1481251138;c=1585803980264) storage 59b30d45-b02b-42c4-9ad4-3f56f5d14926
2020-04-02 05:06:20,877 [IPC Server handler 3 on 32856] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41701
2020-04-02 05:06:20,877 [IPC Server handler 3 on 32856] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 59b30d45-b02b-42c4-9ad4-3f56f5d14926 (127.0.0.1:41701).
2020-04-02 05:06:20,882 [IPC Server handler 3 on 32856] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(391)) - STATE* Safe mode is OFF
2020-04-02 05:06:20,883 [IPC Server handler 3 on 32856] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:20,883 [IPC Server handler 3 on 32856] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 1 datanodes
2020-04-02 05:06:20,885 [IPC Server handler 3 on 32856] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:20,888 [BP-2049781868-172.17.0.14-1585803980264 heartbeating to localhost/127.0.0.1:32856] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2049781868-172.17.0.14-1585803980264 (Datanode Uuid 59b30d45-b02b-42c4-9ad4-3f56f5d14926) service to localhost/127.0.0.1:32856 successfully registered with NN
2020-04-02 05:06:20,888 [BP-2049781868-172.17.0.14-1585803980264 heartbeating to localhost/127.0.0.1:32856] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:32856 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=1000
2020-04-02 05:06:20,902 [IPC Server handler 4 on 32856] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f8b9c5df-a486-4f50-bdf8-9e246244e231 for DN 127.0.0.1:41701
2020-04-02 05:06:20,902 [IPC Server handler 4 on 32856] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d for DN 127.0.0.1:41701
2020-04-02 05:06:20,907 [IPC Server handler 5 on 32856] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41701, datanodeUuid=59b30d45-b02b-42c4-9ad4-3f56f5d14926, infoPort=40282, infoSecurePort=0, ipcPort=38981, storageInfo=lv=-57;cid=testClusterID;nsid=1481251138;c=1585803980264), reports.length=2
2020-04-02 05:06:20,908 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd3b7c1f56d8a1849: Processing first storage report for DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d from datanode 59b30d45-b02b-42c4-9ad4-3f56f5d14926
2020-04-02 05:06:20,908 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd3b7c1f56d8a1849: from storage DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d node DatanodeRegistration(127.0.0.1:41701, datanodeUuid=59b30d45-b02b-42c4-9ad4-3f56f5d14926, infoPort=40282, infoSecurePort=0, ipcPort=38981, storageInfo=lv=-57;cid=testClusterID;nsid=1481251138;c=1585803980264), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:20,908 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd3b7c1f56d8a1849: Processing first storage report for DS-f8b9c5df-a486-4f50-bdf8-9e246244e231 from datanode 59b30d45-b02b-42c4-9ad4-3f56f5d14926
2020-04-02 05:06:20,908 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd3b7c1f56d8a1849: from storage DS-f8b9c5df-a486-4f50-bdf8-9e246244e231 node DatanodeRegistration(127.0.0.1:41701, datanodeUuid=59b30d45-b02b-42c4-9ad4-3f56f5d14926, infoPort=40282, infoSecurePort=0, ipcPort=38981, storageInfo=lv=-57;cid=testClusterID;nsid=1481251138;c=1585803980264), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:20,908 [IPC Server handler 5 on 32856] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd3b7c1f56d8a1849
2020-04-02 05:06:20,909 [BP-2049781868-172.17.0.14-1585803980264 heartbeating to localhost/127.0.0.1:32856] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd3b7c1f56d8a1849,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:20,909 [BP-2049781868-172.17.0.14-1585803980264 heartbeating to localhost/127.0.0.1:32856] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:20,914 [IPC Server handler 6 on 32856] DEBUG BlockStateChange (NameNodeRpcServer.java:cacheReport(1559)) - *BLOCK* NameNode.cacheReport: from DatanodeRegistration(127.0.0.1:41701, datanodeUuid=59b30d45-b02b-42c4-9ad4-3f56f5d14926, infoPort=40282, infoSecurePort=0, ipcPort=38981, storageInfo=lv=-57;cid=testClusterID;nsid=1481251138;c=1585803980264) 0 blocks
2020-04-02 05:06:20,951 [IPC Server handler 7 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:20,954 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:20,954 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [RAM_DISK]DS-f8b9c5df-a486-4f50-bdf8-9e246244e231
2020-04-02 05:06:20,954 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:setDataNodeStorageCapacities(1758)) - setCapacityForTesting -1 for [DISK]DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d
2020-04-02 05:06:21,060 [IPC Server handler 9 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:21,062 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
init: server=localhost;port=;service=DataNode;localVMUrl=null

Domains:
	Domain = Hadoop
	Domain = JMImplementation
	Domain = com.sun.management
	Domain = java.lang
	Domain = java.nio
	Domain = java.util.logging

MBeanServer default domain = DefaultDomain

MBean count = 49

Query MBeanServer MBeans:
Hadoop service: Hadoop:service=DataNode,name=DataNodeActivity-127.0.0.1-41701
Hadoop service: Hadoop:service=DataNode,name=DataNodeInfo
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
Hadoop service: Hadoop:service=DataNode,name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState
Hadoop service: Hadoop:service=DataNode,name=FSDatasetState-59b30d45-b02b-42c4-9ad4-3f56f5d14926
Hadoop service: Hadoop:service=DataNode,name=JvmMetrics-1
Hadoop service: Hadoop:service=DataNode,name=RpcActivityForPort38981
Hadoop service: Hadoop:service=DataNode,name=RpcDetailedActivityForPort38981
2020-04-02 05:06:21,063 [Thread-645] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:startUpCluster(326)) - Cluster startup complete
2020-04-02 05:06:21,064 [IPC Server handler 0 on 32856] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /doShortCircuitReadMetaFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_799951870_1994 at 127.0.0.1
2020-04-02 05:06:21,064 [IPC Server handler 0 on 32856] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/doShortCircuitReadMetaFileCorruptionTest.01.dat, holder=DFSClient_NONMAPREDUCE_799951870_1994, clientMachine=127.0.0.1, createParent=true, replication=1, createFlag=[CREATE, LAZY_PERSIST], blockSize=5242880, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:06:21,065 [IPC Server handler 0 on 32856] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: doShortCircuitReadMetaFileCorruptionTest.01.dat is added
2020-04-02 05:06:21,067 [IPC Server handler 0 on 32856] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /doShortCircuitReadMetaFileCorruptionTest.01.dat inode 16386 DFSClient_NONMAPREDUCE_799951870_1994
2020-04-02 05:06:21,068 [IPC Server handler 0 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:21,087 [IPC Server handler 1 on 32856] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /doShortCircuitReadMetaFileCorruptionTest.01.dat  inodeId 16386 for DFSClient_NONMAPREDUCE_799951870_1994
2020-04-02 05:06:21,088 [IPC Server handler 1 on 32856] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /doShortCircuitReadMetaFileCorruptionTest.01.dat with blk_1073741825_1001 block is added to the in-memory file system
2020-04-02 05:06:21,088 [IPC Server handler 1 on 32856] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:41701 for /doShortCircuitReadMetaFileCorruptionTest.01.dat
2020-04-02 05:06:21,088 [IPC Server handler 1 on 32856] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /doShortCircuitReadMetaFileCorruptionTest.01.dat with new block blk_1073741825_1001, current total block count is 1
2020-04-02 05:06:21,100 [DataXceiver for client DFSClient_NONMAPREDUCE_799951870_1994 at /127.0.0.1:38370 [Receiving block BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001 src: /127.0.0.1:38370 dest: /127.0.0.1:41701
2020-04-02 05:06:21,130 [PacketResponder: BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001, type=LAST_IN_PIPELINE] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:moveBlockFiles(885)) - addFinalizedBlock: Moved file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049781868-172.17.0.14-1585803980264/current/rbw/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049781868-172.17.0.14-1585803980264/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta and file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049781868-172.17.0.14-1585803980264/current/rbw/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049781868-172.17.0.14-1585803980264/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:21,141 [PacketResponder: BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38370, dest: /127.0.0.1:41701, bytes: 5242880, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_799951870_1994, offset: 0, srvID: 59b30d45-b02b-42c4-9ad4-3f56f5d14926, blockid: BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001, duration(ns): 27193426
2020-04-02 05:06:21,142 [PacketResponder: BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:21,142 [IPC Server handler 3 on 32856] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41701, datanodeUuid=59b30d45-b02b-42c4-9ad4-3f56f5d14926, infoPort=40282, infoSecurePort=0, ipcPort=38981, storageInfo=lv=-57;cid=testClusterID;nsid=1481251138;c=1585803980264) 1 blocks.
2020-04-02 05:06:21,146 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:41701 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:21,146 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:21,146 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41701 is added to blk_1073741825_1001 (size=0)
2020-04-02 05:06:21,146 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:41701
2020-04-02 05:06:21,146 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41701 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:21,146 [IPC Server handler 4 on 32856] INFO  hdfs.StateChange (FSNamesystem.java:fsync(3274)) - BLOCK* fsync: /doShortCircuitReadMetaFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_799951870_1994
2020-04-02 05:06:21,147 [IPC Server handler 4 on 32856] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistBlocks(112)) - persistBlocks: /doShortCircuitReadMetaFileCorruptionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:21,148 [IPC Server handler 5 on 32856] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /doShortCircuitReadMetaFileCorruptionTest.01.dat for DFSClient_NONMAPREDUCE_799951870_1994
2020-04-02 05:06:21,149 [IPC Server handler 5 on 32856] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /doShortCircuitReadMetaFileCorruptionTest.01.dat with 1 blocks is persisted to the file system
2020-04-02 05:06:21,150 [IPC Server handler 5 on 32856] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /doShortCircuitReadMetaFileCorruptionTest.01.dat is closed by DFSClient_NONMAPREDUCE_799951870_1994
2020-04-02 05:06:21,151 [Thread-645] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadMetaFileCorruptionTest.01.dat is on StorageType: RAM_DISK
2020-04-02 05:06:21,152 [IPC Server handler 6 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:21,158 [IPC Server handler 7 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:21,159 [IPC Server handler 8 on 32856] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:21,160 [IPC Server handler 8 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:21,162 [IPC Server handler 9 on 32856] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:21,162 [IPC Server handler 9 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:0
2020-04-02 05:06:21,164 [Thread-645] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 0
2020-04-02 05:06:21,784 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@4874db4e] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:saveNextReplica(3108)) - LazyWriter: Start persisting RamDisk block: block pool Id: BP-2049781868-172.17.0.14-1585803980264 block id: 1073741825 on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:21,795 [Async RamDisk lazy persist worker  for volume with id DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:copyBlockFiles(931)) - Copied file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049781868-172.17.0.14-1585803980264/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta and calculated checksum
2020-04-02 05:06:21,795 [Async RamDisk lazy persist worker  for volume with id DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:onCompleteLazyPersist(2969)) - LazyWriter: Finish persisting RamDisk block:  block pool Id: BP-2049781868-172.17.0.14-1585803980264 block id: 1073741825 to block file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current/lazypersist/subdir0/subdir0/blk_1073741825 and meta file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta on target volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
Info: key = RamDiskBlocksLazyPersisted; val = class java.lang.Long:1
2020-04-02 05:06:22,165 [Thread-645] INFO  hdfs.DFSTestUtil (DFSTestUtil.java:get(2275)) - Waiting for RamDiskBlocksLazyPersisted to reach value 1, current value = 1
2020-04-02 05:06:22,166 [Thread-645] DEBUG impl.FsDatasetImpl (FsDatasetImpl.java:evictBlocks(3151)) - Evicting block [BlockPoolID=BP-2049781868-172.17.0.14-1585803980264; BlockId=1073741825]
2020-04-02 05:06:22,176 [Thread-645] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(382)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current/lazypersist/subdir0/subdir0/blk_1073741825 to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:06:22,177 [Thread-645] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:activateSavedReplica(384)) - Moved /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current/lazypersist/subdir0/subdir0/blk_1073741825_1001.meta to /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta
2020-04-02 05:06:22,178 [IPC Server handler 0 on 32856] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41701, datanodeUuid=59b30d45-b02b-42c4-9ad4-3f56f5d14926, infoPort=40282, infoSecurePort=0, ipcPort=38981, storageInfo=lv=-57;cid=testClusterID;nsid=1481251138;c=1585803980264) 1 blocks.
2020-04-02 05:06:22,180 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_1073741825_1001 on 127.0.0.1:41701 size 5242880 replicaState = FINALIZED
2020-04-02 05:06:22,180 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:22,180 [Block report processor] WARN  BlockStateChange (BlockManager.java:addStoredBlock(3248)) - BLOCK* addStoredBlock: block blk_1073741825_1001 moved to storageType DISK on node 127.0.0.1:41701
2020-04-02 05:06:22,180 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_1073741825_1001 is received from 127.0.0.1:41701
2020-04-02 05:06:22,180 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41701 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:22,181 [Thread-645] INFO  impl.LazyPersistTestCase (LazyPersistTestCase.java:ensureFileReplicasOnStorageType(136)) - Ensure path: /doShortCircuitReadMetaFileCorruptionTest.01.dat is on StorageType: DISK
2020-04-02 05:06:22,182 [IPC Server handler 1 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,184 [IPC Server handler 2 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,185 [IPC Server handler 3 on 32856] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:22,185 [IPC Server handler 3 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,194 [IPC Server handler 4 on 32856] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:22,194 [IPC Server handler 4 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,198 [IPC Server handler 5 on 32856] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:22,199 [IPC Server handler 5 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,218 [DataXceiver for client unix:/tmp/socks.1585803980235.1965697671/TestScrLazyPersistFiles.41701.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_799951870_1994, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: 0d273c78bef7367ac3b409b700875700, srvID: 59b30d45-b02b-42c4-9ad4-3f56f5d14926, success: true
2020-04-02 05:06:22,242 [DataXceiver for client unix:/tmp/socks.1585803980235.1965697671/TestScrLazyPersistFiles.41701.sock [Passing file descriptors for block BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 59b30d45-b02b-42c4-9ad4-3f56f5d14926, success: true
2020-04-02 05:06:22,275 [Thread-645] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptMeta(160)) - Corrupting meta file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264/current/finalized/subdir0/subdir0/blk_1073741825_1001.meta
2020-04-02 05:06:22,277 [IPC Server handler 6 on 32856] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:22,278 [IPC Server handler 6 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:22,294 [Thread-645] WARN  hdfs.DFSClient (DFSInputStream.java:readBuffer(706)) - Found Checksum error for BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001 from DatanodeInfoWithStorage[127.0.0.1:41701,DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d,DISK] at 2308608
2020-04-02 05:06:22,294 [Thread-645] WARN  hdfs.DFSClient (DFSInputStream.java:reportLostBlock(959)) - No live nodes contain block BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:41701,DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d,DISK]], ignoredNodes = null
2020-04-02 05:06:22,294 [Thread-645] INFO  hdfs.DFSClient (DFSInputStream.java:refetchLocations(882)) - Could not obtain BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:41701,DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d,DISK] Dead nodes:  DatanodeInfoWithStorage[127.0.0.1:41701,DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d,DISK]. Will get new block locations from namenode and retry...
2020-04-02 05:06:22,294 [Thread-645] WARN  hdfs.DFSClient (DFSInputStream.java:refetchLocations(901)) - DFS chooseDataNode: got # 1 IOException, will wait for 2991.7526562003513 msec.
2020-04-02 05:06:23,502 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:25,287 [IPC Server handler 7 on 32856] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_1073741825_1001]
2020-04-02 05:06:25,287 [IPC Server handler 7 on 32856] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/doShortCircuitReadMetaFileCorruptionTest.01.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:06:25,291 [IPC Server handler 8 on 32856] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-2049781868-172.17.0.14-1585803980264:blk_1073741825_1001 on datanode: 127.0.0.1:41701
2020-04-02 05:06:25,291 [IPC Server handler 8 on 32856] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_1073741825_1001 added as corrupt on 127.0.0.1:41701 by /127.0.0.1  because client machine reported it
2020-04-02 05:06:25,291 [IPC Server handler 8 on 32856] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_1073741825_1001 curReplicas 0 curExpectedReplicas 1 oldReplicas 1 oldExpectedReplicas  1 curPri  4 oldPri  3
2020-04-02 05:06:25,291 [IPC Server handler 8 on 32856] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_1073741825_1001 has only 0 replicas and needs 1 replicas so is added to neededReconstructions at priority level 4
List of the keys matching ^RamDisk :
>>>>>>>>jmx name: name=DataNodeActivity-127.0.0.1-41701,service=DataNode
RamDiskBlocksWrite=1
RamDiskBlocksWriteFallback=0
RamDiskBytesWrite=5242880
RamDiskBlocksReadHits=0
RamDiskBlocksEvicted=1
RamDiskBlocksEvictedWithoutRead=1
RamDiskBlocksEvictionWindowMsNumOps=1
RamDiskBlocksEvictionWindowMsAvgTime=1037.0
RamDiskBlocksLazyPersisted=1
RamDiskBlocksDeletedBeforeLazyPersisted=0
RamDiskBytesLazyPersisted=5242880
RamDiskBlocksLazyPersistWindowMsNumOps=1
RamDiskBlocksLazyPersistWindowMsAvgTime=655.0
>>>>>>>>jmx name: name=DataNodeInfo,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,service=DataNode
>>>>>>>>jmx name: name=DataNodeVolume-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState,service=DataNode
>>>>>>>>jmx name: name=FSDatasetState-59b30d45-b02b-42c4-9ad4-3f56f5d14926,service=DataNode
>>>>>>>>jmx name: name=JvmMetrics-1,service=DataNode
>>>>>>>>jmx name: name=RpcActivityForPort38981,service=DataNode
>>>>>>>>jmx name: name=RpcDetailedActivityForPort38981,service=DataNode
2020-04-02 05:06:25,302 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:25,302 [Thread-645] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38981 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:25,302 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@68e3cc0d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:25,302 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4f42d1d8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:25,312 [Thread-645] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:25,313 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-0c2a3f82-601a-44f0-a70e-4d89cb1d5b4d) exiting.
2020-04-02 05:06:25,313 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-f8b9c5df-a486-4f50-bdf8-9e246244e231) exiting.
2020-04-02 05:06:25,346 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@44044b4c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:25,352 [Thread-645] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7e92cb4a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:25,363 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2162ee32{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:25,363 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@557e5287{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:25,367 [Thread-645] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38981
2020-04-02 05:06:25,370 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:25,370 [IPC Server listener on 38981] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38981
2020-04-02 05:06:25,370 [BP-2049781868-172.17.0.14-1585803980264 heartbeating to localhost/127.0.0.1:32856] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:25,371 [BP-2049781868-172.17.0.14-1585803980264 heartbeating to localhost/127.0.0.1:32856] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2049781868-172.17.0.14-1585803980264 (Datanode Uuid 59b30d45-b02b-42c4-9ad4-3f56f5d14926) service to localhost/127.0.0.1:32856
2020-04-02 05:06:25,371 [BP-2049781868-172.17.0.14-1585803980264 heartbeating to localhost/127.0.0.1:32856] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2049781868-172.17.0.14-1585803980264 (Datanode Uuid 59b30d45-b02b-42c4-9ad4-3f56f5d14926)
2020-04-02 05:06:25,371 [BP-2049781868-172.17.0.14-1585803980264 heartbeating to localhost/127.0.0.1:32856] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2049781868-172.17.0.14-1585803980264
2020-04-02 05:06:25,389 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2049781868-172.17.0.14-1585803980264] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:25,445 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2049781868-172.17.0.14-1585803980264] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:25,450 [org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl$LazyWriter@4874db4e] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:run(3203)) - LazyWriter was interrupted, exiting
2020-04-02 05:06:25,451 [Thread-645] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:25,454 [Thread-645] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:25,454 [Thread-645] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:25,454 [Thread-645] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:25,455 [Thread-645] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:25,455 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:25,455 [Thread-645] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:25,455 [Thread-645] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 32856 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:25,455 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:25,456 [org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor@2d733f27] DEBUG namenode.LeaseManager (LeaseManager.java:run(536)) - Monitor is interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.LeaseManager$Monitor.run(LeaseManager.java:534)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:25,456 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7487801b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:25,456 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@648cb7c9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:25,456 [Thread-645] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:06:25,457 [Thread-645] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 2 Number of syncs: 7 SyncTimes(ms): 2 1 
2020-04-02 05:06:25,458 [Thread-645] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:25,458 [Thread-645] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:06:25,458 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:25,459 [Thread-645] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 32856
2020-04-02 05:06:25,461 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:25,461 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:25,461 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:25,461 [CacheReplicationMonitor(1498994006)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:25,465 [IPC Server listener on 32856] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 32856
2020-04-02 05:06:25,471 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@662ebb23] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:25,479 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:25,479 [Thread-645] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:25,481 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@39133f03{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:25,491 [Thread-645] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c9b49ab{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:25,492 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30b88784{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:25,492 [Thread-645] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d8625de{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:25,504 [Thread-645] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:25,505 [Thread-645] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:25,505 [Thread-645] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testScrMetaFileCorruption
[msx] writeFile testName = org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.TestScrLazyPersistFiles#testScrMetaFileCorruption
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] all testRunFinished

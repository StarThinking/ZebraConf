[msx] before_class
2020-04-02 05:02:57,306 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-04-02 05:02:57,324 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(874)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-04-02 05:02:57,325 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(880)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-04-02 05:02:58,277 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:02:58,299 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:02:58,301 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:02:58,303 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:02:58,312 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:02:58,313 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:02:58,313 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:02:58,319 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:02:58,320 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:02:58,381 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:02:58,387 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:02:58,388 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:02:58,388 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:02:58,397 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:02:58,398 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:02:58
2020-04-02 05:02:58,413 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:02:58,413 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:02:58,416 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:02:58,416 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:02:58,458 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:02:58,469 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:02:58,469 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:02:58,470 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:02:58,470 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:02:58,471 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:02:58,471 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:02:58,471 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:02:58,472 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:02:58,472 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:02:58,472 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:02:58,473 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:02:58,517 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:02:58,540 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:02:58,540 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:02:58,541 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:02:58,541 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:02:58,547 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:02:58,547 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:02:58,548 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:02:58,548 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:02:58,554 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:02:58,558 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:02:58,565 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:02:58,571 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:02:58,572 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:02:58,573 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:02:58,588 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:02:58,588 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:02:58,589 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:02:58,595 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:02:58,596 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:02:58,598 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:02:58,599 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:02:58,600 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:02:58,600 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:02:58,660 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:02:58,679 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:02:58,683 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:02:58,685 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-04-02 05:02:58,709 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:02:58,714 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:02:58,854 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:02:58,866 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:02:58,889 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:02:58,989 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-04-02 05:02:59,016 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-04-02 05:02:59,022 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:02:59,513 [JUnit] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:02:59,621 [JUnit] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:02:59,717 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:02:59,718 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:02:59,731 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:02:59,740 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:02:59,741 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:02:59,810 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@70cf32e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:02:59,825 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:02:59,841 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3952ms
2020-04-02 05:02:59,946 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:02:59,954 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:02:59,974 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:02:59,977 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:02:59,978 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:02:59,978 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:00,010 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:00,011 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:00,020 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33494
2020-04-02 05:03:00,023 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:00,097 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a82c5f1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:00,099 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51c693d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:00,204 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71e9ebae{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:00,214 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5ef5c734{HTTP/1.1,[http/1.1]}{localhost:33494}
2020-04-02 05:03:00,215 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4326ms
2020-04-02 05:03:00,228 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:00,229 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:00,231 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:00,232 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:00,232 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:00,233 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:00,233 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:00,234 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:00,235 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:00,235 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:00,236 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:00,246 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:00,247 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:00,249 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:00
2020-04-02 05:03:00,249 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:00,250 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:00,251 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:00,251 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:00,262 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:00,263 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:00,263 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:00,263 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:00,264 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:00,264 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:00,264 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:00,264 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:00,264 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:00,264 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:00,265 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:00,265 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:00,265 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:00,269 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:00,270 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:00,270 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:00,271 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:00,271 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:00,272 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:00,272 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:00,272 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:00,272 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:00,272 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:00,272 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:00,272 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:00,273 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:00,274 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:00,274 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:00,275 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:00,275 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:00,275 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:00,276 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:00,276 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:00,276 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:00,276 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:00,286 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:00,294 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:00,295 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:00,299 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:00,300 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:00,362 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:00,371 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:00,372 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:03:00,378 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:00,379 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:00,380 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 101 msecs
2020-04-02 05:03:00,572 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:00,584 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:00,600 [Socket Reader #1 for port 46813] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46813
2020-04-02 05:03:00,881 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:00,910 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:00,922 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:00,923 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:00,923 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:00,961 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:00,961 [IPC Server listener on 46813] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46813: starting
2020-04-02 05:03:01,060 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:46813
2020-04-02 05:03:01,063 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:01,065 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:01,065 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:01,066 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 46813 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:01,069 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:01,073 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:01,074 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:01,074 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:01,075 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:03:01,094 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:01,097 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1698fc68] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:01,097 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:01,099 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:01,109 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:01,115 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:01,121 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:01,121 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:01,123 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:01,124 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:01,124 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44248
2020-04-02 05:03:01,125 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:01,129 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b5825fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:01,130 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2cae1042{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:01,138 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f2f9244{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:01,139 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4c4d27c8{HTTP/1.1,[http/1.1]}{localhost:44248}
2020-04-02 05:03:01,139 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5251ms
2020-04-02 05:03:01,141 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:01,142 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:01,142 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:01,143 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:01,143 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:01,143 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:01,144 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:01,144 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:01,144 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:01,145 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:01,145 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:01,145 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:01,146 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:01,146 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:01
2020-04-02 05:03:01,147 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:01,147 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,147 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:01,147 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:01,178 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:01,179 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:01,179 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:01,180 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:01,180 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:01,180 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:01,181 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:01,181 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:01,182 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:01,182 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:01,183 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:01,183 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:01,184 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:01,184 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,185 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:01,185 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:01,193 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:01,193 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:01,194 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:01,195 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:01,195 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:01,196 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:01,196 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:01,197 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,197 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:01,198 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:01,200 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:01,203 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:01,204 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:01,205 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:01,205 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:01,205 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:01,206 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,206 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:01,207 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:01,214 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:01,216 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:01,217 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:01,219 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:01,220 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:01,241 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:01,243 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:01,244 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-04-02 05:03:01,244 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:01,245 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:01,245 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 37 msecs
2020-04-02 05:03:01,246 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:01,247 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:01,249 [Socket Reader #1 for port 42275] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42275
2020-04-02 05:03:01,261 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:01,295 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:01,315 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:01,315 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:01,316 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:01,329 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:01,330 [IPC Server listener on 42275] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42275: starting
2020-04-02 05:03:01,332 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:42275
2020-04-02 05:03:01,333 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:01,333 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:01,333 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:01,334 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 42275 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
Formatting using clusterid: testClusterID
2020-04-02 05:03:01,338 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:01,339 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:01,339 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:01,339 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:01,340 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:01,340 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:01,340 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:01,341 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:01,341 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:01,341 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:01,342 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:01,342 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:01,343 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:01,343 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:01
2020-04-02 05:03:01,344 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:01,344 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,344 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:01,344 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:01,360 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:01,361 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:01,362 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:01,362 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:01,362 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:01,364 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:01,364 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:01,364 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:01,364 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:01,365 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:01,365 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:01,365 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:01,366 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:01,366 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,366 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:01,367 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:01,373 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:01,373 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:01,374 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:01,374 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:01,374 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:01,374 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:01,374 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:01,374 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,375 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:01,375 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:01,377 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:01,377 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:01,377 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:01,377 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:01,378 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:01,378 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:01,378 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,378 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:01,379 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:01,382 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:01,385 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-04-02 05:03:01,387 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-04-02 05:03:01,390 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-04-02 05:03:01,392 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:01,392 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:01,400 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:01,401 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:01,404 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:01,412 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-04-02 05:03:01,415 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-04-02 05:03:01,419 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:01,420 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:01,420 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:01,421 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:01,421 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:01,428 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@662f5666] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:01,428 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:01,453 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:01,463 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:01,481 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:01,483 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:01,483 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:01,483 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:01,485 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:01,486 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:01,486 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38713
2020-04-02 05:03:01,486 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:01,489 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f8f9349{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:01,490 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7446d8d5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:01,500 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@590c73d3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:01,501 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b9ce1bf{HTTP/1.1,[http/1.1]}{localhost:38713}
2020-04-02 05:03:01,502 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5613ms
2020-04-02 05:03:01,504 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:01,505 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:01,505 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:01,519 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:01,520 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:01,520 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:01,520 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:01,521 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:01,521 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:01,521 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:01,521 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:01,522 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:01,522 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:01,522 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:01
2020-04-02 05:03:01,522 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:01,523 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,523 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:01,523 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:01,555 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:01,555 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:01,555 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:01,555 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:01,556 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:01,556 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:01,556 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:01,556 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:01,556 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:01,556 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:01,556 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:01,556 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:01,557 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:01,557 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,557 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:01,557 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:01,565 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:01,566 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:01,566 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:01,567 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:01,567 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:01,567 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:01,567 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:01,568 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,568 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:01,568 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:01,570 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:01,570 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:01,570 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:01,571 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:01,571 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:01,571 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:01,571 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,571 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:01,572 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:01,575 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:01,576 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:01,577 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:01,579 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:01,581 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:01,583 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:01,584 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:01,584 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-04-02 05:03:01,584 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:01,585 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:01,585 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 12 msecs
2020-04-02 05:03:01,585 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:01,586 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:01,587 [Socket Reader #1 for port 40185] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40185
2020-04-02 05:03:01,592 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:01,632 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:01,634 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:01,635 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:01,635 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:01,644 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:01,649 [IPC Server listener on 40185] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40185: starting
2020-04-02 05:03:01,651 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:40185
2020-04-02 05:03:01,652 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:01,652 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:01,652 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:01,653 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 40185 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:01,656 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:01,682 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:01,682 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:01,683 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:01,684 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:01,702 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:01,706 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:01,708 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36546a22] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:01,722 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:01,724 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:01,725 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:01,726 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:01,726 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:01,728 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:01,728 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:01,728 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42095
2020-04-02 05:03:01,729 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:01,736 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@47605f2f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:01,737 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1dd0e7c4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:01,763 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@650eab8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:01,778 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30f5a68a{HTTP/1.1,[http/1.1]}{localhost:42095}
2020-04-02 05:03:01,779 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5890ms
2020-04-02 05:03:01,803 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:01,809 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:01,809 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:01,810 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:01,810 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:01,811 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:01,811 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:01,811 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:01,811 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:01,812 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:01,813 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:01,813 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:01,814 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:01,814 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:01
2020-04-02 05:03:01,815 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:01,815 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,815 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:01,815 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:01,829 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:01,834 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:01,834 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:01,835 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:01,835 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:01,835 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:01,835 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:01,835 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:01,836 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:01,836 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:01,836 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:01,836 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:01,837 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:01,840 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,840 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:01,841 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:01,848 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:01,848 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:01,848 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:01,849 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:01,849 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:01,849 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:01,849 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:01,850 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,850 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:01,850 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:01,852 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:01,853 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:01,853 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:01,853 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:01,853 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:01,853 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:01,853 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,854 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:01,854 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:01,857 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:01,858 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:01,859 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:01,862 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:01,862 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:01,865 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:01,865 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:01,866 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-04-02 05:03:01,866 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:01,866 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:01,867 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 11 msecs
2020-04-02 05:03:01,867 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:01,868 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:01,869 [Socket Reader #1 for port 38894] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38894
2020-04-02 05:03:01,875 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:02,128 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:02,135 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:02,135 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:02,135 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:02,143 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:02,144 [IPC Server listener on 38894] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38894: starting
2020-04-02 05:03:02,146 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38894
2020-04-02 05:03:02,147 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:02,147 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:02,147 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:02,147 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38894 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:02,159 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:02,181 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:02,206 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:02,208 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:02,209 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:02,216 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:02,219 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:02,222 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:02,224 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:02,228 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:02,235 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46108
2020-04-02 05:03:02,238 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:02,238 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:02,256 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:02,257 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:02,259 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:02,260 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:02,260 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:02,260 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:02,264 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39566
2020-04-02 05:03:02,265 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:02,267 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@38f57b3d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:02,268 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3ce3db41{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:02,280 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1d7f7be7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:02,281 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42f3156d{HTTP/1.1,[http/1.1]}{localhost:39566}
2020-04-02 05:03:02,281 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6392ms
2020-04-02 05:03:03,065 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37279
2020-04-02 05:03:03,071 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:03,072 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:03,074 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6928f576] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:03,093 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:03,094 [Socket Reader #1 for port 42361] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42361
2020-04-02 05:03:03,110 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42361
2020-04-02 05:03:03,130 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:03,133 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:03,145 [Thread-154] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42275 starting to offer service
2020-04-02 05:03:03,145 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38894 starting to offer service
2020-04-02 05:03:03,145 [Thread-153] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46813 starting to offer service
2020-04-02 05:03:03,145 [Thread-155] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40185 starting to offer service
2020-04-02 05:03:03,182 [IPC Server listener on 42361] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42361: starting
2020-04-02 05:03:03,184 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42361 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:03,186 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:03,187 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:03,195 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:03,196 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:03,198 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:03,199 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:03,199 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:03,199 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:03,200 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:03,200 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:03,200 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:03,201 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44103
2020-04-02 05:03:03,201 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:03,201 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:03,205 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:03,210 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:03,212 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:03,213 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:03,213 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:03,213 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:03,214 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40359
2020-04-02 05:03:03,214 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:03,217 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@466cf502{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:03,218 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e185cd7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:03,294 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4b629f13{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:03,294 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70925b45{HTTP/1.1,[http/1.1]}{localhost:40359}
2020-04-02 05:03:03,303 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7414ms
2020-04-02 05:03:03,442 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36564
2020-04-02 05:03:03,443 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:03,443 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@aa22f1c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:03,443 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:03,444 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:03,447 [Socket Reader #1 for port 43464] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43464
2020-04-02 05:03:03,470 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43464
2020-04-02 05:03:03,475 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:03,476 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:03,481 [Thread-182] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38894 starting to offer service
2020-04-02 05:03:03,481 [Thread-180] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42275 starting to offer service
2020-04-02 05:03:03,481 [Thread-181] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40185 starting to offer service
2020-04-02 05:03:03,482 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:03,482 [IPC Server listener on 43464] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43464: starting
2020-04-02 05:03:03,484 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43464 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:03,484 [Thread-179] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46813 starting to offer service
2020-04-02 05:03:03,486 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:03,487 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:03,506 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:03,516 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:03,516 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:03,516 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:03,517 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:03,517 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:03,517 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:03,518 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:03,518 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38153
2020-04-02 05:03:03,519 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:03,519 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:03,525 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:03,526 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:03,528 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:03,529 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:03,562 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:03,562 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:03,575 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41006
2020-04-02 05:03:03,575 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:03,578 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@226f885f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:03,581 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d61eccf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:03,644 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5aa0dbf4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:03,645 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@16afbd92{HTTP/1.1,[http/1.1]}{localhost:41006}
2020-04-02 05:03:03,645 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7756ms
2020-04-02 05:03:03,672 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46496
2020-04-02 05:03:03,673 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:03,673 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:03,673 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:03,674 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7fe083b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:03,691 [Socket Reader #1 for port 38173] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38173
2020-04-02 05:03:03,701 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38173
2020-04-02 05:03:03,712 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:03,712 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:03,718 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46813 starting to offer service
2020-04-02 05:03:03,722 [Thread-213] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42275 starting to offer service
2020-04-02 05:03:03,726 [Thread-214] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40185 starting to offer service
2020-04-02 05:03:03,727 [Thread-215] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38894 starting to offer service
2020-04-02 05:03:03,728 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:03,729 [IPC Server listener on 38173] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38173: starting
2020-04-02 05:03:03,739 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38173 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:03,740 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:03,743 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:03,743 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:03,774 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:03,774 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:03,778 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:03,778 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:03,779 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:03,779 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:03,780 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:03,780 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46193
2020-04-02 05:03:03,780 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:03,781 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:03,785 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:03,792 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:03,794 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:03,795 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:03,795 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:03,795 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:03,796 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45974
2020-04-02 05:03:03,796 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:03,801 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21a5fd96{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:03,806 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c77053b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:03,817 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@40f33492{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:03,818 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4fbdc0f0{HTTP/1.1,[http/1.1]}{localhost:45974}
2020-04-02 05:03:03,826 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7937ms
2020-04-02 05:03:03,939 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44866
2020-04-02 05:03:03,940 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:03,940 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6bc28a83] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:03,940 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:03,941 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:03,941 [Socket Reader #1 for port 42790] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42790
2020-04-02 05:03:03,945 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42790
2020-04-02 05:03:03,950 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:03,950 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:03,952 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:46813 starting to offer service
2020-04-02 05:03:03,958 [Thread-239] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42275 starting to offer service
2020-04-02 05:03:03,973 [Thread-240] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40185 starting to offer service
2020-04-02 05:03:03,975 [Thread-241] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38894 starting to offer service
2020-04-02 05:03:03,975 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:03,977 [IPC Server listener on 42790] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42790: starting
2020-04-02 05:03:03,978 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42790 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:04,105 [Thread-180] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:04,110 [Thread-153] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:04,116 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:04,117 [Thread-238] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:04,118 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 1686742628. Formatting...
2020-04-02 05:03:04,119 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-463245ea-463e-41df-9547-82aea6f6d88b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-04-02 05:03:04,122 [Thread-214] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:04,123 [Thread-238] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:04,123 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 1686742628. Formatting...
2020-04-02 05:03:04,123 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-b90586b0-20e9-4801-bddd-bf33068c13b5 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-04-02 05:03:04,124 [Thread-180] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:04,124 [Thread-180] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 1686742628. Formatting...
2020-04-02 05:03:04,124 [Thread-153] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:04,124 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 1686742628. Formatting...
2020-04-02 05:03:04,124 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8f16e333-ad2c-4377-a519-3e818936f550 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-04-02 05:03:04,125 [Thread-180] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-04-02 05:03:04,130 [Thread-153] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:04,131 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 1686742628. Formatting...
2020-04-02 05:03:04,131 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-04-02 05:03:04,132 [Thread-214] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:04,132 [Thread-214] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 490816991. Formatting...
2020-04-02 05:03:04,134 [Thread-214] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c2fdd593-c43d-47a3-9363-412b7536a916 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-04-02 05:03:04,137 [Thread-180] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:04,138 [Thread-180] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 1686742628. Formatting...
2020-04-02 05:03:04,142 [Thread-180] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6f930f92-d816-4306-b152-eb38ffffd576 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-04-02 05:03:04,143 [Thread-214] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 3713@b1fc8b48a924
2020-04-02 05:03:04,143 [Thread-214] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 490816991. Formatting...
2020-04-02 05:03:04,143 [Thread-214] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-04-02 05:03:04,160 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,169 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,170 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-521900919-172.17.0.15-1585803778640 is not formatted. Formatting ...
2020-04-02 05:03:04,170 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-521900919-172.17.0.15-1585803778640 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-521900919-172.17.0.15-1585803778640/current
2020-04-02 05:03:04,176 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,176 [Thread-238] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,161 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,177 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-521900919-172.17.0.15-1585803778640 is not formatted. Formatting ...
2020-04-02 05:03:04,178 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-521900919-172.17.0.15-1585803778640 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-521900919-172.17.0.15-1585803778640/current
2020-04-02 05:03:04,176 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,179 [Thread-180] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,179 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-521900919-172.17.0.15-1585803778640 is not formatted. Formatting ...
2020-04-02 05:03:04,180 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-521900919-172.17.0.15-1585803778640 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-521900919-172.17.0.15-1585803778640/current
2020-04-02 05:03:04,177 [Thread-214] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,180 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1256569654-172.17.0.15-1585803781382 is not formatted. Formatting ...
2020-04-02 05:03:04,184 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,185 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1256569654-172.17.0.15-1585803781382 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1256569654-172.17.0.15-1585803781382/current
2020-04-02 05:03:04,186 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,186 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-521900919-172.17.0.15-1585803778640 is not formatted. Formatting ...
2020-04-02 05:03:04,186 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-521900919-172.17.0.15-1585803778640 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-521900919-172.17.0.15-1585803778640/current
2020-04-02 05:03:04,197 [Thread-155] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:04,197 [Thread-153] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1686742628;bpid=BP-521900919-172.17.0.15-1585803778640;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1686742628;c=1585803778640;bpid=BP-521900919-172.17.0.15-1585803778640;dnuuid=null
2020-04-02 05:03:04,197 [Thread-155] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-04-02 05:03:04,198 [Thread-155] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-04-02 05:03:04,199 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,199 [Thread-238] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,199 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-521900919-172.17.0.15-1585803778640 is not formatted. Formatting ...
2020-04-02 05:03:04,199 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-521900919-172.17.0.15-1585803778640 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-521900919-172.17.0.15-1585803778640/current
2020-04-02 05:03:04,204 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1686742628;bpid=BP-521900919-172.17.0.15-1585803778640;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1686742628;c=1585803778640;bpid=BP-521900919-172.17.0.15-1585803778640;dnuuid=null
2020-04-02 05:03:04,206 [Thread-241] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:04,207 [Thread-241] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-04-02 05:03:04,207 [Thread-241] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-04-02 05:03:04,208 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,208 [Thread-214] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,209 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1256569654-172.17.0.15-1585803781382 is not formatted. Formatting ...
2020-04-02 05:03:04,209 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1256569654-172.17.0.15-1585803781382 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1256569654-172.17.0.15-1585803781382/current
2020-04-02 05:03:04,228 [Thread-155] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,228 [Thread-155] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,229 [Thread-155] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1256569654-172.17.0.15-1585803781382 is not formatted. Formatting ...
2020-04-02 05:03:04,229 [Thread-155] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1256569654-172.17.0.15-1585803781382 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1256569654-172.17.0.15-1585803781382/current
2020-04-02 05:03:04,230 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,230 [Thread-180] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,231 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-521900919-172.17.0.15-1585803778640 is not formatted. Formatting ...
2020-04-02 05:03:04,231 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-521900919-172.17.0.15-1585803778640 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-521900919-172.17.0.15-1585803778640/current
2020-04-02 05:03:04,238 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,239 [Thread-241] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,239 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1256569654-172.17.0.15-1585803781382 is not formatted. Formatting ...
2020-04-02 05:03:04,239 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1256569654-172.17.0.15-1585803781382 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1256569654-172.17.0.15-1585803781382/current
2020-04-02 05:03:04,241 [Thread-180] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1686742628;bpid=BP-521900919-172.17.0.15-1585803778640;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1686742628;c=1585803778640;bpid=BP-521900919-172.17.0.15-1585803778640;dnuuid=null
2020-04-02 05:03:04,251 [Thread-182] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:04,251 [Thread-182] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-04-02 05:03:04,251 [Thread-182] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-04-02 05:03:04,258 [Thread-214] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=490816991;bpid=BP-1256569654-172.17.0.15-1585803781382;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=490816991;c=1585803781382;bpid=BP-1256569654-172.17.0.15-1585803781382;dnuuid=null
2020-04-02 05:03:04,271 [Thread-214] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:04,272 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,281 [Thread-182] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,281 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1256569654-172.17.0.15-1585803781382 is not formatted. Formatting ...
2020-04-02 05:03:04,282 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1256569654-172.17.0.15-1585803781382 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1256569654-172.17.0.15-1585803781382/current
2020-04-02 05:03:04,284 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,284 [Thread-241] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,284 [Thread-155] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,285 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1256569654-172.17.0.15-1585803781382 is not formatted. Formatting ...
2020-04-02 05:03:04,285 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1256569654-172.17.0.15-1585803781382 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1256569654-172.17.0.15-1585803781382/current
2020-04-02 05:03:04,285 [Thread-155] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,286 [Thread-155] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1256569654-172.17.0.15-1585803781382 is not formatted. Formatting ...
2020-04-02 05:03:04,286 [Thread-155] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1256569654-172.17.0.15-1585803781382 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1256569654-172.17.0.15-1585803781382/current
2020-04-02 05:03:04,287 [Thread-241] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=490816991;bpid=BP-1256569654-172.17.0.15-1585803781382;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=490816991;c=1585803781382;bpid=BP-1256569654-172.17.0.15-1585803781382;dnuuid=null
2020-04-02 05:03:04,310 [Thread-238] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:04,312 [Thread-155] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=490816991;bpid=BP-1256569654-172.17.0.15-1585803781382;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=490816991;c=1585803781382;bpid=BP-1256569654-172.17.0.15-1585803781382;dnuuid=null
2020-04-02 05:03:04,318 [Thread-155] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:04,323 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,323 [Thread-182] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,323 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1256569654-172.17.0.15-1585803781382 is not formatted. Formatting ...
2020-04-02 05:03:04,324 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1256569654-172.17.0.15-1585803781382 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1256569654-172.17.0.15-1585803781382/current
2020-04-02 05:03:04,325 [Thread-182] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=490816991;bpid=BP-1256569654-172.17.0.15-1585803781382;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=490816991;c=1585803781382;bpid=BP-1256569654-172.17.0.15-1585803781382;dnuuid=null
2020-04-02 05:03:04,327 [Thread-180] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:04,412 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c2fdd593-c43d-47a3-9363-412b7536a916
2020-04-02 05:03:04,415 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:03:04,415 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-463245ea-463e-41df-9547-82aea6f6d88b
2020-04-02 05:03:04,423 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:03:04,423 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8f16e333-ad2c-4377-a519-3e818936f550
2020-04-02 05:03:04,423 [Thread-155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:03:04,426 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f3238b61-d474-4a26-a05d-752a82a9a2e4
2020-04-02 05:03:04,427 [Thread-180] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:03:04,427 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4
2020-04-02 05:03:04,427 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:03:04,428 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-fa28de4e-17af-4523-b8a6-f19f7df1e677
2020-04-02 05:03:04,434 [Thread-155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:03:04,441 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-b90586b0-20e9-4801-bddd-bf33068c13b5
2020-04-02 05:03:04,460 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:03:04,466 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6f930f92-d816-4306-b152-eb38ffffd576
2020-04-02 05:03:04,466 [Thread-180] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:03:04,498 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:04,499 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:04,499 [Thread-155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:04,502 [Thread-180] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:04,513 [Thread-180] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:04,514 [Thread-214] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:04,513 [Thread-182] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:04,521 [Thread-213] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:04,522 [Thread-213] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-04-02 05:03:04,522 [Thread-213] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-04-02 05:03:04,530 [Thread-155] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:04,530 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,531 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:04,531 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,546 [Thread-182] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:04,547 [Thread-182] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:04,548 [Thread-182] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:04,549 [Thread-155] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:04,552 [Thread-155] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:04,554 [Thread-213] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,557 [Thread-213] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,570 [Thread-213] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-521900919-172.17.0.15-1585803778640 is not formatted. Formatting ...
2020-04-02 05:03:04,571 [Thread-213] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-521900919-172.17.0.15-1585803778640 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-521900919-172.17.0.15-1585803778640/current
2020-04-02 05:03:04,571 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:04,570 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:04,570 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:04,571 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:04,573 [Thread-155] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:04,581 [Thread-213] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,588 [Thread-213] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,588 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:04,588 [Thread-238] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:04,589 [Thread-238] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:04,588 [Thread-213] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-521900919-172.17.0.15-1585803778640 is not formatted. Formatting ...
2020-04-02 05:03:04,591 [Thread-214] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:04,600 [Thread-213] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-521900919-172.17.0.15-1585803778640 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-521900919-172.17.0.15-1585803778640/current
2020-04-02 05:03:04,601 [Thread-214] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:04,601 [Thread-214] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:04,601 [Thread-180] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:04,604 [Thread-213] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1686742628;bpid=BP-521900919-172.17.0.15-1585803778640;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1686742628;c=1585803778640;bpid=BP-521900919-172.17.0.15-1585803778640;dnuuid=b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:04,605 [Thread-213] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,610 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:04,615 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:04,620 [Thread-155] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,621 [Thread-180] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:04,620 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,621 [Thread-180] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,626 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,642 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:04,642 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:04,658 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,745 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-521900919-172.17.0.15-1585803778640 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 130ms
2020-04-02 05:03:04,755 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-521900919-172.17.0.15-1585803778640 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 183ms
2020-04-02 05:03:04,758 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1256569654-172.17.0.15-1585803781382 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 111ms
2020-04-02 05:03:04,781 [Thread-269] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1256569654-172.17.0.15-1585803781382 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 136ms
2020-04-02 05:03:04,782 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1256569654-172.17.0.15-1585803781382: 158ms
2020-04-02 05:03:04,782 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-521900919-172.17.0.15-1585803778640 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 210ms
2020-04-02 05:03:04,783 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1256569654-172.17.0.15-1585803781382 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 211ms
2020-04-02 05:03:04,793 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:04,793 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:04,787 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-521900919-172.17.0.15-1585803778640: 256ms
2020-04-02 05:03:04,796 [Thread-276] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1256569654-172.17.0.15-1585803781382/current/replicas doesn't exist 
2020-04-02 05:03:04,796 [Thread-278] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1256569654-172.17.0.15-1585803781382/current/replicas doesn't exist 
2020-04-02 05:03:04,796 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:04,795 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:04,798 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:04,809 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:04,810 [Thread-280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-521900919-172.17.0.15-1585803778640/current/replicas doesn't exist 
2020-04-02 05:03:04,813 [Thread-282] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-521900919-172.17.0.15-1585803778640/current/replicas doesn't exist 
2020-04-02 05:03:04,813 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:04,813 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 4ms
2020-04-02 05:03:04,813 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 17ms
2020-04-02 05:03:04,814 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:04,814 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 16ms
2020-04-02 05:03:04,815 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-521900919-172.17.0.15-1585803778640: 18ms
2020-04-02 05:03:04,815 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 19ms
2020-04-02 05:03:04,820 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1256569654-172.17.0.15-1585803781382 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 249ms
2020-04-02 05:03:04,821 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-521900919-172.17.0.15-1585803778640 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 211ms
2020-04-02 05:03:04,821 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1256569654-172.17.0.15-1585803781382: 290ms
2020-04-02 05:03:04,822 [Thread-213] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-521900919-172.17.0.15-1585803778640: 217ms
2020-04-02 05:03:04,823 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382: 33ms
2020-04-02 05:03:04,833 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:04,833 [Thread-290] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-521900919-172.17.0.15-1585803778640/current/replicas doesn't exist 
2020-04-02 05:03:04,834 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:04,834 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:04,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:04,840 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:04,840 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-fa28de4e-17af-4523-b8a6-f19f7df1e677): finished scanning block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,840 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:04,840 [Thread-285] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1256569654-172.17.0.15-1585803781382/current/replicas doesn't exist 
2020-04-02 05:03:04,844 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:04,844 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:04,844 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-521900919-172.17.0.15-1585803778640/current/replicas doesn't exist 
2020-04-02 05:03:04,844 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 11ms
2020-04-02 05:03:04,844 [Thread-293] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1256569654-172.17.0.15-1585803781382/current/replicas doesn't exist 
2020-04-02 05:03:04,845 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:03:04,845 [Thread-213] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-521900919-172.17.0.15-1585803778640: 23ms
2020-04-02 05:03:04,845 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:03:04,851 [Thread-153] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:10 AM with interval of 21600000ms
2020-04-02 05:03:04,854 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:04,865 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 26ms
2020-04-02 05:03:04,840 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:04,870 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382: 49ms
2020-04-02 05:03:04,871 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:04,890 [Thread-213] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:38 AM with interval of 21600000ms
2020-04-02 05:03:04,841 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:04,891 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8f16e333-ad2c-4377-a519-3e818936f550): finished scanning block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,890 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4): finished scanning block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,890 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-6f930f92-d816-4306-b152-eb38ffffd576): finished scanning block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,852 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:04,871 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:04,892 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f3238b61-d474-4a26-a05d-752a82a9a2e4): finished scanning block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,892 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c2fdd593-c43d-47a3-9363-412b7536a916): finished scanning block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:04,870 [Thread-182] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:19 AM with interval of 21600000ms
2020-04-02 05:03:04,908 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:04,908 [Thread-241] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:00 AM with interval of 21600000ms
2020-04-02 05:03:04,908 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:04,909 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-463245ea-463e-41df-9547-82aea6f6d88b): finished scanning block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,908 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-b90586b0-20e9-4801-bddd-bf33068c13b5): finished scanning block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:04,928 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:40185 beginning handshake with NN
2020-04-02 05:03:04,928 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:38894 beginning handshake with NN
2020-04-02 05:03:04,928 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:40185 beginning handshake with NN
2020-04-02 05:03:04,929 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:46813 beginning handshake with NN
2020-04-02 05:03:04,929 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:42275 beginning handshake with NN
2020-04-02 05:03:04,931 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:38894 beginning handshake with NN
2020-04-02 05:03:04,939 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:42275 beginning handshake with NN
2020-04-02 05:03:04,946 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:46813 beginning handshake with NN
2020-04-02 05:03:04,955 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-521900919-172.17.0.15-1585803778640 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 157ms
2020-04-02 05:03:04,957 [IPC Server handler 5 on 42275] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640) storage 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:04,957 [IPC Server handler 8 on 38894] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382) storage 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:04,982 [IPC Server handler 5 on 40185] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382) storage dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:04,992 [IPC Server handler 6 on 46813] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640) storage b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:04,999 [IPC Server handler 6 on 46813] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38153
2020-04-02 05:03:04,999 [IPC Server handler 5 on 40185] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46193
2020-04-02 05:03:04,999 [IPC Server handler 8 on 38894] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44103
2020-04-02 05:03:04,999 [IPC Server handler 5 on 42275] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46108
2020-04-02 05:03:05,000 [IPC Server handler 8 on 38894] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7057111a-30f3-4c1e-856b-4c8d18f55b78 (127.0.0.1:44103).
2020-04-02 05:03:05,000 [IPC Server handler 5 on 40185] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dc7961b1-3127-406c-807b-02b55b0ed474 (127.0.0.1:46193).
2020-04-02 05:03:05,000 [IPC Server handler 6 on 46813] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b6f68271-a83e-43a2-8c69-c928e9005565 (127.0.0.1:38153).
2020-04-02 05:03:05,000 [IPC Server handler 5 on 42275] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 764718a9-19eb-4986-88cc-6a9254f796f1 (127.0.0.1:46108).
2020-04-02 05:03:05,009 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-521900919-172.17.0.15-1585803778640 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 175ms
2020-04-02 05:03:05,009 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-b90586b0-20e9-4801-bddd-bf33068c13b5): no suitable block pools found to scan.  Waiting 1814399899 ms.
2020-04-02 05:03:05,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-463245ea-463e-41df-9547-82aea6f6d88b): no suitable block pools found to scan.  Waiting 1814399898 ms.
2020-04-02 05:03:05,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f3238b61-d474-4a26-a05d-752a82a9a2e4): no suitable block pools found to scan.  Waiting 1814399830 ms.
2020-04-02 05:03:05,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4): no suitable block pools found to scan.  Waiting 1814399860 ms.
2020-04-02 05:03:05,011 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-fa28de4e-17af-4523-b8a6-f19f7df1e677): no suitable block pools found to scan.  Waiting 1814399827 ms.
2020-04-02 05:03:05,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c2fdd593-c43d-47a3-9363-412b7536a916): no suitable block pools found to scan.  Waiting 1814399861 ms.
2020-04-02 05:03:05,010 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-6f930f92-d816-4306-b152-eb38ffffd576): no suitable block pools found to scan.  Waiting 1814399830 ms.
2020-04-02 05:03:05,013 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1256569654-172.17.0.15-1585803781382 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 198ms
2020-04-02 05:03:05,014 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8f16e333-ad2c-4377-a519-3e818936f550): no suitable block pools found to scan.  Waiting 1814399824 ms.
2020-04-02 05:03:05,015 [IPC Server handler 1 on 38894] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382) storage dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,016 [IPC Server handler 1 on 38894] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46193
2020-04-02 05:03:05,019 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1256569654-172.17.0.15-1585803781382 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 165ms
2020-04-02 05:03:05,019 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:38894 successfully registered with NN
2020-04-02 05:03:05,019 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38894 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,019 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1256569654-172.17.0.15-1585803781382 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 178ms
2020-04-02 05:03:05,026 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:46813 successfully registered with NN
2020-04-02 05:03:05,026 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-521900919-172.17.0.15-1585803778640 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 228ms
2020-04-02 05:03:05,026 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1256569654-172.17.0.15-1585803781382: 192ms
2020-04-02 05:03:05,025 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:42275 successfully registered with NN
2020-04-02 05:03:05,025 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:40185 successfully registered with NN
2020-04-02 05:03:05,024 [IPC Server handler 8 on 46813] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640) storage 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,027 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:05,023 [IPC Server handler 2 on 40185] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382) storage 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,023 [IPC Server handler 2 on 42275] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640) storage b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,023 [IPC Server handler 1 on 38894] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dc7961b1-3127-406c-807b-02b55b0ed474 (127.0.0.1:46193).
2020-04-02 05:03:05,028 [IPC Server handler 2 on 42275] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38153
2020-04-02 05:03:05,027 [IPC Server handler 2 on 40185] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44103
2020-04-02 05:03:05,027 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1256569654-172.17.0.15-1585803781382 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 213ms
2020-04-02 05:03:05,029 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-521900919-172.17.0.15-1585803778640 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 194ms
2020-04-02 05:03:05,027 [Thread-314] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1256569654-172.17.0.15-1585803781382/current/replicas doesn't exist 
2020-04-02 05:03:05,027 [IPC Server handler 8 on 46813] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46108
2020-04-02 05:03:05,027 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:05,027 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40185 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,027 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42275 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,026 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-521900919-172.17.0.15-1585803778640: 236ms
2020-04-02 05:03:05,026 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46813 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,036 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1256569654-172.17.0.15-1585803781382: 239ms
2020-04-02 05:03:05,037 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:05,037 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-521900919-172.17.0.15-1585803778640/current/replicas doesn't exist 
2020-04-02 05:03:05,034 [IPC Server handler 8 on 46813] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 764718a9-19eb-4986-88cc-6a9254f796f1 (127.0.0.1:46108).
2020-04-02 05:03:05,037 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 0ms
2020-04-02 05:03:05,033 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 6ms
2020-04-02 05:03:05,033 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:38894 successfully registered with NN
2020-04-02 05:03:05,032 [Thread-315] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1256569654-172.17.0.15-1585803781382/current/replicas doesn't exist 
2020-04-02 05:03:05,032 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-521900919-172.17.0.15-1585803778640: 211ms
2020-04-02 05:03:05,052 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 19ms
2020-04-02 05:03:05,030 [IPC Server handler 2 on 40185] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7057111a-30f3-4c1e-856b-4c8d18f55b78 (127.0.0.1:44103).
2020-04-02 05:03:05,029 [IPC Server handler 2 on 42275] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b6f68271-a83e-43a2-8c69-c928e9005565 (127.0.0.1:38153).
2020-04-02 05:03:05,052 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382: 26ms
2020-04-02 05:03:05,052 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:46813 successfully registered with NN
2020-04-02 05:03:05,052 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38894 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,053 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:05,052 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:05,037 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:05,037 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:05,054 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1256569654-172.17.0.15-1585803781382/current/replicas doesn't exist 
2020-04-02 05:03:05,054 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46813 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,054 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1256569654-172.17.0.15-1585803781382/current/replicas doesn't exist 
2020-04-02 05:03:05,054 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:38894 beginning handshake with NN
2020-04-02 05:03:05,055 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:03:05,054 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4): finished scanning block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:05,054 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:40185 successfully registered with NN
2020-04-02 05:03:05,084 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40185 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,084 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4): no suitable block pools found to scan.  Waiting 1814399786 ms.
2020-04-02 05:03:05,054 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:05,085 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c2fdd593-c43d-47a3-9363-412b7536a916): finished scanning block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:05,054 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:40185 beginning handshake with NN
2020-04-02 05:03:05,084 [IPC Server handler 6 on 42275] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8f16e333-ad2c-4377-a519-3e818936f550 for DN 127.0.0.1:46108
2020-04-02 05:03:05,080 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 26ms
2020-04-02 05:03:05,061 [IPC Server handler 0 on 38894] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382) storage b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,086 [IPC Server handler 0 on 38894] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38153
2020-04-02 05:03:05,054 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:05,087 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:42275 successfully registered with NN
2020-04-02 05:03:05,054 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:05,054 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-521900919-172.17.0.15-1585803778640/current/replicas doesn't exist 
2020-04-02 05:03:05,091 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42275 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,093 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 39ms
2020-04-02 05:03:05,091 [Thread-322] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-521900919-172.17.0.15-1585803778640/current/replicas doesn't exist 
2020-04-02 05:03:05,088 [Thread-155] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1256569654-172.17.0.15-1585803781382: 51ms
2020-04-02 05:03:05,108 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:05,108 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:38894 beginning handshake with NN
2020-04-02 05:03:05,108 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:40185 beginning handshake with NN
2020-04-02 05:03:05,109 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-521900919-172.17.0.15-1585803778640: 74ms
2020-04-02 05:03:05,109 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 18ms
2020-04-02 05:03:05,087 [IPC Server handler 6 on 42275] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 for DN 127.0.0.1:46108
2020-04-02 05:03:05,086 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c2fdd593-c43d-47a3-9363-412b7536a916): no suitable block pools found to scan.  Waiting 1814399785 ms.
2020-04-02 05:03:05,110 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:42275 beginning handshake with NN
2020-04-02 05:03:05,110 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:46813 beginning handshake with NN
2020-04-02 05:03:05,109 [Thread-320] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-521900919-172.17.0.15-1585803778640/current/replicas doesn't exist 
2020-04-02 05:03:05,108 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8f16e333-ad2c-4377-a519-3e818936f550): finished scanning block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:05,108 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1256569654-172.17.0.15-1585803781382 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:05,106 [IPC Server handler 0 on 38894] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b6f68271-a83e-43a2-8c69-c928e9005565 (127.0.0.1:38153).
2020-04-02 05:03:05,111 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:05,111 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:05,114 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 27ms
2020-04-02 05:03:05,114 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8f16e333-ad2c-4377-a519-3e818936f550): no suitable block pools found to scan.  Waiting 1814399724 ms.
2020-04-02 05:03:05,117 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-521900919-172.17.0.15-1585803778640: 65ms
2020-04-02 05:03:05,113 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-fa28de4e-17af-4523-b8a6-f19f7df1e677): finished scanning block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:05,122 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:38894 successfully registered with NN
2020-04-02 05:03:05,122 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:05,120 [IPC Server handler 9 on 42275] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2fdd593-c43d-47a3-9363-412b7536a916 for DN 127.0.0.1:38153
2020-04-02 05:03:05,122 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-b90586b0-20e9-4801-bddd-bf33068c13b5): finished scanning block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:05,118 [IPC Server handler 2 on 46813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8f16e333-ad2c-4377-a519-3e818936f550 for DN 127.0.0.1:46108
2020-04-02 05:03:05,130 [IPC Server handler 2 on 46813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 for DN 127.0.0.1:46108
2020-04-02 05:03:05,130 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-b90586b0-20e9-4801-bddd-bf33068c13b5): no suitable block pools found to scan.  Waiting 1814399778 ms.
2020-04-02 05:03:05,113 [IPC Server handler 7 on 38894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-463245ea-463e-41df-9547-82aea6f6d88b for DN 127.0.0.1:46193
2020-04-02 05:03:05,113 [IPC Server handler 7 on 40185] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-463245ea-463e-41df-9547-82aea6f6d88b for DN 127.0.0.1:46193
2020-04-02 05:03:05,117 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-6f930f92-d816-4306-b152-eb38ffffd576): finished scanning block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:05,133 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-6f930f92-d816-4306-b152-eb38ffffd576): no suitable block pools found to scan.  Waiting 1814399707 ms.
2020-04-02 05:03:05,117 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f3238b61-d474-4a26-a05d-752a82a9a2e4): finished scanning block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:05,162 [IPC Server handler 4 on 46813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2fdd593-c43d-47a3-9363-412b7536a916 for DN 127.0.0.1:38153
2020-04-02 05:03:05,133 [IPC Server handler 7 on 40185] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b90586b0-20e9-4801-bddd-bf33068c13b5 for DN 127.0.0.1:46193
2020-04-02 05:03:05,132 [IPC Server handler 7 on 38894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b90586b0-20e9-4801-bddd-bf33068c13b5 for DN 127.0.0.1:46193
2020-04-02 05:03:05,129 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-fa28de4e-17af-4523-b8a6-f19f7df1e677): no suitable block pools found to scan.  Waiting 1814399709 ms.
2020-04-02 05:03:05,124 [IPC Server handler 9 on 42275] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 for DN 127.0.0.1:38153
2020-04-02 05:03:05,122 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:46813 beginning handshake with NN
2020-04-02 05:03:05,164 [IPC Server handler 1 on 42275] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640) storage 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,122 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-521900919-172.17.0.15-1585803778640 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:05,174 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-463245ea-463e-41df-9547-82aea6f6d88b): finished scanning block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:05,175 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-463245ea-463e-41df-9547-82aea6f6d88b): no suitable block pools found to scan.  Waiting 1814399733 ms.
2020-04-02 05:03:05,122 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:42275 beginning handshake with NN
2020-04-02 05:03:05,122 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38894 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,174 [IPC Server handler 1 on 42275] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44103
2020-04-02 05:03:05,178 [IPC Server handler 1 on 42275] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7057111a-30f3-4c1e-856b-4c8d18f55b78 (127.0.0.1:44103).
2020-04-02 05:03:05,178 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f3238b61-d474-4a26-a05d-752a82a9a2e4): no suitable block pools found to scan.  Waiting 1814399662 ms.
2020-04-02 05:03:05,170 [IPC Server handler 9 on 38894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 for DN 127.0.0.1:44103
2020-04-02 05:03:05,170 [IPC Server handler 8 on 40185] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382) storage b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,194 [IPC Server handler 8 on 40185] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38153
2020-04-02 05:03:05,195 [IPC Server handler 8 on 40185] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN b6f68271-a83e-43a2-8c69-c928e9005565 (127.0.0.1:38153).
2020-04-02 05:03:05,168 [IPC Server handler 4 on 46813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 for DN 127.0.0.1:38153
2020-04-02 05:03:05,196 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:40185 successfully registered with NN
2020-04-02 05:03:05,196 [IPC Server handler 0 on 46813] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640) storage 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,196 [IPC Server handler 0 on 46813] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44103
2020-04-02 05:03:05,196 [IPC Server handler 0 on 46813] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7057111a-30f3-4c1e-856b-4c8d18f55b78 (127.0.0.1:44103).
2020-04-02 05:03:05,197 [IPC Server handler 6 on 46813] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640) storage dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,197 [IPC Server handler 6 on 46813] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46193
2020-04-02 05:03:05,197 [IPC Server handler 6 on 46813] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dc7961b1-3127-406c-807b-02b55b0ed474 (127.0.0.1:46193).
2020-04-02 05:03:05,198 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:46813 successfully registered with NN
2020-04-02 05:03:05,198 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46813 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,199 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:46813 successfully registered with NN
2020-04-02 05:03:05,183 [IPC Server handler 3 on 42275] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640) storage dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,211 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:46813 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,208 [IPC Server handler 9 on 40185] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 for DN 127.0.0.1:44103
2020-04-02 05:03:05,196 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40185 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,214 [IPC Server handler 3 on 42275] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46193
2020-04-02 05:03:05,226 [IPC Server handler 3 on 42275] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN dc7961b1-3127-406c-807b-02b55b0ed474 (127.0.0.1:46193).
2020-04-02 05:03:05,227 [IPC Server handler 8 on 46813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 for DN 127.0.0.1:44103
2020-04-02 05:03:05,229 [IPC Server handler 9 on 40185] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f930f92-d816-4306-b152-eb38ffffd576 for DN 127.0.0.1:44103
2020-04-02 05:03:05,229 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:42275 successfully registered with NN
2020-04-02 05:03:05,229 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:42275 successfully registered with NN
2020-04-02 05:03:05,231 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42275 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,227 [IPC Server handler 9 on 38894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f930f92-d816-4306-b152-eb38ffffd576 for DN 127.0.0.1:44103
2020-04-02 05:03:05,231 [IPC Server handler 4 on 40185] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382) storage 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,232 [IPC Server handler 4 on 40185] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46108
2020-04-02 05:03:05,232 [IPC Server handler 4 on 40185] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 764718a9-19eb-4986-88cc-6a9254f796f1 (127.0.0.1:46108).
2020-04-02 05:03:05,229 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42275 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,229 [IPC Server handler 8 on 46813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f930f92-d816-4306-b152-eb38ffffd576 for DN 127.0.0.1:44103
2020-04-02 05:03:05,233 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:40185 successfully registered with NN
2020-04-02 05:03:05,233 [IPC Server handler 5 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,233 [IPC Server handler 9 on 46813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-463245ea-463e-41df-9547-82aea6f6d88b for DN 127.0.0.1:46193
2020-04-02 05:03:05,233 [IPC Server handler 9 on 46813] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b90586b0-20e9-4801-bddd-bf33068c13b5 for DN 127.0.0.1:46193
2020-04-02 05:03:05,232 [IPC Server handler 5 on 38894] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382) storage 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,232 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xccc43af25414a85b: Processing first storage report for DS-8f16e333-ad2c-4377-a519-3e818936f550 from datanode 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,235 [IPC Server handler 5 on 38894] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:46108
2020-04-02 05:03:05,236 [IPC Server handler 5 on 38894] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 764718a9-19eb-4986-88cc-6a9254f796f1 (127.0.0.1:46108).
2020-04-02 05:03:05,233 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6b46e7463975bcb5: Processing first storage report for DS-8f16e333-ad2c-4377-a519-3e818936f550 from datanode 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,233 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40185 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,242 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:38894 successfully registered with NN
2020-04-02 05:03:05,242 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38894 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:05,239 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6b46e7463975bcb5: from storage DS-8f16e333-ad2c-4377-a519-3e818936f550 node DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,242 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xbef63f61da4c05c: Processing first storage report for DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 from datanode b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xbef63f61da4c05c: from storage DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 node DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x14800585bd6ebcf0: Processing first storage report for DS-b90586b0-20e9-4801-bddd-bf33068c13b5 from datanode dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x14800585bd6ebcf0: from storage DS-b90586b0-20e9-4801-bddd-bf33068c13b5 node DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6b46e7463975bcb5: Processing first storage report for DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 from datanode 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6b46e7463975bcb5: from storage DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 node DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xbef63f61da4c05c: Processing first storage report for DS-c2fdd593-c43d-47a3-9363-412b7536a916 from datanode b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xbef63f61da4c05c: from storage DS-c2fdd593-c43d-47a3-9363-412b7536a916 node DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x93028e0da60de70d: Processing first storage report for DS-6f930f92-d816-4306-b152-eb38ffffd576 from datanode 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,243 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x93028e0da60de70d: from storage DS-6f930f92-d816-4306-b152-eb38ffffd576 node DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,244 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x14800585bd6ebcf0: Processing first storage report for DS-463245ea-463e-41df-9547-82aea6f6d88b from datanode dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,244 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x14800585bd6ebcf0: from storage DS-463245ea-463e-41df-9547-82aea6f6d88b node DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,244 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x93028e0da60de70d: Processing first storage report for DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 from datanode 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,244 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x93028e0da60de70d: from storage DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 node DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,237 [IPC Server handler 8 on 38894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2fdd593-c43d-47a3-9363-412b7536a916 for DN 127.0.0.1:38153
2020-04-02 05:03:05,245 [IPC Server handler 8 on 38894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 for DN 127.0.0.1:38153
2020-04-02 05:03:05,237 [IPC Server handler 0 on 40185] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c2fdd593-c43d-47a3-9363-412b7536a916 for DN 127.0.0.1:38153
2020-04-02 05:03:05,242 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xccc43af25414a85b: from storage DS-8f16e333-ad2c-4377-a519-3e818936f550 node DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: true, processing time: 8 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,245 [IPC Server handler 0 on 40185] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 for DN 127.0.0.1:38153
2020-04-02 05:03:05,245 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9496ff6771744e5d: Processing first storage report for DS-b90586b0-20e9-4801-bddd-bf33068c13b5 from datanode dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,251 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcf394ad2af4df983: Processing first storage report for DS-b90586b0-20e9-4801-bddd-bf33068c13b5 from datanode dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,248 [IPC Server handler 7 on 42275] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 for DN 127.0.0.1:44103
2020-04-02 05:03:05,251 [IPC Server handler 7 on 42275] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f930f92-d816-4306-b152-eb38ffffd576 for DN 127.0.0.1:44103
2020-04-02 05:03:05,251 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcf394ad2af4df983: from storage DS-b90586b0-20e9-4801-bddd-bf33068c13b5 node DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,252 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6001dde82cf7cf42: Processing first storage report for DS-6f930f92-d816-4306-b152-eb38ffffd576 from datanode 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,252 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6001dde82cf7cf42: from storage DS-6f930f92-d816-4306-b152-eb38ffffd576 node DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,251 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9496ff6771744e5d: from storage DS-b90586b0-20e9-4801-bddd-bf33068c13b5 node DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: true, processing time: 6 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,252 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xed5dd938bc707678: Processing first storage report for DS-6f930f92-d816-4306-b152-eb38ffffd576 from datanode 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,252 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xed5dd938bc707678: from storage DS-6f930f92-d816-4306-b152-eb38ffffd576 node DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,252 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xed5dd938bc707678: Processing first storage report for DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 from datanode 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,252 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xed5dd938bc707678: from storage DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 node DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,253 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9496ff6771744e5d: Processing first storage report for DS-463245ea-463e-41df-9547-82aea6f6d88b from datanode dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,253 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9496ff6771744e5d: from storage DS-463245ea-463e-41df-9547-82aea6f6d88b node DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,258 [IPC Server handler 2 on 40185] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8f16e333-ad2c-4377-a519-3e818936f550 for DN 127.0.0.1:46108
2020-04-02 05:03:05,258 [IPC Server handler 2 on 40185] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 for DN 127.0.0.1:46108
2020-04-02 05:03:05,258 [IPC Server handler 8 on 42275] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-463245ea-463e-41df-9547-82aea6f6d88b for DN 127.0.0.1:46193
2020-04-02 05:03:05,259 [IPC Server handler 8 on 42275] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-b90586b0-20e9-4801-bddd-bf33068c13b5 for DN 127.0.0.1:46193
2020-04-02 05:03:05,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc89ddc5031fdf1cf: Processing first storage report for DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 from datanode b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc89ddc5031fdf1cf: from storage DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 node DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xccc43af25414a85b: Processing first storage report for DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 from datanode 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xccc43af25414a85b: from storage DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 node DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,259 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x69557f4f893af41e: Processing first storage report for DS-6f930f92-d816-4306-b152-eb38ffffd576 from datanode 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x69557f4f893af41e: from storage DS-6f930f92-d816-4306-b152-eb38ffffd576 node DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xcf394ad2af4df983: Processing first storage report for DS-463245ea-463e-41df-9547-82aea6f6d88b from datanode dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc89ddc5031fdf1cf: Processing first storage report for DS-c2fdd593-c43d-47a3-9363-412b7536a916 from datanode b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,260 [IPC Server handler 0 on 38894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8f16e333-ad2c-4377-a519-3e818936f550 for DN 127.0.0.1:46108
2020-04-02 05:03:05,260 [IPC Server handler 0 on 38894] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 for DN 127.0.0.1:46108
2020-04-02 05:03:05,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xcf394ad2af4df983: from storage DS-463245ea-463e-41df-9547-82aea6f6d88b node DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc89ddc5031fdf1cf: from storage DS-c2fdd593-c43d-47a3-9363-412b7536a916 node DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x69557f4f893af41e: Processing first storage report for DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 from datanode 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x69557f4f893af41e: from storage DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 node DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6001dde82cf7cf42: Processing first storage report for DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 from datanode 7057111a-30f3-4c1e-856b-4c8d18f55b78
2020-04-02 05:03:05,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6001dde82cf7cf42: from storage DS-f3238b61-d474-4a26-a05d-752a82a9a2e4 node DatanodeRegistration(127.0.0.1:44103, datanodeUuid=7057111a-30f3-4c1e-856b-4c8d18f55b78, infoPort=36564, infoSecurePort=0, ipcPort=43464, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x385afdfe91cf1994: Processing first storage report for DS-b90586b0-20e9-4801-bddd-bf33068c13b5 from datanode dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x385afdfe91cf1994: from storage DS-b90586b0-20e9-4801-bddd-bf33068c13b5 node DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x385afdfe91cf1994: Processing first storage report for DS-463245ea-463e-41df-9547-82aea6f6d88b from datanode dc7961b1-3127-406c-807b-02b55b0ed474
2020-04-02 05:03:05,262 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x385afdfe91cf1994: from storage DS-463245ea-463e-41df-9547-82aea6f6d88b node DatanodeRegistration(127.0.0.1:46193, datanodeUuid=dc7961b1-3127-406c-807b-02b55b0ed474, infoPort=44866, infoSecurePort=0, ipcPort=42790, storageInfo=lv=-57;cid=testClusterID;nsid=1686742628;c=1585803778640), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1b9e48ce5b51176: Processing first storage report for DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 from datanode b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,262 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1b9e48ce5b51176: from storage DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 node DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,262 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc123a0e2accbbfa0: Processing first storage report for DS-8f16e333-ad2c-4377-a519-3e818936f550 from datanode 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,262 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc123a0e2accbbfa0: from storage DS-8f16e333-ad2c-4377-a519-3e818936f550 node DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x522b17afff6b4a06: Processing first storage report for DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 from datanode b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,263 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x522b17afff6b4a06: from storage DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4 node DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,263 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1b9e48ce5b51176: Processing first storage report for DS-c2fdd593-c43d-47a3-9363-412b7536a916 from datanode b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,263 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1b9e48ce5b51176: from storage DS-c2fdd593-c43d-47a3-9363-412b7536a916 node DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,263 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc123a0e2accbbfa0: Processing first storage report for DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 from datanode 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,263 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc123a0e2accbbfa0: from storage DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 node DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,263 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x522b17afff6b4a06: Processing first storage report for DS-c2fdd593-c43d-47a3-9363-412b7536a916 from datanode b6f68271-a83e-43a2-8c69-c928e9005565
2020-04-02 05:03:05,264 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x522b17afff6b4a06: from storage DS-c2fdd593-c43d-47a3-9363-412b7536a916 node DatanodeRegistration(127.0.0.1:38153, datanodeUuid=b6f68271-a83e-43a2-8c69-c928e9005565, infoPort=46496, infoSecurePort=0, ipcPort=38173, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,264 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x663bbe7a01c16240: Processing first storage report for DS-8f16e333-ad2c-4377-a519-3e818936f550 from datanode 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,264 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x663bbe7a01c16240: from storage DS-8f16e333-ad2c-4377-a519-3e818936f550 node DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,264 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x663bbe7a01c16240: Processing first storage report for DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 from datanode 764718a9-19eb-4986-88cc-6a9254f796f1
2020-04-02 05:03:05,264 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x663bbe7a01c16240: from storage DS-fa28de4e-17af-4523-b8a6-f19f7df1e677 node DatanodeRegistration(127.0.0.1:46108, datanodeUuid=764718a9-19eb-4986-88cc-6a9254f796f1, infoPort=37279, infoSecurePort=0, ipcPort=42361, storageInfo=lv=-57;cid=testClusterID;nsid=490816991;c=1585803781382), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:05,275 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:44103
2020-04-02 05:03:05,275 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:03:05,290 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1b9e48ce5b51176,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 39 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,290 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9496ff6771744e5d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 85 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,294 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc123a0e2accbbfa0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 33 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,294 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x6001dde82cf7cf42,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 63 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,300 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x663bbe7a01c16240,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 38 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,297 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xcf394ad2af4df983,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 83 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,305 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xccc43af25414a85b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 15 msec to generate and 91 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,305 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x385afdfe91cf1994,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 46 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,317 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc89ddc5031fdf1cf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 82 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,314 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x6b46e7463975bcb5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 100 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,297 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x522b17afff6b4a06,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 42 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,319 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x69557f4f893af41e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 64 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,332 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xed5dd938bc707678,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 96 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,334 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xbef63f61da4c05c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 126 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,334 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x93028e0da60de70d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 98 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,335 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x14800585bd6ebcf0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 97 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:05,379 [IPC Server handler 4 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,392 [IPC Server handler 6 on 42275] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,402 [IPC Server handler 7 on 40185] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,411 [IPC Server handler 4 on 38894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,412 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:05,420 [IPC Server handler 0 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,424 [IPC Server handler 9 on 42275] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,429 [IPC Server handler 8 on 40185] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,434 [IPC Server handler 7 on 38894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,435 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:05,479 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:05,481 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,482 [Socket Reader #1 for port 33700] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33700
2020-04-02 05:03:05,491 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:05,491 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:05,491 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:05,508 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:05,508 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,509 [Socket Reader #1 for port 38038] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38038
2020-04-02 05:03:05,512 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:05,515 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:05,516 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:05,518 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:05,518 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:05,520 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:05,529 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-04-02 05:03:05,530 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:05,532 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-04-02 05:03:05,537 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,538 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,538 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,538 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:38713
2020-04-02 05:03:05,538 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,539 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,539 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,539 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:33494
2020-04-02 05:03:05,539 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,540 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,540 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,540 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:42095
2020-04-02 05:03:05,540 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,540 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,541 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,541 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:44248
2020-04-02 05:03:05,554 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:05,555 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,556 [Socket Reader #1 for port 45151] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45151
2020-04-02 05:03:05,573 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:05,573 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:05,577 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:05,579 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:05,579 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,580 [Socket Reader #1 for port 41157] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41157
2020-04-02 05:03:05,583 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:05,583 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:05,583 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:05,584 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:05,584 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:05,584 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:05,585 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-04-02 05:03:05,585 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:05,587 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-04-02 05:03:05,588 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,588 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,588 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,588 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:38713
2020-04-02 05:03:05,589 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,589 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,589 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,589 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:33494
2020-04-02 05:03:05,590 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,590 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,590 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,590 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:42095
2020-04-02 05:03:05,591 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,591 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,591 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,592 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:44248
2020-04-02 05:03:05,609 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:05,612 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,618 [Socket Reader #1 for port 43257] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43257
2020-04-02 05:03:05,621 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:05,622 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:05,622 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:05,623 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:05,624 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,624 [Socket Reader #1 for port 44271] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44271
2020-04-02 05:03:05,628 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:05,628 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:05,628 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:05,628 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:05,629 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:05,629 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:05,630 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-04-02 05:03:05,630 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:05,631 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-04-02 05:03:05,632 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,632 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,632 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,632 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:38713
2020-04-02 05:03:05,632 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,632 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,632 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,632 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:33494
2020-04-02 05:03:05,633 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,633 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,633 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,633 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:42095
2020-04-02 05:03:05,633 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,633 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,634 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,634 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:44248
2020-04-02 05:03:05,646 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:05,648 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,648 [Socket Reader #1 for port 41063] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41063
2020-04-02 05:03:05,652 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:05,652 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:05,653 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:05,654 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:05,655 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,656 [Socket Reader #1 for port 42660] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42660
2020-04-02 05:03:05,662 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:05,663 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:05,663 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:05,663 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:05,663 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:05,664 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:05,665 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-04-02 05:03:05,665 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:05,667 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-04-02 05:03:05,669 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,669 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,669 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:40185
2020-04-02 05:03:05,669 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:38713
2020-04-02 05:03:05,672 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,672 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,672 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:38894
2020-04-02 05:03:05,672 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:42095
2020-04-02 05:03:05,672 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,672 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,672 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:46813
2020-04-02 05:03:05,673 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:33494
2020-04-02 05:03:05,673 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,673 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,673 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42275
2020-04-02 05:03:05,673 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:44248
2020-04-02 05:03:05,677 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:33700: State Store unavailable
2020-04-02 05:03:05,677 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@e041f0c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:05,677 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:05,684 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat.createCluster(TestRouterHDFSContractConcat.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:05,688 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:05,688 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:05,688 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:05,689 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:05,689 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:05,700 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,702 [IPC Server listener on 33700] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33700: starting
2020-04-02 05:03:05,698 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:05,699 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:05,717 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:33700
2020-04-02 05:03:05,717 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,717 [IPC Server listener on 38038] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38038: starting
2020-04-02 05:03:05,721 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:05,721 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:05,723 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:05,724 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:05,723 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:05,726 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:05,726 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:05,726 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:05,728 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:05,728 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:05,728 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:05,728 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:05,731 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:05,731 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:05,731 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40529
2020-04-02 05:03:05,731 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:05,735 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1e287667{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:05,735 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4201a617{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:05,740 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@35e52059{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:05,743 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62577d6{HTTP/1.1,[http/1.1]}{0.0.0.0:40529}
2020-04-02 05:03:05,744 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @9855ms
2020-04-02 05:03:05,744 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:05,744 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:05,745 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:05,745 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:05,745 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:05,747 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:33700: State Store unavailable
2020-04-02 05:03:05,751 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-04-02 05:03:05,752 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-04-02 05:03:05,753 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-04-02 05:03:05,753 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-04-02 05:03:05,757 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-04-02 05:03:05,757 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:45151: State Store unavailable
2020-04-02 05:03:05,757 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:05,758 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@51bde877] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:05,758 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat.createCluster(TestRouterHDFSContractConcat.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:05,758 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:05,759 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:05,759 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:05,759 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:05,759 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:05,764 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:05,765 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:05,766 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:05,766 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:05,770 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,771 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:05,771 [IPC Server listener on 45151] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45151: starting
2020-04-02 05:03:05,791 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:45151
2020-04-02 05:03:05,793 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,802 [IPC Server listener on 41157] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41157: starting
2020-04-02 05:03:05,802 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:05,813 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:05,814 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:05,815 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:05,815 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:05,816 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:05,816 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:05,816 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:05,816 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:05,818 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:05,818 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:05,818 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36284
2020-04-02 05:03:05,818 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:05,820 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57dc9128{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:05,821 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@17ae98d7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:05,825 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@31198ceb{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:05,849 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@9257031{HTTP/1.1,[http/1.1]}{0.0.0.0:36284}
2020-04-02 05:03:05,864 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @9975ms
2020-04-02 05:03:05,864 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:05,866 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:05,866 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:05,866 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:05,867 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:05,920 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-04-02 05:03:05,920 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-04-02 05:03:05,920 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-04-02 05:03:05,921 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-04-02 05:03:05,921 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-04-02 05:03:05,922 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:45151: State Store unavailable
2020-04-02 05:03:05,926 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:43257: State Store unavailable
2020-04-02 05:03:05,930 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:05,930 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat.createCluster(TestRouterHDFSContractConcat.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:05,943 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:05,944 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:05,944 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:05,944 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:05,931 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1db0ec27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:05,962 [IPC Server handler 7 on 42275] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,961 [IPC Server handler 8 on 38894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,966 [IPC Server handler 8 on 42275] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,960 [IPC Server handler 0 on 38894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,960 [IPC Server handler 0 on 40185] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,960 [IPC Server handler 2 on 40185] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,952 [IPC Server listener on 43257] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43257: starting
2020-04-02 05:03:05,945 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:05,947 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,947 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:05,975 [IPC Server handler 9 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,987 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:43257
2020-04-02 05:03:05,988 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,988 [IPC Server listener on 44271] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44271: starting
2020-04-02 05:03:05,989 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:05,989 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:05,990 [IPC Server handler 5 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:05,990 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:05,991 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:05,991 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:05,991 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:05,992 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:05,993 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:05,993 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:05,993 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:06,008 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:06,008 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:06,008 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42887
2020-04-02 05:03:06,009 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:06,010 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4fdf8f12{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:06,011 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@54f5f647{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:06,015 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@77e2a6e2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:06,016 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5710768a{HTTP/1.1,[http/1.1]}{0.0.0.0:42887}
2020-04-02 05:03:06,016 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @10127ms
2020-04-02 05:03:06,016 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:06,016 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:06,017 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:06,017 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:06,017 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:06,046 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:06,047 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:06,047 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:06,050 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:43257: State Store unavailable
2020-04-02 05:03:06,067 [IPC Server handler 1 on 40185] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:06,076 [IPC Server handler 3 on 38894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:06,065 [IPC Server handler 2 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:06,050 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-04-02 05:03:06,104 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-04-02 05:03:06,104 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-04-02 05:03:06,105 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-04-02 05:03:06,105 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-04-02 05:03:06,106 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:41063: State Store unavailable
2020-04-02 05:03:06,106 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:06,107 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5bf61e67] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:06,109 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat.createCluster(TestRouterHDFSContractConcat.java:38)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:06,110 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:06,110 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:06,110 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:06,114 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:06,115 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:06,115 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:06,115 [IPC Server listener on 41063] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41063: starting
2020-04-02 05:03:06,123 [IPC Server handler 0 on 42275] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:06,137 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:41063
2020-04-02 05:03:06,137 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:06,142 [IPC Server listener on 42660] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42660: starting
2020-04-02 05:03:06,143 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:06,143 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:06,144 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:06,145 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:06,146 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:06,146 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:06,147 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:06,147 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:06,147 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:06,148 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:06,149 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:06,149 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:06,149 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46132
2020-04-02 05:03:06,149 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:06,173 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b09fac1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:06,176 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61019f59{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:06,177 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:06,178 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:06,178 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:06,179 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:06,183 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@53cdecf6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:06,194 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@71ea1fda{HTTP/1.1,[http/1.1]}{0.0.0.0:46132}
2020-04-02 05:03:06,209 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @10320ms
2020-04-02 05:03:06,209 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:06,210 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:06,210 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:06,213 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:06,214 [IPC Server handler 2 on 38894] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:06,214 [IPC Server handler 6 on 40185] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:06,215 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:06,219 [IPC Server handler 3 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:06,234 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:41063: State Store unavailable
2020-04-02 05:03:06,234 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-04-02 05:03:06,235 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-04-02 05:03:06,235 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-04-02 05:03:06,236 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-04-02 05:03:06,238 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-04-02 05:03:06,234 [IPC Server handler 2 on 42275] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:06,280 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:06,280 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:06,294 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:06,296 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-04-02 05:03:06,296 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-04-02 05:03:06,296 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-04-02 05:03:06,297 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:06,304 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:06,325 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:06,326 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:06,326 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:06,330 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:06,502 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:06,505 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:06,511 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:06,520 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:06,513 [CacheReplicationMonitor(1626393240)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:06,521 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:06,521 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:06,524 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:06,525 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:06,525 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:06,525 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:06,525 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 199 msec
2020-04-02 05:03:06,525 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-04-02 05:03:06,526 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-04-02 05:03:06,526 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-04-02 05:03:06,531 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:06,533 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:06,560 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:06,561 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:06,561 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:06,562 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:06,585 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:06,586 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:06,598 [CacheReplicationMonitor(1880583133)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:06,600 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:06,600 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:06,600 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:06,600 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:06,601 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:06,601 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 40 msec
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatEmptyFiles
[msx] unitTestCounterInClass = 0
2020-04-02 05:03:07,624 [Thread-477] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:43257 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1016374200_1329, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:07,676 [IPC Server handler 6 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:07,755 [IPC Server handler 9 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/small.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:07,803 [IPC Server handler 8 on 46813] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:44103, 127.0.0.1:38153, 127.0.0.1:46108 for /test/test/small.txt
2020-04-02 05:03:07,880 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:46706 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001 src: /127.0.0.1:46706 dest: /127.0.0.1:44103
2020-04-02 05:03:07,903 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:32820 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001 src: /127.0.0.1:32820 dest: /127.0.0.1:38153
2020-04-02 05:03:07,911 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:40486 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001 src: /127.0.0.1:40486 dest: /127.0.0.1:46108
2020-04-02 05:03:07,966 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40486, dest: /127.0.0.1:46108, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: 764718a9-19eb-4986-88cc-6a9254f796f1, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, duration(ns): 36815100
2020-04-02 05:03:07,966 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:07,973 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32820, dest: /127.0.0.1:38153, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: b6f68271-a83e-43a2-8c69-c928e9005565, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, duration(ns): 46607789
2020-04-02 05:03:07,975 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108] terminating
2020-04-02 05:03:07,983 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38153, 127.0.0.1:46108]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46706, dest: /127.0.0.1:44103, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: 7057111a-30f3-4c1e-856b-4c8d18f55b78, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, duration(ns): 54800730
2020-04-02 05:03:07,983 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38153, 127.0.0.1:46108]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38153, 127.0.0.1:46108] terminating
2020-04-02 05:03:08,016 [IPC Server handler 3 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/small.txt is closed by DFSClient_NONMAPREDUCE_-1016374200_1329
2020-04-02 05:03:08,029 [IPC Server handler 0 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/zero.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,035 [IPC Server handler 4 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/zero.txt is closed by DFSClient_NONMAPREDUCE_-1016374200_1329
2020-04-02 05:03:08,041 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:40185 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:08,041 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:40185
2020-04-02 05:03:08,043 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:46813 trying to claim ACTIVE state with txid=10
2020-04-02 05:03:08,043 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:46813
2020-04-02 05:03:08,046 [IPC Server handler 9 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,050 [IPC Server handler 8 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_-1016374200_1329
2020-04-02 05:03:08,059 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:46813 trying to claim ACTIVE state with txid=12
2020-04-02 05:03:08,059 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:46813
2020-04-02 05:03:08,064 [IPC Server handler 1 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,070 [IPC Server handler 2 on 43257] WARN  ipc.Server (Server.java:logException(2720)) - IPC Server handler 2 on 43257, call Call#149 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.concat from 172.17.0.15:45548
java.lang.NullPointerException
	at org.apache.hadoop.hdfs.server.federation.router.RouterClientProtocol.concat(RouterClientProtocol.java:486)
	at org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer.concat(RouterRpcServer.java:673)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.concat(ClientNamenodeProtocolServerSideTranslatorPB.java:634)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:03:08,082 [IPC Server handler 2 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,091 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:40185 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:08,091 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:40185
2020-04-02 05:03:08,103 [IPC Server handler 7 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatEmptyFiles
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatEmptyFiles
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatOnSelf
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:08,126 [Thread-491] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:43257 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1016374200_1329, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:08,132 [IPC Server handler 3 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:08,137 [IPC Server handler 0 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/small.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,149 [IPC Server handler 4 on 46813] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:46193, 127.0.0.1:44103, 127.0.0.1:46108 for /test/test/small.txt
2020-04-02 05:03:08,156 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:58678 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002 src: /127.0.0.1:58678 dest: /127.0.0.1:46193
2020-04-02 05:03:08,159 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:46730 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002 src: /127.0.0.1:46730 dest: /127.0.0.1:44103
2020-04-02 05:03:08,162 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:40496 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002 src: /127.0.0.1:40496 dest: /127.0.0.1:46108
2020-04-02 05:03:08,186 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40496, dest: /127.0.0.1:46108, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: 764718a9-19eb-4986-88cc-6a9254f796f1, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, duration(ns): 16734221
2020-04-02 05:03:08,189 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:08,195 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46730, dest: /127.0.0.1:44103, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: 7057111a-30f3-4c1e-856b-4c8d18f55b78, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, duration(ns): 29983405
2020-04-02 05:03:08,195 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108] terminating
2020-04-02 05:03:08,200 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44103, 127.0.0.1:46108]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58678, dest: /127.0.0.1:46193, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: dc7961b1-3127-406c-807b-02b55b0ed474, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, duration(ns): 32895275
2020-04-02 05:03:08,200 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44103, 127.0.0.1:46108]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:44103, 127.0.0.1:46108] terminating
2020-04-02 05:03:08,203 [IPC Server handler 5 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/small.txt is closed by DFSClient_NONMAPREDUCE_-1016374200_1329
2020-04-02 05:03:08,215 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:46813 trying to claim ACTIVE state with txid=20
2020-04-02 05:03:08,215 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:46813
2020-04-02 05:03:08,224 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:46813 trying to claim ACTIVE state with txid=20
2020-04-02 05:03:08,224 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:46813
2020-04-02 05:03:08,224 [IPC Server handler 7 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/zero.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,229 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:40185 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:08,229 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:40185
2020-04-02 05:03:08,243 [IPC Server handler 3 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/zero.txt is closed by DFSClient_NONMAPREDUCE_-1016374200_1329
2020-04-02 05:03:08,264 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:40185 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:08,264 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:40185
2020-04-02 05:03:08,271 [IPC Server handler 0 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,300 [IPC Server handler 4 on 46813] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:44103, 127.0.0.1:46108, 127.0.0.1:46193 for /test/test/target
2020-04-02 05:03:08,308 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:46744 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003 src: /127.0.0.1:46744 dest: /127.0.0.1:44103
2020-04-02 05:03:08,311 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:40510 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003 src: /127.0.0.1:40510 dest: /127.0.0.1:46108
2020-04-02 05:03:08,318 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:58698 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003 src: /127.0.0.1:58698 dest: /127.0.0.1:46193
2020-04-02 05:03:08,359 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58698, dest: /127.0.0.1:46193, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: dc7961b1-3127-406c-807b-02b55b0ed474, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, duration(ns): 36932282
2020-04-02 05:03:08,359 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:08,364 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46193]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40510, dest: /127.0.0.1:46108, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: 764718a9-19eb-4986-88cc-6a9254f796f1, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, duration(ns): 42273741
2020-04-02 05:03:08,364 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46193]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46193] terminating
2020-04-02 05:03:08,374 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46108, 127.0.0.1:46193]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46744, dest: /127.0.0.1:44103, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: 7057111a-30f3-4c1e-856b-4c8d18f55b78, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, duration(ns): 45309386
2020-04-02 05:03:08,375 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46108, 127.0.0.1:46193]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46108, 127.0.0.1:46193] terminating
2020-04-02 05:03:08,390 [IPC Server handler 5 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_-1016374200_1329
2020-04-02 05:03:08,406 [IPC Server handler 1 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,411 [IPC Server handler 2 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,419 [IPC Server handler 7 on 46813] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 46813, call Call#200 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.concat from 127.0.0.1:60510: org.apache.hadoop.HadoopIllegalArgumentException: concat: the src file /test/test/target is the same with the target file /test/test/target
2020-04-02 05:03:08,439 [IPC Server handler 8 on 43257] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 43257, call Call#197 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.concat from 172.17.0.15:45548: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.HadoopIllegalArgumentException): concat: the src file /test/test/target is the same with the target file /test/test/target
2020-04-02 05:03:08,445 [IPC Server handler 3 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,449 [IPC Server handler 0 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatOnSelf
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatOnSelf
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatFileOnFile
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:08,459 [Thread-509] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:43257 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1016374200_1329, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:08,461 [IPC Server handler 4 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:08,474 [IPC Server handler 6 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/small.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,482 [IPC Server handler 9 on 46813] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:38153, 127.0.0.1:46193, 127.0.0.1:46108 for /test/test/small.txt
2020-04-02 05:03:08,488 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:32878 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004 src: /127.0.0.1:32878 dest: /127.0.0.1:38153
2020-04-02 05:03:08,496 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:58730 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004 src: /127.0.0.1:58730 dest: /127.0.0.1:46193
2020-04-02 05:03:08,499 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:40548 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004 src: /127.0.0.1:40548 dest: /127.0.0.1:46108
2020-04-02 05:03:08,551 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40548, dest: /127.0.0.1:46108, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: 764718a9-19eb-4986-88cc-6a9254f796f1, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, duration(ns): 39745681
2020-04-02 05:03:08,551 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:08,556 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58730, dest: /127.0.0.1:46193, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: dc7961b1-3127-406c-807b-02b55b0ed474, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, duration(ns): 35097038
2020-04-02 05:03:08,556 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108] terminating
2020-04-02 05:03:08,567 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46193, 127.0.0.1:46108]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32878, dest: /127.0.0.1:38153, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: b6f68271-a83e-43a2-8c69-c928e9005565, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, duration(ns): 39462702
2020-04-02 05:03:08,568 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46193, 127.0.0.1:46108]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46193, 127.0.0.1:46108] terminating
2020-04-02 05:03:08,600 [IPC Server handler 1 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/small.txt is closed by DFSClient_NONMAPREDUCE_-1016374200_1329
2020-04-02 05:03:08,607 [IPC Server handler 7 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/zero.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,610 [IPC Server handler 3 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/zero.txt is closed by DFSClient_NONMAPREDUCE_-1016374200_1329
2020-04-02 05:03:08,616 [IPC Server handler 0 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,628 [IPC Server handler 4 on 46813] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:44103, 127.0.0.1:38153, 127.0.0.1:46108 for /test/test/target
2020-04-02 05:03:08,640 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:46800 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005 src: /127.0.0.1:46800 dest: /127.0.0.1:44103
2020-04-02 05:03:08,644 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:32902 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005 src: /127.0.0.1:32902 dest: /127.0.0.1:38153
2020-04-02 05:03:08,648 [DataXceiver for client DFSClient_NONMAPREDUCE_-1016374200_1329 at /127.0.0.1:40568 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005 src: /127.0.0.1:40568 dest: /127.0.0.1:46108
2020-04-02 05:03:08,672 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40568, dest: /127.0.0.1:46108, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: 764718a9-19eb-4986-88cc-6a9254f796f1, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, duration(ns): 20422559
2020-04-02 05:03:08,672 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:08,676 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32902, dest: /127.0.0.1:38153, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: b6f68271-a83e-43a2-8c69-c928e9005565, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, duration(ns): 21576117
2020-04-02 05:03:08,676 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:46108] terminating
2020-04-02 05:03:08,681 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38153, 127.0.0.1:46108]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46800, dest: /127.0.0.1:44103, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1016374200_1329, offset: 0, srvID: 7057111a-30f3-4c1e-856b-4c8d18f55b78, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, duration(ns): 26369756
2020-04-02 05:03:08,682 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38153, 127.0.0.1:46108]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:38153, 127.0.0.1:46108] terminating
2020-04-02 05:03:08,696 [IPC Server handler 5 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_-1016374200_1329
2020-04-02 05:03:08,705 [IPC Server handler 1 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,708 [IPC Server handler 2 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/small.txt	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,713 [IPC Server handler 7 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=concat	src=[/test/test/small.txt]	dst=/test/test/target	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,716 [IPC Server handler 3 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,720 [IPC Server handler 0 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,775 [IPC Server handler 4 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,778 [IPC Server handler 6 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatFileOnFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatFileOnFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatMissingTarget
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:08,797 [Thread-529] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:45151 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1835042096_1381, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:08,818 [IPC Server handler 9 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:08,830 [IPC Server handler 8 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/small.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,844 [IPC Server handler 5 on 46813] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:38153, 127.0.0.1:46108, 127.0.0.1:44103 for /test/test/small.txt
2020-04-02 05:03:08,855 [DataXceiver for client DFSClient_NONMAPREDUCE_-1835042096_1381 at /127.0.0.1:32940 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006 src: /127.0.0.1:32940 dest: /127.0.0.1:38153
2020-04-02 05:03:08,862 [DataXceiver for client DFSClient_NONMAPREDUCE_-1835042096_1381 at /127.0.0.1:40606 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006 src: /127.0.0.1:40606 dest: /127.0.0.1:46108
2020-04-02 05:03:08,869 [DataXceiver for client DFSClient_NONMAPREDUCE_-1835042096_1381 at /127.0.0.1:46844 [Receiving block BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006 src: /127.0.0.1:46844 dest: /127.0.0.1:44103
2020-04-02 05:03:08,890 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46844, dest: /127.0.0.1:44103, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1835042096_1381, offset: 0, srvID: 7057111a-30f3-4c1e-856b-4c8d18f55b78, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, duration(ns): 18876049
2020-04-02 05:03:08,891 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:08,894 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44103]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40606, dest: /127.0.0.1:46108, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1835042096_1381, offset: 0, srvID: 764718a9-19eb-4986-88cc-6a9254f796f1, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, duration(ns): 19560688
2020-04-02 05:03:08,901 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44103]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:44103] terminating
2020-04-02 05:03:08,916 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46108, 127.0.0.1:44103]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:32940, dest: /127.0.0.1:38153, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1835042096_1381, offset: 0, srvID: b6f68271-a83e-43a2-8c69-c928e9005565, blockid: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, duration(ns): 35876916
2020-04-02 05:03:08,917 [PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46108, 127.0.0.1:44103]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-521900919-172.17.0.15-1585803778640:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:46108, 127.0.0.1:44103] terminating
2020-04-02 05:03:08,918 [IPC Server handler 0 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/small.txt is closed by DFSClient_NONMAPREDUCE_-1835042096_1381
2020-04-02 05:03:08,931 [IPC Server handler 4 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/zero.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:08,935 [IPC Server handler 6 on 46813] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/zero.txt is closed by DFSClient_NONMAPREDUCE_-1835042096_1381
2020-04-02 05:03:08,939 [IPC Server handler 9 on 46813] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 46813, call Call#268 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:60658: java.io.FileNotFoundException: File does not exist: /test/test/target
2020-04-02 05:03:08,949 [IPC Server handler 8 on 45151] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 45151, call Call#267 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.concat from 172.17.0.15:58628: java.io.FileNotFoundException: File does not exist: /test/test/target
2020-04-02 05:03:08,955 [IPC Server handler 8 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:08,963 [IPC Server handler 5 on 46813] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatMissingTarget
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractConcat#testConcatMissingTarget
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:08,966 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:03:08,966 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:03:08,966 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42790 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:08,967 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:08,967 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-463245ea-463e-41df-9547-82aea6f6d88b) exiting.
2020-04-02 05:03:08,967 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4a9419d7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:08,967 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-b90586b0-20e9-4801-bddd-bf33068c13b5) exiting.
2020-04-02 05:03:08,988 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@40f33492{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:08,992 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4fbdc0f0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:08,992 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c77053b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:08,993 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21a5fd96{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:09,003 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42790
2020-04-02 05:03:09,014 [IPC Server listener on 42790] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42790
2020-04-02 05:03:09,014 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:09,014 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,018 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:46813
2020-04-02 05:03:09,014 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,019 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:42275
2020-04-02 05:03:09,019 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474)
2020-04-02 05:03:09,019 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:09,031 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-521900919-172.17.0.15-1585803778640] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,041 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,041 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:40185
2020-04-02 05:03:09,040 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-521900919-172.17.0.15-1585803778640] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,046 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,046 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474) service to localhost/127.0.0.1:38894
2020-04-02 05:03:09,046 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid dc7961b1-3127-406c-807b-02b55b0ed474)
2020-04-02 05:03:09,046 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:09,057 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1256569654-172.17.0.15-1585803781382] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,067 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1256569654-172.17.0.15-1585803781382] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,075 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:09,078 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:09,080 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:09,080 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:09,090 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:09,090 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:03:09,091 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38173 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:09,091 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1494b84d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:09,091 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:09,092 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-5bf0bfda-aba4-4b07-9c85-c7b0cd24beb4) exiting.
2020-04-02 05:03:09,092 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-c2fdd593-c43d-47a3-9363-412b7536a916) exiting.
2020-04-02 05:03:09,112 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5aa0dbf4{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:09,113 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@16afbd92{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:09,113 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d61eccf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:09,113 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@226f885f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:09,116 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38173
2020-04-02 05:03:09,120 [IPC Server listener on 38173] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38173
2020-04-02 05:03:09,130 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,148 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:42275
2020-04-02 05:03:09,129 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:09,122 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,130 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,149 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:38894
2020-04-02 05:03:09,130 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,149 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:46813
2020-04-02 05:03:09,150 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565)
2020-04-02 05:03:09,151 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:09,150 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565) service to localhost/127.0.0.1:40185
2020-04-02 05:03:09,158 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid b6f68271-a83e-43a2-8c69-c928e9005565)
2020-04-02 05:03:09,160 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-521900919-172.17.0.15-1585803778640] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,186 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-521900919-172.17.0.15-1585803778640] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,186 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:09,204 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:09,205 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:09,207 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:09,207 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:09,213 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1256569654-172.17.0.15-1585803781382] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,229 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1256569654-172.17.0.15-1585803781382] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,237 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:09,238 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:03:09,238 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43464 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:09,238 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:09,238 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@514eedd8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:09,239 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-f3238b61-d474-4a26-a05d-752a82a9a2e4) exiting.
2020-04-02 05:03:09,239 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-6f930f92-d816-4306-b152-eb38ffffd576) exiting.
2020-04-02 05:03:09,276 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4b629f13{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:09,277 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70925b45{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:09,277 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e185cd7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:09,278 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@466cf502{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:09,289 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43464
2020-04-02 05:03:09,290 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:09,290 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,291 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:40185
2020-04-02 05:03:09,290 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,290 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,296 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,291 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:38894
2020-04-02 05:03:09,294 [IPC Server listener on 43464] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43464
2020-04-02 05:03:09,296 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78)
2020-04-02 05:03:09,296 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:46813
2020-04-02 05:03:09,296 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78) service to localhost/127.0.0.1:42275
2020-04-02 05:03:09,297 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:09,297 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 7057111a-30f3-4c1e-856b-4c8d18f55b78)
2020-04-02 05:03:09,307 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1256569654-172.17.0.15-1585803781382] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,313 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1256569654-172.17.0.15-1585803781382] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,314 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:09,327 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-521900919-172.17.0.15-1585803778640] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,334 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-521900919-172.17.0.15-1585803778640] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,348 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:09,349 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:09,351 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:09,352 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:09,357 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:09,358 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:03:09,358 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42361 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:09,363 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:09,363 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2e54db99] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:09,364 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-8f16e333-ad2c-4377-a519-3e818936f550) exiting.
2020-04-02 05:03:09,364 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-fa28de4e-17af-4523-b8a6-f19f7df1e677) exiting.
2020-04-02 05:03:09,413 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1d7f7be7{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:09,414 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42f3156d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:09,414 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3ce3db41{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:09,414 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@38f57b3d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:09,419 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42361
2020-04-02 05:03:09,424 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,431 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,431 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:38894] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:38894
2020-04-02 05:03:09,430 [IPC Server listener on 42361] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42361
2020-04-02 05:03:09,424 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,431 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:40185
2020-04-02 05:03:09,424 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:09,431 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1256569654-172.17.0.15-1585803781382 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1)
2020-04-02 05:03:09,435 [BP-1256569654-172.17.0.15-1585803781382 heartbeating to localhost/127.0.0.1:40185] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1256569654-172.17.0.15-1585803781382
2020-04-02 05:03:09,431 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:09,431 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:46813] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:46813
2020-04-02 05:03:09,431 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1) service to localhost/127.0.0.1:42275
2020-04-02 05:03:09,437 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-521900919-172.17.0.15-1585803778640 (Datanode Uuid 764718a9-19eb-4986-88cc-6a9254f796f1)
2020-04-02 05:03:09,444 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1256569654-172.17.0.15-1585803781382] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,451 [BP-521900919-172.17.0.15-1585803778640 heartbeating to localhost/127.0.0.1:42275] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-521900919-172.17.0.15-1585803778640
2020-04-02 05:03:09,452 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1256569654-172.17.0.15-1585803781382] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,458 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-521900919-172.17.0.15-1585803778640] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,471 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-521900919-172.17.0.15-1585803778640] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:09,488 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:09,489 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:09,492 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:09,492 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:09,499 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:09,499 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:09,500 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 46813 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:09,500 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:09,501 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 54
2020-04-02 05:03:09,501 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4c7a078] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:03:09,502 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@553f3b6e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:03:09,502 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 55 Total time for transactions(ms): 69 Number of transactions batched in Syncs: 11 Number of syncs: 45 SyncTimes(ms): 17 9 4 
2020-04-02 05:03:09,504 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:03:09,505 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:03:09,506 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000055
2020-04-02 05:03:09,507 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:03:09,507 [CacheReplicationMonitor(1626393240)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:03:09,507 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46813
2020-04-02 05:03:09,508 [IPC Server listener on 46813] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46813
2020-04-02 05:03:09,524 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:09,525 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:09,525 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:09,579 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:09,580 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:09,581 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71e9ebae{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:09,602 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5ef5c734{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:09,603 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51c693d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:09,604 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a82c5f1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:09,630 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:09,630 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 42275 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:09,630 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:09,634 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:09,635 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42275
2020-04-02 05:03:09,648 [IPC Server listener on 42275] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42275
2020-04-02 05:03:09,655 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:09,662 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:09,663 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:09,693 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:09,729 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:09,733 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1f2f9244{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:09,736 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4c4d27c8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:09,737 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2cae1042{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:09,737 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b5825fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:09,752 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:09,752 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 40185 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:09,752 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:09,753 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@76f10035] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:03:09,753 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4f8caaf3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:03:09,753 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 1
2020-04-02 05:03:09,765 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 21 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 2 2 
2020-04-02 05:03:09,766 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:03:09,767 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:03:09,768 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:03:09,768 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:03:09,768 [CacheReplicationMonitor(1880583133)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:03:09,769 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40185
2020-04-02 05:03:09,773 [IPC Server listener on 40185] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40185
2020-04-02 05:03:09,773 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:09,773 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:09,788 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:09,813 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:09,813 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:09,815 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@590c73d3{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:09,818 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b9ce1bf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:09,823 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7446d8d5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:09,823 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f8f9349{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:09,834 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:09,834 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38894 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:09,834 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:09,835 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:09,835 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38894
2020-04-02 05:03:09,839 [IPC Server listener on 38894] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38894
2020-04-02 05:03:09,839 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:09,839 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:09,839 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:09,864 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:09,892 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:09,897 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@650eab8{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:09,899 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30f5a68a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:09,899 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1dd0e7c4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:09,900 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@47605f2f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:09,929 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:33700: State Store unavailable
2020-04-02 05:03:09,945 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:09,947 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:09,954 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:09,954 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:09,959 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:09,960 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:09,964 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:09,964 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:09,969 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:09,969 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:09,980 [Thread-543] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@35e52059{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:09,986 [Thread-543] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62577d6{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:09,989 [Thread-543] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4201a617{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:09,991 [Thread-543] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1e287667{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:10,002 [Thread-543] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38038
2020-04-02 05:03:10,015 [IPC Server listener on 38038] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38038
2020-04-02 05:03:10,018 [Thread-543] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33700
2020-04-02 05:03:10,015 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:10,029 [IPC Server listener on 33700] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33700
2020-04-02 05:03:10,029 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:10,056 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:10,056 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:10,068 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:10,069 [Thread-543] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:10,772 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:10,922 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:45151: State Store unavailable
2020-04-02 05:03:10,930 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:45151: State Store unavailable
2020-04-02 05:03:10,942 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:10,943 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:10,953 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:10,953 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:10,966 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:10,966 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:10,972 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:10,973 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:10,981 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:10,996 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:10,996 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:11,005 [Thread-544] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@31198ceb{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:11,006 [Thread-544] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@9257031{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:11,010 [Thread-544] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@17ae98d7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:11,013 [Thread-544] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57dc9128{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:11,018 [Thread-544] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41157
2020-04-02 05:03:11,022 [IPC Server listener on 41157] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41157
2020-04-02 05:03:11,025 [Thread-544] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45151
2020-04-02 05:03:11,022 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,029 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,029 [IPC Server listener on 45151] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45151
2020-04-02 05:03:11,034 [Thread-544] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-04-02 05:03:11,064 [Thread-544] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-04-02 05:03:11,065 [Thread-544] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-04-02 05:03:11,068 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:11,069 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:11,071 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:11,071 [Thread-544] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:11,076 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:43257: State Store unavailable
2020-04-02 05:03:11,115 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:11,234 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:41063: State Store unavailable
2020-04-02 05:03:11,924 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:43257: State Store unavailable
2020-04-02 05:03:11,924 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:11,925 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:11,925 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:11,925 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:11,926 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:11,926 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:11,928 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:11,928 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:11,928 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:11,928 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:11,930 [Thread-545] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@77e2a6e2{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:11,932 [Thread-545] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5710768a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:11,933 [Thread-545] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@54f5f647{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:11,934 [Thread-545] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4fdf8f12{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:11,935 [Thread-545] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44271
2020-04-02 05:03:11,936 [IPC Server listener on 44271] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44271
2020-04-02 05:03:11,936 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,937 [Thread-545] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43257
2020-04-02 05:03:11,937 [IPC Server listener on 43257] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43257
2020-04-02 05:03:11,940 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:11,938 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,942 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:11,943 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:11,943 [Thread-545] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:12,053 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:38894: End of File Exception between local host is: "b1fc8b48a924/172.17.0.15"; destination host is: "localhost":38894; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:12,054 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:42275: End of File Exception between local host is: "b1fc8b48a924/172.17.0.15"; destination host is: "localhost":42275; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:12,054 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:46813: End of File Exception between local host is: "b1fc8b48a924/172.17.0.15"; destination host is: "localhost":46813; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:12,054 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:38894
2020-04-02 05:03:12,054 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:40185: End of File Exception between local host is: "b1fc8b48a924/172.17.0.15"; destination host is: "localhost":40185; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:12,055 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:46813
2020-04-02 05:03:12,055 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:42275
2020-04-02 05:03:12,055 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:40185
2020-04-02 05:03:12,924 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router b1fc8b48a924:41063: State Store unavailable
2020-04-02 05:03:12,924 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:12,924 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:12,925 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:12,925 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:12,926 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:12,926 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:12,927 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:12,927 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:12,928 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:12,928 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:12,930 [Thread-546] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@53cdecf6{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:12,931 [Thread-546] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@71ea1fda{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:12,932 [Thread-546] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61019f59{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:12,933 [Thread-546] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b09fac1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:12,934 [Thread-546] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42660
2020-04-02 05:03:12,935 [IPC Server listener on 42660] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42660
2020-04-02 05:03:12,935 [Thread-546] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41063
2020-04-02 05:03:12,935 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:12,937 [IPC Server listener on 41063] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41063
2020-04-02 05:03:12,937 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:12,937 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:12,938 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:12,938 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:12,938 [Thread-546] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
[msx] all testRunFinished

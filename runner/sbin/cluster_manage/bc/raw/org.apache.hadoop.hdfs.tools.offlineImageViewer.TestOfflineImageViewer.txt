[msx] before_class
2020-04-02 05:09:19,209 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=3
Formatting using clusterid: testClusterID
2020-04-02 05:09:19,971 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:19,987 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:19,988 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:19,990 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:20,015 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:20,016 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:20,017 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:20,018 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:20,095 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:20,101 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:09:20,101 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:20,103 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:20,109 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:20,110 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:20
2020-04-02 05:09:20,113 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:20,115 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:20,117 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:09:20,117 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:20,139 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:09:20,148 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:20,148 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:20,149 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:20,149 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:20,149 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:09:20,150 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:20,150 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:20,150 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:20,150 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:20,150 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:20,151 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:20,187 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:09:20,210 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:20,211 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:20,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:09:20,212 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:20,219 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:09:20,219 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:20,219 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:20,220 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:20,225 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:20,227 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:20,233 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:20,233 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:20,233 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:09:20,234 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:20,241 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:20,242 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:20,242 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:20,247 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:20,248 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:20,252 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:20,257 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:20,258 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:09:20,259 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:20,300 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:20,322 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:09:20,328 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:09:20,343 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:20,347 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:20,493 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:09:20,493 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:09:20,524 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:09:20,529 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:09:20,685 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:09:20,736 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:09:21,113 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:09:21,114 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:09:21,120 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:09:21,159 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:09:21,210 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@59505b48] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:21,229 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:09:21,235 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:21,251 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3029ms
2020-04-02 05:09:21,376 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:21,379 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:09:21,380 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:21,387 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:21,389 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:09:21,390 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:21,390 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:21,418 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:09:21,418 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:09:21,428 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37145
2020-04-02 05:09:21,431 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:21,478 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f67a4d3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:21,480 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2fb0623e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:21,527 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@48c76607{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:09:21,541 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@52e7a6b2{HTTP/1.1,[http/1.1]}{localhost:37145}
2020-04-02 05:09:21,542 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3319ms
2020-04-02 05:09:21,559 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:21,560 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:21,560 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:21,561 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:21,561 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:21,562 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:21,570 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:21,571 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:21,572 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:21,572 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:21,577 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:21,578 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:21,579 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:21
2020-04-02 05:09:21,579 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:21,579 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:21,580 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:09:21,580 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:21,584 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:09:21,585 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:21,586 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:21,586 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:21,586 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:21,586 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:09:21,587 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:21,587 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:21,587 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:21,587 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:21,588 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:21,589 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:21,590 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:21,590 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:21,590 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:09:21,590 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:21,593 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:09:21,593 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:21,593 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:21,593 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:21,593 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:21,594 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:21,594 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:21,594 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:21,595 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:09:21,595 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:21,596 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:21,596 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:21,597 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:21,597 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:21,597 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:21,597 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:21,598 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:21,598 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:09:21,598 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:21,606 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:21,610 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:21,614 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:09:21,615 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:09:21,615 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:09:21,616 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:09:21,647 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:09:21,652 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:09:21,653 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:09:21,663 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:09:21,664 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:09:21,688 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:09:21,688 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 88 msecs
2020-04-02 05:09:21,854 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:09:21,863 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:21,875 [Socket Reader #1 for port 40209] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40209
2020-04-02 05:09:22,141 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:40209 to access this namenode/service.
2020-04-02 05:09:22,149 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:09:22,165 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:09:22,179 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:09:22,180 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:09:22,180 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:09:22,180 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:09:22,181 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:09:22,185 [Thread[Thread-29,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:09:22,186 [Thread[Thread-29,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:09:22,191 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:09:22,191 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:09:22,191 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:09:22,192 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:09:22,192 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:09:22,192 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2020-04-02 05:09:22,258 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:22,264 [IPC Server listener on 40209] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40209: starting
2020-04-02 05:09:22,266 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:40209
2020-04-02 05:09:22,270 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:09:22,271 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:09:22,279 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 8 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:09:22,284 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 40209 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:22,286 [CacheReplicationMonitor(514316430)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:09:22,294 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:22,396 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:22,411 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:22,439 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:22,439 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:22,457 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:22,460 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:22,468 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:22,470 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:22,475 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:22,484 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43929
2020-04-02 05:09:22,491 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:22,494 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:22,511 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:22,516 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:22,517 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:22,518 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:22,521 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:22,522 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:22,523 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:22,523 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:22,526 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40343
2020-04-02 05:09:22,527 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:22,530 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4189d70b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:22,531 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e7634b9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:22,538 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1af146{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:22,539 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4da602fc{HTTP/1.1,[http/1.1]}{localhost:40343}
2020-04-02 05:09:22,539 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4317ms
2020-04-02 05:09:22,982 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34807
2020-04-02 05:09:22,984 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@72bd06ca] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:22,986 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:22,986 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:23,005 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:23,006 [Socket Reader #1 for port 43451] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43451
2020-04-02 05:09:23,021 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43451
2020-04-02 05:09:23,037 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:23,041 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:23,342 [Thread-61] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40209 starting to offer service
2020-04-02 05:09:23,377 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:23,377 [IPC Server listener on 43451] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43451: starting
2020-04-02 05:09:23,408 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43451 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:23,421 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:23,426 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:23,430 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:23,470 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:23,470 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:23,471 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:23,496 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:23,497 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:23,498 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:23,498 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:23,500 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34023
2020-04-02 05:09:23,501 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:23,501 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:23,518 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:23,522 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:23,523 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:23,524 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:23,552 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:23,556 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:23,561 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:23,562 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:23,563 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35050
2020-04-02 05:09:23,563 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:23,565 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bda80bf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:23,567 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ce86164{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:23,589 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5b6813df{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:23,590 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5f2606b{HTTP/1.1,[http/1.1]}{localhost:35050}
2020-04-02 05:09:23,592 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5369ms
2020-04-02 05:09:23,786 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45565
2020-04-02 05:09:23,787 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ebff828] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:23,787 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:23,788 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:23,788 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:23,789 [Socket Reader #1 for port 35254] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35254
2020-04-02 05:09:23,799 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35254
2020-04-02 05:09:23,805 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:23,806 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:23,809 [Thread-86] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40209 starting to offer service
2020-04-02 05:09:23,810 [IPC Server listener on 35254] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35254: starting
2020-04-02 05:09:23,810 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:23,812 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35254 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:23,818 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:23,820 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:23,821 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:23,835 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:23,836 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:23,836 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:23,837 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:23,838 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:23,839 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:23,839 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:23,840 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34396
2020-04-02 05:09:23,841 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:23,842 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:23,844 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:23,854 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:23,860 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:23,861 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:23,863 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:23,864 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:23,864 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:23,870 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:23,873 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44088
2020-04-02 05:09:23,878 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:23,880 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37f21974{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:23,881 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6e521c1e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:23,889 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@62dae245{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:23,890 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4b6579e8{HTTP/1.1,[http/1.1]}{localhost:44088}
2020-04-02 05:09:23,891 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5669ms
2020-04-02 05:09:23,908 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44237
2020-04-02 05:09:23,909 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:23,909 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:23,909 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6c6357f9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:23,910 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:23,911 [Socket Reader #1 for port 39935] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39935
2020-04-02 05:09:23,941 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39935
2020-04-02 05:09:23,944 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:23,945 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:23,947 [Thread-109] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40209 starting to offer service
2020-04-02 05:09:23,948 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:23,949 [IPC Server listener on 39935] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39935: starting
2020-04-02 05:09:23,978 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39935 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:24,039 [Thread-86] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40209
2020-04-02 05:09:24,039 [Thread-61] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40209
2020-04-02 05:09:24,039 [Thread-109] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40209
2020-04-02 05:09:24,042 [Thread-86] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:24,042 [Thread-109] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:24,042 [Thread-61] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:24,055 [Thread-61] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:24,055 [Thread-61] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1032827169. Formatting...
2020-04-02 05:09:24,057 [Thread-61] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-411480cc-f7fa-412b-ab78-a6863ba1a3a4 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:09:24,057 [Thread-86] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:24,058 [Thread-86] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1032827169. Formatting...
2020-04-02 05:09:24,058 [Thread-86] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7f940646-5995-4b4a-b7e8-8937ab9ccebb for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:09:24,059 [Thread-109] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:24,059 [Thread-109] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1032827169. Formatting...
2020-04-02 05:09:24,059 [Thread-109] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fe827aee-df39-4078-b414-6c746d834d83 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:09:24,060 [Thread-61] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:24,061 [Thread-61] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1032827169. Formatting...
2020-04-02 05:09:24,061 [Thread-61] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c3e21842-4340-4bde-afd3-7ab9340cc28a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:09:24,063 [Thread-109] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:24,063 [Thread-109] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1032827169. Formatting...
2020-04-02 05:09:24,063 [Thread-109] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-30278e2f-b579-43f1-96b9-98fe0fe88205 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:09:24,063 [Thread-86] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:24,067 [Thread-86] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1032827169. Formatting...
2020-04-02 05:09:24,068 [Thread-86] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-93c191f0-8e39-4dde-9d17-9874fd766cac for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:09:24,081 [Thread-86] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,092 [Thread-86] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,093 [Thread-86] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-379696632-172.17.0.13-1585804160287 is not formatted. Formatting ...
2020-04-02 05:09:24,093 [Thread-86] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-379696632-172.17.0.13-1585804160287 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-379696632-172.17.0.13-1585804160287/current
2020-04-02 05:09:24,092 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,094 [Thread-61] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,094 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-379696632-172.17.0.13-1585804160287 is not formatted. Formatting ...
2020-04-02 05:09:24,095 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-379696632-172.17.0.13-1585804160287 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-379696632-172.17.0.13-1585804160287/current
2020-04-02 05:09:24,102 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,103 [Thread-109] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,103 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-379696632-172.17.0.13-1585804160287 is not formatted. Formatting ...
2020-04-02 05:09:24,134 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-379696632-172.17.0.13-1585804160287 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-379696632-172.17.0.13-1585804160287/current
2020-04-02 05:09:24,146 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,147 [Thread-109] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,147 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-379696632-172.17.0.13-1585804160287 is not formatted. Formatting ...
2020-04-02 05:09:24,148 [Thread-109] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-379696632-172.17.0.13-1585804160287 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-379696632-172.17.0.13-1585804160287/current
2020-04-02 05:09:24,151 [Thread-109] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1032827169;bpid=BP-379696632-172.17.0.13-1585804160287;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1032827169;c=1585804160287;bpid=BP-379696632-172.17.0.13-1585804160287;dnuuid=null
2020-04-02 05:09:24,154 [Thread-109] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID eab6ec09-5134-4ffe-acc6-74cf1a686eec
2020-04-02 05:09:24,158 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,159 [Thread-61] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,159 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-379696632-172.17.0.13-1585804160287 is not formatted. Formatting ...
2020-04-02 05:09:24,159 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-379696632-172.17.0.13-1585804160287 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-379696632-172.17.0.13-1585804160287/current
2020-04-02 05:09:24,169 [Thread-86] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,169 [Thread-86] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,169 [Thread-86] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-379696632-172.17.0.13-1585804160287 is not formatted. Formatting ...
2020-04-02 05:09:24,169 [Thread-86] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-379696632-172.17.0.13-1585804160287 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-379696632-172.17.0.13-1585804160287/current
2020-04-02 05:09:24,171 [Thread-61] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1032827169;bpid=BP-379696632-172.17.0.13-1585804160287;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1032827169;c=1585804160287;bpid=BP-379696632-172.17.0.13-1585804160287;dnuuid=null
2020-04-02 05:09:24,171 [Thread-86] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1032827169;bpid=BP-379696632-172.17.0.13-1585804160287;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1032827169;c=1585804160287;bpid=BP-379696632-172.17.0.13-1585804160287;dnuuid=null
2020-04-02 05:09:24,173 [Thread-86] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 9e7be53d-f9cf-4638-8999-c22fc4a86c55
2020-04-02 05:09:24,179 [Thread-61] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 2b03d3dc-3cfd-4d63-b181-4483f4993323
2020-04-02 05:09:24,302 [Thread-86] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7f940646-5995-4b4a-b7e8-8937ab9ccebb
2020-04-02 05:09:24,309 [Thread-86] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:09:24,310 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-fe827aee-df39-4078-b414-6c746d834d83
2020-04-02 05:09:24,311 [Thread-109] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:09:24,302 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-411480cc-f7fa-412b-ab78-a6863ba1a3a4
2020-04-02 05:09:24,317 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:09:24,349 [Thread-86] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-93c191f0-8e39-4dde-9d17-9874fd766cac
2020-04-02 05:09:24,350 [Thread-86] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:09:24,354 [Thread-86] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:24,370 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c3e21842-4340-4bde-afd3-7ab9340cc28a
2020-04-02 05:09:24,378 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:09:24,370 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-30278e2f-b579-43f1-96b9-98fe0fe88205
2020-04-02 05:09:24,385 [Thread-109] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:09:24,386 [Thread-109] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:24,387 [Thread-109] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:24,388 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:24,390 [Thread-61] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:24,384 [Thread-86] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:24,418 [Thread-109] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:24,419 [Thread-109] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:24,430 [Thread-61] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:24,431 [Thread-61] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:24,431 [Thread-61] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:24,431 [Thread-86] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:24,431 [Thread-86] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:24,452 [Thread-86] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:24,447 [Thread-109] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:24,438 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,457 [Thread-86] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,459 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:24,470 [Thread-109] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,472 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:24,474 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:09:24,472 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:24,470 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:24,491 [Thread-132] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:09:24,586 [Thread-129] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-379696632-172.17.0.13-1585804160287 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 112ms
2020-04-02 05:09:24,599 [Thread-127] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-379696632-172.17.0.13-1585804160287 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 140ms
2020-04-02 05:09:24,621 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-379696632-172.17.0.13-1585804160287 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 147ms
2020-04-02 05:09:24,648 [Thread-128] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-379696632-172.17.0.13-1585804160287 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 156ms
2020-04-02 05:09:24,651 [Thread-86] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-379696632-172.17.0.13-1585804160287: 193ms
2020-04-02 05:09:24,657 [Thread-126] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-379696632-172.17.0.13-1585804160287 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 180ms
2020-04-02 05:09:24,675 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-379696632-172.17.0.13-1585804160287: 222ms
2020-04-02 05:09:24,681 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:24,682 [Thread-138] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-379696632-172.17.0.13-1585804160287/current/replicas doesn't exist 
2020-04-02 05:09:24,696 [Thread-132] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-379696632-172.17.0.13-1585804160287 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 202ms
2020-04-02 05:09:24,696 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-379696632-172.17.0.13-1585804160287: 222ms
2020-04-02 05:09:24,707 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:09:24,710 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:24,710 [Thread-139] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-379696632-172.17.0.13-1585804160287/current/replicas doesn't exist 
2020-04-02 05:09:24,707 [Thread-142] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:24,718 [Thread-142] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-379696632-172.17.0.13-1585804160287/current/replicas doesn't exist 
2020-04-02 05:09:24,707 [Thread-141] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-379696632-172.17.0.13-1585804160287/current/replicas doesn't exist 
2020-04-02 05:09:24,718 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:24,722 [Thread-140] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-379696632-172.17.0.13-1585804160287/current/replicas doesn't exist 
2020-04-02 05:09:24,737 [Thread-142] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 19ms
2020-04-02 05:09:24,737 [Thread-139] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 27ms
2020-04-02 05:09:24,738 [Thread-143] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:09:24,738 [Thread-143] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-379696632-172.17.0.13-1585804160287/current/replicas doesn't exist 
2020-04-02 05:09:24,739 [Thread-143] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:09:24,739 [Thread-140] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 17ms
2020-04-02 05:09:24,741 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-379696632-172.17.0.13-1585804160287: 66ms
2020-04-02 05:09:24,742 [Thread-141] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 35ms
2020-04-02 05:09:24,742 [Thread-109] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-379696632-172.17.0.13-1585804160287: 46ms
2020-04-02 05:09:24,743 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:09:24,744 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-30278e2f-b579-43f1-96b9-98fe0fe88205): finished scanning block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,752 [Thread-109] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:59 AM with interval of 21600000ms
2020-04-02 05:09:24,766 [Thread-138] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 85ms
2020-04-02 05:09:24,766 [Thread-86] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-379696632-172.17.0.13-1585804160287: 100ms
2020-04-02 05:09:24,743 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:09:24,767 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:24,780 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:24,780 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-93c191f0-8e39-4dde-9d17-9874fd766cac): finished scanning block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,746 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:24,781 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c3e21842-4340-4bde-afd3-7ab9340cc28a): finished scanning block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,781 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-7f940646-5995-4b4a-b7e8-8937ab9ccebb): finished scanning block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,779 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid eab6ec09-5134-4ffe-acc6-74cf1a686eec) service to localhost/127.0.0.1:40209 beginning handshake with NN
2020-04-02 05:09:24,773 [Thread-86] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:24 AM with interval of 21600000ms
2020-04-02 05:09:24,773 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-fe827aee-df39-4078-b414-6c746d834d83): finished scanning block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,767 [Thread-61] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:10 AM with interval of 21600000ms
2020-04-02 05:09:24,749 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-379696632-172.17.0.13-1585804160287 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:24,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-411480cc-f7fa-412b-ab78-a6863ba1a3a4): finished scanning block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:24,825 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid 9e7be53d-f9cf-4638-8999-c22fc4a86c55) service to localhost/127.0.0.1:40209 beginning handshake with NN
2020-04-02 05:09:24,825 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid 2b03d3dc-3cfd-4d63-b181-4483f4993323) service to localhost/127.0.0.1:40209 beginning handshake with NN
2020-04-02 05:09:24,863 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-411480cc-f7fa-412b-ab78-a6863ba1a3a4): no suitable block pools found to scan.  Waiting 1814399883 ms.
2020-04-02 05:09:24,864 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-93c191f0-8e39-4dde-9d17-9874fd766cac): no suitable block pools found to scan.  Waiting 1814399903 ms.
2020-04-02 05:09:24,864 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-7f940646-5995-4b4a-b7e8-8937ab9ccebb): no suitable block pools found to scan.  Waiting 1814399903 ms.
2020-04-02 05:09:24,866 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c3e21842-4340-4bde-afd3-7ab9340cc28a): no suitable block pools found to scan.  Waiting 1814399880 ms.
2020-04-02 05:09:24,867 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-fe827aee-df39-4078-b414-6c746d834d83): no suitable block pools found to scan.  Waiting 1814399876 ms.
2020-04-02 05:09:24,868 [IPC Server handler 5 on 40209] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43929, datanodeUuid=2b03d3dc-3cfd-4d63-b181-4483f4993323, infoPort=34807, infoSecurePort=0, ipcPort=43451, storageInfo=lv=-57;cid=testClusterID;nsid=1032827169;c=1585804160287) storage 2b03d3dc-3cfd-4d63-b181-4483f4993323
2020-04-02 05:09:24,871 [IPC Server handler 5 on 40209] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43929
2020-04-02 05:09:24,872 [IPC Server handler 5 on 40209] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2b03d3dc-3cfd-4d63-b181-4483f4993323 (127.0.0.1:43929).
2020-04-02 05:09:24,874 [IPC Server handler 9 on 40209] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34023, datanodeUuid=9e7be53d-f9cf-4638-8999-c22fc4a86c55, infoPort=45565, infoSecurePort=0, ipcPort=35254, storageInfo=lv=-57;cid=testClusterID;nsid=1032827169;c=1585804160287) storage 9e7be53d-f9cf-4638-8999-c22fc4a86c55
2020-04-02 05:09:24,875 [IPC Server handler 9 on 40209] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34023
2020-04-02 05:09:24,875 [IPC Server handler 9 on 40209] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9e7be53d-f9cf-4638-8999-c22fc4a86c55 (127.0.0.1:34023).
2020-04-02 05:09:24,876 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-30278e2f-b579-43f1-96b9-98fe0fe88205): no suitable block pools found to scan.  Waiting 1814399868 ms.
2020-04-02 05:09:24,877 [IPC Server handler 7 on 40209] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34396, datanodeUuid=eab6ec09-5134-4ffe-acc6-74cf1a686eec, infoPort=44237, infoSecurePort=0, ipcPort=39935, storageInfo=lv=-57;cid=testClusterID;nsid=1032827169;c=1585804160287) storage eab6ec09-5134-4ffe-acc6-74cf1a686eec
2020-04-02 05:09:24,877 [IPC Server handler 7 on 40209] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34396
2020-04-02 05:09:24,878 [IPC Server handler 7 on 40209] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN eab6ec09-5134-4ffe-acc6-74cf1a686eec (127.0.0.1:34396).
2020-04-02 05:09:24,881 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid 2b03d3dc-3cfd-4d63-b181-4483f4993323) service to localhost/127.0.0.1:40209 successfully registered with NN
2020-04-02 05:09:24,881 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40209 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:24,882 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid eab6ec09-5134-4ffe-acc6-74cf1a686eec) service to localhost/127.0.0.1:40209 successfully registered with NN
2020-04-02 05:09:24,882 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40209 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:24,891 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid 9e7be53d-f9cf-4638-8999-c22fc4a86c55) service to localhost/127.0.0.1:40209 successfully registered with NN
2020-04-02 05:09:24,891 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40209 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:24,927 [IPC Server handler 3 on 40209] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-411480cc-f7fa-412b-ab78-a6863ba1a3a4 for DN 127.0.0.1:43929
2020-04-02 05:09:24,930 [IPC Server handler 3 on 40209] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c3e21842-4340-4bde-afd3-7ab9340cc28a for DN 127.0.0.1:43929
2020-04-02 05:09:24,960 [IPC Server handler 2 on 40209] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fe827aee-df39-4078-b414-6c746d834d83 for DN 127.0.0.1:34396
2020-04-02 05:09:24,963 [IPC Server handler 2 on 40209] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-30278e2f-b579-43f1-96b9-98fe0fe88205 for DN 127.0.0.1:34396
2020-04-02 05:09:24,970 [IPC Server handler 4 on 40209] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7f940646-5995-4b4a-b7e8-8937ab9ccebb for DN 127.0.0.1:34023
2020-04-02 05:09:24,971 [IPC Server handler 4 on 40209] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-93c191f0-8e39-4dde-9d17-9874fd766cac for DN 127.0.0.1:34023
2020-04-02 05:09:24,995 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x41f757096e20c517: Processing first storage report for DS-411480cc-f7fa-412b-ab78-a6863ba1a3a4 from datanode 2b03d3dc-3cfd-4d63-b181-4483f4993323
2020-04-02 05:09:25,000 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x41f757096e20c517: from storage DS-411480cc-f7fa-412b-ab78-a6863ba1a3a4 node DatanodeRegistration(127.0.0.1:43929, datanodeUuid=2b03d3dc-3cfd-4d63-b181-4483f4993323, infoPort=34807, infoSecurePort=0, ipcPort=43451, storageInfo=lv=-57;cid=testClusterID;nsid=1032827169;c=1585804160287), blocks: 0, hasStaleStorage: true, processing time: 5 msecs, invalidatedBlocks: 0
2020-04-02 05:09:25,001 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfed918c1403ff895: Processing first storage report for DS-93c191f0-8e39-4dde-9d17-9874fd766cac from datanode 9e7be53d-f9cf-4638-8999-c22fc4a86c55
2020-04-02 05:09:25,001 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfed918c1403ff895: from storage DS-93c191f0-8e39-4dde-9d17-9874fd766cac node DatanodeRegistration(127.0.0.1:34023, datanodeUuid=9e7be53d-f9cf-4638-8999-c22fc4a86c55, infoPort=45565, infoSecurePort=0, ipcPort=35254, storageInfo=lv=-57;cid=testClusterID;nsid=1032827169;c=1585804160287), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:25,001 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xab4d23ea4c94cc41: Processing first storage report for DS-fe827aee-df39-4078-b414-6c746d834d83 from datanode eab6ec09-5134-4ffe-acc6-74cf1a686eec
2020-04-02 05:09:25,001 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xab4d23ea4c94cc41: from storage DS-fe827aee-df39-4078-b414-6c746d834d83 node DatanodeRegistration(127.0.0.1:34396, datanodeUuid=eab6ec09-5134-4ffe-acc6-74cf1a686eec, infoPort=44237, infoSecurePort=0, ipcPort=39935, storageInfo=lv=-57;cid=testClusterID;nsid=1032827169;c=1585804160287), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:25,001 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x41f757096e20c517: Processing first storage report for DS-c3e21842-4340-4bde-afd3-7ab9340cc28a from datanode 2b03d3dc-3cfd-4d63-b181-4483f4993323
2020-04-02 05:09:25,001 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x41f757096e20c517: from storage DS-c3e21842-4340-4bde-afd3-7ab9340cc28a node DatanodeRegistration(127.0.0.1:43929, datanodeUuid=2b03d3dc-3cfd-4d63-b181-4483f4993323, infoPort=34807, infoSecurePort=0, ipcPort=43451, storageInfo=lv=-57;cid=testClusterID;nsid=1032827169;c=1585804160287), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:25,001 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfed918c1403ff895: Processing first storage report for DS-7f940646-5995-4b4a-b7e8-8937ab9ccebb from datanode 9e7be53d-f9cf-4638-8999-c22fc4a86c55
2020-04-02 05:09:25,001 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfed918c1403ff895: from storage DS-7f940646-5995-4b4a-b7e8-8937ab9ccebb node DatanodeRegistration(127.0.0.1:34023, datanodeUuid=9e7be53d-f9cf-4638-8999-c22fc4a86c55, infoPort=45565, infoSecurePort=0, ipcPort=35254, storageInfo=lv=-57;cid=testClusterID;nsid=1032827169;c=1585804160287), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:25,002 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xab4d23ea4c94cc41: Processing first storage report for DS-30278e2f-b579-43f1-96b9-98fe0fe88205 from datanode eab6ec09-5134-4ffe-acc6-74cf1a686eec
2020-04-02 05:09:25,002 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xab4d23ea4c94cc41: from storage DS-30278e2f-b579-43f1-96b9-98fe0fe88205 node DatanodeRegistration(127.0.0.1:34396, datanodeUuid=eab6ec09-5134-4ffe-acc6-74cf1a686eec, infoPort=44237, infoSecurePort=0, ipcPort=39935, storageInfo=lv=-57;cid=testClusterID;nsid=1032827169;c=1585804160287), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:25,023 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfed918c1403ff895,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 40 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:25,024 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:25,025 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xab4d23ea4c94cc41,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:25,025 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:25,032 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x41f757096e20c517,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 68 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:25,032 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:25,064 [IPC Server handler 1 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:25,094 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:25,123 [IPC Server handler 5 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:25,125 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:25,144 [IPC Server handler 7 on 40209] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(412)) - Enable the erasure coding policy XOR-2-1-1024k
2020-04-02 05:09:25,146 [IPC Server handler 7 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=XOR-2-1-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:09:25,209 [IPC Server handler 9 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=addErasureCodingPolicies	src=[RS-10-4-1k]	dst=null	perm=null	proto=rpc
2020-04-02 05:09:25,250 [IPC Server handler 3 on 40209] INFO  namenode.ErasureCodingPolicyManager (ErasureCodingPolicyManager.java:enablePolicy(412)) - Enable the erasure coding policy RS-10-4-1k
2020-04-02 05:09:25,251 [IPC Server handler 3 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-10-4-1k	dst=null	perm=null	proto=rpc
2020-04-02 05:09:25,287 [IPC Server handler 2 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dir0	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:25,309 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:25,358 [IPC Server handler 8 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir0/file0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:25,425 [IPC Server handler 6 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:34023, 127.0.0.1:34396, 127.0.0.1:43929 for /dir0/file0
2020-04-02 05:09:25,534 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:54216 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001 src: /127.0.0.1:54216 dest: /127.0.0.1:34023
2020-04-02 05:09:25,583 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:40768 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001 src: /127.0.0.1:40768 dest: /127.0.0.1:34396
2020-04-02 05:09:25,599 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:45946 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001 src: /127.0.0.1:45946 dest: /127.0.0.1:43929
2020-04-02 05:09:25,687 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45946, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, duration(ns): 54335041
2020-04-02 05:09:25,687 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:25,703 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40768, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, duration(ns): 75368228
2020-04-02 05:09:25,703 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929] terminating
2020-04-02 05:09:25,712 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54216, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, duration(ns): 72467551
2020-04-02 05:09:25,713 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:43929] terminating
2020-04-02 05:09:25,764 [IPC Server handler 1 on 40209] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /dir0/file0
2020-04-02 05:09:26,188 [IPC Server handler 3 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir0/file0 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:26,196 [IPC Server handler 2 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir0/file0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:26,200 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir0/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:26,208 [IPC Server handler 8 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:43929, 127.0.0.1:34023, 127.0.0.1:34396 for /dir0/file1
2020-04-02 05:09:26,213 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46240 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002 src: /127.0.0.1:46240 dest: /127.0.0.1:43929
2020-04-02 05:09:26,219 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:54602 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002 src: /127.0.0.1:54602 dest: /127.0.0.1:34023
2020-04-02 05:09:26,259 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41078 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002 src: /127.0.0.1:41078 dest: /127.0.0.1:34396
2020-04-02 05:09:26,297 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41078, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, duration(ns): 13295118
2020-04-02 05:09:26,297 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:26,314 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54602, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, duration(ns): 14028033
2020-04-02 05:09:26,316 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396] terminating
2020-04-02 05:09:26,316 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:34396]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46240, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, duration(ns): 31442621
2020-04-02 05:09:26,317 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:34396]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:34396] terminating
2020-04-02 05:09:26,324 [IPC Server handler 5 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir0/file1 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:26,339 [IPC Server handler 9 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir0/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:26,353 [IPC Server handler 1 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir0/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:26,363 [IPC Server handler 3 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:43929, 127.0.0.1:34396, 127.0.0.1:34023 for /dir0/file2
2020-04-02 05:09:26,379 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46310 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003 src: /127.0.0.1:46310 dest: /127.0.0.1:43929
2020-04-02 05:09:26,385 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41152 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003 src: /127.0.0.1:41152 dest: /127.0.0.1:34396
2020-04-02 05:09:26,399 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:54684 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003 src: /127.0.0.1:54684 dest: /127.0.0.1:34023
2020-04-02 05:09:26,478 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54684, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, duration(ns): 61933151
2020-04-02 05:09:26,479 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:26,514 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34023]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41152, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, duration(ns): 71012690
2020-04-02 05:09:26,515 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34023]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34023] terminating
2020-04-02 05:09:26,527 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:34023]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46310, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, duration(ns): 107031487
2020-04-02 05:09:26,528 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:34023]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:34023] terminating
2020-04-02 05:09:26,552 [IPC Server handler 6 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir0/file2 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:26,556 [IPC Server handler 0 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir0/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:09:26,563 [IPC Server handler 5 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir0/file3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:26,576 [IPC Server handler 7 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:34023, 127.0.0.1:43929, 127.0.0.1:34396 for /dir0/file3
2020-04-02 05:09:26,591 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:54810 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004 src: /127.0.0.1:54810 dest: /127.0.0.1:34023
2020-04-02 05:09:26,606 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46460 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004 src: /127.0.0.1:46460 dest: /127.0.0.1:43929
2020-04-02 05:09:26,612 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41290 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004 src: /127.0.0.1:41290 dest: /127.0.0.1:34396
2020-04-02 05:09:26,668 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41290, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, duration(ns): 53366883
2020-04-02 05:09:26,669 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:26,692 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46460, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, duration(ns): 60491414
2020-04-02 05:09:26,693 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396] terminating
2020-04-02 05:09:26,707 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43929, 127.0.0.1:34396]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54810, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, duration(ns): 64250037
2020-04-02 05:09:26,707 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43929, 127.0.0.1:34396]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741828_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43929, 127.0.0.1:34396] terminating
2020-04-02 05:09:26,712 [IPC Server handler 3 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir0/file3 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:26,727 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir0/file3	dst=null	perm=null	proto=rpc
2020-04-02 05:09:26,730 [IPC Server handler 8 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dir1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:26,732 [IPC Server handler 6 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:26,735 [IPC Server handler 0 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir1/file0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:26,751 [IPC Server handler 5 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:34023, 127.0.0.1:34396, 127.0.0.1:43929 for /dir1/file0
2020-04-02 05:09:26,756 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:54846 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005 src: /127.0.0.1:54846 dest: /127.0.0.1:34023
2020-04-02 05:09:26,764 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41318 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005 src: /127.0.0.1:41318 dest: /127.0.0.1:34396
2020-04-02 05:09:26,767 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46492 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005 src: /127.0.0.1:46492 dest: /127.0.0.1:43929
2020-04-02 05:09:26,803 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46492, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, duration(ns): 33200264
2020-04-02 05:09:26,803 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:26,815 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41318, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, duration(ns): 43338273
2020-04-02 05:09:26,815 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929] terminating
2020-04-02 05:09:26,832 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54846, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, duration(ns): 52857105
2020-04-02 05:09:26,832 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741829_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:43929] terminating
2020-04-02 05:09:26,838 [IPC Server handler 2 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir1/file0 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:26,842 [IPC Server handler 3 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir1/file0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:26,847 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir1/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:26,864 [IPC Server handler 8 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:34396, 127.0.0.1:34023, 127.0.0.1:43929 for /dir1/file1
2020-04-02 05:09:26,869 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41354 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006 src: /127.0.0.1:41354 dest: /127.0.0.1:34396
2020-04-02 05:09:26,872 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:54886 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006 src: /127.0.0.1:54886 dest: /127.0.0.1:34023
2020-04-02 05:09:26,877 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46530 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006 src: /127.0.0.1:46530 dest: /127.0.0.1:43929
2020-04-02 05:09:26,921 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46530, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, duration(ns): 40429185
2020-04-02 05:09:26,922 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:26,951 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54886, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, duration(ns): 71824153
2020-04-02 05:09:26,952 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929] terminating
2020-04-02 05:09:26,955 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41354, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, duration(ns): 75017688
2020-04-02 05:09:26,955 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741830_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929] terminating
2020-04-02 05:09:26,960 [IPC Server handler 7 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir1/file1 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:26,977 [IPC Server handler 1 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir1/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:26,980 [IPC Server handler 9 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir1/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:26,996 [IPC Server handler 2 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:43929, 127.0.0.1:34023, 127.0.0.1:34396 for /dir1/file2
2020-04-02 05:09:27,002 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46598 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007 src: /127.0.0.1:46598 dest: /127.0.0.1:43929
2020-04-02 05:09:27,004 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:54958 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007 src: /127.0.0.1:54958 dest: /127.0.0.1:34023
2020-04-02 05:09:27,010 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41430 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007 src: /127.0.0.1:41430 dest: /127.0.0.1:34396
2020-04-02 05:09:27,065 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41430, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, duration(ns): 43698702
2020-04-02 05:09:27,065 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:27,068 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54958, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, duration(ns): 52762227
2020-04-02 05:09:27,068 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396] terminating
2020-04-02 05:09:27,070 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:34396]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46598, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, duration(ns): 56505123
2020-04-02 05:09:27,071 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:34396]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:34396] terminating
2020-04-02 05:09:27,078 [IPC Server handler 3 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir1/file2 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:27,098 [IPC Server handler 0 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir1/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,101 [IPC Server handler 5 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir1/file3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:27,115 [IPC Server handler 7 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:34396, 127.0.0.1:34023, 127.0.0.1:43929 for /dir1/file3
2020-04-02 05:09:27,119 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41508 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008 src: /127.0.0.1:41508 dest: /127.0.0.1:34396
2020-04-02 05:09:27,123 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:55048 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008 src: /127.0.0.1:55048 dest: /127.0.0.1:34023
2020-04-02 05:09:27,125 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46694 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008 src: /127.0.0.1:46694 dest: /127.0.0.1:43929
2020-04-02 05:09:27,141 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46694, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, duration(ns): 14372598
2020-04-02 05:09:27,141 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:27,145 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55048, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, duration(ns): 15110647
2020-04-02 05:09:27,146 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929] terminating
2020-04-02 05:09:27,148 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41508, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, duration(ns): 20440900
2020-04-02 05:09:27,149 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929] terminating
2020-04-02 05:09:27,151 [IPC Server handler 2 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir1/file3 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:27,162 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir1/file3	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,169 [IPC Server handler 6 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dir2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,170 [IPC Server handler 8 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir2	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,174 [IPC Server handler 0 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir2/file0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:27,180 [IPC Server handler 5 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:34396, 127.0.0.1:43929, 127.0.0.1:34023 for /dir2/file0
2020-04-02 05:09:27,183 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41572 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009 src: /127.0.0.1:41572 dest: /127.0.0.1:34396
2020-04-02 05:09:27,186 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46746 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009 src: /127.0.0.1:46746 dest: /127.0.0.1:43929
2020-04-02 05:09:27,188 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:55106 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009 src: /127.0.0.1:55106 dest: /127.0.0.1:34023
2020-04-02 05:09:27,254 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55106, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, duration(ns): 57108150
2020-04-02 05:09:27,254 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:27,258 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34023]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46746, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, duration(ns): 67489882
2020-04-02 05:09:27,259 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34023]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34023] terminating
2020-04-02 05:09:27,260 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43929, 127.0.0.1:34023]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41572, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, duration(ns): 67179321
2020-04-02 05:09:27,260 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43929, 127.0.0.1:34023]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:43929, 127.0.0.1:34023] terminating
2020-04-02 05:09:27,264 [IPC Server handler 2 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir2/file0 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:27,284 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir2/file0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,292 [IPC Server handler 3 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir2/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:27,301 [IPC Server handler 6 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:34396, 127.0.0.1:34023, 127.0.0.1:43929 for /dir2/file1
2020-04-02 05:09:27,312 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41634 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010 src: /127.0.0.1:41634 dest: /127.0.0.1:34396
2020-04-02 05:09:27,328 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:55172 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010 src: /127.0.0.1:55172 dest: /127.0.0.1:34023
2020-04-02 05:09:27,340 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46834 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010 src: /127.0.0.1:46834 dest: /127.0.0.1:43929
2020-04-02 05:09:27,360 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46834, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, duration(ns): 16428387
2020-04-02 05:09:27,360 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:27,363 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55172, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, duration(ns): 13722520
2020-04-02 05:09:27,363 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929] terminating
2020-04-02 05:09:27,367 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41634, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, duration(ns): 22579742
2020-04-02 05:09:27,367 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929] terminating
2020-04-02 05:09:27,374 [IPC Server handler 5 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir2/file1 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:27,380 [IPC Server handler 9 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir2/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,384 [IPC Server handler 1 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir2/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:27,396 [IPC Server handler 2 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:43929, 127.0.0.1:34023, 127.0.0.1:34396 for /dir2/file2
2020-04-02 05:09:27,399 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46886 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011 src: /127.0.0.1:46886 dest: /127.0.0.1:43929
2020-04-02 05:09:27,403 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:55246 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011 src: /127.0.0.1:55246 dest: /127.0.0.1:34023
2020-04-02 05:09:27,408 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41718 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011 src: /127.0.0.1:41718 dest: /127.0.0.1:34396
2020-04-02 05:09:27,427 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41718, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, duration(ns): 16363026
2020-04-02 05:09:27,428 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:27,456 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55246, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, duration(ns): 16908389
2020-04-02 05:09:27,456 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34396] terminating
2020-04-02 05:09:27,471 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:34396]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46886, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, duration(ns): 46364621
2020-04-02 05:09:27,472 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:34396]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741835_1011, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:34396] terminating
2020-04-02 05:09:27,496 [IPC Server handler 8 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir2/file2 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:27,508 [IPC Server handler 0 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir2/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,516 [IPC Server handler 5 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir2/file3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:27,524 [IPC Server handler 9 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:34396, 127.0.0.1:34023, 127.0.0.1:43929 for /dir2/file3
2020-04-02 05:09:27,531 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41768 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012 src: /127.0.0.1:41768 dest: /127.0.0.1:34396
2020-04-02 05:09:27,533 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:55300 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012 src: /127.0.0.1:55300 dest: /127.0.0.1:34023
2020-04-02 05:09:27,538 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:46944 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012 src: /127.0.0.1:46944 dest: /127.0.0.1:43929
2020-04-02 05:09:27,559 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46944, dest: /127.0.0.1:43929, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, duration(ns): 17056374
2020-04-02 05:09:27,559 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:27,560 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55300, dest: /127.0.0.1:34023, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, duration(ns): 18921201
2020-04-02 05:09:27,561 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929] terminating
2020-04-02 05:09:27,562 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41768, dest: /127.0.0.1:34396, bytes: 1, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, duration(ns): 20343291
2020-04-02 05:09:27,563 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741836_1012, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34023, 127.0.0.1:43929] terminating
2020-04-02 05:09:27,567 [IPC Server handler 2 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir2/file3 is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:27,590 [IPC Server handler 3 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir2/file3	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,598 [IPC Server handler 6 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/emptydir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,602 [IPC Server handler 8 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/emptydir	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,607 [IPC Server handler 0 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dirContainingInvalidXMLChar\u0000here	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,610 [IPC Server handler 5 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dirContainingEntityRef&here	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,613 [IPC Server handler 9 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dirContainingEntityRef&here	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,619 [IPC Server handler 7 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/stickyBit	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,627 [IPC Server handler 2 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/stickyBit	dst=null	perm=root:supergroup:rwxrwxrwt	proto=rpc
2020-04-02 05:09:27,637 [IPC Server handler 1 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/stickyBit	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,642 [IPC Server handler 4 on 40209] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:createPassword(407)) - Creating password for identifier: (token for root: HDFS_DELEGATION_TOKEN owner=root, renewer=JobTracker, realUser=, issueDate=1585804167642, maxDate=1585804177642, sequenceNumber=1, masterKeyId=2), currentKey: 2
2020-04-02 05:09:27,651 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getDelegationToken	src=HDFS_DELEGATION_TOKEN token 1 for root with renewer JobTracker	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,667 [main] INFO  hdfs.DFSClient (DFSClient.java:getDelegationToken(703)) - Created token for root: HDFS_DELEGATION_TOKEN owner=root, renewer=JobTracker, realUser=, issueDate=1585804167642, maxDate=1585804177642, sequenceNumber=1, masterKeyId=2 on 127.0.0.1:40209
2020-04-02 05:09:27,686 [IPC Server handler 3 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/src	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,689 [IPC Server handler 6 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/src	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,691 [IPC Server handler 8 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/src/orig	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,700 [IPC Server handler 0 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/src/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:27,716 [IPC Server handler 5 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:34023, 127.0.0.1:34396, 127.0.0.1:43929 for /src/file
2020-04-02 05:09:27,723 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:55388 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013 src: /127.0.0.1:55388 dest: /127.0.0.1:34023
2020-04-02 05:09:27,725 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:41862 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013 src: /127.0.0.1:41862 dest: /127.0.0.1:34396
2020-04-02 05:09:27,727 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:47036 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013 src: /127.0.0.1:47036 dest: /127.0.0.1:43929
2020-04-02 05:09:27,741 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47036, dest: /127.0.0.1:43929, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, duration(ns): 8373650
2020-04-02 05:09:27,741 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:27,747 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41862, dest: /127.0.0.1:34396, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: eab6ec09-5134-4ffe-acc6-74cf1a686eec, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, duration(ns): 13038831
2020-04-02 05:09:27,748 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:43929] terminating
2020-04-02 05:09:27,751 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:43929]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55388, dest: /127.0.0.1:34023, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, duration(ns): 16703378
2020-04-02 05:09:27,752 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:43929]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34396, 127.0.0.1:43929] terminating
2020-04-02 05:09:27,762 [IPC Server handler 1 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /src/file is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:27,789 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=allowSnapshot	src=/src	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,814 [IPC Server handler 3 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=createSnapshot	src=/src	dst=/src/.snapshot/snapshot	perm=null	proto=rpc
2020-04-02 05:09:27,834 [IPC Server handler 6 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/src/orig	dst=/dst	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,853 [IPC Server handler 8 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dst	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,864 [IPC Server handler 0 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=truncate	src=/src/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:27,874 [IPC Server handler 5 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/src/file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,877 [IPC Server handler 7 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/xattr	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,891 [IPC Server handler 9 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/xattr	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,900 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/xattr	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,902 [IPC Server handler 6 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/xattr	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,906 [IPC Server handler 8 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/xattr	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,908 [IPC Server handler 0 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/xattr	dst=null	perm=null	proto=rpc
2020-04-02 05:09:27,908 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@6b166a9b] INFO  datanode.DataNode (BlockRecoveryWorker.java:logRecoverBlock(547)) - BlockRecoveryWorker: NameNode at localhost/127.0.0.1:40209 calls recoverBlock(BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, targets=[DatanodeInfoWithStorage[127.0.0.1:34396,null,null], DatanodeInfoWithStorage[127.0.0.1:34023,null,null], DatanodeInfoWithStorage[127.0.0.1:43929,null,null]], newGenerationStamp=1014, newBlock=blk_1073741838_1014, isStriped=false)
2020-04-02 05:09:27,956 [IPC Server handler 5 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setAcl	src=/xattr	dst=null	perm=root:supergroup:rwxrwx--x	proto=rpc
2020-04-02 05:09:27,957 [IPC Server handler 1 on 39935] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741837_1013, recoveryId=1014, replica=FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 2
  getBytesOnDisk()  = 2
  getVisibleLength()= 2
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-379696632-172.17.0.13-1585804160287/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:09:27,958 [IPC Server handler 1 on 39935] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741837_1013 from FINALIZED to RUR
2020-04-02 05:09:27,970 [IPC Server handler 7 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,977 [IPC Server handler 2 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/ec	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:27,978 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@6b166a9b] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741837_1013, recoveryId=1014, replica=FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 2
  getBytesOnDisk()  = 2
  getVisibleLength()= 2
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-379696632-172.17.0.13-1585804160287/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:09:27,978 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@6b166a9b] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741837_1013 from FINALIZED to RUR
2020-04-02 05:09:27,993 [IPC Server handler 0 on 43451] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2588)) - initReplicaRecovery: blk_1073741837_1013, recoveryId=1014, replica=FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 2
  getBytesOnDisk()  = 2
  getVisibleLength()= 2
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-379696632-172.17.0.13-1585804160287/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:09:27,994 [IPC Server handler 0 on 43451] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:initReplicaRecoveryImpl(2646)) - initReplicaRecovery: changing replica state for blk_1073741837_1013 from FINALIZED to RUR
2020-04-02 05:09:27,995 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@6b166a9b] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(200)) - BlockRecoveryWorker: block=BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013 (length=2), isTruncateRecovery=true, syncList=[block:blk_1073741837_1013[numBytes=2,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:34396,null,null], block:blk_1073741837_1013[numBytes=2,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:34023,null,null], block:blk_1073741837_1013[numBytes=2,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:43929,null,null]]
2020-04-02 05:09:27,999 [IPC Server handler 9 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/ec	dst=null	perm=null	proto=rpc
2020-04-02 05:09:28,006 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@6b166a9b] INFO  datanode.DataNode (BlockRecoveryWorker.java:syncBlock(291)) - BlockRecoveryWorker: block=BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013 (length=2), bestState=FINALIZED, newBlock=BP-379696632-172.17.0.13-1585804160287:blk_1073741838_1014 (length=1), participatingList=[block:blk_1073741837_1013[numBytes=2,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:34396,null,null], block:blk_1073741837_1013[numBytes=2,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:34023,null,null], block:blk_1073741837_1013[numBytes=2,originalReplicaState=FINALIZED] node:DatanodeInfoWithStorage[127.0.0.1:43929,null,null]]
2020-04-02 05:09:28,010 [IPC Server handler 1 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/ec/EmptyECFile.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:28,014 [IPC Server handler 2 on 39935] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, recoveryId=1014, length=1, replica=ReplicaUnderRecovery, blk_1073741837_1013, RUR
  getNumBytes()     = 2
  getBytesOnDisk()  = 2
  getVisibleLength()= 2
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-379696632-172.17.0.13-1585804160287/current/finalized/subdir0/subdir0/blk_1073741837
  recoveryId=1014
  original=FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 2
  getBytesOnDisk()  = 2
  getVisibleLength()= 2
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-379696632-172.17.0.13-1585804160287/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:09:28,019 [main] WARN  erasurecode.ErasureCodeNative (ErasureCodeNative.java:<clinit>(55)) - ISA-L support is not available in your platform... using builtin-java codec where applicable
2020-04-02 05:09:28,070 [IPC Server handler 2 on 39935] INFO  datanode.LocalReplica (LocalReplica.java:truncateBlock(468)) - truncateBlock: blockFile=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-379696632-172.17.0.13-1585804160287/tmp/subdir0/subdir0/blk_1073741838, metaFile=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-379696632-172.17.0.13-1585804160287/tmp/subdir0/subdir0/blk_1073741838_1014.meta, oldlen=2, newlen=1
2020-04-02 05:09:28,079 [IPC Server handler 6 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /ec/EmptyECFile.txt is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:28,090 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@6b166a9b] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013[numBytes=2,originalReplicaState=FINALIZED], recoveryId=1014, length=1, replica=ReplicaUnderRecovery, blk_1073741837_1013, RUR
  getNumBytes()     = 2
  getBytesOnDisk()  = 2
  getVisibleLength()= 2
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-379696632-172.17.0.13-1585804160287/current/finalized/subdir0/subdir0/blk_1073741837
  recoveryId=1014
  original=FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 2
  getBytesOnDisk()  = 2
  getVisibleLength()= 2
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-379696632-172.17.0.13-1585804160287/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:09:28,095 [IPC Server handler 3 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/ec/EmptyECFile.txt	dst=null	perm=null	proto=rpc
2020-04-02 05:09:28,099 [IPC Server handler 3 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/ec/SmallECFile.txt	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:28,121 [IPC Server handler 0 on 40209] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1015, replicas=127.0.0.1:34023, 127.0.0.1:34396, 127.0.0.1:43929 for /ec/SmallECFile.txt
2020-04-02 05:09:28,154 [IPC Server handler 5 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/ec/SmallECFile.txt	dst=null	perm=null	proto=rpc
2020-04-02 05:09:28,159 [Thread[Thread-29,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:09:28,159 [IPC Server handler 5 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:09:28,160 [IPC Server handler 5 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_enter	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:28,164 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@6b166a9b] INFO  datanode.LocalReplica (LocalReplica.java:truncateBlock(468)) - truncateBlock: blockFile=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-379696632-172.17.0.13-1585804160287/tmp/subdir0/subdir0/blk_1073741838, metaFile=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-379696632-172.17.0.13-1585804160287/tmp/subdir0/subdir0/blk_1073741838_1014.meta, oldlen=2, newlen=1
2020-04-02 05:09:28,181 [IPC Server handler 3 on 43451] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:updateReplicaUnderRecovery(2667)) - updateReplica: BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, recoveryId=1014, length=1, replica=ReplicaUnderRecovery, blk_1073741837_1013, RUR
  getNumBytes()     = 2
  getBytesOnDisk()  = 2
  getVisibleLength()= 2
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-379696632-172.17.0.13-1585804160287/current/finalized/subdir0/subdir0/blk_1073741837
  recoveryId=1014
  original=FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 2
  getBytesOnDisk()  = 2
  getVisibleLength()= 2
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-379696632-172.17.0.13-1585804160287/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:09:28,184 [IPC Server handler 9 on 40209] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:09:28,184 [IPC Server handler 9 on 40209] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 102
2020-04-02 05:09:28,185 [IPC Server handler 9 on 40209] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 103 Total time for transactions(ms): 93 Number of transactions batched in Syncs: 16 Number of syncs: 88 SyncTimes(ms): 5 3 
2020-04-02 05:09:28,187 [IPC Server handler 9 on 40209] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000103
2020-04-02 05:09:28,187 [IPC Server handler 9 on 40209] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000103
2020-04-02 05:09:28,190 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000103 using no compression
2020-04-02 05:09:28,190 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000103 using no compression
2020-04-02 05:09:28,248 [IPC Server handler 3 on 43451] INFO  datanode.LocalReplica (LocalReplica.java:truncateBlock(468)) - truncateBlock: blockFile=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-379696632-172.17.0.13-1585804160287/tmp/subdir0/subdir0/blk_1073741838, metaFile=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-379696632-172.17.0.13-1585804160287/tmp/subdir0/subdir0/blk_1073741838_1014.meta, oldlen=2, newlen=1
2020-04-02 05:09:28,266 [IPC Server handler 4 on 40209] INFO  namenode.FSNamesystem (FSNamesystem.java:commitBlockSynchronization(3568)) - commitBlockSynchronization(oldBlock=BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013, newgenerationstamp=1014, newlength=1, newtargets=[127.0.0.1:34396, 127.0.0.1:34023, 127.0.0.1:43929], closeFile=true, deleteBlock=false)
2020-04-02 05:09:28,272 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000103 of size 2838 bytes saved in 0 seconds .
2020-04-02 05:09:28,274 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000103 of size 2838 bytes saved in 0 seconds .
2020-04-02 05:09:28,283 [IPC Server handler 9 on 40209] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-04-02 05:09:28,296 [IPC Server handler 9 on 40209] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 104
2020-04-02 05:09:28,322 [IPC Server handler 9 on 40209] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:09:28,322 [IPC Server handler 9 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=saveNamespace	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:28,326 [IPC Server handler 4 on 40209] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 40209, call Call#161 Retry#0 org.apache.hadoop.hdfs.server.protocol.DatanodeProtocol.commitBlockSynchronization from 127.0.0.1:54070: org.apache.hadoop.hdfs.server.namenode.SafeModeException: Cannot commitBlockSynchronization while in safe mode. Name node is in safe mode.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off. NamenodeHostName:localhost
2020-04-02 05:09:28,329 [IPC Server handler 4 on 40209] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 6 secs
2020-04-02 05:09:28,329 [IPC Server handler 4 on 40209] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 3 datanodes
2020-04-02 05:09:28,330 [IPC Server handler 4 on 40209] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:09:28,330 [IPC Server handler 4 on 40209] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:09:28,331 [IPC Server handler 4 on 40209] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_leave	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:28,331 [org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1@6b166a9b] WARN  datanode.DataNode (BlockRecoveryWorker.java:run(605)) - recoverBlocks FAILED: RecoveringBlock{BP-379696632-172.17.0.13-1585804160287:blk_1073741837_1013; getBlockSize()=2; corrupt=false; offset=-1; locs=[DatanodeInfoWithStorage[127.0.0.1:34396,null,null], DatanodeInfoWithStorage[127.0.0.1:34023,null,null], DatanodeInfoWithStorage[127.0.0.1:43929,null,null]]}
org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.hdfs.server.namenode.SafeModeException): Cannot commitBlockSynchronization while in safe mode. Name node is in safe mode.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off. NamenodeHostName:localhost
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.newSafemodeException(FSNamesystem.java:1461)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.checkNameNodeSafeMode(FSNamesystem.java:1448)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.commitBlockSynchronization(FSNamesystem.java:3585)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.commitBlockSynchronization(NameNodeRpcServer.java:979)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolServerSideTranslatorPB.commitBlockSynchronization(DatanodeProtocolServerSideTranslatorPB.java:302)
	at org.apache.hadoop.hdfs.protocol.proto.DatanodeProtocolProtos$DatanodeProtocolService$2.callBlockingMethod(DatanodeProtocolProtos.java:31674)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy23.commitBlockSynchronization(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.DatanodeProtocolClientSideTranslatorPB.commitBlockSynchronization(DatanodeProtocolClientSideTranslatorPB.java:325)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskContiguous.syncBlock(BlockRecoveryWorker.java:331)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$RecoveryTaskContiguous.recover(BlockRecoveryWorker.java:188)
	at org.apache.hadoop.hdfs.server.datanode.BlockRecoveryWorker$1.run(BlockRecoveryWorker.java:602)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:09:28,337 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:09:28,340 [Thread[Thread-276,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:09:28,340 [Thread[Thread-276,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:09:28,356 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:55728 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775792_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775792_1015 src: /127.0.0.1:55728 dest: /127.0.0.1:34023
2020-04-02 05:09:28,357 [DataXceiver for client DFSClient_NONMAPREDUCE_-938411512_1 at /127.0.0.1:47374 [Receiving block BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775790_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775790_1015 src: /127.0.0.1:47374 dest: /127.0.0.1:43929
2020-04-02 05:09:28,422 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775792_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55728, dest: /127.0.0.1:34023, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 9e7be53d-f9cf-4638-8999-c22fc4a86c55, blockid: BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775792_1015, duration(ns): 61411292
2020-04-02 05:09:28,423 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775792_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775792_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:28,436 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775790_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47374, dest: /127.0.0.1:43929, bytes: 10240, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-938411512_1, offset: 0, srvID: 2b03d3dc-3cfd-4d63-b181-4483f4993323, blockid: BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775790_1015, duration(ns): 70674717
2020-04-02 05:09:28,436 [PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775790_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-379696632-172.17.0.13-1585804160287:blk_-9223372036854775790_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:28,448 [IPC Server handler 0 on 40209] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /ec/SmallECFile.txt is closed by DFSClient_NONMAPREDUCE_-938411512_1
2020-04-02 05:09:28,449 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:09:28,449 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39935 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:28,450 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:28,453 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-30278e2f-b579-43f1-96b9-98fe0fe88205) exiting.
2020-04-02 05:09:28,453 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-fe827aee-df39-4078-b414-6c746d834d83) exiting.
2020-04-02 05:09:28,454 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6c345c5f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:28,594 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@62dae245{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:28,602 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4b6579e8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:28,605 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6e521c1e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:28,605 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37f21974{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:28,635 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39935
2020-04-02 05:09:28,662 [IPC Server listener on 39935] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39935
2020-04-02 05:09:28,663 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:28,663 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:28,663 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid eab6ec09-5134-4ffe-acc6-74cf1a686eec) service to localhost/127.0.0.1:40209
2020-04-02 05:09:28,663 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid eab6ec09-5134-4ffe-acc6-74cf1a686eec)
2020-04-02 05:09:28,663 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:28,678 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:28,679 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:28,680 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:28,680 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:28,684 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-379696632-172.17.0.13-1585804160287] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:28,701 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-379696632-172.17.0.13-1585804160287] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:28,720 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:28,721 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:09:28,721 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35254 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:28,721 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:28,722 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@191ae03f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:28,741 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-93c191f0-8e39-4dde-9d17-9874fd766cac) exiting.
2020-04-02 05:09:28,741 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-7f940646-5995-4b4a-b7e8-8937ab9ccebb) exiting.
2020-04-02 05:09:28,809 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5b6813df{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:29,036 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5f2606b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:29,037 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ce86164{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:29,037 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bda80bf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:29,089 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35254
2020-04-02 05:09:29,104 [IPC Server listener on 35254] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35254
2020-04-02 05:09:29,104 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:29,104 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:29,110 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid 9e7be53d-f9cf-4638-8999-c22fc4a86c55) service to localhost/127.0.0.1:40209
2020-04-02 05:09:29,110 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid 9e7be53d-f9cf-4638-8999-c22fc4a86c55)
2020-04-02 05:09:29,110 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:29,124 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-379696632-172.17.0.13-1585804160287] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:29,143 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-379696632-172.17.0.13-1585804160287] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:29,161 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:29,161 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:29,164 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:29,164 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:29,166 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:29,166 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:09:29,166 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43451 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:29,166 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:29,166 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@66b7550d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:29,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c3e21842-4340-4bde-afd3-7ab9340cc28a) exiting.
2020-04-02 05:09:29,168 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-411480cc-f7fa-412b-ab78-a6863ba1a3a4) exiting.
2020-04-02 05:09:29,257 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1af146{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:29,262 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4da602fc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:29,263 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e7634b9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:29,263 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4189d70b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:29,265 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43451
2020-04-02 05:09:29,270 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:29,270 [IPC Server listener on 43451] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43451
2020-04-02 05:09:29,270 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:29,270 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid 2b03d3dc-3cfd-4d63-b181-4483f4993323) service to localhost/127.0.0.1:40209
2020-04-02 05:09:29,273 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-379696632-172.17.0.13-1585804160287 (Datanode Uuid 2b03d3dc-3cfd-4d63-b181-4483f4993323)
2020-04-02 05:09:29,274 [BP-379696632-172.17.0.13-1585804160287 heartbeating to localhost/127.0.0.1:40209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-379696632-172.17.0.13-1585804160287
2020-04-02 05:09:29,289 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-379696632-172.17.0.13-1585804160287] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:29,299 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-379696632-172.17.0.13-1585804160287] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:29,308 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:29,308 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:29,311 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:29,311 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:29,334 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:29,335 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:09:29,335 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 40209 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:29,335 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:29,335 [Thread[Thread-276,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:09:29,337 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@c055c54] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:09:29,337 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@25e2ab5a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:09:29,338 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 104, 107
2020-04-02 05:09:29,338 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 5 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 6 SyncTimes(ms): 4 0 
2020-04-02 05:09:29,339 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000104 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000104-0000000000000000108
2020-04-02 05:09:29,340 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000104 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000104-0000000000000000108
2020-04-02 05:09:29,346 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:09:29,347 [CacheReplicationMonitor(514316430)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:09:29,376 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40209
2020-04-02 05:09:29,377 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:09:29,377 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:09:29,380 [IPC Server listener on 40209] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40209
2020-04-02 05:09:29,386 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:29,465 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:29,469 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:09:29,471 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@48c76607{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:09:29,484 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@52e7a6b2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:29,485 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2fb0623e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:29,485 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f67a4d3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:29,502 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:09:29,513 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:09:29,530 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testFileDistributionCalculatorWithOptions
[msx] unitTestCounterInClass = 0
Processed 0 inodes.
Size	NumFiles
0	2
8	13
totalFiles = 15
totalDirectories = 12
totalBlocks = 14
totalSpace = 39
maxFileSize = 1
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testFileDistributionCalculatorWithOptions
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testFileDistributionCalculatorWithOptions
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testWebImageViewer
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:29,683 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadStringTable(250)) - Loading 10 strings
2020-04-02 05:09:29,683 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadINodeSection(231)) - Loading 27 inodes.
2020-04-02 05:09:29,684 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadINodeReferenceSection(210)) - Loading inode references
2020-04-02 05:09:29,686 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadINodeReferenceSection(223)) - Loaded 2 inode references
2020-04-02 05:09:29,686 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadINodeDirectorySection(182)) - Loading inode directory section
2020-04-02 05:09:29,687 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadINodeDirectorySection(204)) - Loaded 6 directories
2020-04-02 05:09:29,700 [main] INFO  offlineImageViewer.WebImageViewer (WebImageViewer.java:initServer(124)) - WebImageViewer started. Listening on /127.0.0.1:38265. Press Ctrl+C to stop the viewer.
2020-04-02 05:09:29,879 [nioEventLoopGroup-9-1] INFO  offlineImageViewer.FSImageHandler (FSImageHandler.java:channelRead0(117)) - op=LISTSTATUS target=/
2020-04-02 05:09:29,977 [nioEventLoopGroup-9-2] INFO  offlineImageViewer.FSImageHandler (FSImageHandler.java:channelRead0(117)) - op=LISTSTATUS target=/dir0
2020-04-02 05:09:30,004 [nioEventLoopGroup-9-3] INFO  offlineImageViewer.FSImageHandler (FSImageHandler.java:channelRead0(117)) - op=LISTSTATUS target=/dir0/file0
2020-04-02 05:09:30,015 [nioEventLoopGroup-9-4] INFO  offlineImageViewer.FSImageHandler (FSImageHandler.java:channelRead0(117)) - op=LISTSTATUS target=/emptydir
2020-04-02 05:09:30,072 [nioEventLoopGroup-9-7] INFO  offlineImageViewer.FSImageHandler (FSImageHandler.java:channelRead0(117)) - op=GETFILESTATUS target=/ec/EmptyECFile.txt
2020-04-02 05:09:30,091 [nioEventLoopGroup-9-8] INFO  offlineImageViewer.FSImageHandler (FSImageHandler.java:channelRead0(117)) - op=GETFILESTATUS target=/ec/EmptyECFile.txt
HdfsNamedFileStatus{path=webhdfs://localhost:38265/ec/EmptyECFile.txt; isDirectory=false; length=0; replication=1; blocksize=134217728; modification_time=1585804168078; access_time=1585804168009; owner=root; group=supergroup; permission=rw-r--r--; isSymlink=false; hasAcl=false; isEncrypted=false; isErasureCoded=false}
2020-04-02 05:09:30,103 [nioEventLoopGroup-9-9] INFO  offlineImageViewer.FSImageHandler (FSImageHandler.java:channelRead0(117)) - op=GETFILESTATUS target=/ec/SmallECFile.txt
2020-04-02 05:09:30,117 [nioEventLoopGroup-9-10] INFO  offlineImageViewer.FSImageHandler (FSImageHandler.java:channelRead0(117)) - op=GETFILESTATUS target=/dir0/file0
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testWebImageViewer
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testWebImageViewer
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testInvalidProcessorOption
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
Invalid processor specified : invalid
Usage: bin/hdfs oiv [OPTIONS] -i INPUTFILE -o OUTPUTFILE
Offline Image Viewer
View a Hadoop fsimage INPUTFILE using the specified PROCESSOR,
saving the results in OUTPUTFILE.

The oiv utility will attempt to parse correctly formed image files
and will abort fail with mal-formed image files.

The tool works offline and does not require a running cluster in
order to process an image file.

The following image processors are available:
  * XML: This processor creates an XML document with all elements of
    the fsimage enumerated, suitable for further analysis by XML
    tools.
  * ReverseXML: This processor takes an XML file and creates a
    binary fsimage containing the same elements.
  * FileDistribution: This processor analyzes the file size
    distribution in the image.
    -maxSize specifies the range [0, maxSize] of file sizes to be
     analyzed (128GB by default).
    -step defines the granularity of the distribution. (2MB by default)
    -format formats the output result in a human-readable fashion
     rather than a number of bytes. (false by default)
  * Web: Run a viewer to expose read-only WebHDFS API.
    -addr specifies the address to listen. (localhost:5978 by default)
    It does not support secure mode nor HTTPS.
  * Delimited (experimental): Generate a text file with all of the elements common
    to both inodes and inodes-under-construction, separated by a
    delimiter. The default delimiter is \t, though this may be
    changed via the -delimiter argument.

Required command line arguments:
-i,--inputFile <arg>   FSImage or XML file to process.

Optional command line arguments:
-o,--outputFile <arg>  Name of output file. If the specified
                       file exists, it will be overwritten.
                       (output to stdout by default)
                       If the input file was an XML file, we
                       will also create an <outputFile>.md5 file.
-p,--processor <arg>   Select which type of processor to apply
                       against image file. (XML|FileDistribution|
                       ReverseXML|Web|Delimited)
                       The default is Web.
-delimiter <arg>       Delimiting string to use with Delimited processor.  
-t,--temp <arg>        Use temporary dir to cache intermediate result to generate
                       Delimited outputs. If not set, Delimited processor constructs
                       the namespace in memory before outputting text.
-h,--help              Display usage information and exit

[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testInvalidProcessorOption
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testInvalidProcessorOption
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testPBDelimitedWriter
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:30,251 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:visit(471)) - Loading string table
2020-04-02 05:09:30,251 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadStringTable(250)) - Loading 10 strings
2020-04-02 05:09:30,251 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:visit(477)) - Loading inode references
2020-04-02 05:09:30,251 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadINodeReferenceSection(210)) - Loading inode references
2020-04-02 05:09:30,252 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadINodeReferenceSection(223)) - Loaded 2 inode references
2020-04-02 05:09:30,252 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadDirectories(520)) - Loading directories
2020-04-02 05:09:30,252 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadDirectoriesInINodeSection(561)) - Loading directories in INode section.
2020-04-02 05:09:30,253 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadDirectoriesInINodeSection(573)) - Found 12 directories in INode section.
2020-04-02 05:09:30,253 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadDirectories(533)) - Finished loading directories in 1ms
2020-04-02 05:09:30,253 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadINodeDirSection(540)) - Loading INode directory section.
2020-04-02 05:09:30,254 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:buildNamespace(603)) - Scanned 6 INode directories to build namespace.
2020-04-02 05:09:30,254 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadINodeDirSection(553)) - Finished loading INode directory section in 1ms
2020-04-02 05:09:30,254 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:outputINodes(608)) - Found 27 INodes in the INode section
2020-04-02 05:09:30,260 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:outputINodes(636)) - Outputted 27 INodes.
Path	Replication	ModificationTime	AccessTime	PreferredBlockSize	BlocksCount	FileSize	NSQUOTA	DSQUOTA	Permission	UserName	GroupName
/	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	9223372036854775807	-1	drwxr-xr-x	root	supergroup
/dir0	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dir0/file0	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir0/file1	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir0/file2	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir0/file3	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir1	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dir1/file0	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir1/file1	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir1/file2	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir1/file3	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir2	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dir2/file0	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir2/file1	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir2/file2	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir2/file3	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/emptydir	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dirContainingInvalidXMLChar here	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dirContainingEntityRef&here	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/stickyBit	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxrwxrwt	root	supergroup
/src	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dst	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/src/file	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/xattr	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxrwx--x+	root	supergroup
/ec	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/ec/EmptyECFile.txt	0	2020-04-02 05:09	2020-04-02 05:09	134217728	0	0	0	0	-rw-r--r--	root	supergroup
/ec/SmallECFile.txt	0	2020-04-02 05:09	2020-04-02 05:09	134217728	1	0	0	0	-rw-r--r--	root	supergroup
2020-04-02 05:09:30,330 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:visit(471)) - Loading string table
2020-04-02 05:09:30,331 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadStringTable(250)) - Loading 10 strings
2020-04-02 05:09:30,331 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:visit(477)) - Loading inode references
2020-04-02 05:09:30,331 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadINodeReferenceSection(210)) - Loading inode references
2020-04-02 05:09:30,332 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadINodeReferenceSection(223)) - Loaded 2 inode references
2020-04-02 05:09:30,332 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadDirectories(520)) - Loading directories
2020-04-02 05:09:30,332 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadDirectoriesInINodeSection(561)) - Loading directories in INode section.
2020-04-02 05:09:30,337 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadDirectoriesInINodeSection(573)) - Found 12 directories in INode section.
2020-04-02 05:09:30,337 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadDirectories(533)) - Finished loading directories in 5ms
2020-04-02 05:09:30,338 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadINodeDirSection(540)) - Loading INode directory section.
2020-04-02 05:09:30,339 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:buildNamespace(603)) - Scanned 6 INode directories to build namespace.
2020-04-02 05:09:30,339 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:loadINodeDirSection(553)) - Finished loading INode directory section in 1ms
2020-04-02 05:09:30,341 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:outputINodes(608)) - Found 27 INodes in the INode section
2020-04-02 05:09:30,351 [main] INFO  offlineImageViewer.PBImageTextWriter (PBImageTextWriter.java:outputINodes(636)) - Outputted 27 INodes.
Path	Replication	ModificationTime	AccessTime	PreferredBlockSize	BlocksCount	FileSize	NSQUOTA	DSQUOTA	Permission	UserName	GroupName
/	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	9223372036854775807	-1	drwxr-xr-x	root	supergroup
/dir0	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dir0/file0	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir0/file1	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir0/file2	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir0/file3	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir1	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dir1/file0	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir1/file1	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir1/file2	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir1/file3	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir2	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dir2/file0	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir2/file1	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir2/file2	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/dir2/file3	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/emptydir	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dirContainingInvalidXMLChar here	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dirContainingEntityRef&here	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/stickyBit	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxrwxrwt	root	supergroup
/src	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/dst	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/src/file	3	2020-04-02 05:09	2020-04-02 05:09	134217728	1	1	0	0	-rw-r--r--	root	supergroup
/xattr	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxrwx--x+	root	supergroup
/ec	0	2020-04-02 05:09	1970-01-01 00:00	0	0	0	-1	-1	drwxr-xr-x	root	supergroup
/ec/EmptyECFile.txt	0	2020-04-02 05:09	2020-04-02 05:09	134217728	0	0	0	0	-rw-r--r--	root	supergroup
/ec/SmallECFile.txt	0	2020-04-02 05:09	2020-04-02 05:09	134217728	1	0	0	0	-rw-r--r--	root	supergroup
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testPBDelimitedWriter
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testPBDelimitedWriter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testWebImageViewerSecureMode
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testWebImageViewerSecureMode
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testWebImageViewerSecureMode
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerWithFormatOption
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerWithFormatOption
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerWithFormatOption
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerHelpMessage
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerHelpMessage
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerHelpMessage
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testTruncatedFSImage
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testTruncatedFSImage
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testTruncatedFSImage
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testPBImageXmlWriter
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:30,604 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadStringTable(250)) - Loading 10 strings
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testPBImageXmlWriter
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testPBImageXmlWriter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerMaxSizeAndStepOptions
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerMaxSizeAndStepOptions
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerMaxSizeAndStepOptions
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testFileDistributionCalculator
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testFileDistributionCalculator
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testFileDistributionCalculator
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testDelimitedWithExistingFolder
[msx] perform reset as unitTestCounterInClass 11 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testDelimitedWithExistingFolder
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testDelimitedWithExistingFolder
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testReverseXmlRoundTrip
[msx] perform reset as unitTestCounterInClass 12 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:30,961 [main] INFO  offlineImageViewer.OfflineImageViewerPB (TestOfflineImageViewer.java:testReverseXmlRoundTrip(747)) - Creating reverseImage.xml=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/reverseImage.xml, reverseImage=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/reverseImage, reverseImage2Xml=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/reverseImage2.xml
2020-04-02 05:09:30,963 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadStringTable(250)) - Loading 10 strings
2020-04-02 05:09:31,009 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:processXml(1748)) - Loading <fsimage>.
2020-04-02 05:09:31,011 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:expectTag(223)) - Skipping XMLEvent of type 7([Stax Event #7])
2020-04-02 05:09:31,017 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=version fields, terminators=[]):{[]onDiskVersion: [1], oivRevision: [Unknown], layoutVersion: [-64]}
2020-04-02 05:09:31,017 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:readVersion(1708)) - Loaded <version> with onDiskVersion=1, layoutVersion=-64.
2020-04-02 05:09:31,018 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=NameSection fields, terminators=[]):{[]namespaceId: [1032827169], genstampV1: [1000], genstampV2: [1015], txid: [103], lastAllocatedBlockId: [1073741838], genstampV1Limit: [0]}
2020-04-02 05:09:31,025 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:process(490)) - NS_INFO writing header: {namespaceId: 1032827169
genstampV1: 1000
genstampV2: 1015
genstampV1Limit: 0
lastAllocatedBlockId: 1073741838
transactionId: 103
}
2020-04-02 05:09:31,027 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=ErasureCodingSection fields, terminators=[]):{[












]erasureCodingPolicy: {[

]policyId: [1], policyState: [DISABLED], policyName: [RS-6-3-1024k], ecSchema: {[
]dataUnits: [6], parityUnits: [3], codecName: [rs]}, cellSize: [1048576]}, erasureCodingPolicy: {[

]policyId: [2], policyState: [DISABLED], policyName: [RS-3-2-1024k], ecSchema: {[
]dataUnits: [3], parityUnits: [2], codecName: [rs]}, cellSize: [1048576]}, erasureCodingPolicy: {[

]policyId: [3], policyState: [DISABLED], policyName: [RS-LEGACY-6-3-1024k], ecSchema: {[
]dataUnits: [6], parityUnits: [3], codecName: [rs-legacy]}, cellSize: [1048576]}, erasureCodingPolicy: {[

]policyId: [4], policyState: [ENABLED], policyName: [XOR-2-1-1024k], ecSchema: {[
]dataUnits: [2], parityUnits: [1], codecName: [xor]}, cellSize: [1048576]}, erasureCodingPolicy: {[

]policyId: [5], policyState: [DISABLED], policyName: [RS-10-4-1024k], ecSchema: {[
]dataUnits: [10], parityUnits: [4], codecName: [rs]}, cellSize: [1048576]}, erasureCodingPolicy: {[

]policyId: [64], policyState: [ENABLED], policyName: [RS-10-4-1k], ecSchema: {[

]dataUnits: [10], extraOptions: {[


]option: {[
]value: [v1], key: [k1]}, option: {[
]value: [v2], key: [k2]}}, parityUnits: [4], codecName: [rs]}, cellSize: [1024]}}
2020-04-02 05:09:31,029 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INodeSection fields, terminators=[inode]):{[]numInodes: [27], lastInodeId: [16411]}
2020-04-02 05:09:31,029 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [], nsquota: [9223372036854775807], permission: [root:supergroup:0755], id: [16385], type: [DIRECTORY], mtime: [1585804167970]}
2020-04-02 05:09:31,033 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [dir0], nsquota: [-1], permission: [root:supergroup:0755], id: [16386], type: [DIRECTORY], mtime: [1585804166562]}
2020-04-02 05:09:31,034 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804165345], blocks: {[
]block: {[]numBytes: [1], id: [1073741825], genstamp: [1001]}}, name: [file0], permission: [root:supergroup:0644], id: [16387], storagePolicyId: [0], type: [FILE], mtime: [1585804166187], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,035 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804166199], blocks: {[
]block: {[]numBytes: [1], id: [1073741826], genstamp: [1002]}}, name: [file1], permission: [root:supergroup:0644], id: [16388], storagePolicyId: [0], type: [FILE], mtime: [1585804166324], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,036 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804166352], blocks: {[
]block: {[]numBytes: [1], id: [1073741827], genstamp: [1003]}}, name: [file2], permission: [root:supergroup:0644], id: [16389], storagePolicyId: [0], type: [FILE], mtime: [1585804166552], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,037 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804166562], blocks: {[
]block: {[]numBytes: [1], id: [1073741828], genstamp: [1004]}}, name: [file3], permission: [root:supergroup:0644], id: [16390], storagePolicyId: [0], type: [FILE], mtime: [1585804166712], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,038 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [dir1], nsquota: [-1], permission: [root:supergroup:0755], id: [16391], type: [DIRECTORY], mtime: [1585804167101]}
2020-04-02 05:09:31,039 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804166735], blocks: {[
]block: {[]numBytes: [1], id: [1073741829], genstamp: [1005]}}, name: [file0], permission: [root:supergroup:0644], id: [16392], storagePolicyId: [0], type: [FILE], mtime: [1585804166838], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,039 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804166846], blocks: {[
]block: {[]numBytes: [1], id: [1073741830], genstamp: [1006]}}, name: [file1], permission: [root:supergroup:0644], id: [16393], storagePolicyId: [0], type: [FILE], mtime: [1585804166960], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,040 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804166980], blocks: {[
]block: {[]numBytes: [1], id: [1073741831], genstamp: [1007]}}, name: [file2], permission: [root:supergroup:0644], id: [16394], storagePolicyId: [0], type: [FILE], mtime: [1585804167078], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,041 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804167101], blocks: {[
]block: {[]numBytes: [1], id: [1073741832], genstamp: [1008]}}, name: [file3], permission: [root:supergroup:0644], id: [16395], storagePolicyId: [0], type: [FILE], mtime: [1585804167151], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,041 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [dir2], nsquota: [-1], permission: [root:supergroup:0755], id: [16396], type: [DIRECTORY], mtime: [1585804167515]}
2020-04-02 05:09:31,042 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804167173], blocks: {[
]block: {[]numBytes: [1], id: [1073741833], genstamp: [1009]}}, name: [file0], permission: [root:supergroup:0644], id: [16397], storagePolicyId: [0], type: [FILE], mtime: [1585804167264], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,043 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804167291], blocks: {[
]block: {[]numBytes: [1], id: [1073741834], genstamp: [1010]}}, name: [file1], permission: [root:supergroup:0644], id: [16398], storagePolicyId: [0], type: [FILE], mtime: [1585804167374], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,044 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804167384], blocks: {[
]block: {[]numBytes: [1], id: [1073741835], genstamp: [1011]}}, name: [file2], permission: [root:supergroup:0644], id: [16399], storagePolicyId: [0], type: [FILE], mtime: [1585804167495], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,044 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[
]replication: [3], atime: [1585804167515], blocks: {[
]block: {[]numBytes: [1], id: [1073741836], genstamp: [1012]}}, name: [file3], permission: [root:supergroup:0644], id: [16400], storagePolicyId: [0], type: [FILE], mtime: [1585804167567], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,045 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [emptydir], nsquota: [-1], permission: [root:supergroup:0755], id: [16401], type: [DIRECTORY], mtime: [1585804167598]}
2020-04-02 05:09:31,047 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [dirContainingInvalidXMLChar here], nsquota: [-1], permission: [root:supergroup:0755], id: [16402], type: [DIRECTORY], mtime: [1585804167606]}
2020-04-02 05:09:31,049 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [dirContainingEntityRef&here], nsquota: [-1], permission: [root:supergroup:0755], id: [16403], type: [DIRECTORY], mtime: [1585804167610]}
2020-04-02 05:09:31,051 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [stickyBit], nsquota: [-1], permission: [root:supergroup:1777], id: [16404], type: [DIRECTORY], mtime: [1585804167619]}
2020-04-02 05:09:31,052 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [src], nsquota: [-1], permission: [root:supergroup:0755], id: [16405], type: [DIRECTORY], mtime: [1585804167824]}
2020-04-02 05:09:31,053 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [dst], nsquota: [-1], permission: [root:supergroup:0755], id: [16406], type: [DIRECTORY], mtime: [1585804167691]}
2020-04-02 05:09:31,054 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[

]replication: [3], atime: [1585804167699], blocks: {[
]block: {[]numBytes: [1], id: [1073741838], genstamp: [1014]}}, name: [file], permission: [root:supergroup:0644], id: [16407], storagePolicyId: [0], type: [FILE], mtime: [1585804167857], file-under-construction: {[]clientMachine: [127.0.0.1], clientName: [DFSClient_NONMAPREDUCE_-938411512_1]}, preferredBlockSize: [134217728]}
2020-04-02 05:09:31,054 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], acls: {[]acl: [user:foo:rwx], acl: [group::r-x], acl: [group:bar:r-x]}, name: [xattr], xattrs: {[]xattr: {[]ns: [USER], name: [a4], valHex: [c328]}, xattr: {[]val: [], ns: [USER], name: [a3]}, xattr: {[]val: [789], ns: [USER], name: [a2]}, xattr: {[]val: [123], ns: [USER], name: [a1]}}, nsquota: [-1], permission: [root:supergroup:0771], id: [16408], type: [DIRECTORY], mtime: [1585804167876]}
2020-04-02 05:09:31,059 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]dsquota: [-1], name: [ec], xattrs: {[]xattr: {[]val: [   
XOR-2-1-1024k], ns: [SYSTEM], name: [hdfs.erasurecoding.policy]}}, nsquota: [-1], permission: [root:supergroup:0755], id: [16409], type: [DIRECTORY], mtime: [1585804168098]}
2020-04-02 05:09:31,061 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[]replication: [1], erasureCodingPolicyId: [4], atime: [1585804168009], blockType: [STRIPED], name: [EmptyECFile.txt], permission: [root:supergroup:0644], id: [16410], storagePolicyId: [0], type: [FILE], mtime: [1585804168078], preferredBlockSize: [134217728]}
2020-04-02 05:09:31,062 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INode fields, terminators=[]):{[

]replication: [1], erasureCodingPolicyId: [4], atime: [1585804168098], blocks: {[
]block: {[]numBytes: [0], id: [-9223372036854775792], genstamp: [1015]}}, blockType: [STRIPED], permission: [root:supergroup:0644], storagePolicyId: [0], type: [FILE], mtime: [1585804168098], file-under-construction: {[]clientMachine: [127.0.0.1], clientName: [DFSClient_NONMAPREDUCE_-938411512_1]}, preferredBlockSize: [134217728], name: [SmallECFile.txt], id: [16411]}
2020-04-02 05:09:31,062 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INodeReference, terminators=[]):{[]referredId: [16406], lastSnapshotId: [0], name: [], dstSnapshotId: [2147483646]}
2020-04-02 05:09:31,063 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=INodeReference, terminators=[]):{[]referredId: [16406], lastSnapshotId: [0], name: [orig], dstSnapshotId: [0]}
2020-04-02 05:09:31,063 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=SnapshotSection fields, terminators=[snapshot]):{[
]numSnapshots: [1], snapshottableDir: {[]dir: [16405]}, snapshotCounter: [1]}
2020-04-02 05:09:31,064 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=snapshot fields, terminators=[]):{[]root: {[]dsquota: [-1], name: [snapshot], nsquota: [-1], permission: [root:supergroup:0755], id: [16405], type: [DIRECTORY], mtime: [1585804167813]}, id: [0]}
2020-04-02 05:09:31,064 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=directory, terminators=[]):{[]parent: [16385], refChild: [0], child: [16386], child: [16391], child: [16396], child: [16403], child: [16402], child: [16409], child: [16401], child: [16405], child: [16404], child: [16408]}
2020-04-02 05:09:31,065 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=directory, terminators=[]):{[]parent: [16386], child: [16387], child: [16388], child: [16389], child: [16390]}
2020-04-02 05:09:31,065 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=directory, terminators=[]):{[]parent: [16391], child: [16392], child: [16393], child: [16394], child: [16395]}
2020-04-02 05:09:31,065 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=directory, terminators=[]):{[]parent: [16396], child: [16397], child: [16398], child: [16399], child: [16400]}
2020-04-02 05:09:31,066 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=directory, terminators=[]):{[]parent: [16405], child: [16407]}
2020-04-02 05:09:31,066 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=directory, terminators=[]):{[]parent: [16409], child: [16410], child: [16411]}
2020-04-02 05:09:31,066 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=file under construction, terminators=[]):{[]path: [/src/file], id: [16407]}
2020-04-02 05:09:31,067 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=file under construction, terminators=[]):{[]path: [/ec/SmallECFile.txt], id: [16411]}
2020-04-02 05:09:31,067 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:process(1396)) - Processing SnapshotDiffSection
2020-04-02 05:09:31,067 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:processDirDiffEntry(1420)) - Processing dirDiffEntry
2020-04-02 05:09:31,067 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=dirDiffEntry fields, terminators=[dirDiff]):{[]inodeId: [16385], count: [0]}
2020-04-02 05:09:31,068 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:processDirDiffEntry(1420)) - Processing dirDiffEntry
2020-04-02 05:09:31,068 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=dirDiffEntry fields, terminators=[dirDiff]):{[]inodeId: [16405], count: [1]}
2020-04-02 05:09:31,068 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=dirDiff fields, terminators=[]):{[]snapshotId: [0], createdListSize: [0], childrenSize: [2], deletedInoderef: [1], isSnapshotRoot: [], name: []}
2020-04-02 05:09:31,069 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:processDirDiffEntry(1420)) - Processing dirDiffEntry
2020-04-02 05:09:31,069 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=dirDiffEntry fields, terminators=[dirDiff]):{[]inodeId: [16406], count: [1]}
2020-04-02 05:09:31,069 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=dirDiff fields, terminators=[]):{[
]snapshotId: [0], createdListSize: [0], childrenSize: [0], name: [orig], snapshotCopy: {[]dsquota: [-1], nsquota: [-1], permission: [root:supergroup:0755], mtime: [1585804167691]}}
2020-04-02 05:09:31,070 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:processFileDiffEntry(1527)) - Processing fileDiffEntry
2020-04-02 05:09:31,070 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=fileDiffEntry fields, terminators=[fileDiff]):{[]inodeId: [16407], count: [1]}
2020-04-02 05:09:31,070 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=fileDiff fields, terminators=[]):{[

]snapshotId: [0], size: [2], blocks: {[
]block: {[]numBytes: [2], id: [1073741837], genstamp: [1013]}}, name: [file], snapshotCopy: {[]replication: [3], atime: [1585804167699], permission: [root:supergroup:0644], storagePolicyId: [0], mtime: [1585804167762], preferredBlockSize: [134217728]}}
2020-04-02 05:09:31,071 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=SecretManager fields, terminators=[delegationKey,token]):{[]currentId: [2], tokenSequenceNumber: [1], numDelegationKeys: [2], numTokens: [1]}
2020-04-02 05:09:31,071 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=Delegation key fields, terminators=[]):{[]id: [1], expiry: [2020-04-02T05:09:32.186], key: [8e512a627297d617]}
2020-04-02 05:09:31,072 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=Delegation key fields, terminators=[]):{[]id: [2], expiry: [2020-04-03T05:09:32.186], key: [f432d5769390c3c1]}
2020-04-02 05:09:31,073 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=PersistToken key fields, terminators=[]):{[]owner: [root], masterKeyId: [2], expiryDate: [2020-04-02T05:09:32.642], sequenceNumber: [1], realUser: [], renewer: [JobTracker], maxDate: [2020-04-02T05:09:37.642], issueDate: [2020-04-02T05:09:27.642]}
2020-04-02 05:09:31,074 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=CacheManager fields, terminators=[pool,directive]):{[]numPools: [0], numDirectives: [0], nextDirectiveId: [1]}
2020-04-02 05:09:31,074 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1722)) - STRING_TABLE writing header: {numEntry: 10
}
2020-04-02 05:09:31,075 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 3
str: ""
}
2020-04-02 05:09:31,075 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 8
str: "a1"
}
2020-04-02 05:09:31,076 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 7
str: "a2"
}
2020-04-02 05:09:31,076 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 1
str: "supergroup"
}
2020-04-02 05:09:31,076 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 4
str: "bar"
}
2020-04-02 05:09:31,076 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 6
str: "a3"
}
2020-04-02 05:09:31,077 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 9
str: "hdfs.erasurecoding.policy"
}
2020-04-02 05:09:31,077 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 5
str: "a4"
}
2020-04-02 05:09:31,077 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 0
str: "root"
}
2020-04-02 05:09:31,078 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:writeStringTableSection(1736)) - Writing string table entry: {id: 2
str: "foo"
}
2020-04-02 05:09:31,081 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:processXml(1798)) - Writing FileSummary: {ondiskVersion: 1
layoutVersion: 4294967232
sections {
  name: "NS_INFO"
  length: 23
  offset: 8
}
sections {
  name: "ERASURE_CODING"
  length: 240
  offset: 31
}
sections {
  name: "INODE"
  length: 1844
  offset: 271
}
sections {
  name: "INODE_REFERENCE"
  length: 30
  offset: 2115
}
sections {
  name: "SNAPSHOT"
  length: 73
  offset: 2145
}
sections {
  name: "INODE_DIR"
  length: 120
  offset: 2218
}
sections {
  name: "FILES_UNDERCONSTRUCTION"
  length: 42
  offset: 2338
}
sections {
  name: "SNAPSHOT_DIFF"
  length: 165
  offset: 2380
}
sections {
  name: "SECRET_MANAGER"
  length: 95
  offset: 2545
}
sections {
  name: "CACHE_MANAGER"
  length: 7
  offset: 2640
}
sections {
  name: "STRING_TABLE"
  length: 106
  offset: 2647
}
}
2020-04-02 05:09:31,085 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadStringTable(250)) - Loading 10 strings
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testReverseXmlRoundTrip
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testReverseXmlRoundTrip
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerForECPolicies
[msx] perform reset as unitTestCounterInClass 13 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:31,112 [main] INFO  offlineImageViewer.FSImageHandler (FSImageLoader.java:loadStringTable(250)) - Loading 10 strings
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerForECPolicies
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testOfflineImageViewerForECPolicies
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testFileDistributionCalculatorForException
[msx] perform reset as unitTestCounterInClass 14 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:31,207 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:09:31,235 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:31,236 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:31,237 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:31,237 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:31,237 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:31,237 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:31,237 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:31,237 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:31,238 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:31,238 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:31,238 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:31,282 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:31,283 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:31
2020-04-02 05:09:31,284 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:31,285 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:31,286 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:09:31,286 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:31,292 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:09:31,293 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:31,293 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:31,294 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:31,294 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:31,295 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:09:31,295 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:31,295 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:31,295 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:31,300 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:31,301 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:31,301 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:31,302 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:31,303 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:31,303 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:09:31,303 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:31,306 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:31,318 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:31,318 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:31,319 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:31,319 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:31,319 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:31,320 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:31,320 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:31,320 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:09:31,320 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:31,321 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:31,322 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:31,322 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:31,323 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:31,323 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:31,323 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:31,323 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:31,324 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:09:31,324 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:31,326 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:31,334 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:09:31,336 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:09:31,345 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:31,347 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:31,354 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 470 bytes saved in 0 seconds .
2020-04-02 05:09:31,376 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 470 bytes saved in 0 seconds .
2020-04-02 05:09:31,381 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:09:31,385 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:09:31,395 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:09:31,398 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:09:31,398 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:09:31,399 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:09:31,400 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:09:31,407 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:09:31,408 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:31,409 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:31,410 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@10ad20cb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:31,411 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:09:31,411 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:31,413 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:31,414 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:09:31,414 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:31,414 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:31,417 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:09:31,417 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:09:31,417 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33564
2020-04-02 05:09:31,418 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:31,428 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26f143ed{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:31,434 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4b770e40{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:31,446 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@271f18d3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:09:31,447 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6bd51ed8{HTTP/1.1,[http/1.1]}{localhost:33564}
2020-04-02 05:09:31,448 [main] INFO  server.Server (Server.java:doStart(419)) - Started @13225ms
2020-04-02 05:09:31,468 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:31,468 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:31,469 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:31,469 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:31,469 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:31,469 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:31,469 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:31,469 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:31,470 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:31,470 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:31,470 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:31,470 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:31,471 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:31
2020-04-02 05:09:31,471 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:31,471 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:31,471 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:09:31,471 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:31,481 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:09:31,487 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:31,487 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:31,487 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:31,487 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:31,487 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:09:31,488 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:31,488 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:31,488 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:31,488 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:31,488 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:31,488 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:31,491 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:31,491 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:31,491 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:09:31,492 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:31,498 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:31,498 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:31,498 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:31,498 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:31,498 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:31,498 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:31,498 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:31,499 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:31,499 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:09:31,499 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:31,500 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:31,500 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:31,500 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:31,500 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:31,500 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:31,500 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:31,500 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:31,501 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:09:31,501 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:31,509 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:31,511 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:31,513 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:09:31,513 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:09:31,513 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:09:31,514 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:09:31,515 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:09:31,516 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:09:31,516 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:09:31,516 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:09:31,517 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:09:31,539 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:09:31,539 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 31 msecs
2020-04-02 05:09:31,540 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:09:31,540 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:31,541 [Socket Reader #1 for port 38950] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38950
2020-04-02 05:09:31,546 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38950 to access this namenode/service.
2020-04-02 05:09:31,548 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:09:31,587 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:09:31,590 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:09:31,590 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:09:31,590 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:09:31,590 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:09:31,596 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:09:31,596 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:09:31,596 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:09:31,596 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:09:31,596 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:09:31,596 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-04-02 05:09:31,617 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:31,617 [IPC Server listener on 38950] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38950: starting
2020-04-02 05:09:31,641 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38950
2020-04-02 05:09:31,641 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:09:31,642 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:09:31,642 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:09:31,643 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38950 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:31,645 [CacheReplicationMonitor(998697396)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:09:31,695 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:31,696 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:31,702 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:31,903 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:31,904 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:31,904 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:31,904 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:31,905 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:31,905 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:31,905 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:31,906 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43097
2020-04-02 05:09:31,906 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:31,906 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:31,908 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:31,910 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:31,911 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:31,911 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:31,913 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:31,914 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:31,914 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:31,914 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:31,915 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45976
2020-04-02 05:09:31,915 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:31,916 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@35e52059{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:31,917 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49bd54f7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:31,922 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5a772895{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:31,925 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@39fc6b2c{HTTP/1.1,[http/1.1]}{localhost:45976}
2020-04-02 05:09:31,925 [main] INFO  server.Server (Server.java:doStart(419)) - Started @13703ms
2020-04-02 05:09:31,952 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36872
2020-04-02 05:09:31,952 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3ee39da0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:31,953 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:31,953 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:31,953 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:31,954 [Socket Reader #1 for port 39656] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39656
2020-04-02 05:09:31,960 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39656
2020-04-02 05:09:31,966 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:31,967 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:31,968 [Thread-344] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38950 starting to offer service
2020-04-02 05:09:31,980 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:31,980 [IPC Server listener on 39656] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39656: starting
2020-04-02 05:09:31,981 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39656 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:32,018 [IPC Server handler 1 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:32,029 [Thread-344] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38950
2020-04-02 05:09:32,029 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:32,033 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:32,033 [Thread-344] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:32,037 [Thread-344] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:32,037 [Thread-344] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 692390529. Formatting...
2020-04-02 05:09:32,039 [Thread-344] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-96d7dba5-65f7-49e0-bb00-e5f1d896d696 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:09:32,047 [Thread-344] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 21645@5909b7672181
2020-04-02 05:09:32,047 [Thread-344] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 692390529. Formatting...
2020-04-02 05:09:32,048 [Thread-344] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-78828ae6-981f-439a-b323-570104eacd01 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:09:32,064 [Thread-344] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:32,065 [Thread-344] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:32,065 [Thread-344] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-2067076682-172.17.0.13-1585804171326 is not formatted. Formatting ...
2020-04-02 05:09:32,065 [Thread-344] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2067076682-172.17.0.13-1585804171326 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2067076682-172.17.0.13-1585804171326/current
2020-04-02 05:09:32,074 [Thread-344] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:32,074 [Thread-344] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:32,075 [Thread-344] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-2067076682-172.17.0.13-1585804171326 is not formatted. Formatting ...
2020-04-02 05:09:32,075 [Thread-344] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2067076682-172.17.0.13-1585804171326 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2067076682-172.17.0.13-1585804171326/current
2020-04-02 05:09:32,077 [Thread-344] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=692390529;bpid=BP-2067076682-172.17.0.13-1585804171326;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=692390529;c=1585804171326;bpid=BP-2067076682-172.17.0.13-1585804171326;dnuuid=null
2020-04-02 05:09:32,079 [Thread-344] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3
2020-04-02 05:09:32,081 [Thread-344] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-96d7dba5-65f7-49e0-bb00-e5f1d896d696
2020-04-02 05:09:32,084 [Thread-344] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:09:32,086 [Thread-344] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-78828ae6-981f-439a-b323-570104eacd01
2020-04-02 05:09:32,088 [Thread-344] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:09:32,089 [Thread-344] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:32,090 [Thread-344] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:32,091 [Thread-344] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:32,091 [Thread-344] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:32,091 [Thread-344] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:32,091 [Thread-344] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:32,092 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2067076682-172.17.0.13-1585804171326 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:32,092 [Thread-360] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2067076682-172.17.0.13-1585804171326 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:32,133 [Thread-360] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2067076682-172.17.0.13-1585804171326 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 41ms
2020-04-02 05:09:32,133 [Thread-359] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2067076682-172.17.0.13-1585804171326 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 41ms
2020-04-02 05:09:32,143 [IPC Server handler 2 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:32,144 [Thread-344] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2067076682-172.17.0.13-1585804171326: 52ms
2020-04-02 05:09:32,145 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:32,146 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:32,145 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2067076682-172.17.0.13-1585804171326 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:32,146 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2067076682-172.17.0.13-1585804171326 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:32,146 [Thread-363] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2067076682-172.17.0.13-1585804171326/current/replicas doesn't exist 
2020-04-02 05:09:32,146 [Thread-364] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2067076682-172.17.0.13-1585804171326/current/replicas doesn't exist 
2020-04-02 05:09:32,147 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2067076682-172.17.0.13-1585804171326 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:09:32,147 [Thread-364] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2067076682-172.17.0.13-1585804171326 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:09:32,148 [Thread-344] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2067076682-172.17.0.13-1585804171326: 3ms
2020-04-02 05:09:32,148 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2067076682-172.17.0.13-1585804171326 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:32,148 [Thread-344] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:22 AM with interval of 21600000ms
2020-04-02 05:09:32,148 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-96d7dba5-65f7-49e0-bb00-e5f1d896d696): finished scanning block pool BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:32,149 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2067076682-172.17.0.13-1585804171326 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:32,151 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-78828ae6-981f-439a-b323-570104eacd01): finished scanning block pool BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:32,153 [BP-2067076682-172.17.0.13-1585804171326 heartbeating to localhost/127.0.0.1:38950] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2067076682-172.17.0.13-1585804171326 (Datanode Uuid 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3) service to localhost/127.0.0.1:38950 beginning handshake with NN
2020-04-02 05:09:32,155 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-96d7dba5-65f7-49e0-bb00-e5f1d896d696): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:09:32,155 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-78828ae6-981f-439a-b323-570104eacd01): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:09:32,165 [IPC Server handler 3 on 38950] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43097, datanodeUuid=322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3, infoPort=36872, infoSecurePort=0, ipcPort=39656, storageInfo=lv=-57;cid=testClusterID;nsid=692390529;c=1585804171326) storage 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3
2020-04-02 05:09:32,166 [IPC Server handler 3 on 38950] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43097
2020-04-02 05:09:32,166 [IPC Server handler 3 on 38950] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3 (127.0.0.1:43097).
2020-04-02 05:09:32,174 [BP-2067076682-172.17.0.13-1585804171326 heartbeating to localhost/127.0.0.1:38950] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2067076682-172.17.0.13-1585804171326 (Datanode Uuid 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3) service to localhost/127.0.0.1:38950 successfully registered with NN
2020-04-02 05:09:32,174 [BP-2067076682-172.17.0.13-1585804171326 heartbeating to localhost/127.0.0.1:38950] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38950 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:32,189 [IPC Server handler 4 on 38950] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-96d7dba5-65f7-49e0-bb00-e5f1d896d696 for DN 127.0.0.1:43097
2020-04-02 05:09:32,190 [IPC Server handler 4 on 38950] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-78828ae6-981f-439a-b323-570104eacd01 for DN 127.0.0.1:43097
2020-04-02 05:09:32,203 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb5c01dbc73b8bbca: Processing first storage report for DS-96d7dba5-65f7-49e0-bb00-e5f1d896d696 from datanode 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3
2020-04-02 05:09:32,205 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb5c01dbc73b8bbca: from storage DS-96d7dba5-65f7-49e0-bb00-e5f1d896d696 node DatanodeRegistration(127.0.0.1:43097, datanodeUuid=322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3, infoPort=36872, infoSecurePort=0, ipcPort=39656, storageInfo=lv=-57;cid=testClusterID;nsid=692390529;c=1585804171326), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:32,205 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb5c01dbc73b8bbca: Processing first storage report for DS-78828ae6-981f-439a-b323-570104eacd01 from datanode 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3
2020-04-02 05:09:32,206 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb5c01dbc73b8bbca: from storage DS-78828ae6-981f-439a-b323-570104eacd01 node DatanodeRegistration(127.0.0.1:43097, datanodeUuid=322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3, infoPort=36872, infoSecurePort=0, ipcPort=39656, storageInfo=lv=-57;cid=testClusterID;nsid=692390529;c=1585804171326), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:32,209 [BP-2067076682-172.17.0.13-1585804171326 heartbeating to localhost/127.0.0.1:38950] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb5c01dbc73b8bbca,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:32,209 [BP-2067076682-172.17.0.13-1585804171326 heartbeating to localhost/127.0.0.1:38950] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:32,247 [IPC Server handler 6 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:32,255 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:32,262 [IPC Server handler 7 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:32,263 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:32,265 [IPC Server handler 8 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:32,278 [IPC Server handler 9 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir	dst=null	perm=null	proto=rpc
2020-04-02 05:09:32,280 [IPC Server handler 1 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:32,284 [IPC Server handler 0 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir/file0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:32,305 [IPC Server handler 2 on 38950] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:43097 for /dir/file0
2020-04-02 05:09:32,315 [DataXceiver for client DFSClient_NONMAPREDUCE_1700791897_1 at /127.0.0.1:41708 [Receiving block BP-2067076682-172.17.0.13-1585804171326:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2067076682-172.17.0.13-1585804171326:blk_1073741825_1001 src: /127.0.0.1:41708 dest: /127.0.0.1:43097
2020-04-02 05:09:32,331 [PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41708, dest: /127.0.0.1:43097, bytes: 3, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1700791897_1, offset: 0, srvID: 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3, blockid: BP-2067076682-172.17.0.13-1585804171326:blk_1073741825_1001, duration(ns): 11082607
2020-04-02 05:09:32,331 [PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:32,332 [IPC Server handler 4 on 38950] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /dir/file0
2020-04-02 05:09:32,761 [IPC Server handler 6 on 38950] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir/file0 is closed by DFSClient_NONMAPREDUCE_1700791897_1
2020-04-02 05:09:32,763 [IPC Server handler 7 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir/file0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:32,764 [IPC Server handler 8 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:32,766 [IPC Server handler 9 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir/file1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:32,771 [IPC Server handler 1 on 38950] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:43097 for /dir/file1
2020-04-02 05:09:32,774 [DataXceiver for client DFSClient_NONMAPREDUCE_1700791897_1 at /127.0.0.1:42152 [Receiving block BP-2067076682-172.17.0.13-1585804171326:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2067076682-172.17.0.13-1585804171326:blk_1073741826_1002 src: /127.0.0.1:42152 dest: /127.0.0.1:43097
2020-04-02 05:09:32,779 [PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42152, dest: /127.0.0.1:43097, bytes: 9, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1700791897_1, offset: 0, srvID: 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3, blockid: BP-2067076682-172.17.0.13-1585804171326:blk_1073741826_1002, duration(ns): 3438397
2020-04-02 05:09:32,780 [PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:32,782 [IPC Server handler 0 on 38950] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741826_1002 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /dir/file1
2020-04-02 05:09:33,187 [IPC Server handler 3 on 38950] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir/file1 is closed by DFSClient_NONMAPREDUCE_1700791897_1
2020-04-02 05:09:33,189 [IPC Server handler 4 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir/file1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:33,190 [IPC Server handler 5 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:33,192 [IPC Server handler 6 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir/file2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:33,198 [IPC Server handler 7 on 38950] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:43097 for /dir/file2
2020-04-02 05:09:33,200 [DataXceiver for client DFSClient_NONMAPREDUCE_1700791897_1 at /127.0.0.1:42398 [Receiving block BP-2067076682-172.17.0.13-1585804171326:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2067076682-172.17.0.13-1585804171326:blk_1073741827_1003 src: /127.0.0.1:42398 dest: /127.0.0.1:43097
2020-04-02 05:09:33,206 [PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42398, dest: /127.0.0.1:43097, bytes: 15, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1700791897_1, offset: 0, srvID: 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3, blockid: BP-2067076682-172.17.0.13-1585804171326:blk_1073741827_1003, duration(ns): 3216874
2020-04-02 05:09:33,206 [PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:33,208 [IPC Server handler 9 on 38950] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir/file2 is closed by DFSClient_NONMAPREDUCE_1700791897_1
2020-04-02 05:09:33,211 [IPC Server handler 1 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir/file2	dst=null	perm=null	proto=rpc
2020-04-02 05:09:33,216 [IPC Server handler 0 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/dir	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:33,218 [IPC Server handler 2 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/dir/file3	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:33,221 [IPC Server handler 3 on 38950] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:43097 for /dir/file3
2020-04-02 05:09:33,223 [DataXceiver for client DFSClient_NONMAPREDUCE_1700791897_1 at /127.0.0.1:42400 [Receiving block BP-2067076682-172.17.0.13-1585804171326:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2067076682-172.17.0.13-1585804171326:blk_1073741828_1004 src: /127.0.0.1:42400 dest: /127.0.0.1:43097
2020-04-02 05:09:33,243 [PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:42400, dest: /127.0.0.1:43097, bytes: 21, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1700791897_1, offset: 0, srvID: 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3, blockid: BP-2067076682-172.17.0.13-1585804171326:blk_1073741828_1004, duration(ns): 17458026
2020-04-02 05:09:33,243 [PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2067076682-172.17.0.13-1585804171326:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:33,245 [IPC Server handler 5 on 38950] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /dir/file3 is closed by DFSClient_NONMAPREDUCE_1700791897_1
2020-04-02 05:09:33,248 [IPC Server handler 6 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/dir/file3	dst=null	perm=null	proto=rpc
2020-04-02 05:09:33,249 [IPC Server handler 7 on 38950] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:09:33,250 [IPC Server handler 7 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_enter	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:33,251 [IPC Server handler 8 on 38950] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:09:33,251 [IPC Server handler 8 on 38950] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 22
2020-04-02 05:09:33,252 [IPC Server handler 8 on 38950] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 23 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 3 Number of syncs: 21 SyncTimes(ms): 3 4 
2020-04-02 05:09:33,253 [IPC Server handler 8 on 38950] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000023
2020-04-02 05:09:33,254 [IPC Server handler 8 on 38950] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000023
2020-04-02 05:09:33,259 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000023 using no compression
2020-04-02 05:09:33,260 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000023 using no compression
2020-04-02 05:09:33,268 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000023 of size 812 bytes saved in 0 seconds .
2020-04-02 05:09:33,269 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000023 of size 812 bytes saved in 0 seconds .
2020-04-02 05:09:33,272 [IPC Server handler 8 on 38950] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-04-02 05:09:33,275 [IPC Server handler 8 on 38950] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 24
2020-04-02 05:09:33,283 [IPC Server handler 8 on 38950] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:09:33,283 [IPC Server handler 8 on 38950] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=saveNamespace	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:33,284 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:09:33,284 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:09:33,284 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39656 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:33,285 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:33,285 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1c4ee95c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:33,289 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-78828ae6-981f-439a-b323-570104eacd01) exiting.
2020-04-02 05:09:33,289 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-96d7dba5-65f7-49e0-bb00-e5f1d896d696) exiting.
2020-04-02 05:09:33,320 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5a772895{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:33,321 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@39fc6b2c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:33,321 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49bd54f7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:33,322 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@35e52059{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:33,338 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39656
2020-04-02 05:09:33,342 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:33,342 [BP-2067076682-172.17.0.13-1585804171326 heartbeating to localhost/127.0.0.1:38950] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:33,342 [BP-2067076682-172.17.0.13-1585804171326 heartbeating to localhost/127.0.0.1:38950] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2067076682-172.17.0.13-1585804171326 (Datanode Uuid 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3) service to localhost/127.0.0.1:38950
2020-04-02 05:09:33,342 [BP-2067076682-172.17.0.13-1585804171326 heartbeating to localhost/127.0.0.1:38950] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2067076682-172.17.0.13-1585804171326 (Datanode Uuid 322cae3f-4ba2-4b5f-938d-3fc63fd5f2a3)
2020-04-02 05:09:33,343 [BP-2067076682-172.17.0.13-1585804171326 heartbeating to localhost/127.0.0.1:38950] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2067076682-172.17.0.13-1585804171326
2020-04-02 05:09:33,353 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2067076682-172.17.0.13-1585804171326] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:33,361 [IPC Server listener on 39656] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39656
2020-04-02 05:09:33,371 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2067076682-172.17.0.13-1585804171326] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:33,374 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:33,374 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:33,374 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:33,374 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:33,376 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:33,376 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:09:33,376 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38950 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:33,376 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:33,376 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 24, 24
2020-04-02 05:09:33,376 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@bae47a0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:09:33,376 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@74a9c4b0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:09:33,379 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 0 
2020-04-02 05:09:33,379 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000024 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000024-0000000000000000025
2020-04-02 05:09:33,380 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000024 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000024-0000000000000000025
2020-04-02 05:09:33,380 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:09:33,380 [CacheReplicationMonitor(998697396)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:09:33,384 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38950
2020-04-02 05:09:33,384 [IPC Server listener on 38950] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38950
2020-04-02 05:09:33,398 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:33,398 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:09:33,400 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:09:33,411 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:33,411 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:09:33,414 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@271f18d3{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:09:33,417 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6bd51ed8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:33,420 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4b770e40{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:33,422 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26f143ed{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:33,434 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:09:33,436 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:09:33,437 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
Processed 0 inodes.
Size	NumFiles
4	1
12	1
16	1
20	1
totalFiles = 4
totalDirectories = 2
totalBlocks = 4
totalSpace = 48
maxFileSize = 21
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testFileDistributionCalculatorForException
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testFileDistributionCalculatorForException
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testReverseXmlWrongLayoutVersion
[msx] perform reset as unitTestCounterInClass 15 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:33,447 [main] DEBUG offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:processXml(1748)) - Loading <fsimage>.
2020-04-02 05:09:33,448 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:expectTag(223)) - Skipping XMLEvent of type 7([Stax Event #7])
2020-04-02 05:09:33,448 [main] TRACE offlineImageViewer.OfflineImageReconstructor (OfflineImageReconstructor.java:loadNodeChildren(425)) - loadNodeChildren(expected=version fields, terminators=[]):{[



]onDiskVersion: [1], oivRevision: [545bbef596c06af1c3c8dca1ce29096a64608478], layoutVersion: [-63]}
[msx] test Finished org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testReverseXmlWrongLayoutVersion
[msx] writeFile testName = org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer#testReverseXmlWrongLayoutVersion
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] all testRunFinished

[msx] before_class
2020-04-02 05:08:44,637 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=9
Formatting using clusterid: testClusterID
2020-04-02 05:08:45,437 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:45,457 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:45,459 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:45,460 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:45,468 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:45,468 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:45,469 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:45,470 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:45,526 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:45,532 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:08:45,533 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:45,533 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:45,539 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:45,540 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:45
2020-04-02 05:08:45,543 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:45,545 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:45,548 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:08:45,548 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:45,583 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:45,591 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:45,592 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:45,592 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:45,592 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:45,592 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:45,592 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:45,593 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:45,593 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:08:45,593 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:45,593 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:45,593 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:45,627 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:08:45,646 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:45,647 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:45,647 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:08:45,647 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:45,653 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:45,654 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:45,654 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:45,654 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:45,660 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:45,663 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:45,667 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:45,667 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:45,668 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:08:45,668 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:45,677 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:45,677 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:45,678 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:45,683 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:45,684 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:45,692 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:45,692 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:45,696 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:08:45,696 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:45,737 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:45,757 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:08:45,760 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:08:45,772 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:45,772 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:45,938 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:45,942 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:45,987 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:08:45,992 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:08:46,200 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:08:46,286 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:08:46,690 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:08:46,691 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:08:46,698 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:08:46,732 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:08:46,806 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54e1c68b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:46,816 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:08:46,822 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:46,839 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3907ms
2020-04-02 05:08:46,966 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:46,970 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:08:46,975 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:46,984 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:46,987 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:08:46,988 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:46,988 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:47,016 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:08:47,016 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:08:47,031 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43795
2020-04-02 05:08:47,033 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:47,115 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d322cad{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:47,117 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f49f6af{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:47,172 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@797b0699{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:08:47,209 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4f704591{HTTP/1.1,[http/1.1]}{localhost:43795}
2020-04-02 05:08:47,210 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4278ms
2020-04-02 05:08:47,227 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:47,228 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:08:47,229 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:47,229 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:47,229 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:47,230 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:47,230 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:47,230 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:47,231 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:47,232 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:47,232 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:47,233 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:47,233 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:47
2020-04-02 05:08:47,233 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:47,234 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:47,234 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:08:47,234 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:47,247 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:08:47,248 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:47,249 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:47,249 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:47,249 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:47,249 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:08:47,250 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:47,250 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:47,250 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 0
2020-04-02 05:08:47,250 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:47,250 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:47,251 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:47,251 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:47,251 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:47,252 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:08:47,252 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:47,254 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:47,254 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:47,255 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:47,255 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:47,255 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:47,268 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:47,268 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:47,269 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:47,269 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:08:47,269 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:47,270 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:47,271 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:47,271 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:47,271 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:47,271 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:47,271 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:47,272 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:47,272 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:08:47,272 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:47,284 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:47,287 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:47,290 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:08:47,291 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:08:47,291 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:08:47,292 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:08:47,338 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:08:47,346 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:08:47,346 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:08:47,352 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:08:47,353 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:08:47,388 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:08:47,389 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 109 msecs
2020-04-02 05:08:47,608 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:08:47,620 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:47,636 [Socket Reader #1 for port 42662] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42662
2020-04-02 05:08:47,984 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:42662 to access this namenode/service.
2020-04-02 05:08:47,997 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:08:48,060 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:08:48,061 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7e5d9a50] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:08:48,095 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:08:48,111 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:08:48,111 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:08:48,113 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:08:48,115 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:08:48,115 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:08:48,115 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:08:48,116 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:08:48,116 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:08:48,116 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-02 05:08:48,197 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:48,214 [IPC Server listener on 42662] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42662: starting
2020-04-02 05:08:48,242 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:42662
2020-04-02 05:08:48,260 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:08:48,260 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:08:48,272 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 12 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:08:48,278 [CacheReplicationMonitor(735212060)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:08:48,280 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 42662 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:48,293 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:48,401 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:48,430 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:48,451 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:48,451 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:48,468 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:48,470 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:48,475 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:48,476 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:48,482 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:48,505 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33115
2020-04-02 05:08:48,509 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:48,510 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:48,543 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:48,545 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:48,562 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:48,562 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:48,564 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:48,565 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:48,565 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:48,566 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:48,569 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34327
2020-04-02 05:08:48,570 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:48,586 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@665df3c6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:48,588 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4044fb95{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:48,608 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@40cb698e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:48,609 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3382f8ae{HTTP/1.1,[http/1.1]}{localhost:34327}
2020-04-02 05:08:48,609 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5677ms
2020-04-02 05:08:49,269 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42886
2020-04-02 05:08:49,299 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@165b8a71] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:49,299 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:49,299 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:49,320 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:49,326 [Socket Reader #1 for port 34460] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34460
2020-04-02 05:08:49,372 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34460
2020-04-02 05:08:49,398 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:49,403 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:49,982 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662 starting to offer service
2020-04-02 05:08:50,024 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34460 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:50,018 [IPC Server listener on 34460] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34460: starting
2020-04-02 05:08:50,026 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:50,018 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:50,034 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:50,038 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:50,040 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:50,040 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:50,040 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,040 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:50,041 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:50,041 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,053 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:50,061 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37707
2020-04-02 05:08:50,062 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:50,062 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:50,064 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,087 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:50,093 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:50,094 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,096 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:50,101 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:50,112 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:50,113 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:50,114 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44941
2020-04-02 05:08:50,114 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:50,121 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60fa3495{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:50,123 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@79e18e38{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:50,167 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@35fe2125{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:50,167 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@94f6bfb{HTTP/1.1,[http/1.1]}{localhost:44941}
2020-04-02 05:08:50,168 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7236ms
2020-04-02 05:08:50,327 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35335
2020-04-02 05:08:50,327 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:50,328 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:50,327 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2484f433] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:50,328 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:50,331 [Socket Reader #1 for port 42874] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42874
2020-04-02 05:08:50,347 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42874
2020-04-02 05:08:50,356 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:50,356 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:50,357 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662 starting to offer service
2020-04-02 05:08:50,358 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:50,381 [IPC Server listener on 42874] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42874: starting
2020-04-02 05:08:50,391 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42874 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:50,392 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:50,394 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:50,402 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:50,406 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:50,407 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:50,407 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,408 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:50,418 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:50,418 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,419 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:50,420 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40001
2020-04-02 05:08:50,420 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:50,420 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:50,422 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,424 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:50,425 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:50,433 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,440 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:50,450 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:50,450 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:50,450 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:50,451 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33755
2020-04-02 05:08:50,451 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:50,454 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d9bec4d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:50,455 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10c8f62{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:50,479 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@72ccd81a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:50,480 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d8792db{HTTP/1.1,[http/1.1]}{localhost:33755}
2020-04-02 05:08:50,482 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7551ms
2020-04-02 05:08:50,552 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42142
2020-04-02 05:08:50,559 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:50,560 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:50,560 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:50,561 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@493dfb8e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:50,565 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34155
2020-04-02 05:08:50,570 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:50,570 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:50,572 [Socket Reader #1 for port 34155] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34155
2020-04-02 05:08:50,588 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:50,589 [Thread-108] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662 starting to offer service
2020-04-02 05:08:50,590 [IPC Server listener on 34155] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34155: starting
2020-04-02 05:08:50,598 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34155 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:50,609 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:50,611 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:50,611 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:50,646 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:50,646 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:50,647 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,647 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:50,647 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:50,648 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,648 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:50,651 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37829
2020-04-02 05:08:50,652 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:50,652 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:50,654 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,656 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:50,658 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:50,659 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,660 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:50,661 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:50,662 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:50,662 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:50,663 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38953
2020-04-02 05:08:50,663 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:50,671 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32232e55{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:50,673 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37ebc9d8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:50,680 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@c65a5ef{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:50,681 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b5176f2{HTTP/1.1,[http/1.1]}{localhost:38953}
2020-04-02 05:08:50,681 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7749ms
2020-04-02 05:08:50,790 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43541
2020-04-02 05:08:50,798 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:50,798 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:50,798 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:50,802 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2fab4aff] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:50,802 [Socket Reader #1 for port 40489] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40489
2020-04-02 05:08:50,809 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40489
2020-04-02 05:08:50,813 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:50,814 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:50,815 [Thread-131] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662 starting to offer service
2020-04-02 05:08:50,845 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:50,863 [IPC Server listener on 40489] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40489: starting
2020-04-02 05:08:50,870 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40489 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:50,872 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:50,876 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:50,902 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:50,911 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:50,911 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:50,911 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,912 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:50,912 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:50,912 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:50,913 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:50,914 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39182
2020-04-02 05:08:50,914 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:50,914 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:50,916 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,935 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:50,955 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:50,956 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:50,962 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:50,965 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662
2020-04-02 05:08:50,967 [Thread-131] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662
2020-04-02 05:08:50,968 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:50,974 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:50,975 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:50,975 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:50,976 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46111
2020-04-02 05:08:50,976 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:50,978 [Thread-131] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:50,980 [Thread-108] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662
2020-04-02 05:08:50,980 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662
2020-04-02 05:08:50,981 [Thread-131] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:50,981 [Thread-131] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:50,982 [Thread-131] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-faac3c39-e24d-489d-89c7-3f7aafb6128e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:08:50,983 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:50,983 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:50,983 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2f3b72e1-12fc-47d7-a350-5539188d4e05 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:08:50,984 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a1217f9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:50,985 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@523424b5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:50,990 [Thread-108] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:50,991 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:50,991 [Thread-108] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,004 [Thread-108] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,004 [Thread-108] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-be6a1974-1295-47b9-8f93-ef3b934316bb for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:08:51,002 [Thread-131] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,006 [Thread-131] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,006 [Thread-131] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:08:51,008 [Thread-108] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,008 [Thread-108] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,009 [Thread-108] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1944b14f-74e6-4e06-b100-58bcc8482d77 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:08:51,005 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,010 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,010 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-99be8a6c-9a79-4efb-bfda-3855f9256956 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:08:51,006 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,014 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,014 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8edadad1-bdcd-4481-9522-bd34697c24fd for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:08:51,017 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,018 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,018 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:08:51,041 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,044 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,045 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,044 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,054 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,068 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,070 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,070 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,070 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,078 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3bffddff{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:51,079 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@66971f6b{HTTP/1.1,[http/1.1]}{localhost:46111}
2020-04-02 05:08:51,079 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8148ms
2020-04-02 05:08:51,086 [Thread-108] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,087 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,087 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,088 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,088 [Thread-131] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,088 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,088 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,105 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:08:51,131 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,131 [Thread-108] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,131 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,131 [Thread-108] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,136 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35339
2020-04-02 05:08:51,137 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:51,137 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:51,137 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:51,138 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@517bd097] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:51,144 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,144 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,145 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,145 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,145 [Socket Reader #1 for port 42715] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42715
2020-04-02 05:08:51,160 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,160 [Thread-131] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,160 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,160 [Thread-131] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,161 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,161 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,161 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,161 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,163 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42715
2020-04-02 05:08:51,164 [Thread-131] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1548675985;bpid=BP-1076427830-172.17.0.10-1585804125723;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1548675985;c=1585804125723;bpid=BP-1076427830-172.17.0.10-1585804125723;dnuuid=null
2020-04-02 05:08:51,165 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1548675985;bpid=BP-1076427830-172.17.0.10-1585804125723;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1548675985;c=1585804125723;bpid=BP-1076427830-172.17.0.10-1585804125723;dnuuid=null
2020-04-02 05:08:51,167 [Thread-131] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 0b1a99b1-285a-4d40-aaa2-947eb8093a05
2020-04-02 05:08:51,168 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:51,167 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1548675985;bpid=BP-1076427830-172.17.0.10-1585804125723;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1548675985;c=1585804125723;bpid=BP-1076427830-172.17.0.10-1585804125723;dnuuid=null
2020-04-02 05:08:51,168 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:51,170 [Thread-154] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662 starting to offer service
2020-04-02 05:08:51,170 [Thread-108] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1548675985;bpid=BP-1076427830-172.17.0.10-1585804125723;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1548675985;c=1585804125723;bpid=BP-1076427830-172.17.0.10-1585804125723;dnuuid=null
2020-04-02 05:08:51,170 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8008a631-dd3a-486b-bb6f-3e3169812d8f
2020-04-02 05:08:51,171 [Thread-108] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 56e1ca3a-367a-47af-9e27-26584ae1102e
2020-04-02 05:08:51,173 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID cdf1e358-9297-4c05-a11a-c18f14af501f
2020-04-02 05:08:51,176 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:51,190 [IPC Server listener on 42715] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42715: starting
2020-04-02 05:08:51,201 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42715 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:51,202 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:51,203 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:51,222 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:51,249 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:51,250 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:51,250 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,250 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:51,251 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:51,251 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,251 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:51,252 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34235
2020-04-02 05:08:51,252 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:51,252 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:51,253 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,258 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:51,259 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:51,266 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,267 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:51,268 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:51,268 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:51,268 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:51,269 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46039
2020-04-02 05:08:51,269 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:51,262 [Thread-154] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662
2020-04-02 05:08:51,287 [Thread-154] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:51,289 [Thread-154] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,289 [Thread-154] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,289 [Thread-154] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3c0d1081-362b-4414-9407-4b5365359f1f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:08:51,308 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@759fad4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:51,310 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53499d85{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:51,336 [Thread-154] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,337 [Thread-154] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,337 [Thread-154] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:08:51,340 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2f2bf0e2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:51,342 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1eba372c{HTTP/1.1,[http/1.1]}{localhost:46039}
2020-04-02 05:08:51,342 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8410ms
2020-04-02 05:08:51,348 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,349 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,349 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,349 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,371 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,371 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,371 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,372 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,385 [Thread-154] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1548675985;bpid=BP-1076427830-172.17.0.10-1585804125723;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1548675985;c=1585804125723;bpid=BP-1076427830-172.17.0.10-1585804125723;dnuuid=null
2020-04-02 05:08:51,386 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46203
2020-04-02 05:08:51,388 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:51,389 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:51,389 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:51,393 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@25f9407e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:51,393 [Socket Reader #1 for port 33614] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33614
2020-04-02 05:08:51,397 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33614
2020-04-02 05:08:51,394 [Thread-154] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7ef49c98-3053-4533-a2a0-b3306760451d
2020-04-02 05:08:51,406 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:51,412 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:51,415 [Thread-177] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662 starting to offer service
2020-04-02 05:08:51,416 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:51,416 [IPC Server listener on 33614] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33614: starting
2020-04-02 05:08:51,418 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33614 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:51,419 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:51,423 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:51,425 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:51,451 [Thread-177] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662
2020-04-02 05:08:51,452 [Thread-177] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:51,456 [Thread-177] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,456 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:51,456 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:51,457 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,457 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:51,456 [Thread-177] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,458 [Thread-177] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:08:51,461 [Thread-177] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,461 [Thread-177] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,461 [Thread-177] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4188b01d-cb51-4778-873f-1c29b449b256 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:08:51,474 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,475 [Thread-177] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,475 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,475 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,487 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,488 [Thread-177] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,488 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,488 [Thread-177] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:51,495 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:51,495 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,496 [Thread-177] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1548675985;bpid=BP-1076427830-172.17.0.10-1585804125723;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1548675985;c=1585804125723;bpid=BP-1076427830-172.17.0.10-1585804125723;dnuuid=null
2020-04-02 05:08:51,498 [Thread-177] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 3d79862e-baf0-436b-a0a8-9028da1ac3a8
2020-04-02 05:08:51,502 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:51,503 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34710
2020-04-02 05:08:51,504 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:51,504 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:51,506 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,508 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:51,509 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:51,509 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,510 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:51,511 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:51,512 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:51,512 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:51,512 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36796
2020-04-02 05:08:51,512 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:51,514 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e70bd39{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:51,515 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6de54b40{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:51,523 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@56db847e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:51,523 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@740abb5{HTTP/1.1,[http/1.1]}{localhost:36796}
2020-04-02 05:08:51,524 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8592ms
2020-04-02 05:08:51,527 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3c0d1081-362b-4414-9407-4b5365359f1f
2020-04-02 05:08:51,527 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef
2020-04-02 05:08:51,528 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-be6a1974-1295-47b9-8f93-ef3b934316bb
2020-04-02 05:08:51,537 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:08:51,528 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:08:51,538 [Thread-177] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:08:51,540 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2f3b72e1-12fc-47d7-a350-5539188d4e05
2020-04-02 05:08:51,545 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:08:51,541 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-faac3c39-e24d-489d-89c7-3f7aafb6128e
2020-04-02 05:08:51,546 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:08:51,558 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c
2020-04-02 05:08:51,558 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:08:51,565 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:51,566 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf
2020-04-02 05:08:51,566 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:08:51,567 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8edadad1-bdcd-4481-9522-bd34697c24fd
2020-04-02 05:08:51,567 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:08:51,567 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:51,579 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-99be8a6c-9a79-4efb-bfda-3855f9256956
2020-04-02 05:08:51,580 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:08:51,580 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:51,588 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1944b14f-74e6-4e06-b100-58bcc8482d77
2020-04-02 05:08:51,589 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:08:51,604 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:51,620 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:51,621 [Thread-108] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:51,626 [Thread-154] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:51,626 [Thread-131] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:51,646 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-4188b01d-cb51-4778-873f-1c29b449b256
2020-04-02 05:08:51,646 [Thread-177] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:08:51,647 [Thread-177] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:51,648 [Thread-177] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:51,659 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277
2020-04-02 05:08:51,659 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:08:51,659 [Thread-131] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:51,660 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:51,661 [Thread-131] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:51,661 [Thread-131] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:51,667 [Thread-177] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:51,671 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:51,671 [Thread-177] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:51,671 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:51,671 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:51,680 [Thread-131] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,682 [Thread-108] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:51,682 [Thread-108] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:51,682 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45183
2020-04-02 05:08:51,683 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:08:51,685 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,685 [Thread-108] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:51,687 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:51,689 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:51,689 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:51,689 [Thread-154] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:51,690 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:51,690 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:51,690 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:51,690 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:51,690 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:51,703 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:08:51,703 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:08:51,702 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5fe8b721] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:51,695 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:08:51,695 [Thread-177] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:51,704 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:51,718 [Socket Reader #1 for port 40541] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40541
2020-04-02 05:08:51,722 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40541
2020-04-02 05:08:51,725 [Thread-177] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,727 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:08:51,727 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:08:51,729 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,729 [Thread-108] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,730 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:51,730 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:51,730 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:08:51,730 [Thread-220] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:08:51,732 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:08:51,732 [Thread-221] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662 starting to offer service
2020-04-02 05:08:51,732 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:08:51,738 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:51,738 [IPC Server listener on 40541] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40541: starting
2020-04-02 05:08:51,758 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40541 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:51,765 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:51,767 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:51,778 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,790 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:51,800 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:51,800 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:51,801 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,801 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:51,832 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:51,833 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:51,834 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:08:51,837 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:51,839 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34393
2020-04-02 05:08:51,840 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:51,840 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:51,842 [Thread-243] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:08:51,866 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,869 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:51,883 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:51,884 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:51,885 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:51,885 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:51,886 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:51,886 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:51,886 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44367
2020-04-02 05:08:51,887 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:51,889 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7927bd9f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:51,890 [Thread-221] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662
2020-04-02 05:08:51,903 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@410954b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:51,911 [Thread-216] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 179ms
2020-04-02 05:08:51,930 [Thread-221] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:51,934 [Thread-221] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,934 [Thread-221] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,934 [Thread-221] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-00abaa25-d804-45a0-be08-3b0d3cda7f91 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:08:51,934 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 203ms
2020-04-02 05:08:51,938 [Thread-220] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 207ms
2020-04-02 05:08:51,952 [Thread-221] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:51,952 [Thread-221] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:51,952 [Thread-221] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-13c6ccfb-8066-4557-9355-42241365fc0c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:08:51,974 [Thread-206] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 288ms
2020-04-02 05:08:51,975 [Thread-210] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 271ms
2020-04-02 05:08:51,975 [Thread-207] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 271ms
2020-04-02 05:08:51,978 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1076427830-172.17.0.10-1585804125723: 298ms
2020-04-02 05:08:51,979 [Thread-218] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 248ms
2020-04-02 05:08:51,980 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1076427830-172.17.0.10-1585804125723: 250ms
2020-04-02 05:08:51,981 [Thread-235] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 147ms
2020-04-02 05:08:51,983 [Thread-221] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,983 [Thread-221] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:51,983 [Thread-221] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:51,983 [Thread-221] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:52,018 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@10b892d5{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:52,019 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:08:52,019 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:08:52,019 [Thread-253] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,019 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3d3f761a{HTTP/1.1,[http/1.1]}{localhost:44367}
2020-04-02 05:08:52,019 [Thread-255] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,030 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 326ms
2020-04-02 05:08:52,030 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1076427830-172.17.0.10-1585804125723: 344ms
2020-04-02 05:08:52,031 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:08:52,030 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 297ms
2020-04-02 05:08:52,031 [Thread-256] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,030 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:08:52,032 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9088ms
2020-04-02 05:08:52,031 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1076427830-172.17.0.10-1585804125723: 302ms
2020-04-02 05:08:52,036 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 17ms
2020-04-02 05:08:52,035 [Thread-254] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,042 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:08:52,046 [Thread-256] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 15ms
2020-04-02 05:08:52,048 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 321ms
2020-04-02 05:08:52,048 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1076427830-172.17.0.10-1585804125723: 322ms
2020-04-02 05:08:52,050 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 18ms
2020-04-02 05:08:52,050 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:08:52,051 [Thread-258] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,051 [Thread-257] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,052 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 10ms
2020-04-02 05:08:52,052 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 33ms
2020-04-02 05:08:52,052 [Thread-131] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723: 34ms
2020-04-02 05:08:52,054 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:08:52,056 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,058 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:08:52,058 [Thread-259] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,058 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 0ms
2020-04-02 05:08:52,063 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:08:52,063 [Thread-262] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,064 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-04-02 05:08:52,068 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 17ms
2020-04-02 05:08:52,069 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723: 39ms
2020-04-02 05:08:52,073 [Thread-243] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 230ms
2020-04-02 05:08:52,073 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1076427830-172.17.0.10-1585804125723: 295ms
2020-04-02 05:08:52,055 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:08:52,099 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-faac3c39-e24d-489d-89c7-3f7aafb6128e): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,100 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723: 64ms
2020-04-02 05:08:52,148 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:08:52,148 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,070 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:08:52,070 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:08:52,114 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:08:52,170 [Thread-266] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,171 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-99be8a6c-9a79-4efb-bfda-3855f9256956): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,173 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 3ms
2020-04-02 05:08:52,105 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:08:52,175 [Thread-221] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,175 [Thread-221] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,175 [Thread-221] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:52,175 [Thread-221] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:52,176 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2f3b72e1-12fc-47d7-a350-5539188d4e05): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,105 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:08:52,176 [Thread-131] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:53 AM with interval of 21600000ms
2020-04-02 05:08:52,175 [Thread-154] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:43 AM with interval of 21600000ms
2020-04-02 05:08:52,152 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:08:52,141 [Thread-108] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723: 109ms
2020-04-02 05:08:52,148 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:08:52,199 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:08:52,200 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-be6a1974-1295-47b9-8f93-ef3b934316bb): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,200 [Thread-267] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,201 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:08:52,202 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-1944b14f-74e6-4e06-b100-58bcc8482d77): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,202 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 2ms
2020-04-02 05:08:52,205 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723: 133ms
2020-04-02 05:08:52,206 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:08:52,209 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:08:52,210 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8edadad1-bdcd-4481-9522-bd34697c24fd): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,215 [Thread-260] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,215 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,216 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 42ms
2020-04-02 05:08:52,217 [Thread-265] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,218 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:44 AM with interval of 21600000ms
2020-04-02 05:08:52,225 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-be6a1974-1295-47b9-8f93-ef3b934316bb): no suitable block pools found to scan.  Waiting 1814399974 ms.
2020-04-02 05:08:52,226 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8edadad1-bdcd-4481-9522-bd34697c24fd): no suitable block pools found to scan.  Waiting 1814399980 ms.
2020-04-02 05:08:52,226 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-1944b14f-74e6-4e06-b100-58bcc8482d77): no suitable block pools found to scan.  Waiting 1814399973 ms.
2020-04-02 05:08:52,227 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2f3b72e1-12fc-47d7-a350-5539188d4e05): no suitable block pools found to scan.  Waiting 1814399843 ms.
2020-04-02 05:08:52,228 [Thread-108] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:45 AM with interval of 21600000ms
2020-04-02 05:08:52,228 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-3c0d1081-362b-4414-9407-4b5365359f1f): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,235 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c): no suitable block pools found to scan.  Waiting 1814399819 ms.
2020-04-02 05:08:52,236 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:33 AM with interval of 21600000ms
2020-04-02 05:08:52,249 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf): no suitable block pools found to scan.  Waiting 1814399899 ms.
2020-04-02 05:08:52,249 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-faac3c39-e24d-489d-89c7-3f7aafb6128e): no suitable block pools found to scan.  Waiting 1814399805 ms.
2020-04-02 05:08:52,250 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-04-02 05:08:52,251 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-99be8a6c-9a79-4efb-bfda-3855f9256956): no suitable block pools found to scan.  Waiting 1814399820 ms.
2020-04-02 05:08:52,294 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-3c0d1081-362b-4414-9407-4b5365359f1f): no suitable block pools found to scan.  Waiting 1814399853 ms.
2020-04-02 05:08:52,294 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 96ms
2020-04-02 05:08:52,295 [Thread-177] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723: 247ms
2020-04-02 05:08:52,295 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 7ef49c98-3053-4533-a2a0-b3306760451d) service to localhost/127.0.0.1:42662 beginning handshake with NN
2020-04-02 05:08:52,295 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:08:52,295 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:08:52,296 [Thread-177] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:02 AM with interval of 21600000ms
2020-04-02 05:08:52,296 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-4188b01d-cb51-4778-873f-1c29b449b256): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,296 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,296 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-4188b01d-cb51-4778-873f-1c29b449b256): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:08:52,296 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:08:52,307 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 3d79862e-baf0-436b-a0a8-9028da1ac3a8) service to localhost/127.0.0.1:42662 beginning handshake with NN
2020-04-02 05:08:52,322 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid cdf1e358-9297-4c05-a11a-c18f14af501f) service to localhost/127.0.0.1:42662 beginning handshake with NN
2020-04-02 05:08:52,322 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) storage 3d79862e-baf0-436b-a0a8-9028da1ac3a8
2020-04-02 05:08:52,323 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 56e1ca3a-367a-47af-9e27-26584ae1102e) service to localhost/127.0.0.1:42662 beginning handshake with NN
2020-04-02 05:08:52,324 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 8008a631-dd3a-486b-bb6f-3e3169812d8f) service to localhost/127.0.0.1:42662 beginning handshake with NN
2020-04-02 05:08:52,324 [IPC Server handler 1 on 42662] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34235
2020-04-02 05:08:52,325 [IPC Server handler 1 on 42662] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 3d79862e-baf0-436b-a0a8-9028da1ac3a8 (127.0.0.1:34235).
2020-04-02 05:08:52,326 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 0b1a99b1-285a-4d40-aaa2-947eb8093a05) service to localhost/127.0.0.1:42662 beginning handshake with NN
2020-04-02 05:08:52,332 [Thread-221] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1548675985;bpid=BP-1076427830-172.17.0.10-1585804125723;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1548675985;c=1585804125723;bpid=BP-1076427830-172.17.0.10-1585804125723;dnuuid=null
2020-04-02 05:08:52,334 [Thread-221] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a2660b52-86f3-40c5-94b0-9d1be84af49e
2020-04-02 05:08:52,338 [IPC Server handler 8 on 42662] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) storage cdf1e358-9297-4c05-a11a-c18f14af501f
2020-04-02 05:08:52,338 [IPC Server handler 8 on 42662] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33115
2020-04-02 05:08:52,342 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 3d79862e-baf0-436b-a0a8-9028da1ac3a8) service to localhost/127.0.0.1:42662 successfully registered with NN
2020-04-02 05:08:52,342 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42662 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:52,344 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-00abaa25-d804-45a0-be08-3b0d3cda7f91
2020-04-02 05:08:52,346 [IPC Server handler 8 on 42662] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cdf1e358-9297-4c05-a11a-c18f14af501f (127.0.0.1:33115).
2020-04-02 05:08:52,347 [IPC Server handler 8 on 42662] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) storage 0b1a99b1-285a-4d40-aaa2-947eb8093a05
2020-04-02 05:08:52,347 [IPC Server handler 8 on 42662] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37829
2020-04-02 05:08:52,347 [IPC Server handler 8 on 42662] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0b1a99b1-285a-4d40-aaa2-947eb8093a05 (127.0.0.1:37829).
2020-04-02 05:08:52,350 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 0b1a99b1-285a-4d40-aaa2-947eb8093a05) service to localhost/127.0.0.1:42662 successfully registered with NN
2020-04-02 05:08:52,350 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42662 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:52,346 [Thread-221] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:08:52,376 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) storage 8008a631-dd3a-486b-bb6f-3e3169812d8f
2020-04-02 05:08:52,386 [IPC Server handler 7 on 42662] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37707
2020-04-02 05:08:52,386 [IPC Server handler 7 on 42662] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8008a631-dd3a-486b-bb6f-3e3169812d8f (127.0.0.1:37707).
2020-04-02 05:08:52,387 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 8008a631-dd3a-486b-bb6f-3e3169812d8f) service to localhost/127.0.0.1:42662 successfully registered with NN
2020-04-02 05:08:52,388 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-13c6ccfb-8066-4557-9355-42241365fc0c
2020-04-02 05:08:52,388 [Thread-221] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:08:52,388 [Thread-221] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:52,379 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid cdf1e358-9297-4c05-a11a-c18f14af501f) service to localhost/127.0.0.1:42662 successfully registered with NN
2020-04-02 05:08:52,391 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42662 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:52,391 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41499
2020-04-02 05:08:52,393 [Thread-221] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:52,388 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42662 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:52,395 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:52,396 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:52,396 [Thread-221] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:52,396 [Thread-221] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:52,396 [Thread-221] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:52,399 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) storage 56e1ca3a-367a-47af-9e27-26584ae1102e
2020-04-02 05:08:52,400 [IPC Server handler 4 on 42662] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40001
2020-04-02 05:08:52,400 [IPC Server handler 4 on 42662] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 56e1ca3a-367a-47af-9e27-26584ae1102e (127.0.0.1:40001).
2020-04-02 05:08:52,400 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) storage 7ef49c98-3053-4533-a2a0-b3306760451d
2020-04-02 05:08:52,395 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@579d011c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:52,396 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:52,401 [IPC Server handler 2 on 42662] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39182
2020-04-02 05:08:52,402 [IPC Server handler 2 on 42662] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7ef49c98-3053-4533-a2a0-b3306760451d (127.0.0.1:39182).
2020-04-02 05:08:52,402 [Socket Reader #1 for port 45640] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45640
2020-04-02 05:08:52,404 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 7ef49c98-3053-4533-a2a0-b3306760451d) service to localhost/127.0.0.1:42662 successfully registered with NN
2020-04-02 05:08:52,405 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42662 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:52,408 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 56e1ca3a-367a-47af-9e27-26584ae1102e) service to localhost/127.0.0.1:42662 successfully registered with NN
2020-04-02 05:08:52,408 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42662 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:52,435 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45640
2020-04-02 05:08:52,442 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:52,442 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:52,448 [Thread-291] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662 starting to offer service
2020-04-02 05:08:52,460 [IPC Server listener on 45640] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45640: starting
2020-04-02 05:08:52,460 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:52,461 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45640 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:52,462 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:52,463 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:52,463 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:52,464 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:08:52,465 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:08:52,465 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:52,465 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:08:52,472 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:08:52,472 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:52,473 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:08:52,486 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34415
2020-04-02 05:08:52,486 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:08:52,486 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:08:52,496 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:52,497 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:52,499 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:08:52,499 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:52,501 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:52,502 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:08:52,504 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:52,504 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:52,507 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38218
2020-04-02 05:08:52,512 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:52,511 [Thread-221] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,516 [Thread-291] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662
2020-04-02 05:08:52,519 [Thread-291] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:52,521 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:08:52,521 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:08:52,521 [Thread-291] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:52,522 [Thread-291] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:52,523 [Thread-291] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-abe0dd56-f350-4914-a7a9-ac579897ae0c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:08:52,544 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d61eccf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:52,545 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52350abb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:52,546 [Thread-291] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:52,547 [Thread-291] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:52,547 [Thread-291] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:08:52,550 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2c5d601e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:08:52,550 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fe083b1{HTTP/1.1,[http/1.1]}{localhost:38218}
2020-04-02 05:08:52,551 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9619ms
2020-04-02 05:08:52,578 [IPC Server handler 9 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8edadad1-bdcd-4481-9522-bd34697c24fd for DN 127.0.0.1:37707
2020-04-02 05:08:52,579 [IPC Server handler 9 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277 for DN 127.0.0.1:37707
2020-04-02 05:08:52,604 [IPC Server handler 1 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3c0d1081-362b-4414-9407-4b5365359f1f for DN 127.0.0.1:39182
2020-04-02 05:08:52,634 [Thread-308] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 114ms
2020-04-02 05:08:52,636 [Thread-291] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,642 [Thread-291] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,652 [Thread-291] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:52,653 [IPC Server handler 1 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf for DN 127.0.0.1:39182
2020-04-02 05:08:52,654 [Thread-291] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:52,656 [IPC Server handler 3 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2f3b72e1-12fc-47d7-a350-5539188d4e05 for DN 127.0.0.1:33115
2020-04-02 05:08:52,656 [IPC Server handler 3 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-99be8a6c-9a79-4efb-bfda-3855f9256956 for DN 127.0.0.1:33115
2020-04-02 05:08:52,661 [IPC Server handler 0 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-be6a1974-1295-47b9-8f93-ef3b934316bb for DN 127.0.0.1:40001
2020-04-02 05:08:52,661 [IPC Server handler 0 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1944b14f-74e6-4e06-b100-58bcc8482d77 for DN 127.0.0.1:40001
2020-04-02 05:08:52,661 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32943
2020-04-02 05:08:52,668 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:08:52,668 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:08:52,668 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@486be205] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:52,677 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:52,679 [Socket Reader #1 for port 34250] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34250
2020-04-02 05:08:52,681 [IPC Server handler 5 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef for DN 127.0.0.1:34235
2020-04-02 05:08:52,682 [IPC Server handler 5 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4188b01d-cb51-4778-873f-1c29b449b256 for DN 127.0.0.1:34235
2020-04-02 05:08:52,682 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34250
2020-04-02 05:08:52,682 [IPC Server handler 8 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-faac3c39-e24d-489d-89c7-3f7aafb6128e for DN 127.0.0.1:37829
2020-04-02 05:08:52,682 [IPC Server handler 8 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c for DN 127.0.0.1:37829
2020-04-02 05:08:52,690 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 169ms
2020-04-02 05:08:52,691 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1076427830-172.17.0.10-1585804125723: 176ms
2020-04-02 05:08:52,691 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:08:52,692 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:08:52,693 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,693 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-04-02 05:08:52,693 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:52,694 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 2ms
2020-04-02 05:08:52,718 [Thread-291] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,718 [Thread-291] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,718 [Thread-291] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:52,718 [Thread-291] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:52,729 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:08:52,734 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:08:52,734 [Thread-320] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662 starting to offer service
2020-04-02 05:08:52,735 [Thread-291] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1548675985;bpid=BP-1076427830-172.17.0.10-1585804125723;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1548675985;c=1585804125723;bpid=BP-1076427830-172.17.0.10-1585804125723;dnuuid=null
2020-04-02 05:08:52,735 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:52,735 [IPC Server listener on 34250] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34250: starting
2020-04-02 05:08:52,738 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34250 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:52,739 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723: 48ms
2020-04-02 05:08:52,739 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:08:52,740 [Thread-221] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:14 AM with interval of 21600000ms
2020-04-02 05:08:52,741 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:08:52,754 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), reports.length=2
2020-04-02 05:08:52,742 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-00abaa25-d804-45a0-be08-3b0d3cda7f91): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,783 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x58af4a7d67ed20f5: Processing first storage report for DS-8edadad1-bdcd-4481-9522-bd34697c24fd from datanode 8008a631-dd3a-486b-bb6f-3e3169812d8f
2020-04-02 05:08:52,783 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-00abaa25-d804-45a0-be08-3b0d3cda7f91): no suitable block pools found to scan.  Waiting 1814399956 ms.
2020-04-02 05:08:52,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-13c6ccfb-8066-4557-9355-42241365fc0c): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-13c6ccfb-8066-4557-9355-42241365fc0c): no suitable block pools found to scan.  Waiting 1814399955 ms.
2020-04-02 05:08:52,785 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x58af4a7d67ed20f5: from storage DS-8edadad1-bdcd-4481-9522-bd34697c24fd node DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,785 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x58af4a7d67ed20f5: Processing first storage report for DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277 from datanode 8008a631-dd3a-486b-bb6f-3e3169812d8f
2020-04-02 05:08:52,785 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x58af4a7d67ed20f5: from storage DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277 node DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,786 [Thread-291] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 1cda337e-92c5-4d2b-a450-460ae3b1f996
2020-04-02 05:08:52,786 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x58af4a7d67ed20f5
2020-04-02 05:08:52,788 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), reports.length=2
2020-04-02 05:08:52,789 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa89ddb46a5eb6cde: Processing first storage report for DS-2f3b72e1-12fc-47d7-a350-5539188d4e05 from datanode cdf1e358-9297-4c05-a11a-c18f14af501f
2020-04-02 05:08:52,789 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa89ddb46a5eb6cde: from storage DS-2f3b72e1-12fc-47d7-a350-5539188d4e05 node DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,786 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), reports.length=2
2020-04-02 05:08:52,789 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-abe0dd56-f350-4914-a7a9-ac579897ae0c
2020-04-02 05:08:52,798 [Thread-291] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:08:52,814 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x82d9a99528b650a8: Processing first storage report for DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf from datanode 7ef49c98-3053-4533-a2a0-b3306760451d
2020-04-02 05:08:52,814 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x82d9a99528b650a8: from storage DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf node DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,814 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa89ddb46a5eb6cde: Processing first storage report for DS-99be8a6c-9a79-4efb-bfda-3855f9256956 from datanode cdf1e358-9297-4c05-a11a-c18f14af501f
2020-04-02 05:08:52,814 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa89ddb46a5eb6cde: from storage DS-99be8a6c-9a79-4efb-bfda-3855f9256956 node DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,815 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), reports.length=2
2020-04-02 05:08:52,816 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), reports.length=2
2020-04-02 05:08:52,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa3dcfd2bd1b8bbb0: Processing first storage report for DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef from datanode 3d79862e-baf0-436b-a0a8-9028da1ac3a8
2020-04-02 05:08:52,816 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa3dcfd2bd1b8bbb0: from storage DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef node DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,816 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0
2020-04-02 05:08:52,817 [Thread-291] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:08:52,817 [Thread-291] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:52,819 [Thread-291] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:52,820 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), reports.length=2
2020-04-02 05:08:52,843 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2ca9d7a36cfba981: Processing first storage report for DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c from datanode 0b1a99b1-285a-4d40-aaa2-947eb8093a05
2020-04-02 05:08:52,846 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2ca9d7a36cfba981: from storage DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c node DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: true, processing time: 29 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,846 [IPC Server handler 4 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xa89ddb46a5eb6cde
2020-04-02 05:08:52,846 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa3dcfd2bd1b8bbb0: Processing first storage report for DS-4188b01d-cb51-4778-873f-1c29b449b256 from datanode 3d79862e-baf0-436b-a0a8-9028da1ac3a8
2020-04-02 05:08:52,847 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa3dcfd2bd1b8bbb0: from storage DS-4188b01d-cb51-4778-873f-1c29b449b256 node DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,847 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7e00012188797bfe: Processing first storage report for DS-1944b14f-74e6-4e06-b100-58bcc8482d77 from datanode 56e1ca3a-367a-47af-9e27-26584ae1102e
2020-04-02 05:08:52,847 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7e00012188797bfe: from storage DS-1944b14f-74e6-4e06-b100-58bcc8482d77 node DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,847 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x82d9a99528b650a8: Processing first storage report for DS-3c0d1081-362b-4414-9407-4b5365359f1f from datanode 7ef49c98-3053-4533-a2a0-b3306760451d
2020-04-02 05:08:52,847 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x82d9a99528b650a8: from storage DS-3c0d1081-362b-4414-9407-4b5365359f1f node DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,847 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2ca9d7a36cfba981: Processing first storage report for DS-faac3c39-e24d-489d-89c7-3f7aafb6128e from datanode 0b1a99b1-285a-4d40-aaa2-947eb8093a05
2020-04-02 05:08:52,847 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2ca9d7a36cfba981: from storage DS-faac3c39-e24d-489d-89c7-3f7aafb6128e node DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,847 [IPC Server handler 6 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xa3dcfd2bd1b8bbb0
2020-04-02 05:08:52,848 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7e00012188797bfe: Processing first storage report for DS-be6a1974-1295-47b9-8f93-ef3b934316bb from datanode 56e1ca3a-367a-47af-9e27-26584ae1102e
2020-04-02 05:08:52,848 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7e00012188797bfe: from storage DS-be6a1974-1295-47b9-8f93-ef3b934316bb node DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,848 [IPC Server handler 3 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x2ca9d7a36cfba981
2020-04-02 05:08:52,849 [Thread-320] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42662
2020-04-02 05:08:52,849 [IPC Server handler 2 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x82d9a99528b650a8
2020-04-02 05:08:52,849 [IPC Server handler 9 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x7e00012188797bfe
2020-04-02 05:08:52,850 [Thread-291] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:52,850 [Thread-291] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:52,850 [Thread-291] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:52,862 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid a2660b52-86f3-40c5-94b0-9d1be84af49e) service to localhost/127.0.0.1:42662 beginning handshake with NN
2020-04-02 05:08:52,863 [Thread-320] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:08:52,872 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) storage a2660b52-86f3-40c5-94b0-9d1be84af49e
2020-04-02 05:08:52,872 [IPC Server handler 0 on 42662] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34710
2020-04-02 05:08:52,873 [IPC Server handler 0 on 42662] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a2660b52-86f3-40c5-94b0-9d1be84af49e (127.0.0.1:34710).
2020-04-02 05:08:52,873 [Thread-320] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:52,873 [Thread-320] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:52,873 [Thread-320] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:08:52,876 [Thread-291] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,876 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:08:52,877 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid a2660b52-86f3-40c5-94b0-9d1be84af49e) service to localhost/127.0.0.1:42662 successfully registered with NN
2020-04-02 05:08:52,877 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42662 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:52,878 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:08:52,888 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa3dcfd2bd1b8bbb0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 165 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:52,888 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa89ddb46a5eb6cde,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 9 msec to generate and 189 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:52,888 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,888 [Thread-320] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 11121@4db00c0139b4
2020-04-02 05:08:52,889 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,889 [Thread-320] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1548675985. Formatting...
2020-04-02 05:08:52,889 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x82d9a99528b650a8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 10 msec to generate and 188 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:52,889 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,889 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x7e00012188797bfe,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 26 msec to generate and 166 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:52,889 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,889 [Thread-320] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:08:52,903 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x58af4a7d67ed20f5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 168 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:52,903 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,903 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2ca9d7a36cfba981,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 168 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:52,903 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,915 [IPC Server handler 5 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-00abaa25-d804-45a0-be08-3b0d3cda7f91 for DN 127.0.0.1:34710
2020-04-02 05:08:52,915 [IPC Server handler 5 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-13c6ccfb-8066-4557-9355-42241365fc0c for DN 127.0.0.1:34710
2020-04-02 05:08:52,930 [Thread-320] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,930 [Thread-320] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,931 [Thread-320] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:52,931 [Thread-320] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:52,959 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), reports.length=2
2020-04-02 05:08:52,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x36e7222b3bc6f3c5: Processing first storage report for DS-13c6ccfb-8066-4557-9355-42241365fc0c from datanode a2660b52-86f3-40c5-94b0-9d1be84af49e
2020-04-02 05:08:52,974 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x36e7222b3bc6f3c5: from storage DS-13c6ccfb-8066-4557-9355-42241365fc0c node DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,975 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x36e7222b3bc6f3c5: Processing first storage report for DS-00abaa25-d804-45a0-be08-3b0d3cda7f91 from datanode a2660b52-86f3-40c5-94b0-9d1be84af49e
2020-04-02 05:08:52,975 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x36e7222b3bc6f3c5: from storage DS-00abaa25-d804-45a0-be08-3b0d3cda7f91 node DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:52,975 [IPC Server handler 8 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x36e7222b3bc6f3c5
2020-04-02 05:08:52,978 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x36e7222b3bc6f3c5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 48 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:52,978 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,980 [Thread-337] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 102ms
2020-04-02 05:08:52,995 [Thread-320] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,995 [Thread-336] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 118ms
2020-04-02 05:08:52,995 [Thread-320] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:52,996 [Thread-320] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1076427830-172.17.0.10-1585804125723 is not formatted. Formatting ...
2020-04-02 05:08:52,996 [Thread-320] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1076427830-172.17.0.10-1585804125723 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723/current
2020-04-02 05:08:52,997 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1076427830-172.17.0.10-1585804125723: 122ms
2020-04-02 05:08:53,002 [Thread-340] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:08:53,002 [Thread-341] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:08:53,002 [Thread-340] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:53,002 [Thread-341] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:53,003 [Thread-340] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-04-02 05:08:53,012 [Thread-341] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 10ms
2020-04-02 05:08:53,012 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723: 14ms
2020-04-02 05:08:53,012 [Thread-320] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1548675985;bpid=BP-1076427830-172.17.0.10-1585804125723;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1548675985;c=1585804125723;bpid=BP-1076427830-172.17.0.10-1585804125723;dnuuid=null
2020-04-02 05:08:53,012 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:08:53,013 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:08:53,013 [Thread-291] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 11:02 AM with interval of 21600000ms
2020-04-02 05:08:53,013 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:53,013 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-abe0dd56-f350-4914-a7a9-ac579897ae0c): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:53,014 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:08:53,014 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-abe0dd56-f350-4914-a7a9-ac579897ae0c): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:08:53,019 [Thread-320] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 16d40bdc-9ce5-4b23-8a8c-b7603581f803
2020-04-02 05:08:53,035 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 1cda337e-92c5-4d2b-a450-460ae3b1f996) service to localhost/127.0.0.1:42662 beginning handshake with NN
2020-04-02 05:08:53,037 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) storage 1cda337e-92c5-4d2b-a450-460ae3b1f996
2020-04-02 05:08:53,041 [IPC Server handler 1 on 42662] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34393
2020-04-02 05:08:53,041 [IPC Server handler 1 on 42662] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1cda337e-92c5-4d2b-a450-460ae3b1f996 (127.0.0.1:34393).
2020-04-02 05:08:53,042 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda
2020-04-02 05:08:53,043 [Thread-320] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:08:53,046 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 1cda337e-92c5-4d2b-a450-460ae3b1f996) service to localhost/127.0.0.1:42662 successfully registered with NN
2020-04-02 05:08:53,055 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42662 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:53,055 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b
2020-04-02 05:08:53,066 [Thread-320] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:08:53,068 [Thread-320] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:08:53,069 [Thread-320] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:53,070 [Thread-320] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:53,079 [Thread-320] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:53,080 [Thread-320] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:53,085 [Thread-320] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:53,086 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:08:53,086 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:08:53,092 [IPC Server handler 0 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-abe0dd56-f350-4914-a7a9-ac579897ae0c for DN 127.0.0.1:34393
2020-04-02 05:08:53,092 [IPC Server handler 0 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0 for DN 127.0.0.1:34393
2020-04-02 05:08:53,096 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), reports.length=2
2020-04-02 05:08:53,097 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf69639adb08fd436: Processing first storage report for DS-abe0dd56-f350-4914-a7a9-ac579897ae0c from datanode 1cda337e-92c5-4d2b-a450-460ae3b1f996
2020-04-02 05:08:53,097 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf69639adb08fd436: from storage DS-abe0dd56-f350-4914-a7a9-ac579897ae0c node DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:53,097 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf69639adb08fd436: Processing first storage report for DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0 from datanode 1cda337e-92c5-4d2b-a450-460ae3b1f996
2020-04-02 05:08:53,097 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf69639adb08fd436: from storage DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0 node DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:53,097 [IPC Server handler 4 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xf69639adb08fd436
2020-04-02 05:08:53,098 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf69639adb08fd436,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:53,098 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:53,177 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 91ms
2020-04-02 05:08:53,248 [Thread-348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1076427830-172.17.0.10-1585804125723 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 162ms
2020-04-02 05:08:53,248 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1076427830-172.17.0.10-1585804125723: 162ms
2020-04-02 05:08:53,251 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:08:53,251 [Thread-351] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:53,263 [Thread-351] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 12ms
2020-04-02 05:08:53,264 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:08:53,264 [Thread-352] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723/current/replicas doesn't exist 
2020-04-02 05:08:53,270 [Thread-352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 6ms
2020-04-02 05:08:53,270 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1076427830-172.17.0.10-1585804125723: 22ms
2020-04-02 05:08:53,271 [Thread-320] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:47 AM with interval of 21600000ms
2020-04-02 05:08:53,274 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 16d40bdc-9ce5-4b23-8a8c-b7603581f803) service to localhost/127.0.0.1:42662 beginning handshake with NN
2020-04-02 05:08:53,275 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:08:53,278 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) storage 16d40bdc-9ce5-4b23-8a8c-b7603581f803
2020-04-02 05:08:53,277 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1076427830-172.17.0.10-1585804125723 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:08:53,279 [IPC Server handler 6 on 42662] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34415
2020-04-02 05:08:53,279 [IPC Server handler 6 on 42662] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 16d40bdc-9ce5-4b23-8a8c-b7603581f803 (127.0.0.1:34415).
2020-04-02 05:08:53,279 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:53,280 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda): no suitable block pools found to scan.  Waiting 1814399990 ms.
2020-04-02 05:08:53,280 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b): finished scanning block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:53,281 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 16d40bdc-9ce5-4b23-8a8c-b7603581f803) service to localhost/127.0.0.1:42662 successfully registered with NN
2020-04-02 05:08:53,281 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-04-02 05:08:53,281 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42662 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:08:53,321 [IPC Server handler 2 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda for DN 127.0.0.1:34415
2020-04-02 05:08:53,321 [IPC Server handler 2 on 42662] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b for DN 127.0.0.1:34415
2020-04-02 05:08:53,331 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), reports.length=2
2020-04-02 05:08:53,331 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x547d49628c279d8d: Processing first storage report for DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda from datanode 16d40bdc-9ce5-4b23-8a8c-b7603581f803
2020-04-02 05:08:53,331 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x547d49628c279d8d: from storage DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda node DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:53,331 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x547d49628c279d8d: Processing first storage report for DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b from datanode 16d40bdc-9ce5-4b23-8a8c-b7603581f803
2020-04-02 05:08:53,332 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x547d49628c279d8d: from storage DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b node DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:08:53,332 [IPC Server handler 9 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x547d49628c279d8d
2020-04-02 05:08:53,333 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x547d49628c279d8d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 10 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:08:53,333 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:08:53,723 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:53,739 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:08:53,766 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:08:53,812 [IPC Server handler 5 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[0]
[msx] unitTestCounterInClass = 0
2020-04-02 05:08:53,825 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_1_0, dataBlkDelNum = 1, parityBlkDelNum = 0, deleteBlockFile? false
2020-04-02 05:08:53,975 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:53,998 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_1_0 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:08:53,999 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_1_0, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:08:54,024 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_1_0 is added
2020-04-02 05:08:54,026 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_1_0 inode 16386 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:08:54,033 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_1_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:08:54,055 [Thread-359] WARN  erasurecode.ErasureCodeNative (ErasureCodeNative.java:<clinit>(55)) - ISA-L support is not available in your platform... using builtin-java codec where applicable
2020-04-02 05:08:54,117 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:08:54,506 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_1_0  inodeId 16386 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:08:54,510 [IPC Server handler 3 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:08:54,517 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_1_0 with blk_-9223372036854775792_1001 block is added to the in-memory file system
2020-04-02 05:08:54,517 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:34415, 127.0.0.1:37707, 127.0.0.1:34710, 127.0.0.1:34393, 127.0.0.1:40001, 127.0.0.1:37829, 127.0.0.1:39182, 127.0.0.1:33115, 127.0.0.1:34235 for /corrupted_1_0
2020-04-02 05:08:54,518 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_1_0 with new block blk_-9223372036854775792_1001, current total block count is 1
2020-04-02 05:08:54,698 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57080 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 src: /127.0.0.1:57080 dest: /127.0.0.1:34415
2020-04-02 05:08:54,698 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59136 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775791_1001 src: /127.0.0.1:59136 dest: /127.0.0.1:37707
2020-04-02 05:08:54,730 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:43768 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775790_1001 src: /127.0.0.1:43768 dest: /127.0.0.1:34710
2020-04-02 05:08:54,730 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:39578 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775789_1001 src: /127.0.0.1:39578 dest: /127.0.0.1:34393
2020-04-02 05:08:54,771 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:45198 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775788_1001 src: /127.0.0.1:45198 dest: /127.0.0.1:40001
2020-04-02 05:08:54,821 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:56878 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775787_1001 src: /127.0.0.1:56878 dest: /127.0.0.1:37829
2020-04-02 05:08:55,055 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:39256 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775786_1001 src: /127.0.0.1:39256 dest: /127.0.0.1:39182
2020-04-02 05:08:55,120 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:40988 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775785_1001 src: /127.0.0.1:40988 dest: /127.0.0.1:33115
2020-04-02 05:08:55,134 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:60764 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775784_1001 src: /127.0.0.1:60764 dest: /127.0.0.1:34235
2020-04-02 05:08:55,429 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,429 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,431 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:34235 size 4194304 replicaState = RBW
2020-04-02 05:08:55,432 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,449 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:34235
2020-04-02 05:08:55,450 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:55,450 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,456 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:33115 size 4194304 replicaState = RBW
2020-04-02 05:08:55,456 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,456 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:33115
2020-04-02 05:08:55,456 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:55,456 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:37829 size 4194304 replicaState = RBW
2020-04-02 05:08:55,456 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,456 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:37829
2020-04-02 05:08:55,456 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:55,460 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,460 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,461 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:39182 size 4194304 replicaState = RBW
2020-04-02 05:08:55,461 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,461 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:39182
2020-04-02 05:08:55,461 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:55,461 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:37707 size 4194304 replicaState = RBW
2020-04-02 05:08:55,461 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,461 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:37707
2020-04-02 05:08:55,461 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:55,463 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,466 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:40001 size 4194304 replicaState = RBW
2020-04-02 05:08:55,466 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,466 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:40001
2020-04-02 05:08:55,466 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 1, received: 0, deleted: 0
2020-04-02 05:08:55,632 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,633 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:55,633 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,634 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:55,635 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57080, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001, duration(ns): 739223051
2020-04-02 05:08:55,635 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,637 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:34415
2020-04-02 05:08:55,638 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:55,650 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59136, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775791_1001, duration(ns): 766457899
2020-04-02 05:08:55,666 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,677 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,677 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:55,677 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,677 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:55,677 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:37707
2020-04-02 05:08:55,677 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:55,682 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43768, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775790_1001, duration(ns): 792658132
2020-04-02 05:08:55,682 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,685 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,687 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39578, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775789_1001, duration(ns): 798768913
2020-04-02 05:08:55,687 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,688 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:55,688 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,688 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:55,688 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:34710
2020-04-02 05:08:55,695 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:55,696 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,696 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:55,697 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,697 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:55,697 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:34393
2020-04-02 05:08:55,697 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:55,710 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45198, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775788_1001, duration(ns): 839578184
2020-04-02 05:08:55,710 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,716 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56878, dest: /127.0.0.1:37829, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775787_1001, duration(ns): 839719197
2020-04-02 05:08:55,716 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,720 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,720 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:55,721 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,721 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:55,721 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:40001
2020-04-02 05:08:55,721 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:55,728 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,729 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39256, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775786_1001, duration(ns): 662646663
2020-04-02 05:08:55,730 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,734 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:37829 size 4194181 replicaState = FINALIZED
2020-04-02 05:08:55,734 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,735 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:55,736 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:37829
2020-04-02 05:08:55,736 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:55,736 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40988, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775785_1001, duration(ns): 612586861
2020-04-02 05:08:55,736 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,738 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,738 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,744 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60764, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775784_1001, duration(ns): 606895333
2020-04-02 05:08:55,744 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:08:55,747 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:08:55,754 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:55,755 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:08:55,755 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:08:55,755 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:33115
2020-04-02 05:08:55,755 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:55,758 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_1_0 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:08:55,765 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_1_0 with 1 blocks is persisted to the file system
2020-04-02 05:08:55,765 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:add(293)) - BLOCK* NameSystem.LowRedundancyBlock.add: blk_-9223372036854775792_1001 has only 7 replicas and need 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:08:55,766 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_1_0 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:08:55,766 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:55,766 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:08:55,766 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775792_1001 (size=25165701)
2020-04-02 05:08:55,767 [Block report processor] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  2 oldPri  1
2020-04-02 05:08:55,767 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 1
2020-04-02 05:08:55,767 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:08:55,767 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:39182
2020-04-02 05:08:55,767 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:55,767 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:08:55,767 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:08:55,768 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775792_1001 (size=25165701)
2020-04-02 05:08:55,769 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-04-02 05:08:55,769 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:34235
2020-04-02 05:08:55,769 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:08:55,778 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_1_0
2020-04-02 05:08:55,807 [IPC Server handler 6 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:08:55,809 [IPC Server handler 6 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,839 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001
2020-04-02 05:08:55,843 [Thread-359] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:55,849 [Thread-359] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:55,850 [Thread-359] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:55,851 [Thread-359] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:55,851 [Thread-359] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:55,852 [Thread-359] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:55,852 [Thread-359] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:55,853 [Thread-359] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:08:55,855 [Thread-359] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775792
2020-04-02 05:08:55,855 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_1_0
2020-04-02 05:08:55,862 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_1_0
2020-04-02 05:08:55,866 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,869 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_1_0
2020-04-02 05:08:55,873 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,879 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:08:55,879 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:08:55,977 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 from DatanodeInfoWithStorage[127.0.0.1:34415,DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda,DISK] at 0
2020-04-02 05:08:56,222 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 on datanode: 127.0.0.1:34415
2020-04-02 05:08:56,223 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775792_1001 added as corrupt on 127.0.0.1:34415 by /127.0.0.1  because client machine reported it
2020-04-02 05:08:56,224 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:08:56,224 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:08:57,138 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:08:57,138 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:08:59,899 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 from DatanodeInfoWithStorage[127.0.0.1:34415,DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda,DISK] at 0
2020-04-02 05:09:00,016 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775792_1001 on datanode: 127.0.0.1:34415
2020-04-02 05:09:00,016 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775792_1001 to add as corrupt on 127.0.0.1:34415 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:00,016 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775792_1001 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:09:00,017 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-04-02 05:09:00,017 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:09:00,206 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:00,206 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:03,210 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:03,210 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:06,210 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:06,211 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:09,256 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:09,257 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:12,258 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:12,258 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:15,259 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:15,259 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:17,901 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_1_0
2020-04-02 05:09:17,908 [IPC Server handler 8 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:17,920 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:18,259 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:18,260 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:21,260 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:21,260 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:22,471 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_1_0
2020-04-02 05:09:22,476 [IPC Server handler 0 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:22,477 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:24,261 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:24,261 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:27,262 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:27,263 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:27,565 [Thread-359] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_1_0
2020-04-02 05:09:27,569 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:09:27,570 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:09:30,263 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:30,264 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:33,319 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:33,319 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[0]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[0]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[1]
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:35,492 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_1_1, dataBlkDelNum = 1, parityBlkDelNum = 1, deleteBlockFile? false
2020-04-02 05:09:35,568 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:35,570 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_1_1 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:09:35,571 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_1_1, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:09:35,572 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_1_1 is added
2020-04-02 05:09:35,572 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_1_1 inode 16387 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:09:35,572 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_1_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:35,599 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_1_1  inodeId 16387 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:09:35,599 [IPC Server handler 5 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:09:35,602 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_1_1 with blk_-9223372036854775776_1002 block is added to the in-memory file system
2020-04-02 05:09:35,603 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775776_1002, replicas=127.0.0.1:40001, 127.0.0.1:39182, 127.0.0.1:37829, 127.0.0.1:34415, 127.0.0.1:37707, 127.0.0.1:33115, 127.0.0.1:34710, 127.0.0.1:34235, 127.0.0.1:34393 for /corrupted_1_1
2020-04-02 05:09:35,603 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_1_1 with new block blk_-9223372036854775776_1002, current total block count is 1
2020-04-02 05:09:35,634 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:39374 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 src: /127.0.0.1:39374 dest: /127.0.0.1:39182
2020-04-02 05:09:35,642 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:45520 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775776_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775776_1002 src: /127.0.0.1:45520 dest: /127.0.0.1:40001
2020-04-02 05:09:35,670 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57214 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775774_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775774_1002 src: /127.0.0.1:57214 dest: /127.0.0.1:37829
2020-04-02 05:09:35,726 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57524 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775773_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775773_1002 src: /127.0.0.1:57524 dest: /127.0.0.1:34415
2020-04-02 05:09:35,748 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59524 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775772_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775772_1002 src: /127.0.0.1:59524 dest: /127.0.0.1:37707
2020-04-02 05:09:35,750 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:41160 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775771_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775771_1002 src: /127.0.0.1:41160 dest: /127.0.0.1:33115
2020-04-02 05:09:35,828 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:44304 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 src: /127.0.0.1:44304 dest: /127.0.0.1:34710
2020-04-02 05:09:35,858 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:60976 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775769_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775769_1002 src: /127.0.0.1:60976 dest: /127.0.0.1:34235
2020-04-02 05:09:35,923 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:40194 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775768_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775768_1002 src: /127.0.0.1:40194 dest: /127.0.0.1:34393
2020-04-02 05:09:36,239 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45520, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775776_1002, duration(ns): 587407617
2020-04-02 05:09:36,239 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775776_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,247 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:09:36,249 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39374, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002, duration(ns): 608412390
2020-04-02 05:09:36,249 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,250 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775776_1002 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:36,254 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:36,258 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:36,259 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775776_1002 is received from 127.0.0.1:40001
2020-04-02 05:09:36,259 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:36,259 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:09:36,258 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:09:36,261 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775774_1002 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:36,261 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:36,262 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:36,262 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775774_1002 is received from 127.0.0.1:37829
2020-04-02 05:09:36,262 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:36,262 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775775_1002 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:36,262 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:36,262 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:36,262 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775775_1002 is received from 127.0.0.1:39182
2020-04-02 05:09:36,262 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:36,256 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57214, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775774_1002, duration(ns): 531234889
2020-04-02 05:09:36,263 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775774_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,280 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57524, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775773_1002, duration(ns): 517955797
2020-04-02 05:09:36,280 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775773_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,284 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:09:36,287 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775773_1002 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:36,287 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:36,287 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59524, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775772_1002, duration(ns): 489457849
2020-04-02 05:09:36,287 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:36,287 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775772_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,287 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775773_1002 is received from 127.0.0.1:34415
2020-04-02 05:09:36,288 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:36,289 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:09:36,289 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775772_1002 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:36,289 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:36,289 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:36,289 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775772_1002 is received from 127.0.0.1:37707
2020-04-02 05:09:36,289 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:36,295 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41160, dest: /127.0.0.1:33115, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775771_1002, duration(ns): 498798445
2020-04-02 05:09:36,295 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775771_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,300 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44304, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002, duration(ns): 469141094
2020-04-02 05:09:36,300 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,302 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:09:36,302 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:09:36,303 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775770_1002 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:36,303 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:36,303 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:36,303 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775770_1002 is received from 127.0.0.1:34710
2020-04-02 05:09:36,303 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:36,303 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775771_1002 on 127.0.0.1:33115 size 4194181 replicaState = FINALIZED
2020-04-02 05:09:36,303 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:36,304 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:36,304 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775771_1002 is received from 127.0.0.1:33115
2020-04-02 05:09:36,304 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:36,308 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60976, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775769_1002, duration(ns): 437935493
2020-04-02 05:09:36,308 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775769_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,316 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40194, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775768_1002, duration(ns): 387199611
2020-04-02 05:09:36,317 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775768_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,327 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:36,327 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 1 pendingReconstruction = 0
2020-04-02 05:09:36,328 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:09:36,328 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:09:36,328 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775768_1002 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:36,328 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:36,329 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:36,329 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775768_1002 is received from 127.0.0.1:34393
2020-04-02 05:09:36,329 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:36,329 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775769_1002 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:09:36,329 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:09:36,329 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775776_1002 (size=0)
2020-04-02 05:09:36,329 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775769_1002 is received from 127.0.0.1:34235
2020-04-02 05:09:36,330 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:09:36,332 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_1_1 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:09:36,332 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_1_1 with 1 blocks is persisted to the file system
2020-04-02 05:09:36,332 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_1_1 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:09:36,335 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_1_1
2020-04-02 05:09:36,336 [IPC Server handler 6 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:09:36,337 [IPC Server handler 6 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:36,344 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002
2020-04-02 05:09:36,345 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,347 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,348 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,348 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,349 [Thread-433] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775775
2020-04-02 05:09:36,360 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,361 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,361 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,362 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,362 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002
2020-04-02 05:09:36,363 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,363 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,363 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,364 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,368 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,368 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,369 [Thread-433] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775770
2020-04-02 05:09:36,369 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,371 [Thread-433] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:09:36,372 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_1_1
2020-04-02 05:09:36,376 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_1_1
2020-04-02 05:09:36,378 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:36,379 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_1_1
2020-04-02 05:09:36,381 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:36,382 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:09:36,383 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:36,401 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf,DISK] at 0
2020-04-02 05:09:36,438 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-13c6ccfb-8066-4557-9355-42241365fc0c,DISK] at 0
2020-04-02 05:09:36,557 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 on datanode: 127.0.0.1:39182
2020-04-02 05:09:36,557 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775776_1002 added as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:36,558 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:09:36,558 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:09:36,558 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 on datanode: 127.0.0.1:34710
2020-04-02 05:09:36,558 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775776_1002 added as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:36,558 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:36,558 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 2
2020-04-02 05:09:36,558 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:38,998 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf,DISK] at 0
2020-04-02 05:09:39,016 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-13c6ccfb-8066-4557-9355-42241365fc0c,DISK] at 0
2020-04-02 05:09:39,159 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 on datanode: 127.0.0.1:39182
2020-04-02 05:09:39,159 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775776_1002 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:39,159 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:39,159 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:09:39,159 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:39,160 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 on datanode: 127.0.0.1:34710
2020-04-02 05:09:39,160 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775776_1002 to add as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:39,160 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:39,160 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:09:39,160 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:39,328 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:39,328 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:39,328 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:41,210 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf,DISK] at 0
2020-04-02 05:09:41,247 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-13c6ccfb-8066-4557-9355-42241365fc0c,DISK] at 0
2020-04-02 05:09:41,410 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 on datanode: 127.0.0.1:39182
2020-04-02 05:09:41,411 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775776_1002 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:41,411 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:41,411 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:09:41,411 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:41,411 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 on datanode: 127.0.0.1:34710
2020-04-02 05:09:41,411 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775776_1002 to add as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:41,411 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:41,412 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:09:41,412 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:42,329 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:42,329 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:42,329 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:44,454 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf,DISK] at 0
2020-04-02 05:09:44,502 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-13c6ccfb-8066-4557-9355-42241365fc0c,DISK] at 0
2020-04-02 05:09:44,645 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 on datanode: 127.0.0.1:39182
2020-04-02 05:09:44,645 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775776_1002 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:44,646 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:44,646 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:09:44,646 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:44,646 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 on datanode: 127.0.0.1:34710
2020-04-02 05:09:44,646 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775776_1002 to add as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:44,646 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:44,646 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:09:44,646 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:45,330 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:45,330 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:45,330 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:47,507 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf,DISK] at 0
2020-04-02 05:09:47,514 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-13c6ccfb-8066-4557-9355-42241365fc0c,DISK] at 0
2020-04-02 05:09:47,640 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775775_1002 on datanode: 127.0.0.1:39182
2020-04-02 05:09:47,640 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775776_1002 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:47,641 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:47,641 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:09:47,641 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:47,641 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775770_1002 on datanode: 127.0.0.1:34710
2020-04-02 05:09:47,641 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775776_1002 to add as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:09:47,641 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775776_1002 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:09:47,641 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:09:47,641 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775776_1002 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:09:48,331 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:48,331 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:48,331 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:51,332 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:51,332 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:51,332 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:54,332 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:54,332 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:54,332 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:09:55,771 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_1_1
2020-04-02 05:09:55,773 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:09:55,773 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:09:57,333 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:09:57,333 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:09:57,333 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:10:00,334 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:00,335 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:00,335 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:10:00,349 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_1_1
2020-04-02 05:10:00,365 [IPC Server handler 2 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:10:00,365 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:10:03,336 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:03,336 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:03,336 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:10:04,585 [Thread-433] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_1_1
2020-04-02 05:10:04,586 [IPC Server handler 9 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775776_1002]
2020-04-02 05:10:04,587 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:10:06,337 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:06,337 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:06,337 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
2020-04-02 05:10:09,338 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:09,338 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:09,338 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 2 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[1]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[1]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[2]
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:10:10,534 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_1_2, dataBlkDelNum = 1, parityBlkDelNum = 2, deleteBlockFile? false
2020-04-02 05:10:10,583 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:10,585 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_1_2 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:10:10,585 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_1_2, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:10:10,586 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_1_2 is added
2020-04-02 05:10:10,587 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_1_2 inode 16388 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:10:10,587 [IPC Server handler 5 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_1_2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:10:10,588 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 14 Total time for transactions(ms): 34 Number of transactions batched in Syncs: 3 Number of syncs: 11 SyncTimes(ms): 5 9 
2020-04-02 05:10:10,606 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_1_2  inodeId 16388 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:10:10,607 [IPC Server handler 0 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:10:10,610 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_1_2 with blk_-9223372036854775760_1003 block is added to the in-memory file system
2020-04-02 05:10:10,610 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775760_1003, replicas=127.0.0.1:37707, 127.0.0.1:39182, 127.0.0.1:33115, 127.0.0.1:40001, 127.0.0.1:37829, 127.0.0.1:34393, 127.0.0.1:34710, 127.0.0.1:34235, 127.0.0.1:34415 for /corrupted_1_2
2020-04-02 05:10:10,610 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_1_2 with new block blk_-9223372036854775760_1003, current total block count is 1
2020-04-02 05:10:10,618 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:48912 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775760_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775760_1003 src: /127.0.0.1:48912 dest: /127.0.0.1:37707
2020-04-02 05:10:10,619 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57028 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 src: /127.0.0.1:57028 dest: /127.0.0.1:39182
2020-04-02 05:10:10,628 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58704 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775758_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775758_1003 src: /127.0.0.1:58704 dest: /127.0.0.1:33115
2020-04-02 05:10:10,657 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:34954 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775757_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775757_1003 src: /127.0.0.1:34954 dest: /127.0.0.1:40001
2020-04-02 05:10:10,668 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:46616 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775756_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775756_1003 src: /127.0.0.1:46616 dest: /127.0.0.1:37829
2020-04-02 05:10:10,714 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57602 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775755_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775755_1003 src: /127.0.0.1:57602 dest: /127.0.0.1:34393
2020-04-02 05:10:10,720 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:33582 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 src: /127.0.0.1:33582 dest: /127.0.0.1:34710
2020-04-02 05:10:10,765 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50242 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 src: /127.0.0.1:50242 dest: /127.0.0.1:34235
2020-04-02 05:10:10,768 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:46930 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775752_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775752_1003 src: /127.0.0.1:46930 dest: /127.0.0.1:34415
2020-04-02 05:10:10,963 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48912, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775760_1003, duration(ns): 341255616
2020-04-02 05:10:10,963 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775760_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:10,968 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57028, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003, duration(ns): 340068316
2020-04-02 05:10:10,968 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:10,969 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:10,969 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:10,970 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58704, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775758_1003, duration(ns): 325059169
2020-04-02 05:10:10,970 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775760_1003 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:10,970 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775758_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:10,970 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:10,972 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:10,972 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:10,972 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775760_1003 is received from 127.0.0.1:37707
2020-04-02 05:10:10,972 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:10,973 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34954, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775757_1003, duration(ns): 313376917
2020-04-02 05:10:10,973 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775759_1003 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:10,973 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:10,973 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775757_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:10,973 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:10,973 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775759_1003 is received from 127.0.0.1:39182
2020-04-02 05:10:10,974 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:10,974 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:10,974 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775758_1003 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:10,975 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:10,975 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46616, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775756_1003, duration(ns): 305544907
2020-04-02 05:10:10,975 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:10,975 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775756_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:10,975 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775758_1003 is received from 127.0.0.1:33115
2020-04-02 05:10:10,975 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:10,976 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775757_1003 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:10,976 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:10,976 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:10,976 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:10,976 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775757_1003 is received from 127.0.0.1:40001
2020-04-02 05:10:10,977 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:10,976 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57602, dest: /127.0.0.1:34393, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775755_1003, duration(ns): 232547676
2020-04-02 05:10:10,977 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775756_1003 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:10,977 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775755_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:10,977 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:10,977 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:10,978 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775756_1003 is received from 127.0.0.1:37829
2020-04-02 05:10:10,978 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:10,978 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33582, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003, duration(ns): 257310421
2020-04-02 05:10:10,979 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:10,979 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:10,979 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775755_1003 on 127.0.0.1:34393 size 4194181 replicaState = FINALIZED
2020-04-02 05:10:10,979 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:10,980 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:10,980 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775755_1003 is received from 127.0.0.1:34393
2020-04-02 05:10:10,980 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:10,980 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:10,980 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775754_1003 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:10,980 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:10,981 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:10,981 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775754_1003 is received from 127.0.0.1:34710
2020-04-02 05:10:10,981 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:10,981 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50242, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003, duration(ns): 212117734
2020-04-02 05:10:10,981 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:10,981 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:10,982 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775753_1003 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:10,982 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:10,982 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:10,982 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775753_1003 is received from 127.0.0.1:34235
2020-04-02 05:10:10,983 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:10,983 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46930, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775752_1003, duration(ns): 209441474
2020-04-02 05:10:10,983 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775752_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:10,983 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:10,984 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775752_1003 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:10,985 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:10,986 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775760_1003 (size=0)
2020-04-02 05:10:10,986 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775752_1003 is received from 127.0.0.1:34415
2020-04-02 05:10:10,987 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:10,990 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_1_2 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:10:10,991 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_1_2 with 1 blocks is persisted to the file system
2020-04-02 05:10:10,992 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_1_2 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:10:10,993 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_1_2
2020-04-02 05:10:10,995 [IPC Server handler 6 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:10,996 [IPC Server handler 6 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:10,999 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003
2020-04-02 05:10:11,000 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,001 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,001 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,002 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,003 [Thread-502] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775759
2020-04-02 05:10:11,003 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,005 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,005 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,006 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,006 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003
2020-04-02 05:10:11,006 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,007 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,008 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,009 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,010 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,010 [Thread-502] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775753
2020-04-02 05:10:11,010 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,012 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,012 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,012 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003
2020-04-02 05:10:11,013 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,013 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,013 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,014 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,018 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,018 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,019 [Thread-502] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775754
2020-04-02 05:10:11,019 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,019 [Thread-502] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:11,020 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_1_2
2020-04-02 05:10:11,024 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_1_2
2020-04-02 05:10:11,026 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:11,027 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_1_2
2020-04-02 05:10:11,028 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:11,028 [IPC Server handler 4 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:11,029 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:11,043 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:10:11,050 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-00abaa25-d804-45a0-be08-3b0d3cda7f91,DISK] at 0
2020-04-02 05:10:11,051 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef,DISK] at 0
2020-04-02 05:10:11,196 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 on datanode: 127.0.0.1:39182
2020-04-02 05:10:11,196 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775760_1003 added as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:11,196 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:10:11,196 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:10:11,197 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 on datanode: 127.0.0.1:34710
2020-04-02 05:10:11,197 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775760_1003 added as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:11,197 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:11,197 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 2
2020-04-02 05:10:11,197 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:11,197 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 on datanode: 127.0.0.1:34235
2020-04-02 05:10:11,197 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775760_1003 added as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:11,198 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:11,198 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 1
2020-04-02 05:10:11,198 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:12,339 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:12,339 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:12,339 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:12,339 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:12,542 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:10:12,548 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-00abaa25-d804-45a0-be08-3b0d3cda7f91,DISK] at 0
2020-04-02 05:10:12,550 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef,DISK] at 0
2020-04-02 05:10:12,680 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 on datanode: 127.0.0.1:39182
2020-04-02 05:10:12,680 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:12,680 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:12,680 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:12,680 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:12,681 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 on datanode: 127.0.0.1:34710
2020-04-02 05:10:12,681 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:12,681 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:12,681 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:12,681 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:12,681 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 on datanode: 127.0.0.1:34235
2020-04-02 05:10:12,681 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:12,681 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:12,682 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:12,682 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:14,137 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:10:14,144 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-00abaa25-d804-45a0-be08-3b0d3cda7f91,DISK] at 0
2020-04-02 05:10:14,146 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef,DISK] at 0
2020-04-02 05:10:14,295 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 on datanode: 127.0.0.1:39182
2020-04-02 05:10:14,296 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:14,296 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:14,296 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:14,297 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:14,297 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 on datanode: 127.0.0.1:34710
2020-04-02 05:10:14,297 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:14,297 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:14,297 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:14,297 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:14,297 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 on datanode: 127.0.0.1:34235
2020-04-02 05:10:14,298 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:14,298 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:14,298 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:14,298 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:15,340 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:15,341 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:15,342 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:15,342 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:16,292 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:10:16,303 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-00abaa25-d804-45a0-be08-3b0d3cda7f91,DISK] at 0
2020-04-02 05:10:16,305 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef,DISK] at 0
2020-04-02 05:10:16,440 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 on datanode: 127.0.0.1:39182
2020-04-02 05:10:16,441 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:16,441 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:16,441 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:16,441 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:16,442 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 on datanode: 127.0.0.1:34710
2020-04-02 05:10:16,442 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:16,442 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:16,442 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:16,442 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:16,442 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 on datanode: 127.0.0.1:34235
2020-04-02 05:10:16,442 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:16,442 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:16,443 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:16,443 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:18,343 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:18,343 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:18,343 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:18,343 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:18,441 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:10:18,445 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 from DatanodeInfoWithStorage[127.0.0.1:34710,DS-00abaa25-d804-45a0-be08-3b0d3cda7f91,DISK] at 0
2020-04-02 05:10:18,447 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef,DISK] at 0
2020-04-02 05:10:18,582 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775759_1003 on datanode: 127.0.0.1:39182
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775754_1003 on datanode: 127.0.0.1:34710
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:34710 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775753_1003 on datanode: 127.0.0.1:34235
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775760_1003 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775760_1003 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:10:18,583 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:10:18,584 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775760_1003 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:10:21,344 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:21,345 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:21,345 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:21,345 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:24,346 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:24,346 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:24,346 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:24,346 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:25,113 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_1_2
2020-04-02 05:10:25,115 [IPC Server handler 0 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:25,116 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:27,347 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:27,347 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:27,347 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:27,347 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:28,535 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_1_2
2020-04-02 05:10:28,539 [IPC Server handler 3 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:28,540 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:30,348 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:30,348 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:30,348 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:30,348 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:31,945 [Thread-502] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_1_2
2020-04-02 05:10:31,947 [IPC Server handler 0 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775760_1003]
2020-04-02 05:10:31,947 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:10:33,349 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:33,349 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:33,349 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:33,349 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:10:36,350 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:36,351 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:36,351 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:36,351 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[2]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[2]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[3]
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:10:37,254 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_2_0, dataBlkDelNum = 2, parityBlkDelNum = 0, deleteBlockFile? false
2020-04-02 05:10:37,310 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:37,312 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_2_0 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:10:37,313 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_2_0, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:10:37,314 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_2_0 is added
2020-04-02 05:10:37,314 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_2_0 inode 16389 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:10:37,315 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_2_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:10:37,340 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_2_0  inodeId 16389 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:10:37,341 [IPC Server handler 4 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:10:37,343 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_2_0 with blk_-9223372036854775744_1004 block is added to the in-memory file system
2020-04-02 05:10:37,343 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775744_1004, replicas=127.0.0.1:40001, 127.0.0.1:34235, 127.0.0.1:33115, 127.0.0.1:34415, 127.0.0.1:39182, 127.0.0.1:34393, 127.0.0.1:34710, 127.0.0.1:37707, 127.0.0.1:37829 for /corrupted_2_0
2020-04-02 05:10:37,343 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_2_0 with new block blk_-9223372036854775744_1004, current total block count is 1
2020-04-02 05:10:37,348 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:35096 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775744_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775744_1004 src: /127.0.0.1:35096 dest: /127.0.0.1:40001
2020-04-02 05:10:37,364 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50378 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775743_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775743_1004 src: /127.0.0.1:50378 dest: /127.0.0.1:34235
2020-04-02 05:10:37,366 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58852 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 src: /127.0.0.1:58852 dest: /127.0.0.1:33115
2020-04-02 05:10:37,379 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47068 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 src: /127.0.0.1:47068 dest: /127.0.0.1:34415
2020-04-02 05:10:37,391 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57182 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775740_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775740_1004 src: /127.0.0.1:57182 dest: /127.0.0.1:39182
2020-04-02 05:10:37,407 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57750 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775739_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775739_1004 src: /127.0.0.1:57750 dest: /127.0.0.1:34393
2020-04-02 05:10:37,454 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:33730 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775738_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775738_1004 src: /127.0.0.1:33730 dest: /127.0.0.1:34710
2020-04-02 05:10:37,462 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:49074 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775737_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775737_1004 src: /127.0.0.1:49074 dest: /127.0.0.1:37707
2020-04-02 05:10:37,485 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,485 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,485 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775744_1004 on 127.0.0.1:40001 size 4194304 replicaState = RBW
2020-04-02 05:10:37,485 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,485 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,489 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,489 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775744_1004 is received from 127.0.0.1:40001
2020-04-02 05:10:37,489 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 1, received: 0, deleted: 0
2020-04-02 05:10:37,489 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775740_1004 on 127.0.0.1:39182 size 4194304 replicaState = RBW
2020-04-02 05:10:37,489 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,489 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775740_1004 is received from 127.0.0.1:39182
2020-04-02 05:10:37,489 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 1, received: 0, deleted: 0
2020-04-02 05:10:37,489 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775743_1004 on 127.0.0.1:34235 size 4194304 replicaState = RBW
2020-04-02 05:10:37,490 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,490 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775743_1004 is received from 127.0.0.1:34235
2020-04-02 05:10:37,490 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 1, received: 0, deleted: 0
2020-04-02 05:10:37,490 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775742_1004 on 127.0.0.1:33115 size 4194304 replicaState = RBW
2020-04-02 05:10:37,490 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,490 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775742_1004 is received from 127.0.0.1:33115
2020-04-02 05:10:37,490 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 1, received: 0, deleted: 0
2020-04-02 05:10:37,492 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,492 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:46772 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775736_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775736_1004 src: /127.0.0.1:46772 dest: /127.0.0.1:37829
2020-04-02 05:10:37,492 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775737_1004 on 127.0.0.1:37707 size 4194304 replicaState = RBW
2020-04-02 05:10:37,492 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,492 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775737_1004 is received from 127.0.0.1:37707
2020-04-02 05:10:37,493 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 1, received: 0, deleted: 0
2020-04-02 05:10:37,663 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35096, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775744_1004, duration(ns): 307535118
2020-04-02 05:10:37,664 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775744_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:37,666 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50378, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775743_1004, duration(ns): 296292165
2020-04-02 05:10:37,667 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,667 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775743_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:37,667 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775744_1004 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:37,668 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,668 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,668 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:37,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775744_1004 is received from 127.0.0.1:40001
2020-04-02 05:10:37,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:37,669 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775743_1004 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:37,670 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58852, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004, duration(ns): 298331511
2020-04-02 05:10:37,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,670 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:37,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:37,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775743_1004 is received from 127.0.0.1:34235
2020-04-02 05:10:37,670 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:37,671 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775742_1004 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:37,671 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,672 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47068, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004, duration(ns): 283759248
2020-04-02 05:10:37,672 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:37,672 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:37,672 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775742_1004 is received from 127.0.0.1:33115
2020-04-02 05:10:37,672 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:37,674 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,674 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775741_1004 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:37,674 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,675 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57182, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775740_1004, duration(ns): 276119322
2020-04-02 05:10:37,675 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:37,675 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775740_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:37,675 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775741_1004 is received from 127.0.0.1:34415
2020-04-02 05:10:37,675 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:37,676 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,676 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775740_1004 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:37,677 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,678 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:37,678 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57750, dest: /127.0.0.1:34393, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775739_1004, duration(ns): 267586313
2020-04-02 05:10:37,678 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775740_1004 is received from 127.0.0.1:39182
2020-04-02 05:10:37,678 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:37,678 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775739_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:37,678 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,679 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775739_1004 on 127.0.0.1:34393 size 4194181 replicaState = FINALIZED
2020-04-02 05:10:37,679 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,679 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:37,679 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775739_1004 is received from 127.0.0.1:34393
2020-04-02 05:10:37,679 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:37,680 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33730, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775738_1004, duration(ns): 223215046
2020-04-02 05:10:37,681 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775738_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:37,681 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,682 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775738_1004 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:37,682 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,682 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:37,683 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775738_1004 is received from 127.0.0.1:34710
2020-04-02 05:10:37,683 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49074, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775737_1004, duration(ns): 216590679
2020-04-02 05:10:37,683 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:37,683 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775737_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:37,683 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,684 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775737_1004 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:37,685 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,685 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:37,685 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46772, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775736_1004, duration(ns): 188568881
2020-04-02 05:10:37,686 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775737_1004 is received from 127.0.0.1:37707
2020-04-02 05:10:37,686 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:37,686 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775736_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:10:37,686 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:10:37,686 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775736_1004 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:10:37,686 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:10:37,687 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775744_1004 (size=0)
2020-04-02 05:10:37,687 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775736_1004 is received from 127.0.0.1:37829
2020-04-02 05:10:37,687 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:10:37,687 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_2_0 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:10:37,688 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_2_0 with 1 blocks is persisted to the file system
2020-04-02 05:10:37,688 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_2_0 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:10:37,689 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_2_0
2020-04-02 05:10:37,691 [IPC Server handler 0 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:37,692 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:37,694 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004
2020-04-02 05:10:37,695 [Thread-556] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775742
2020-04-02 05:10:37,695 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,696 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,696 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,697 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,697 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,697 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,698 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,698 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,698 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004
2020-04-02 05:10:37,699 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,699 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,699 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,700 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,700 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,700 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,701 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,701 [Thread-556] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:10:37,702 [Thread-556] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775741
2020-04-02 05:10:37,702 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_2_0
2020-04-02 05:10:37,709 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_2_0
2020-04-02 05:10:37,710 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:37,711 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_2_0
2020-04-02 05:10:37,712 [IPC Server handler 6 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:10:37,713 [IPC Server handler 8 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:37,713 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:37,757 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 from DatanodeInfoWithStorage[127.0.0.1:33115,DS-99be8a6c-9a79-4efb-bfda-3855f9256956,DISK] at 0
2020-04-02 05:10:37,758 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 from DatanodeInfoWithStorage[127.0.0.1:34415,DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b,DISK] at 0
2020-04-02 05:10:37,855 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 on datanode: 127.0.0.1:33115
2020-04-02 05:10:37,855 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775744_1004 added as corrupt on 127.0.0.1:33115 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:37,855 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:10:37,855 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:10:37,855 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 on datanode: 127.0.0.1:34415
2020-04-02 05:10:37,855 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775744_1004 added as corrupt on 127.0.0.1:34415 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:37,856 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:37,856 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 2
2020-04-02 05:10:37,856 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:39,109 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 from DatanodeInfoWithStorage[127.0.0.1:33115,DS-99be8a6c-9a79-4efb-bfda-3855f9256956,DISK] at 0
2020-04-02 05:10:39,110 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 from DatanodeInfoWithStorage[127.0.0.1:34415,DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b,DISK] at 0
2020-04-02 05:10:39,196 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 on datanode: 127.0.0.1:33115
2020-04-02 05:10:39,196 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775744_1004 to add as corrupt on 127.0.0.1:33115 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:39,197 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:39,197 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:10:39,197 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:39,197 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 on datanode: 127.0.0.1:34415
2020-04-02 05:10:39,197 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775744_1004 to add as corrupt on 127.0.0.1:34415 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:39,197 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:39,198 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:10:39,198 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:39,351 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:39,351 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:39,352 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:39,352 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:39,352 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:40,403 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 from DatanodeInfoWithStorage[127.0.0.1:33115,DS-99be8a6c-9a79-4efb-bfda-3855f9256956,DISK] at 0
2020-04-02 05:10:40,404 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 from DatanodeInfoWithStorage[127.0.0.1:34415,DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b,DISK] at 0
2020-04-02 05:10:40,499 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 on datanode: 127.0.0.1:33115
2020-04-02 05:10:40,499 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775744_1004 to add as corrupt on 127.0.0.1:33115 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:40,500 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:40,500 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:10:40,500 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:40,500 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 on datanode: 127.0.0.1:34415
2020-04-02 05:10:40,500 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775744_1004 to add as corrupt on 127.0.0.1:34415 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:40,500 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:40,500 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:10:40,501 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:42,353 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:42,353 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:42,353 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:42,354 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:42,354 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:42,486 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 from DatanodeInfoWithStorage[127.0.0.1:33115,DS-99be8a6c-9a79-4efb-bfda-3855f9256956,DISK] at 0
2020-04-02 05:10:42,487 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 from DatanodeInfoWithStorage[127.0.0.1:34415,DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b,DISK] at 0
2020-04-02 05:10:42,584 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 on datanode: 127.0.0.1:33115
2020-04-02 05:10:42,584 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775744_1004 to add as corrupt on 127.0.0.1:33115 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:42,584 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:42,585 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:10:42,585 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:42,585 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 on datanode: 127.0.0.1:34415
2020-04-02 05:10:42,585 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775744_1004 to add as corrupt on 127.0.0.1:34415 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:42,585 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:42,585 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:10:42,585 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:44,326 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 from DatanodeInfoWithStorage[127.0.0.1:33115,DS-99be8a6c-9a79-4efb-bfda-3855f9256956,DISK] at 0
2020-04-02 05:10:44,327 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 from DatanodeInfoWithStorage[127.0.0.1:34415,DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b,DISK] at 0
2020-04-02 05:10:44,410 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775742_1004 on datanode: 127.0.0.1:33115
2020-04-02 05:10:44,411 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775744_1004 to add as corrupt on 127.0.0.1:33115 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:44,411 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:44,411 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:10:44,411 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:44,411 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775741_1004 on datanode: 127.0.0.1:34415
2020-04-02 05:10:44,411 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775744_1004 to add as corrupt on 127.0.0.1:34415 by /127.0.0.1  because client machine reported it
2020-04-02 05:10:44,412 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775744_1004 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:10:44,412 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:10:44,412 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775744_1004 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:10:45,366 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:45,366 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:45,366 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:45,366 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:45,367 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:48,367 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:48,367 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:48,367 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:48,367 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:48,367 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:50,641 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_2_0
2020-04-02 05:10:50,642 [IPC Server handler 9 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:50,643 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:51,368 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:51,368 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:51,368 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:51,368 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:51,369 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:54,311 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_2_0
2020-04-02 05:10:54,327 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:54,329 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:10:54,369 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:54,369 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:54,369 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:54,370 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:54,370 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:57,370 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:10:57,371 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:10:57,371 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:10:57,371 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:10:57,371 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:10:57,904 [Thread-556] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_2_0
2020-04-02 05:10:57,905 [IPC Server handler 2 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775744_1004]
2020-04-02 05:10:57,905 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:00,371 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:00,372 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:00,372 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:00,372 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:00,372 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[3]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[3]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[4]
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:11:03,209 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_2_1, dataBlkDelNum = 2, parityBlkDelNum = 1, deleteBlockFile? false
2020-04-02 05:11:03,259 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:03,260 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_2_1 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:11:03,260 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_2_1, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:11:03,261 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_2_1 is added
2020-04-02 05:11:03,262 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_2_1 inode 16390 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:03,262 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_2_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:11:03,283 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_2_1  inodeId 16390 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:03,284 [IPC Server handler 5 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:03,286 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_2_1 with blk_-9223372036854775728_1005 block is added to the in-memory file system
2020-04-02 05:11:03,287 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775728_1005, replicas=127.0.0.1:34415, 127.0.0.1:34393, 127.0.0.1:37707, 127.0.0.1:39182, 127.0.0.1:34235, 127.0.0.1:34710, 127.0.0.1:40001, 127.0.0.1:33115, 127.0.0.1:37829 for /corrupted_2_1
2020-04-02 05:11:03,287 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_2_1 with new block blk_-9223372036854775728_1005, current total block count is 1
2020-04-02 05:11:03,291 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47212 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775728_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775728_1005 src: /127.0.0.1:47212 dest: /127.0.0.1:34415
2020-04-02 05:11:03,296 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57892 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775727_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775727_1005 src: /127.0.0.1:57892 dest: /127.0.0.1:34393
2020-04-02 05:11:03,314 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:49214 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 src: /127.0.0.1:49214 dest: /127.0.0.1:37707
2020-04-02 05:11:03,320 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57330 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 src: /127.0.0.1:57330 dest: /127.0.0.1:39182
2020-04-02 05:11:03,337 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50534 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775724_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775724_1005 src: /127.0.0.1:50534 dest: /127.0.0.1:34235
2020-04-02 05:11:03,346 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:33878 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775723_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775723_1005 src: /127.0.0.1:33878 dest: /127.0.0.1:34710
2020-04-02 05:11:03,372 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:03,373 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:03,373 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:03,373 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:03,373 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:11:03,390 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:35258 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 src: /127.0.0.1:35258 dest: /127.0.0.1:40001
2020-04-02 05:11:03,402 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59012 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775721_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775721_1005 src: /127.0.0.1:59012 dest: /127.0.0.1:33115
2020-04-02 05:11:03,410 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:46922 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775720_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775720_1005 src: /127.0.0.1:46922 dest: /127.0.0.1:37829
2020-04-02 05:11:03,600 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47212, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775728_1005, duration(ns): 304325770
2020-04-02 05:11:03,600 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775728_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:03,603 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:03,603 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57892, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775727_1005, duration(ns): 301168993
2020-04-02 05:11:03,603 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775727_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:03,604 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:03,604 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775728_1005 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:03,605 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:03,606 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:03,606 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775728_1005 is received from 127.0.0.1:34415
2020-04-02 05:11:03,606 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:03,606 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49214, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005, duration(ns): 289090307
2020-04-02 05:11:03,607 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775727_1005 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:03,607 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:03,607 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:03,607 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:03,608 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:03,608 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775727_1005 is received from 127.0.0.1:34393
2020-04-02 05:11:03,608 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:03,608 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775726_1005 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:03,609 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:03,609 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:03,609 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57330, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005, duration(ns): 285143623
2020-04-02 05:11:03,609 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775726_1005 is received from 127.0.0.1:37707
2020-04-02 05:11:03,609 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:03,609 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:03,609 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:03,610 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775725_1005 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:03,610 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:03,611 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:03,611 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775725_1005 is received from 127.0.0.1:39182
2020-04-02 05:11:03,611 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:03,611 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50534, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775724_1005, duration(ns): 271265939
2020-04-02 05:11:03,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775724_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:03,612 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:03,613 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775724_1005 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:03,613 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:03,613 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:03,614 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775724_1005 is received from 127.0.0.1:34235
2020-04-02 05:11:03,614 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:03,614 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33878, dest: /127.0.0.1:34710, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775723_1005, duration(ns): 265068957
2020-04-02 05:11:03,614 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775723_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:03,615 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:03,615 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775723_1005 on 127.0.0.1:34710 size 4194181 replicaState = FINALIZED
2020-04-02 05:11:03,616 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:03,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:03,617 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35258, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005, duration(ns): 223093341
2020-04-02 05:11:03,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775723_1005 is received from 127.0.0.1:34710
2020-04-02 05:11:03,617 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:03,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:03,618 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:03,618 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775722_1005 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:03,618 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:03,619 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:03,619 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59012, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775721_1005, duration(ns): 214193428
2020-04-02 05:11:03,619 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775722_1005 is received from 127.0.0.1:40001
2020-04-02 05:11:03,619 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775721_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:03,619 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:03,621 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:03,621 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775721_1005 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:03,621 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:03,622 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:03,622 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46922, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775720_1005, duration(ns): 208821021
2020-04-02 05:11:03,622 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775721_1005 is received from 127.0.0.1:33115
2020-04-02 05:11:03,622 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775720_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:03,622 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:03,622 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:03,622 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775720_1005 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:03,623 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:03,623 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775728_1005 (size=0)
2020-04-02 05:11:03,623 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775720_1005 is received from 127.0.0.1:37829
2020-04-02 05:11:03,623 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:03,623 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_2_1 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:03,624 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_2_1 with 1 blocks is persisted to the file system
2020-04-02 05:11:03,624 [IPC Server handler 8 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_2_1 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:03,625 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_2_1
2020-04-02 05:11:03,626 [IPC Server handler 2 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:03,627 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:03,628 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005
2020-04-02 05:11:03,629 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,630 [Thread-609] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775726
2020-04-02 05:11:03,630 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,630 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,631 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,634 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,635 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,635 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,636 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,636 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005
2020-04-02 05:11:03,636 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,637 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,637 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,637 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,638 [Thread-609] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775725
2020-04-02 05:11:03,638 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,638 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,639 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,639 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,639 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005
2020-04-02 05:11:03,640 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,640 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,641 [Thread-609] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775722
2020-04-02 05:11:03,641 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,642 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,642 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,643 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,643 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,644 [Thread-609] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:03,647 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_2_1
2020-04-02 05:11:03,652 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_2_1
2020-04-02 05:11:03,652 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:03,653 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_2_1
2020-04-02 05:11:03,654 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:03,655 [IPC Server handler 9 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:03,655 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:03,665 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-8edadad1-bdcd-4481-9522-bd34697c24fd,DISK] at 0
2020-04-02 05:11:03,665 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:11:03,668 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-be6a1974-1295-47b9-8f93-ef3b934316bb,DISK] at 0
2020-04-02 05:11:03,810 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 on datanode: 127.0.0.1:37707
2020-04-02 05:11:03,811 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775728_1005 added as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:03,811 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:11:03,811 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:11:03,811 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 on datanode: 127.0.0.1:39182
2020-04-02 05:11:03,811 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775728_1005 added as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:03,812 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:11:03,812 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 2
2020-04-02 05:11:03,812 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:11:03,812 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 on datanode: 127.0.0.1:40001
2020-04-02 05:11:03,812 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775728_1005 added as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:03,812 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:03,812 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 1
2020-04-02 05:11:03,812 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:05,120 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-8edadad1-bdcd-4481-9522-bd34697c24fd,DISK] at 0
2020-04-02 05:11:05,121 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:11:05,124 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-be6a1974-1295-47b9-8f93-ef3b934316bb,DISK] at 0
2020-04-02 05:11:05,247 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 on datanode: 127.0.0.1:37707
2020-04-02 05:11:05,247 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:05,247 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:05,248 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:05,248 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:05,248 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 on datanode: 127.0.0.1:39182
2020-04-02 05:11:05,248 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:05,248 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:05,248 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:05,248 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:05,248 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 on datanode: 127.0.0.1:40001
2020-04-02 05:11:05,248 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:05,249 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:05,249 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:05,249 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:06,373 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:06,374 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:06,374 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:06,374 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:06,374 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:06,374 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:06,496 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-8edadad1-bdcd-4481-9522-bd34697c24fd,DISK] at 0
2020-04-02 05:11:06,498 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:11:06,501 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-be6a1974-1295-47b9-8f93-ef3b934316bb,DISK] at 0
2020-04-02 05:11:06,636 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 on datanode: 127.0.0.1:37707
2020-04-02 05:11:06,636 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:06,636 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:06,636 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:06,636 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:06,637 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 on datanode: 127.0.0.1:39182
2020-04-02 05:11:06,637 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:06,637 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:06,637 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:06,637 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:06,637 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 on datanode: 127.0.0.1:40001
2020-04-02 05:11:06,637 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:06,637 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:06,637 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:06,638 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:08,479 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-8edadad1-bdcd-4481-9522-bd34697c24fd,DISK] at 0
2020-04-02 05:11:08,480 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:11:08,483 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-be6a1974-1295-47b9-8f93-ef3b934316bb,DISK] at 0
2020-04-02 05:11:08,607 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 on datanode: 127.0.0.1:37707
2020-04-02 05:11:08,607 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:08,607 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:08,607 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 on datanode: 127.0.0.1:39182
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 on datanode: 127.0.0.1:40001
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:08,608 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:08,609 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:09,374 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:09,375 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:09,375 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:09,375 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:09,375 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:09,375 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:10,402 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-8edadad1-bdcd-4481-9522-bd34697c24fd,DISK] at 0
2020-04-02 05:11:10,403 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:11:10,406 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-be6a1974-1295-47b9-8f93-ef3b934316bb,DISK] at 0
2020-04-02 05:11:10,549 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775726_1005 on datanode: 127.0.0.1:37707
2020-04-02 05:11:10,549 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:10,549 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:10,549 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:10,550 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:10,550 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775725_1005 on datanode: 127.0.0.1:39182
2020-04-02 05:11:10,550 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:10,550 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:10,550 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:10,550 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:10,550 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775722_1005 on datanode: 127.0.0.1:40001
2020-04-02 05:11:10,550 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775728_1005 to add as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:10,550 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775728_1005 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:10,551 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:11:10,551 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775728_1005 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:12,376 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:12,377 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:12,377 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:12,377 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:12,377 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:12,377 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:15,378 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:15,378 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:15,378 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:15,378 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:15,378 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:15,378 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:16,868 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_2_1
2020-04-02 05:11:16,870 [IPC Server handler 0 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:16,870 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:18,378 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:18,379 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:18,379 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:18,379 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:18,379 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:18,379 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:20,300 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_2_1
2020-04-02 05:11:20,314 [IPC Server handler 2 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:20,314 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:21,379 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:21,380 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:21,380 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:21,380 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:21,380 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:21,380 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:23,940 [Thread-609] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_2_1
2020-04-02 05:11:23,941 [IPC Server handler 6 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775728_1005]
2020-04-02 05:11:23,942 [IPC Server handler 6 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:11:24,380 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:24,381 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:24,381 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:24,381 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:24,381 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:24,381 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:11:27,381 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:27,382 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:27,382 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:27,382 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:27,382 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:27,382 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[4]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[4]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:11:29,098 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_3_0, dataBlkDelNum = 3, parityBlkDelNum = 0, deleteBlockFile? false
2020-04-02 05:11:29,147 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:29,148 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_3_0 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:11:29,148 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_3_0, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:11:29,149 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_3_0 is added
2020-04-02 05:11:29,150 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_3_0 inode 16391 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:29,150 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_3_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:11:29,150 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 29 Total time for transactions(ms): 36 Number of transactions batched in Syncs: 6 Number of syncs: 23 SyncTimes(ms): 6 9 
2020-04-02 05:11:29,174 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_3_0  inodeId 16391 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:29,174 [IPC Server handler 4 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:29,176 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_3_0 with blk_-9223372036854775712_1006 block is added to the in-memory file system
2020-04-02 05:11:29,176 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775712_1006, replicas=127.0.0.1:37707, 127.0.0.1:37829, 127.0.0.1:34393, 127.0.0.1:39182, 127.0.0.1:40001, 127.0.0.1:33115, 127.0.0.1:34415, 127.0.0.1:34710, 127.0.0.1:34235 for /corrupted_3_0
2020-04-02 05:11:29,177 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_3_0 with new block blk_-9223372036854775712_1006, current total block count is 1
2020-04-02 05:11:29,182 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:49376 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 src: /127.0.0.1:49376 dest: /127.0.0.1:37707
2020-04-02 05:11:29,192 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47074 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 src: /127.0.0.1:47074 dest: /127.0.0.1:37829
2020-04-02 05:11:29,207 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58060 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775710_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775710_1006 src: /127.0.0.1:58060 dest: /127.0.0.1:34393
2020-04-02 05:11:29,213 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57496 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775709_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775709_1006 src: /127.0.0.1:57496 dest: /127.0.0.1:39182
2020-04-02 05:11:29,226 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:35420 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 src: /127.0.0.1:35420 dest: /127.0.0.1:40001
2020-04-02 05:11:29,242 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59174 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775707_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775707_1006 src: /127.0.0.1:59174 dest: /127.0.0.1:33115
2020-04-02 05:11:29,297 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47390 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775706_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775706_1006 src: /127.0.0.1:47390 dest: /127.0.0.1:34415
2020-04-02 05:11:29,310 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:34048 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775705_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775705_1006 src: /127.0.0.1:34048 dest: /127.0.0.1:34710
2020-04-02 05:11:29,324 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50708 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775704_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775704_1006 src: /127.0.0.1:50708 dest: /127.0.0.1:34235
2020-04-02 05:11:29,484 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,484 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775706_1006 on 127.0.0.1:34415 size 4194304 replicaState = RBW
2020-04-02 05:11:29,484 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,484 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775706_1006 is received from 127.0.0.1:34415
2020-04-02 05:11:29,484 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 1, received: 0, deleted: 0
2020-04-02 05:11:29,524 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49376, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006, duration(ns): 333772998
2020-04-02 05:11:29,524 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:29,526 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,526 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775712_1006 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:29,530 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,530 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47074, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006, duration(ns): 329471635
2020-04-02 05:11:29,530 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:29,530 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:29,530 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775712_1006 is received from 127.0.0.1:37707
2020-04-02 05:11:29,530 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:29,531 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,531 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775711_1006 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:29,532 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,532 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:29,532 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775711_1006 is received from 127.0.0.1:37829
2020-04-02 05:11:29,532 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58060, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775710_1006, duration(ns): 321548926
2020-04-02 05:11:29,532 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:29,532 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775710_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:29,533 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,533 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775710_1006 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:29,533 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,534 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:29,534 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57496, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775709_1006, duration(ns): 313914247
2020-04-02 05:11:29,534 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775710_1006 is received from 127.0.0.1:34393
2020-04-02 05:11:29,534 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775709_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:29,534 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:29,535 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,535 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775709_1006 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:29,535 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,535 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:29,535 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35420, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006, duration(ns): 299279844
2020-04-02 05:11:29,535 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775709_1006 is received from 127.0.0.1:39182
2020-04-02 05:11:29,536 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:29,536 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:29,536 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,537 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775708_1006 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:29,537 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,537 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:29,537 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775708_1006 is received from 127.0.0.1:40001
2020-04-02 05:11:29,537 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:29,537 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59174, dest: /127.0.0.1:33115, bytes: 4194181, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775707_1006, duration(ns): 293643512
2020-04-02 05:11:29,537 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775707_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:29,538 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,539 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775707_1006 on 127.0.0.1:33115 size 4194181 replicaState = FINALIZED
2020-04-02 05:11:29,539 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,539 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:29,539 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775707_1006 is received from 127.0.0.1:33115
2020-04-02 05:11:29,539 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:29,539 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47390, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775706_1006, duration(ns): 239315100
2020-04-02 05:11:29,539 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775706_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:29,540 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,541 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775706_1006 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:29,541 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34048, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775705_1006, duration(ns): 225766859
2020-04-02 05:11:29,541 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,541 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775705_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:29,541 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:29,541 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775706_1006 is received from 127.0.0.1:34415
2020-04-02 05:11:29,541 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:29,542 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,542 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775705_1006 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:29,543 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,543 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50708, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775704_1006, duration(ns): 210695485
2020-04-02 05:11:29,543 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:29,543 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775704_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:29,543 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:29,543 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775705_1006 is received from 127.0.0.1:34710
2020-04-02 05:11:29,546 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:29,549 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775704_1006 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:29,549 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:29,550 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775712_1006 (size=0)
2020-04-02 05:11:29,550 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775704_1006 is received from 127.0.0.1:34235
2020-04-02 05:11:29,550 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:29,550 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_3_0 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:29,551 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_3_0 with 1 blocks is persisted to the file system
2020-04-02 05:11:29,551 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_3_0 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:29,551 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_3_0
2020-04-02 05:11:29,553 [IPC Server handler 8 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:29,553 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:29,555 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006
2020-04-02 05:11:29,555 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,556 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,556 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,556 [Thread-665] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775711
2020-04-02 05:11:29,557 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,557 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,557 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,558 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,558 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,558 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006
2020-04-02 05:11:29,559 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,559 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,559 [Thread-665] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775708
2020-04-02 05:11:29,560 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,560 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,560 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,561 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,561 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,561 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,562 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006
2020-04-02 05:11:29,562 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,562 [Thread-665] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775712
2020-04-02 05:11:29,562 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,563 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,563 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,563 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,564 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,564 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,564 [Thread-665] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:29,565 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_3_0
2020-04-02 05:11:29,572 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_3_0
2020-04-02 05:11:29,573 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:29,573 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_3_0
2020-04-02 05:11:29,574 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:29,575 [IPC Server handler 9 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:29,576 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:29,587 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277,DISK] at 0
2020-04-02 05:11:29,587 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 from DatanodeInfoWithStorage[127.0.0.1:37829,DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c,DISK] at 0
2020-04-02 05:11:29,591 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-1944b14f-74e6-4e06-b100-58bcc8482d77,DISK] at 0
2020-04-02 05:11:29,722 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 on datanode: 127.0.0.1:37707
2020-04-02 05:11:29,723 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775712_1006 added as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:29,723 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 8 curExpectedReplicas 9 oldReplicas 9 oldExpectedReplicas  9 curPri  2 oldPri  3
2020-04-02 05:11:29,723 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:11:29,723 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 on datanode: 127.0.0.1:37829
2020-04-02 05:11:29,723 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775712_1006 added as corrupt on 127.0.0.1:37829 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:29,723 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 7 curExpectedReplicas 9 oldReplicas 8 oldExpectedReplicas  9 curPri  1 oldPri  2
2020-04-02 05:11:29,724 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 2
2020-04-02 05:11:29,724 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 7 replicas and needs 9 replicas so is added to neededReconstructions at priority level 1
2020-04-02 05:11:29,724 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 on datanode: 127.0.0.1:40001
2020-04-02 05:11:29,724 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775712_1006 added as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:29,724 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:29,724 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 1
2020-04-02 05:11:29,724 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:30,382 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:30,383 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:30,383 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:30,383 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:30,383 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:30,383 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:30,383 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:31,049 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 from DatanodeInfoWithStorage[127.0.0.1:37829,DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c,DISK] at 0
2020-04-02 05:11:31,052 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-1944b14f-74e6-4e06-b100-58bcc8482d77,DISK] at 0
2020-04-02 05:11:31,054 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277,DISK] at 0
2020-04-02 05:11:31,205 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 on datanode: 127.0.0.1:37707
2020-04-02 05:11:31,206 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:31,206 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:31,206 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:31,206 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:31,206 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 on datanode: 127.0.0.1:37829
2020-04-02 05:11:31,206 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:37829 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:31,207 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:31,207 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:31,207 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:31,207 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 on datanode: 127.0.0.1:40001
2020-04-02 05:11:31,207 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:31,207 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:31,207 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:31,207 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:32,922 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 from DatanodeInfoWithStorage[127.0.0.1:37829,DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c,DISK] at 0
2020-04-02 05:11:32,924 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-1944b14f-74e6-4e06-b100-58bcc8482d77,DISK] at 0
2020-04-02 05:11:32,926 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277,DISK] at 0
2020-04-02 05:11:33,056 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 on datanode: 127.0.0.1:37707
2020-04-02 05:11:33,057 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:33,057 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:33,057 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:33,057 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:33,057 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 on datanode: 127.0.0.1:37829
2020-04-02 05:11:33,057 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:37829 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:33,058 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:33,058 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:33,058 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:33,058 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 on datanode: 127.0.0.1:40001
2020-04-02 05:11:33,058 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:33,058 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:33,058 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:33,058 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:33,384 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:33,384 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:33,384 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:33,384 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:33,384 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:33,384 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:33,384 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:35,069 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 from DatanodeInfoWithStorage[127.0.0.1:37829,DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c,DISK] at 0
2020-04-02 05:11:35,072 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-1944b14f-74e6-4e06-b100-58bcc8482d77,DISK] at 0
2020-04-02 05:11:35,074 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277,DISK] at 0
2020-04-02 05:11:35,203 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 on datanode: 127.0.0.1:37707
2020-04-02 05:11:35,204 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:35,204 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:35,204 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:35,204 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:35,205 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 on datanode: 127.0.0.1:37829
2020-04-02 05:11:35,205 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:37829 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:35,205 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:35,205 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:35,205 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:35,205 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 on datanode: 127.0.0.1:40001
2020-04-02 05:11:35,205 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:35,205 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:35,206 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:35,206 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:36,397 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:36,398 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:36,398 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:36,398 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:36,398 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:36,398 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:36,398 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:37,079 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 from DatanodeInfoWithStorage[127.0.0.1:40001,DS-1944b14f-74e6-4e06-b100-58bcc8482d77,DISK] at 0
2020-04-02 05:11:37,080 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 from DatanodeInfoWithStorage[127.0.0.1:37707,DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277,DISK] at 0
2020-04-02 05:11:37,081 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 from DatanodeInfoWithStorage[127.0.0.1:37829,DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c,DISK] at 0
2020-04-02 05:11:37,209 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775712_1006 on datanode: 127.0.0.1:37707
2020-04-02 05:11:37,209 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:37707 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:37,209 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:37,209 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:37,210 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:37,210 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775711_1006 on datanode: 127.0.0.1:37829
2020-04-02 05:11:37,210 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:37829 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:37,210 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:37,210 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:37,210 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:37,210 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775708_1006 on datanode: 127.0.0.1:40001
2020-04-02 05:11:37,210 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775712_1006 to add as corrupt on 127.0.0.1:40001 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:37,211 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775712_1006 curReplicas 6 curExpectedReplicas 9 oldReplicas 7 oldExpectedReplicas  9 curPri  0 oldPri  1
2020-04-02 05:11:37,211 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:11:37,211 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775712_1006 has only 6 replicas and needs 9 replicas so is added to neededReconstructions at priority level 0
2020-04-02 05:11:39,398 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:39,399 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:39,399 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:39,399 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:39,399 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:39,399 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:39,399 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:42,399 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:42,400 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:42,400 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:42,400 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:42,400 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:42,400 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:42,400 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:43,717 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_3_0
2020-04-02 05:11:43,718 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:43,719 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:45,401 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:45,401 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:45,401 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:45,401 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:45,401 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:45,401 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:45,401 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:47,255 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_3_0
2020-04-02 05:11:47,270 [IPC Server handler 2 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:47,272 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:48,402 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:48,402 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:48,402 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:48,402 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:48,402 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:48,402 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:48,402 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:50,891 [Thread-665] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_3_0
2020-04-02 05:11:50,894 [IPC Server handler 8 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775712_1006]
2020-04-02 05:11:50,895 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:51,403 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:51,403 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:51,403 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:51,403 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:51,403 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:51,403 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:51,404 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:54,404 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:54,404 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:54,404 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:54,404 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:54,405 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:54,405 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775792_1001 cannot be reconstructed from any node
2020-04-02 05:11:54,405 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[5]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[6]
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:11:55,978 [Thread-724] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_1_0, dataBlkDelNum = 1, parityBlkDelNum = 0, deleteBlockFile? false
2020-04-02 05:11:56,033 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:56,037 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/corrupted_1_0, recursive=true
2020-04-02 05:11:56,040 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /corrupted_1_0
2020-04-02 05:11:56,041 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /corrupted_1_0
2020-04-02 05:11:56,045 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /corrupted_1_0 is removed
2020-04-02 05:11:56,046 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /corrupted_1_0 is removed
2020-04-02 05:11:56,047 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775792_1001 127.0.0.1:34415 127.0.0.1:37707 127.0.0.1:34710 127.0.0.1:34393 127.0.0.1:40001 127.0.0.1:37829 127.0.0.1:39182 127.0.0.1:33115 127.0.0.1:34235 
2020-04-02 05:11:56,047 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-04-02 05:11:56,047 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:56,051 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_1_0 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:11:56,051 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_1_0, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:11:56,052 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_1_0 is added
2020-04-02 05:11:56,052 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_1_0 inode 16392 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:56,053 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_1_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:11:56,076 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_1_0  inodeId 16392 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:56,077 [IPC Server handler 0 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:56,079 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_1_0 with blk_-9223372036854775696_1007 block is added to the in-memory file system
2020-04-02 05:11:56,079 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775696_1007, replicas=127.0.0.1:37829, 127.0.0.1:34710, 127.0.0.1:40001, 127.0.0.1:34393, 127.0.0.1:33115, 127.0.0.1:37707, 127.0.0.1:34235, 127.0.0.1:34415, 127.0.0.1:39182 for /corrupted_1_0
2020-04-02 05:11:56,079 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_1_0 with new block blk_-9223372036854775696_1007, current total block count is 1
2020-04-02 05:11:56,083 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47250 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775696_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775696_1007 src: /127.0.0.1:47250 dest: /127.0.0.1:37829
2020-04-02 05:11:56,086 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:34214 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775695_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775695_1007 src: /127.0.0.1:34214 dest: /127.0.0.1:34710
2020-04-02 05:11:56,105 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:35594 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775694_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775694_1007 src: /127.0.0.1:35594 dest: /127.0.0.1:40001
2020-04-02 05:11:56,105 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58240 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775693_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775693_1007 src: /127.0.0.1:58240 dest: /127.0.0.1:34393
2020-04-02 05:11:56,110 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,112 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775695_1007 on 127.0.0.1:34710 size 4194304 replicaState = RBW
2020-04-02 05:11:56,114 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,117 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775695_1007 is received from 127.0.0.1:34710
2020-04-02 05:11:56,118 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 1, received: 0, deleted: 0
2020-04-02 05:11:56,119 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59350 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775692_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775692_1007 src: /127.0.0.1:59350 dest: /127.0.0.1:33115
2020-04-02 05:11:56,119 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,120 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775693_1007 on 127.0.0.1:34393 size 4194304 replicaState = RBW
2020-04-02 05:11:56,121 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,121 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775693_1007 is received from 127.0.0.1:34393
2020-04-02 05:11:56,121 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 1, received: 0, deleted: 0
2020-04-02 05:11:56,135 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:49564 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775691_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775691_1007 src: /127.0.0.1:49564 dest: /127.0.0.1:37707
2020-04-02 05:11:56,178 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50882 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775690_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775690_1007 src: /127.0.0.1:50882 dest: /127.0.0.1:34235
2020-04-02 05:11:56,192 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47570 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775689_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775689_1007 src: /127.0.0.1:47570 dest: /127.0.0.1:34415
2020-04-02 05:11:56,204 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57684 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775688_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775688_1007 src: /127.0.0.1:57684 dest: /127.0.0.1:39182
2020-04-02 05:11:56,376 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35594, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775694_1007, duration(ns): 264922128
2020-04-02 05:11:56,377 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50882, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775690_1007, duration(ns): 190133835
2020-04-02 05:11:56,378 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,378 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,378 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775690_1007 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:56,377 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49564, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775691_1007, duration(ns): 235754102
2020-04-02 05:11:56,377 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47250, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775696_1007, duration(ns): 283040164
2020-04-02 05:11:56,377 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59350, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775692_1007, duration(ns): 251015409
2020-04-02 05:11:56,377 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57684, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775688_1007, duration(ns): 167142223
2020-04-02 05:11:56,377 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47570, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775689_1007, duration(ns): 178502666
2020-04-02 05:11:56,377 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34214, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775695_1007, duration(ns): 281806180
2020-04-02 05:11:56,379 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775689_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,379 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775695_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,379 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775688_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,379 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775692_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,378 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775696_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,378 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,378 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775691_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,378 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,378 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,378 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,378 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,378 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,378 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775690_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,378 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775694_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,378 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58240, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775693_1007, duration(ns): 258717033
2020-04-02 05:11:56,378 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,378 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,382 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775693_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,382 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:11:56,383 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775690_1007 is received from 127.0.0.1:34235
2020-04-02 05:11:56,383 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,383 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775688_1007 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:56,383 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,383 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_1_0  inodeId 16392 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:56,383 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:11:56,383 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775688_1007 is received from 127.0.0.1:39182
2020-04-02 05:11:56,383 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,383 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775691_1007 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:56,383 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,383 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:11:56,384 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775691_1007 is received from 127.0.0.1:37707
2020-04-02 05:11:56,384 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,384 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775694_1007 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:56,384 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,384 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:11:56,384 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775694_1007 is received from 127.0.0.1:40001
2020-04-02 05:11:56,384 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,384 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775693_1007 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:56,384 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,384 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:11:56,384 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775693_1007 is received from 127.0.0.1:34393
2020-04-02 05:11:56,384 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,384 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775696_1007 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:56,384 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,385 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:11:56,385 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775696_1007 is received from 127.0.0.1:37829
2020-04-02 05:11:56,385 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,385 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775692_1007 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:56,385 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,385 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:11:56,385 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775692_1007 is received from 127.0.0.1:33115
2020-04-02 05:11:56,385 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,385 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775689_1007 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:56,385 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,385 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:11:56,385 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775689_1007 is received from 127.0.0.1:34415
2020-04-02 05:11:56,385 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,385 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775695_1007 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:11:56,386 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,386 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775696_1007 (size=0)
2020-04-02 05:11:56,386 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775695_1007 is received from 127.0.0.1:34710
2020-04-02 05:11:56,386 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,386 [IPC Server handler 9 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:11:56,388 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_1_0 with blk_-9223372036854775680_1008 block is added to the in-memory file system
2020-04-02 05:11:56,388 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775680_1008, replicas=127.0.0.1:34393, 127.0.0.1:34415, 127.0.0.1:37707, 127.0.0.1:34710, 127.0.0.1:33115, 127.0.0.1:37829, 127.0.0.1:34235, 127.0.0.1:40001, 127.0.0.1:39182 for /corrupted_1_0
2020-04-02 05:11:56,388 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_1_0 with new block blk_-9223372036854775680_1008, current total block count is 2
2020-04-02 05:11:56,390 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57688 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775672_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775672_1008 src: /127.0.0.1:57688 dest: /127.0.0.1:39182
2020-04-02 05:11:56,390 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50888 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775674_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775674_1008 src: /127.0.0.1:50888 dest: /127.0.0.1:34235
2020-04-02 05:11:56,393 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58256 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 src: /127.0.0.1:58256 dest: /127.0.0.1:34393
2020-04-02 05:11:56,398 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:35612 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775673_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775673_1008 src: /127.0.0.1:35612 dest: /127.0.0.1:40001
2020-04-02 05:11:56,405 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58256, dest: /127.0.0.1:34393, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008, duration(ns): 5854581
2020-04-02 05:11:56,406 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,406 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,406 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775680_1008 on 127.0.0.1:34393 size 123 replicaState = FINALIZED
2020-04-02 05:11:56,406 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,407 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775680_1008 (size=0)
2020-04-02 05:11:56,407 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50888, dest: /127.0.0.1:34235, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775674_1008, duration(ns): 11699760
2020-04-02 05:11:56,407 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775680_1008 is received from 127.0.0.1:34393
2020-04-02 05:11:56,407 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775674_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,407 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,408 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,409 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775674_1008 on 127.0.0.1:34235 size 123 replicaState = FINALIZED
2020-04-02 05:11:56,409 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,409 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35612, dest: /127.0.0.1:40001, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775673_1008, duration(ns): 5129865
2020-04-02 05:11:56,409 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775680_1008 (size=0)
2020-04-02 05:11:56,409 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775673_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,409 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775674_1008 is received from 127.0.0.1:34235
2020-04-02 05:11:56,409 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,409 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,410 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775673_1008 on 127.0.0.1:40001 size 123 replicaState = FINALIZED
2020-04-02 05:11:56,410 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,411 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57688, dest: /127.0.0.1:39182, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775672_1008, duration(ns): 16869066
2020-04-02 05:11:56,411 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775680_1008 (size=0)
2020-04-02 05:11:56,411 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775673_1008 is received from 127.0.0.1:40001
2020-04-02 05:11:56,411 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,411 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:11:56,411 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775672_1008 on 127.0.0.1:39182 size 123 replicaState = FINALIZED
2020-04-02 05:11:56,411 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:11:56,411 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775672_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:11:56,411 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775680_1008 (size=0)
2020-04-02 05:11:56,411 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775672_1008 is received from 127.0.0.1:39182
2020-04-02 05:11:56,412 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:11:56,412 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_1_0 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:56,413 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_1_0 with 2 blocks is persisted to the file system
2020-04-02 05:11:56,413 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_1_0 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:11:56,414 [Thread-724] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_1_0
2020-04-02 05:11:56,415 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:11:56,415 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:56,416 [Thread-724] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008
2020-04-02 05:11:56,417 [Thread-724] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:56,418 [Thread-724] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:56,418 [Thread-724] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:56,418 [Thread-724] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:56,419 [Thread-724] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:56,419 [Thread-724] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:56,419 [Thread-724] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:56,420 [Thread-724] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775680
2020-04-02 05:11:56,420 [Thread-724] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:11:56,420 [Thread-724] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_1_0
2020-04-02 05:11:56,428 [Thread-724] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_1_0
2020-04-02 05:11:56,429 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:56,430 [Thread-724] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_1_0
2020-04-02 05:11:56,430 [IPC Server handler 6 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:11:56,432 [IPC Server handler 8 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:11:56,433 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:11:56,454 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:11:56,457 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:11:56,457 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775680_1008 added as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:56,457 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:11:56,458 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:11:57,405 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:11:57,405 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:11:57,405 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:11:57,406 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:11:57,406 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:11:57,406 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:11:57,406 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:11:57,406 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33115 to delete [blk_-9223372036854775785_1001]
2020-04-02 05:11:57,406 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:40001 to delete [blk_-9223372036854775788_1001]
2020-04-02 05:11:57,406 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34393 to delete [blk_-9223372036854775789_1001]
2020-04-02 05:11:57,760 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:11:57,763 [IPC Server handler 8 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:11:57,764 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775680_1008 to add as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:57,764 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:11:57,764 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775680_1008 from priority queue 2
2020-04-02 05:11:57,764 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:11:58,498 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775785_1001 replica FinalizedReplica, blk_-9223372036854775785_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775785 for deletion
2020-04-02 05:11:58,498 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775788_1001 replica FinalizedReplica, blk_-9223372036854775788_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775788 for deletion
2020-04-02 05:11:58,515 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775788_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775788
2020-04-02 05:11:58,563 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775785_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775785
2020-04-02 05:11:59,143 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775789_1001 replica FinalizedReplica, blk_-9223372036854775789_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775789 for deletion
2020-04-02 05:11:59,146 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775789_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775789
2020-04-02 05:11:59,359 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:11:59,362 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:11:59,363 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775680_1008 to add as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:11:59,363 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:11:59,363 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775680_1008 from priority queue 2
2020-04-02 05:11:59,364 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:12:00,407 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:00,407 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:00,407 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:00,407 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:00,407 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:00,407 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:00,408 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:12:00,408 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34235 to delete [blk_-9223372036854775784_1001]
2020-04-02 05:12:00,408 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37707 to delete [blk_-9223372036854775791_1001]
2020-04-02 05:12:00,408 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34415 to delete [blk_-9223372036854775792_1001]
2020-04-02 05:12:01,259 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:12:01,261 [IPC Server handler 4 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:12:01,261 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775680_1008 to add as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:12:01,261 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:12:01,261 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775680_1008 from priority queue 2
2020-04-02 05:12:01,262 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:12:01,482 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775784_1001 replica FinalizedReplica, blk_-9223372036854775784_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775784 for deletion
2020-04-02 05:12:01,485 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775784_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775784
2020-04-02 05:12:01,544 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775791_1001 replica FinalizedReplica, blk_-9223372036854775791_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775791 for deletion
2020-04-02 05:12:01,553 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775791_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775791
2020-04-02 05:12:02,485 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775792_1001 replica FinalizedReplica, blk_-9223372036854775792_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775792 for deletion
2020-04-02 05:12:02,499 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775792_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775792
2020-04-02 05:12:03,296 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:12:03,302 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:12:03,302 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775680_1008 to add as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:12:03,303 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:12:03,303 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775680_1008 from priority queue 2
2020-04-02 05:12:03,303 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:12:03,408 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:03,409 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:03,409 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:03,409 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:03,409 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:03,409 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:03,409 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:12:03,410 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:39182 to delete [blk_-9223372036854775786_1001]
2020-04-02 05:12:03,410 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34710 to delete [blk_-9223372036854775790_1001]
2020-04-02 05:12:03,410 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37829 to delete [blk_-9223372036854775787_1001]
2020-04-02 05:12:04,475 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775787_1001 replica FinalizedReplica, blk_-9223372036854775787_1001, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775787 for deletion
2020-04-02 05:12:04,477 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775787_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775787
2020-04-02 05:12:04,484 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775786_1001 replica FinalizedReplica, blk_-9223372036854775786_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775786 for deletion
2020-04-02 05:12:04,492 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775786_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775786
2020-04-02 05:12:05,119 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:12:05,122 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:12:05,122 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775680_1008 to add as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:12:05,122 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:12:05,122 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775680_1008 from priority queue 2
2020-04-02 05:12:05,122 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:12:05,142 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775790_1001 replica FinalizedReplica, blk_-9223372036854775790_1001, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775790 for deletion
2020-04-02 05:12:05,144 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775790_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775790
2020-04-02 05:12:06,456 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:06,463 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:06,463 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:06,463 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:06,463 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:06,463 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:06,463 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:12:06,609 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:12:06,612 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:12:06,612 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775680_1008 to add as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:12:06,612 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:12:06,613 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775680_1008 from priority queue 2
2020-04-02 05:12:06,613 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:12:08,067 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:12:08,069 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:12:08,069 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775680_1008 to add as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:12:08,069 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:12:08,069 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775680_1008 from priority queue 2
2020-04-02 05:12:08,069 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:12:09,464 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:09,464 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:09,464 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:09,464 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:09,464 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:09,464 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:09,464 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:12:09,465 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:12:09,467 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:12:09,468 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775680_1008 to add as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:12:09,468 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:12:09,468 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775680_1008 from priority queue 2
2020-04-02 05:12:09,468 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:12:09,469 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 from DatanodeInfoWithStorage[127.0.0.1:34393,DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0,DISK] at 0
2020-04-02 05:12:09,471 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775680_1008 on datanode: 127.0.0.1:34393
2020-04-02 05:12:09,472 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775680_1008 to add as corrupt on 127.0.0.1:34393 by /127.0.0.1  because client machine reported it
2020-04-02 05:12:09,472 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775680_1008 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:12:09,472 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775680_1008 from priority queue 2
2020-04-02 05:12:09,472 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775680_1008 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:12:09,472 [Thread-724] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_1_0
2020-04-02 05:12:09,473 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:12:09,474 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:12,465 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:12,466 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:12,466 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:12,466 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:12,466 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:12,466 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:12,466 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:12:12,886 [Thread-724] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_1_0
2020-04-02 05:12:12,902 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:12:12,902 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:15,467 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:15,467 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:15,467 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:15,468 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:15,468 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:15,468 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:15,468 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:12:16,524 [Thread-724] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_1_0
2020-04-02 05:12:16,527 [IPC Server handler 4 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775696_1007, blk_-9223372036854775680_1008]
2020-04-02 05:12:16,528 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_0	dst=null	perm=null	proto=rpc
2020-04-02 05:12:18,469 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:18,469 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:18,469 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:18,469 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:18,469 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:18,469 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:18,469 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
2020-04-02 05:12:21,470 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:21,471 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:21,471 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:21,471 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775776_1002 cannot be reconstructed from any node
2020-04-02 05:12:21,471 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:21,471 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:21,471 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 6 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[6]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[6]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[7]
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:12:21,755 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_1_1, dataBlkDelNum = 1, parityBlkDelNum = 1, deleteBlockFile? false
2020-04-02 05:12:21,812 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:21,814 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/corrupted_1_1, recursive=true
2020-04-02 05:12:21,815 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /corrupted_1_1
2020-04-02 05:12:21,815 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /corrupted_1_1
2020-04-02 05:12:21,815 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /corrupted_1_1 is removed
2020-04-02 05:12:21,816 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /corrupted_1_1 is removed
2020-04-02 05:12:21,816 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775776_1002 127.0.0.1:40001 127.0.0.1:39182 127.0.0.1:37829 127.0.0.1:34415 127.0.0.1:37707 127.0.0.1:33115 127.0.0.1:34710 127.0.0.1:34235 127.0.0.1:34393 
2020-04-02 05:12:21,816 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775776_1002 from priority queue 1
2020-04-02 05:12:21,817 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:21,818 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_1_1 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:12:21,818 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_1_1, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:12:21,819 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_1_1 is added
2020-04-02 05:12:21,819 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_1_1 inode 16393 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:21,819 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_1_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:12:21,843 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_1_1  inodeId 16393 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:21,843 [IPC Server handler 1 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:21,845 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_1_1 with blk_-9223372036854775664_1009 block is added to the in-memory file system
2020-04-02 05:12:21,845 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775664_1009, replicas=127.0.0.1:33115, 127.0.0.1:34710, 127.0.0.1:39182, 127.0.0.1:40001, 127.0.0.1:34393, 127.0.0.1:34415, 127.0.0.1:37829, 127.0.0.1:37707, 127.0.0.1:34235 for /corrupted_1_1
2020-04-02 05:12:21,846 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_1_1 with new block blk_-9223372036854775664_1009, current total block count is 1
2020-04-02 05:12:21,850 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59492 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775664_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775664_1009 src: /127.0.0.1:59492 dest: /127.0.0.1:33115
2020-04-02 05:12:21,857 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:34364 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775663_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775663_1009 src: /127.0.0.1:34364 dest: /127.0.0.1:34710
2020-04-02 05:12:21,866 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57822 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775662_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775662_1009 src: /127.0.0.1:57822 dest: /127.0.0.1:39182
2020-04-02 05:12:21,877 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:35746 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775661_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775661_1009 src: /127.0.0.1:35746 dest: /127.0.0.1:40001
2020-04-02 05:12:21,902 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58392 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775660_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775660_1009 src: /127.0.0.1:58392 dest: /127.0.0.1:34393
2020-04-02 05:12:21,916 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47716 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775659_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775659_1009 src: /127.0.0.1:47716 dest: /127.0.0.1:34415
2020-04-02 05:12:21,964 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47412 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775658_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775658_1009 src: /127.0.0.1:47412 dest: /127.0.0.1:37829
2020-04-02 05:12:21,977 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:49718 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775657_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775657_1009 src: /127.0.0.1:49718 dest: /127.0.0.1:37707
2020-04-02 05:12:21,991 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:51036 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775656_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775656_1009 src: /127.0.0.1:51036 dest: /127.0.0.1:34235
2020-04-02 05:12:22,169 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57822, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775662_1009, duration(ns): 288843310
2020-04-02 05:12:22,169 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47412, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775658_1009, duration(ns): 197824906
2020-04-02 05:12:22,169 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49718, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775657_1009, duration(ns): 184641814
2020-04-02 05:12:22,169 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51036, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775656_1009, duration(ns): 170748506
2020-04-02 05:12:22,169 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47716, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775659_1009, duration(ns): 244071877
2020-04-02 05:12:22,169 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34364, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775663_1009, duration(ns): 302820409
2020-04-02 05:12:22,169 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35746, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775661_1009, duration(ns): 281267830
2020-04-02 05:12:22,169 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59492, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775664_1009, duration(ns): 311521265
2020-04-02 05:12:22,171 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775661_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,171 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775664_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,169 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58392, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775660_1009, duration(ns): 259467101
2020-04-02 05:12:22,171 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,171 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,171 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,172 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_1_1  inodeId 16393 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:22,170 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775663_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,170 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775659_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,170 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775656_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,170 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775657_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,170 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775658_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,170 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775662_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,172 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775660_1009 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:22,171 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,171 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,171 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,171 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,171 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775660_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,171 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,171 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,173 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,174 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:22,174 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775660_1009 is received from 127.0.0.1:34393
2020-04-02 05:12:22,174 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,174 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775656_1009 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:22,175 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,175 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:22,175 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775656_1009 is received from 127.0.0.1:34235
2020-04-02 05:12:22,175 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,175 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775658_1009 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:22,175 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,175 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:22,175 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775658_1009 is received from 127.0.0.1:37829
2020-04-02 05:12:22,175 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,175 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775662_1009 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:22,175 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,175 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:22,175 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775662_1009 is received from 127.0.0.1:39182
2020-04-02 05:12:22,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,176 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775661_1009 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:22,176 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:22,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775661_1009 is received from 127.0.0.1:40001
2020-04-02 05:12:22,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,176 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775663_1009 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:22,176 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:22,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775663_1009 is received from 127.0.0.1:34710
2020-04-02 05:12:22,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,176 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775659_1009 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:22,176 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:22,176 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775659_1009 is received from 127.0.0.1:34415
2020-04-02 05:12:22,177 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,177 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775664_1009 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:22,177 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,177 [IPC Server handler 1 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:22,177 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:22,177 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775664_1009 is received from 127.0.0.1:33115
2020-04-02 05:12:22,177 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,177 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775657_1009 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:22,177 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,178 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775664_1009 (size=0)
2020-04-02 05:12:22,178 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775657_1009 is received from 127.0.0.1:37707
2020-04-02 05:12:22,178 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,179 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_1_1 with blk_-9223372036854775648_1010 block is added to the in-memory file system
2020-04-02 05:12:22,179 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775648_1010, replicas=127.0.0.1:37707, 127.0.0.1:34393, 127.0.0.1:34415, 127.0.0.1:37829, 127.0.0.1:33115, 127.0.0.1:40001, 127.0.0.1:39182, 127.0.0.1:34235, 127.0.0.1:34710 for /corrupted_1_1
2020-04-02 05:12:22,179 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_1_1 with new block blk_-9223372036854775648_1010, current total block count is 2
2020-04-02 05:12:22,181 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:34386 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775640_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775640_1010 src: /127.0.0.1:34386 dest: /127.0.0.1:34710
2020-04-02 05:12:22,181 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57840 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010 src: /127.0.0.1:57840 dest: /127.0.0.1:39182
2020-04-02 05:12:22,181 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:49722 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775648_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775648_1010 src: /127.0.0.1:49722 dest: /127.0.0.1:37707
2020-04-02 05:12:22,182 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:51038 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775641_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775641_1010 src: /127.0.0.1:51038 dest: /127.0.0.1:34235
2020-04-02 05:12:22,189 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49722, dest: /127.0.0.1:37707, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775648_1010, duration(ns): 3917203
2020-04-02 05:12:22,189 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775648_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,191 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,191 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57840, dest: /127.0.0.1:39182, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010, duration(ns): 5635797
2020-04-02 05:12:22,191 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775648_1010 on 127.0.0.1:37707 size 123 replicaState = FINALIZED
2020-04-02 05:12:22,191 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,191 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,191 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775648_1010 (size=0)
2020-04-02 05:12:22,191 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,191 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775648_1010 is received from 127.0.0.1:37707
2020-04-02 05:12:22,193 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,193 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51038, dest: /127.0.0.1:34235, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775641_1010, duration(ns): 8612200
2020-04-02 05:12:22,193 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775642_1010 on 127.0.0.1:39182 size 123 replicaState = FINALIZED
2020-04-02 05:12:22,193 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775641_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,193 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,193 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775648_1010 (size=0)
2020-04-02 05:12:22,193 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,193 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775642_1010 is received from 127.0.0.1:39182
2020-04-02 05:12:22,193 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,194 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775641_1010 on 127.0.0.1:34235 size 123 replicaState = FINALIZED
2020-04-02 05:12:22,194 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,195 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775648_1010 (size=0)
2020-04-02 05:12:22,195 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34386, dest: /127.0.0.1:34710, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775640_1010, duration(ns): 10831481
2020-04-02 05:12:22,195 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775641_1010 is received from 127.0.0.1:34235
2020-04-02 05:12:22,195 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,195 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775640_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:22,195 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:22,196 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775640_1010 on 127.0.0.1:34710 size 123 replicaState = FINALIZED
2020-04-02 05:12:22,196 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:22,196 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775648_1010 (size=0)
2020-04-02 05:12:22,196 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775640_1010 is received from 127.0.0.1:34710
2020-04-02 05:12:22,196 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:22,196 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_1_1 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:22,197 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_1_1 with 2 blocks is persisted to the file system
2020-04-02 05:12:22,197 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_1_1 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:22,198 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_1_1
2020-04-02 05:12:22,199 [IPC Server handler 3 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:22,199 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:22,200 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
2020-04-02 05:12:22,201 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,201 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,202 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,202 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,202 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,203 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,203 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,203 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,203 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775644_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,204 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010
2020-04-02 05:12:22,204 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,204 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,204 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,205 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,205 [Thread-807] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775642
2020-04-02 05:12:22,206 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,206 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,206 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,207 [Thread-807] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775642_1010
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:22,207 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_1_1
2020-04-02 05:12:22,212 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_1_1
2020-04-02 05:12:22,214 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:22,214 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_1_1
2020-04-02 05:12:22,215 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:12:22,216 [IPC Server handler 4 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:22,216 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:24,471 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:24,472 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:24,472 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:24,472 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:24,472 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:24,472 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:24,472 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34415 to delete [blk_-9223372036854775773_1002]
2020-04-02 05:12:24,472 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:40001 to delete [blk_-9223372036854775776_1002]
2020-04-02 05:12:24,472 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:39182 to delete [blk_-9223372036854775775_1002]
2020-04-02 05:12:25,489 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775775_1002 replica FinalizedReplica, blk_-9223372036854775775_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775775 for deletion
2020-04-02 05:12:25,489 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775776_1002 replica FinalizedReplica, blk_-9223372036854775776_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775776 for deletion
2020-04-02 05:12:25,492 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775775_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775775
2020-04-02 05:12:25,492 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775776_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775776
2020-04-02 05:12:26,485 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775773_1002 replica FinalizedReplica, blk_-9223372036854775773_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775773 for deletion
2020-04-02 05:12:26,487 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775773_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775773
2020-04-02 05:12:27,472 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:27,477 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:27,477 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:27,477 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:27,477 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:27,477 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:27,477 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34710 to delete [blk_-9223372036854775770_1002]
2020-04-02 05:12:27,477 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37829 to delete [blk_-9223372036854775774_1002]
2020-04-02 05:12:27,478 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37707 to delete [blk_-9223372036854775772_1002]
2020-04-02 05:12:28,489 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775774_1002 replica FinalizedReplica, blk_-9223372036854775774_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775774 for deletion
2020-04-02 05:12:28,491 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775774_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775774
2020-04-02 05:12:28,544 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775772_1002 replica FinalizedReplica, blk_-9223372036854775772_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775772 for deletion
2020-04-02 05:12:28,549 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775772_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775772
2020-04-02 05:12:29,145 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775770_1002 replica FinalizedReplica, blk_-9223372036854775770_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775770 for deletion
2020-04-02 05:12:29,162 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775770_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775770
2020-04-02 05:12:30,478 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:30,486 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:30,486 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:30,486 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:30,486 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:30,486 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:30,486 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34235 to delete [blk_-9223372036854775769_1002]
2020-04-02 05:12:30,486 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34393 to delete [blk_-9223372036854775768_1002]
2020-04-02 05:12:30,486 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33115 to delete [blk_-9223372036854775771_1002]
2020-04-02 05:12:31,489 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775771_1002 replica FinalizedReplica, blk_-9223372036854775771_1002, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775771 for deletion
2020-04-02 05:12:31,489 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775769_1002 replica FinalizedReplica, blk_-9223372036854775769_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775769 for deletion
2020-04-02 05:12:31,492 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775769_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775769
2020-04-02 05:12:31,492 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775771_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775771
2020-04-02 05:12:32,144 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775768_1002 replica FinalizedReplica, blk_-9223372036854775768_1002, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775768 for deletion
2020-04-02 05:12:32,146 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775768_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775768
2020-04-02 05:12:33,487 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:33,488 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:33,488 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:33,488 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:33,488 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:33,488 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:34,890 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_1_1
2020-04-02 05:12:34,894 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:34,896 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:36,489 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:36,489 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:36,490 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:36,490 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:36,490 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:36,490 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:38,492 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_1_1
2020-04-02 05:12:38,497 [IPC Server handler 4 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:38,499 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:39,490 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:39,490 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:39,490 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:39,491 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:39,491 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:39,491 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:42,058 [Thread-807] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_1_1
2020-04-02 05:12:42,059 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775664_1009, blk_-9223372036854775648_1010]
2020-04-02 05:12:42,059 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_1	dst=null	perm=null	proto=rpc
2020-04-02 05:12:42,491 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:42,491 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:42,491 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:42,491 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:42,491 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:42,491 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
2020-04-02 05:12:45,492 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775760_1003 cannot be reconstructed from any node
2020-04-02 05:12:45,493 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:45,493 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:45,493 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:45,493 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:45,493 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 5 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[7]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[7]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[8]
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:12:47,336 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_1_2, dataBlkDelNum = 1, parityBlkDelNum = 2, deleteBlockFile? false
2020-04-02 05:12:47,395 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:47,398 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/corrupted_1_2, recursive=true
2020-04-02 05:12:47,398 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /corrupted_1_2
2020-04-02 05:12:47,398 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /corrupted_1_2
2020-04-02 05:12:47,399 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /corrupted_1_2 is removed
2020-04-02 05:12:47,399 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /corrupted_1_2 is removed
2020-04-02 05:12:47,400 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775760_1003 127.0.0.1:37707 127.0.0.1:39182 127.0.0.1:33115 127.0.0.1:40001 127.0.0.1:37829 127.0.0.1:34393 127.0.0.1:34710 127.0.0.1:34235 127.0.0.1:34415 
2020-04-02 05:12:47,400 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 52 Total time for transactions(ms): 40 Number of transactions batched in Syncs: 11 Number of syncs: 41 SyncTimes(ms): 6 9 
2020-04-02 05:12:47,400 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775760_1003 from priority queue 0
2020-04-02 05:12:47,400 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:47,402 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_1_2 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:12:47,402 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_1_2, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:12:47,402 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_1_2 is added
2020-04-02 05:12:47,403 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_1_2 inode 16394 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:47,403 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_1_2	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:12:47,420 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_1_2  inodeId 16394 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:47,421 [IPC Server handler 9 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:47,422 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_1_2 with blk_-9223372036854775632_1011 block is added to the in-memory file system
2020-04-02 05:12:47,422 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775632_1011, replicas=127.0.0.1:34710, 127.0.0.1:37707, 127.0.0.1:34415, 127.0.0.1:40001, 127.0.0.1:39182, 127.0.0.1:37829, 127.0.0.1:33115, 127.0.0.1:34393, 127.0.0.1:34235 for /corrupted_1_2
2020-04-02 05:12:47,423 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_1_2 with new block blk_-9223372036854775632_1011, current total block count is 1
2020-04-02 05:12:47,426 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:34470 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775632_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775632_1011 src: /127.0.0.1:34470 dest: /127.0.0.1:34710
2020-04-02 05:12:47,434 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:49814 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775631_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775631_1011 src: /127.0.0.1:49814 dest: /127.0.0.1:37707
2020-04-02 05:12:47,451 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:35854 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775629_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775629_1011 src: /127.0.0.1:35854 dest: /127.0.0.1:40001
2020-04-02 05:12:47,469 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47818 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775630_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775630_1011 src: /127.0.0.1:47818 dest: /127.0.0.1:34415
2020-04-02 05:12:47,470 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:57934 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775628_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775628_1011 src: /127.0.0.1:57934 dest: /127.0.0.1:39182
2020-04-02 05:12:47,486 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47518 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775627_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775627_1011 src: /127.0.0.1:47518 dest: /127.0.0.1:37829
2020-04-02 05:12:47,502 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,502 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775630_1011 on 127.0.0.1:34415 size 4194304 replicaState = RBW
2020-04-02 05:12:47,503 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,503 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775630_1011 is received from 127.0.0.1:34415
2020-04-02 05:12:47,503 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 1, received: 0, deleted: 0
2020-04-02 05:12:47,535 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59612 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775626_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775626_1011 src: /127.0.0.1:59612 dest: /127.0.0.1:33115
2020-04-02 05:12:47,544 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58506 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775625_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775625_1011 src: /127.0.0.1:58506 dest: /127.0.0.1:34393
2020-04-02 05:12:47,554 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:51144 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775624_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775624_1011 src: /127.0.0.1:51144 dest: /127.0.0.1:34235
2020-04-02 05:12:47,741 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775632_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34470, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775632_1011, duration(ns): 304185378
2020-04-02 05:12:47,742 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775631_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49814, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775631_1011, duration(ns): 297890060
2020-04-02 05:12:47,743 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775624_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51144, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775624_1011, duration(ns): 182697499
2020-04-02 05:12:47,743 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775632_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775632_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,743 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775625_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58506, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775625_1011, duration(ns): 192296528
2020-04-02 05:12:47,744 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775631_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775631_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,743 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775624_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775624_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,744 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775625_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775625_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,745 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775627_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47518, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775627_1011, duration(ns): 250676771
2020-04-02 05:12:47,745 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,746 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775627_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775627_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,746 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,746 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775630_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47818, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775630_1011, duration(ns): 267606342
2020-04-02 05:12:47,746 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,745 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775629_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35854, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775629_1011, duration(ns): 271813519
2020-04-02 05:12:47,745 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,747 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775629_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775629_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,746 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775630_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775630_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,746 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,747 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,746 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775626_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59612, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775626_1011, duration(ns): 201939146
2020-04-02 05:12:47,746 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775628_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57934, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775628_1011, duration(ns): 261598400
2020-04-02 05:12:47,746 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,746 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,746 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775624_1011 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:47,748 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775628_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775628_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,747 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775626_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775626_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,747 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,748 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,748 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_1_2  inodeId 16394 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:47,748 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775624_1011 is received from 127.0.0.1:34235
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,749 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775631_1011 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:47,749 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775631_1011 is received from 127.0.0.1:37707
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,749 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775632_1011 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:47,749 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775632_1011 is received from 127.0.0.1:34710
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,749 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775625_1011 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:47,749 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775625_1011 is received from 127.0.0.1:34393
2020-04-02 05:12:47,749 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,750 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775630_1011 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:47,750 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775630_1011 is received from 127.0.0.1:34415
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,750 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775628_1011 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:47,750 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775628_1011 is received from 127.0.0.1:39182
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,750 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775629_1011 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:47,750 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775629_1011 is received from 127.0.0.1:40001
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,750 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775627_1011 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:47,750 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775627_1011 is received from 127.0.0.1:37829
2020-04-02 05:12:47,750 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,751 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775626_1011 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:12:47,751 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,751 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775632_1011 (size=0)
2020-04-02 05:12:47,751 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775626_1011 is received from 127.0.0.1:33115
2020-04-02 05:12:47,751 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,751 [IPC Server handler 6 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:12:47,753 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_1_2 with blk_-9223372036854775616_1012 block is added to the in-memory file system
2020-04-02 05:12:47,753 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775616_1012, replicas=127.0.0.1:37707, 127.0.0.1:34415, 127.0.0.1:34710, 127.0.0.1:40001, 127.0.0.1:37829, 127.0.0.1:39182, 127.0.0.1:34235, 127.0.0.1:34393, 127.0.0.1:33115 for /corrupted_1_2
2020-04-02 05:12:47,753 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_1_2 with new block blk_-9223372036854775616_1012, current total block count is 2
2020-04-02 05:12:47,755 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59620 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775608_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775608_1012 src: /127.0.0.1:59620 dest: /127.0.0.1:33115
2020-04-02 05:12:47,755 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:49830 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775616_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775616_1012 src: /127.0.0.1:49830 dest: /127.0.0.1:37707
2020-04-02 05:12:47,755 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58514 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012 src: /127.0.0.1:58514 dest: /127.0.0.1:34393
2020-04-02 05:12:47,755 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:51152 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012 src: /127.0.0.1:51152 dest: /127.0.0.1:34235
2020-04-02 05:12:47,765 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775616_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49830, dest: /127.0.0.1:37707, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775616_1012, duration(ns): 7455216
2020-04-02 05:12:47,765 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775616_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775616_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,766 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,766 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775616_1012 on 127.0.0.1:37707 size 123 replicaState = FINALIZED
2020-04-02 05:12:47,767 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,767 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51152, dest: /127.0.0.1:34235, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012, duration(ns): 4262445
2020-04-02 05:12:47,767 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775616_1012 (size=0)
2020-04-02 05:12:47,767 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,767 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775616_1012 is received from 127.0.0.1:37707
2020-04-02 05:12:47,767 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,767 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,767 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775610_1012 on 127.0.0.1:34235 size 123 replicaState = FINALIZED
2020-04-02 05:12:47,767 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,768 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775616_1012 (size=0)
2020-04-02 05:12:47,768 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775610_1012 is received from 127.0.0.1:34235
2020-04-02 05:12:47,768 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,768 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58514, dest: /127.0.0.1:34393, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012, duration(ns): 7138238
2020-04-02 05:12:47,769 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,769 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,769 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775609_1012 on 127.0.0.1:34393 size 123 replicaState = FINALIZED
2020-04-02 05:12:47,770 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,770 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775608_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59620, dest: /127.0.0.1:33115, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775608_1012, duration(ns): 8978524
2020-04-02 05:12:47,770 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775616_1012 (size=0)
2020-04-02 05:12:47,770 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775608_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775608_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:12:47,770 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775609_1012 is received from 127.0.0.1:34393
2020-04-02 05:12:47,771 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,774 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:12:47,776 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775608_1012 on 127.0.0.1:33115 size 123 replicaState = FINALIZED
2020-04-02 05:12:47,778 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:12:47,778 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775616_1012 (size=0)
2020-04-02 05:12:47,779 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775608_1012 is received from 127.0.0.1:33115
2020-04-02 05:12:47,779 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:12:47,779 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_1_2 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:47,779 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_1_2 with 2 blocks is persisted to the file system
2020-04-02 05:12:47,780 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_1_2 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:12:47,780 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_1_2
2020-04-02 05:12:47,782 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:12:47,782 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:47,783 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
2020-04-02 05:12:47,784 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,784 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,785 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,785 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,785 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,786 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,786 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,786 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,787 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775611_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,787 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012
2020-04-02 05:12:47,787 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,787 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,788 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,788 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,788 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,788 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,789 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,789 [Thread-881] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775609
2020-04-02 05:12:47,789 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775609_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,790 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012
2020-04-02 05:12:47,790 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,790 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,790 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,791 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,791 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,791 [Thread-881] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775610
2020-04-02 05:12:47,792 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,792 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,792 [Thread-881] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775610_1012
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:12:47,792 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_1_2
2020-04-02 05:12:47,800 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_1_2
2020-04-02 05:12:47,801 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:47,801 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_1_2
2020-04-02 05:12:47,802 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:12:47,802 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:12:47,803 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:12:48,494 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:48,494 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:48,494 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:48,494 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:48,494 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:48,495 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34710 to delete [blk_-9223372036854775754_1003]
2020-04-02 05:12:48,495 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37707 to delete [blk_-9223372036854775760_1003]
2020-04-02 05:12:48,495 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34415 to delete [blk_-9223372036854775752_1003]
2020-04-02 05:12:49,545 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775760_1003 replica FinalizedReplica, blk_-9223372036854775760_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775760 for deletion
2020-04-02 05:12:49,547 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775760_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775760
2020-04-02 05:12:50,149 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775754_1003 replica FinalizedReplica, blk_-9223372036854775754_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775754 for deletion
2020-04-02 05:12:50,160 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775754_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775754
2020-04-02 05:12:50,503 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775752_1003 replica FinalizedReplica, blk_-9223372036854775752_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775752 for deletion
2020-04-02 05:12:50,514 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775752_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775752
2020-04-02 05:12:51,495 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:51,498 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:51,498 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:51,498 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:51,498 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:51,499 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34393 to delete [blk_-9223372036854775755_1003]
2020-04-02 05:12:51,499 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:39182 to delete [blk_-9223372036854775759_1003]
2020-04-02 05:12:51,499 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34235 to delete [blk_-9223372036854775753_1003]
2020-04-02 05:12:52,495 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775753_1003 replica FinalizedReplica, blk_-9223372036854775753_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775753 for deletion
2020-04-02 05:12:52,495 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775759_1003 replica FinalizedReplica, blk_-9223372036854775759_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775759 for deletion
2020-04-02 05:12:52,497 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775759_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775759
2020-04-02 05:12:52,507 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775753_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775753
2020-04-02 05:12:53,145 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775755_1003 replica FinalizedReplica, blk_-9223372036854775755_1003, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775755 for deletion
2020-04-02 05:12:53,148 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775755_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775755
2020-04-02 05:12:54,499 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:54,503 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:54,503 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:54,503 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:54,503 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:12:54,503 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37829 to delete [blk_-9223372036854775756_1003]
2020-04-02 05:12:54,504 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:40001 to delete [blk_-9223372036854775757_1003]
2020-04-02 05:12:54,504 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33115 to delete [blk_-9223372036854775758_1003]
2020-04-02 05:12:55,496 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775757_1003 replica FinalizedReplica, blk_-9223372036854775757_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775757 for deletion
2020-04-02 05:12:55,496 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775756_1003 replica FinalizedReplica, blk_-9223372036854775756_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775756 for deletion
2020-04-02 05:12:55,496 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775758_1003 replica FinalizedReplica, blk_-9223372036854775758_1003, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775758 for deletion
2020-04-02 05:12:55,507 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775757_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775757
2020-04-02 05:12:55,516 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775756_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775756
2020-04-02 05:12:55,516 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775758_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775758
2020-04-02 05:12:57,504 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:12:57,504 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:12:57,504 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:12:57,504 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:12:57,505 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:00,505 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:00,505 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:00,505 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:00,505 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:00,505 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:00,665 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_1_2
2020-04-02 05:13:00,669 [IPC Server handler 0 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:13:00,671 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:13:03,506 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:03,507 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:03,507 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:03,507 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:03,507 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:04,290 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_1_2
2020-04-02 05:13:04,304 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:13:04,306 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:13:06,509 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:06,510 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:06,510 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:06,510 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:06,510 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:08,257 [Thread-881] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_1_2
2020-04-02 05:13:08,259 [IPC Server handler 5 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775632_1011, blk_-9223372036854775616_1012]
2020-04-02 05:13:08,260 [IPC Server handler 5 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_1_2	dst=null	perm=null	proto=rpc
2020-04-02 05:13:09,511 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:09,511 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:09,511 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:09,511 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:09,511 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:12,512 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:12,513 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:12,513 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775744_1004 cannot be reconstructed from any node
2020-04-02 05:13:12,513 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:12,513 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[8]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[8]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[9]
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:13:13,454 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_2_0, dataBlkDelNum = 2, parityBlkDelNum = 0, deleteBlockFile? false
2020-04-02 05:13:13,510 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:13,512 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/corrupted_2_0, recursive=true
2020-04-02 05:13:13,512 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /corrupted_2_0
2020-04-02 05:13:13,512 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /corrupted_2_0
2020-04-02 05:13:13,513 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /corrupted_2_0 is removed
2020-04-02 05:13:13,513 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /corrupted_2_0 is removed
2020-04-02 05:13:13,513 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775744_1004 127.0.0.1:40001 127.0.0.1:34235 127.0.0.1:33115 127.0.0.1:34415 127.0.0.1:39182 127.0.0.1:34393 127.0.0.1:34710 127.0.0.1:37707 127.0.0.1:37829 
2020-04-02 05:13:13,514 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775744_1004 from priority queue 1
2020-04-02 05:13:13,514 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:13,515 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_2_0 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:13:13,515 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_2_0, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:13:13,516 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_2_0 is added
2020-04-02 05:13:13,516 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_2_0 inode 16395 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:13,516 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_2_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:13:13,535 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_2_0  inodeId 16395 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:13,536 [IPC Server handler 0 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:13:13,538 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_2_0 with blk_-9223372036854775600_1013 block is added to the in-memory file system
2020-04-02 05:13:13,538 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775600_1013, replicas=127.0.0.1:37829, 127.0.0.1:40001, 127.0.0.1:37707, 127.0.0.1:33115, 127.0.0.1:34393, 127.0.0.1:34235, 127.0.0.1:34415, 127.0.0.1:34710, 127.0.0.1:39182 for /corrupted_2_0
2020-04-02 05:13:13,538 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_2_0 with new block blk_-9223372036854775600_1013, current total block count is 1
2020-04-02 05:13:13,598 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47608 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775600_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775600_1013 src: /127.0.0.1:47608 dest: /127.0.0.1:37829
2020-04-02 05:13:13,599 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:35950 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775599_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775599_1013 src: /127.0.0.1:35950 dest: /127.0.0.1:40001
2020-04-02 05:13:13,606 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:49916 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775598_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775598_1013 src: /127.0.0.1:49916 dest: /127.0.0.1:37707
2020-04-02 05:13:13,620 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59706 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775597_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775597_1013 src: /127.0.0.1:59706 dest: /127.0.0.1:33115
2020-04-02 05:13:13,629 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58600 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775596_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775596_1013 src: /127.0.0.1:58600 dest: /127.0.0.1:34393
2020-04-02 05:13:13,635 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:51238 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775595_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775595_1013 src: /127.0.0.1:51238 dest: /127.0.0.1:34235
2020-04-02 05:13:13,681 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47926 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775594_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775594_1013 src: /127.0.0.1:47926 dest: /127.0.0.1:34415
2020-04-02 05:13:13,695 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:34584 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775593_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775593_1013 src: /127.0.0.1:34584 dest: /127.0.0.1:34710
2020-04-02 05:13:13,709 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58042 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775592_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775592_1013 src: /127.0.0.1:58042 dest: /127.0.0.1:39182
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775593_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34584, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775593_1013, duration(ns): 183029881
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775595_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51238, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775595_1013, duration(ns): 243231663
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775593_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775593_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775600_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47608, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775600_1013, duration(ns): 280358108
2020-04-02 05:13:13,885 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775600_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775600_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775599_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35950, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775599_1013, duration(ns): 279527083
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775598_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49916, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775598_1013, duration(ns): 272700548
2020-04-02 05:13:13,885 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775599_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775599_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,885 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775597_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59706, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775597_1013, duration(ns): 258147120
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775594_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47926, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775594_1013, duration(ns): 197108834
2020-04-02 05:13:13,886 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775597_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775597_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,886 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775599_1013 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:13,885 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,885 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,885 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,885 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,885 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,885 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,885 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,885 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,885 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775598_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775598_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775592_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58042, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775592_1013, duration(ns): 169810526
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775595_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775595_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,884 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775596_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58600, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775596_1013, duration(ns): 248959523
2020-04-02 05:13:13,887 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775592_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775592_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,886 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,886 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775594_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775594_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,887 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775596_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775596_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,888 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:13,888 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775599_1013 is received from 127.0.0.1:40001
2020-04-02 05:13:13,888 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,888 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775593_1013 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:13,888 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_2_0  inodeId 16395 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:13,888 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,888 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:13,889 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775593_1013 is received from 127.0.0.1:34710
2020-04-02 05:13:13,889 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,889 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775597_1013 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:13,889 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,889 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:13,889 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775597_1013 is received from 127.0.0.1:33115
2020-04-02 05:13:13,889 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,889 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775594_1013 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:13,889 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,889 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:13,889 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775594_1013 is received from 127.0.0.1:34415
2020-04-02 05:13:13,889 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,889 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775592_1013 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:13,889 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,890 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:13,890 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775592_1013 is received from 127.0.0.1:39182
2020-04-02 05:13:13,890 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,890 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775595_1013 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:13,890 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,890 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:13,890 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775595_1013 is received from 127.0.0.1:34235
2020-04-02 05:13:13,890 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,890 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775596_1013 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:13,890 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,890 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:13,890 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775596_1013 is received from 127.0.0.1:34393
2020-04-02 05:13:13,890 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,891 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775598_1013 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:13,891 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,891 [IPC Server handler 5 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:13:13,891 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:13,891 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775598_1013 is received from 127.0.0.1:37707
2020-04-02 05:13:13,891 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,891 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775600_1013 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:13,891 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,891 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775600_1013 (size=0)
2020-04-02 05:13:13,891 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775600_1013 is received from 127.0.0.1:37829
2020-04-02 05:13:13,891 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,892 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_2_0 with blk_-9223372036854775584_1014 block is added to the in-memory file system
2020-04-02 05:13:13,892 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775584_1014, replicas=127.0.0.1:34235, 127.0.0.1:37707, 127.0.0.1:40001, 127.0.0.1:37829, 127.0.0.1:34393, 127.0.0.1:34710, 127.0.0.1:39182, 127.0.0.1:34415, 127.0.0.1:33115 for /corrupted_2_0
2020-04-02 05:13:13,892 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_2_0 with new block blk_-9223372036854775584_1014, current total block count is 2
2020-04-02 05:13:13,894 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:51246 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 src: /127.0.0.1:51246 dest: /127.0.0.1:34235
2020-04-02 05:13:13,895 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59724 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775576_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775576_1014 src: /127.0.0.1:59724 dest: /127.0.0.1:33115
2020-04-02 05:13:13,895 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47936 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775577_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775577_1014 src: /127.0.0.1:47936 dest: /127.0.0.1:34415
2020-04-02 05:13:13,895 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58046 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775578_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775578_1014 src: /127.0.0.1:58046 dest: /127.0.0.1:39182
2020-04-02 05:13:13,904 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51246, dest: /127.0.0.1:34235, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014, duration(ns): 7248086
2020-04-02 05:13:13,904 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,904 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,904 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775584_1014 on 127.0.0.1:34235 size 123 replicaState = FINALIZED
2020-04-02 05:13:13,905 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,905 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775578_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58046, dest: /127.0.0.1:39182, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775578_1014, duration(ns): 5664590
2020-04-02 05:13:13,905 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775584_1014 (size=0)
2020-04-02 05:13:13,905 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775578_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775578_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,906 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775584_1014 is received from 127.0.0.1:34235
2020-04-02 05:13:13,906 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,906 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,907 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775578_1014 on 127.0.0.1:39182 size 123 replicaState = FINALIZED
2020-04-02 05:13:13,907 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,907 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775577_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47936, dest: /127.0.0.1:34415, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775577_1014, duration(ns): 5433045
2020-04-02 05:13:13,907 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775584_1014 (size=0)
2020-04-02 05:13:13,907 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775577_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775577_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,907 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775578_1014 is received from 127.0.0.1:39182
2020-04-02 05:13:13,907 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,907 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,908 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775577_1014 on 127.0.0.1:34415 size 123 replicaState = FINALIZED
2020-04-02 05:13:13,908 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,908 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775584_1014 (size=0)
2020-04-02 05:13:13,909 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775576_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59724, dest: /127.0.0.1:33115, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775576_1014, duration(ns): 9867053
2020-04-02 05:13:13,909 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775577_1014 is received from 127.0.0.1:34415
2020-04-02 05:13:13,909 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,909 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775576_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775576_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:13,909 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:13,909 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775576_1014 on 127.0.0.1:33115 size 123 replicaState = FINALIZED
2020-04-02 05:13:13,909 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:13,909 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775584_1014 (size=0)
2020-04-02 05:13:13,909 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775576_1014 is received from 127.0.0.1:33115
2020-04-02 05:13:13,910 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:13,910 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_2_0 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:13,911 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_2_0 with 2 blocks is persisted to the file system
2020-04-02 05:13:13,911 [IPC Server handler 8 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_2_0 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:13,911 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_2_0
2020-04-02 05:13:13,912 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:13,913 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:13,914 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014
2020-04-02 05:13:13,914 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,915 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,915 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,915 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,916 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,916 [Thread-942] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775584
2020-04-02 05:13:13,917 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,917 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,917 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,917 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
2020-04-02 05:13:13,917 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,918 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,918 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,918 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,919 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,919 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,919 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,919 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,919 [Thread-942] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775580_1014
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:13,920 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_2_0
2020-04-02 05:13:13,924 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_2_0
2020-04-02 05:13:13,925 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:13,926 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_2_0
2020-04-02 05:13:13,926 [IPC Server handler 6 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:13:13,927 [IPC Server handler 3 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:13,927 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:13,947 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:13,949 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:13,949 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775584_1014 added as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:13,949 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:13,949 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:15,220 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:15,221 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:15,222 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775584_1014 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:15,222 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:15,222 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775584_1014 from priority queue 2
2020-04-02 05:13:15,222 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:15,545 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:15,545 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:15,546 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:15,546 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:15,546 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:15,546 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34415 to delete [blk_-9223372036854775741_1004]
2020-04-02 05:13:15,546 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37829 to delete [blk_-9223372036854775736_1004]
2020-04-02 05:13:15,546 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33115 to delete [blk_-9223372036854775742_1004]
2020-04-02 05:13:16,495 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775742_1004 replica FinalizedReplica, blk_-9223372036854775742_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775742 for deletion
2020-04-02 05:13:16,495 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775736_1004 replica FinalizedReplica, blk_-9223372036854775736_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775736 for deletion
2020-04-02 05:13:16,497 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775742_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775742
2020-04-02 05:13:16,498 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775736_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775736
2020-04-02 05:13:16,541 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:16,542 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:16,542 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775584_1014 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:16,543 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:16,543 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775584_1014 from priority queue 2
2020-04-02 05:13:16,543 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:17,510 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775741_1004 replica FinalizedReplica, blk_-9223372036854775741_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775741 for deletion
2020-04-02 05:13:17,512 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775741_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775741
2020-04-02 05:13:18,419 [StripedRead-0] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:18,422 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:18,422 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775584_1014 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:18,422 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:18,423 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775584_1014 from priority queue 2
2020-04-02 05:13:18,423 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:18,546 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:18,546 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:18,546 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:18,546 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:18,546 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:18,546 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37707 to delete [blk_-9223372036854775737_1004]
2020-04-02 05:13:18,547 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34393 to delete [blk_-9223372036854775739_1004]
2020-04-02 05:13:18,547 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:40001 to delete [blk_-9223372036854775744_1004]
2020-04-02 05:13:19,498 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775744_1004 replica FinalizedReplica, blk_-9223372036854775744_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775744 for deletion
2020-04-02 05:13:19,501 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775744_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775744
2020-04-02 05:13:19,596 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775737_1004 replica FinalizedReplica, blk_-9223372036854775737_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775737 for deletion
2020-04-02 05:13:19,600 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775737_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775737
2020-04-02 05:13:20,175 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775739_1004 replica FinalizedReplica, blk_-9223372036854775739_1004, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775739 for deletion
2020-04-02 05:13:20,179 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775739_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775739
2020-04-02 05:13:20,496 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:20,500 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:20,500 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775584_1014 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:20,501 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:20,501 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775584_1014 from priority queue 2
2020-04-02 05:13:20,501 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:21,547 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:21,547 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:21,547 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:21,548 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:21,548 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:21,548 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34710 to delete [blk_-9223372036854775738_1004]
2020-04-02 05:13:21,548 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:39182 to delete [blk_-9223372036854775740_1004]
2020-04-02 05:13:21,548 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34235 to delete [blk_-9223372036854775743_1004]
2020-04-02 05:13:22,436 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:22,438 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:22,438 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775584_1014 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:22,438 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:22,438 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775584_1014 from priority queue 2
2020-04-02 05:13:22,438 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:22,495 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775740_1004 replica FinalizedReplica, blk_-9223372036854775740_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775740 for deletion
2020-04-02 05:13:22,495 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775743_1004 replica FinalizedReplica, blk_-9223372036854775743_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775743 for deletion
2020-04-02 05:13:22,497 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775740_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775740
2020-04-02 05:13:22,497 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775743_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775743
2020-04-02 05:13:23,182 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775738_1004 replica FinalizedReplica, blk_-9223372036854775738_1004, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775738 for deletion
2020-04-02 05:13:23,184 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775738_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775738
2020-04-02 05:13:23,994 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:23,997 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:23,998 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775584_1014 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:23,998 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:23,998 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775584_1014 from priority queue 2
2020-04-02 05:13:23,998 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:24,548 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:24,549 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:24,549 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:24,549 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:24,549 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:25,677 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:25,678 [IPC Server handler 1 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:25,678 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775584_1014 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:25,679 [IPC Server handler 1 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:25,679 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775584_1014 from priority queue 2
2020-04-02 05:13:25,679 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:27,101 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:27,102 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:27,102 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775584_1014 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:27,103 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:27,103 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775584_1014 from priority queue 2
2020-04-02 05:13:27,103 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:27,104 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 from DatanodeInfoWithStorage[127.0.0.1:34235,DS-4188b01d-cb51-4778-873f-1c29b449b256,DISK] at 0
2020-04-02 05:13:27,105 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775584_1014 on datanode: 127.0.0.1:34235
2020-04-02 05:13:27,105 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775584_1014 to add as corrupt on 127.0.0.1:34235 by /127.0.0.1  because client machine reported it
2020-04-02 05:13:27,105 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775584_1014 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:13:27,105 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775584_1014 from priority queue 2
2020-04-02 05:13:27,106 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775584_1014 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:13:27,106 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_2_0
2020-04-02 05:13:27,106 [IPC Server handler 8 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:27,107 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:27,549 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:27,549 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:27,549 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:27,549 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:27,549 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:30,550 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:30,551 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:30,551 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:30,551 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:30,552 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:30,663 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_2_0
2020-04-02 05:13:30,679 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:30,680 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:33,552 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:33,552 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:33,552 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:33,552 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:33,552 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
2020-04-02 05:13:34,176 [Thread-942] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_2_0
2020-04-02 05:13:34,177 [IPC Server handler 5 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775600_1013, blk_-9223372036854775584_1014]
2020-04-02 05:13:34,177 [IPC Server handler 5 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_0	dst=null	perm=null	proto=rpc
2020-04-02 05:13:36,553 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775728_1005 cannot be reconstructed from any node
2020-04-02 05:13:36,553 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:36,553 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:36,553 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:36,553 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 4 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[9]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[9]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[10]
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:13:38,982 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_2_1, dataBlkDelNum = 2, parityBlkDelNum = 1, deleteBlockFile? false
2020-04-02 05:13:39,032 [IPC Server handler 5 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:39,033 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/corrupted_2_1, recursive=true
2020-04-02 05:13:39,034 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /corrupted_2_1
2020-04-02 05:13:39,034 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /corrupted_2_1
2020-04-02 05:13:39,034 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /corrupted_2_1 is removed
2020-04-02 05:13:39,035 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /corrupted_2_1 is removed
2020-04-02 05:13:39,035 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775728_1005 127.0.0.1:34415 127.0.0.1:34393 127.0.0.1:37707 127.0.0.1:39182 127.0.0.1:34235 127.0.0.1:34710 127.0.0.1:40001 127.0.0.1:33115 127.0.0.1:37829 
2020-04-02 05:13:39,035 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775728_1005 from priority queue 0
2020-04-02 05:13:39,036 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:39,037 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_2_1 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:13:39,037 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_2_1, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:13:39,038 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_2_1 is added
2020-04-02 05:13:39,038 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_2_1 inode 16396 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:39,038 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_2_1	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:13:39,063 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_2_1  inodeId 16396 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:39,063 [IPC Server handler 6 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:13:39,065 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_2_1 with blk_-9223372036854775568_1015 block is added to the in-memory file system
2020-04-02 05:13:39,065 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775568_1015, replicas=127.0.0.1:37707, 127.0.0.1:34235, 127.0.0.1:33115, 127.0.0.1:39182, 127.0.0.1:40001, 127.0.0.1:37829, 127.0.0.1:34710, 127.0.0.1:34393, 127.0.0.1:34415 for /corrupted_2_1
2020-04-02 05:13:39,065 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_2_1 with new block blk_-9223372036854775568_1015, current total block count is 1
2020-04-02 05:13:39,069 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50042 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775568_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775568_1015 src: /127.0.0.1:50042 dest: /127.0.0.1:37707
2020-04-02 05:13:39,074 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:51360 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775567_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775567_1015 src: /127.0.0.1:51360 dest: /127.0.0.1:34235
2020-04-02 05:13:39,077 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59834 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775566_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775566_1015 src: /127.0.0.1:59834 dest: /127.0.0.1:33115
2020-04-02 05:13:39,080 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58162 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775565_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775565_1015 src: /127.0.0.1:58162 dest: /127.0.0.1:39182
2020-04-02 05:13:39,086 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:36086 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775564_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775564_1015 src: /127.0.0.1:36086 dest: /127.0.0.1:40001
2020-04-02 05:13:39,088 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47748 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775563_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775563_1015 src: /127.0.0.1:47748 dest: /127.0.0.1:37829
2020-04-02 05:13:39,126 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:34712 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775562_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775562_1015 src: /127.0.0.1:34712 dest: /127.0.0.1:34710
2020-04-02 05:13:39,130 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58736 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775561_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775561_1015 src: /127.0.0.1:58736 dest: /127.0.0.1:34393
2020-04-02 05:13:39,133 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:48060 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775560_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775560_1015 src: /127.0.0.1:48060 dest: /127.0.0.1:34415
2020-04-02 05:13:39,330 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775568_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50042, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775568_1015, duration(ns): 155691327
2020-04-02 05:13:39,331 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775564_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36086, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775564_1015, duration(ns): 159581189
2020-04-02 05:13:39,331 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775561_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58736, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775561_1015, duration(ns): 157307085
2020-04-02 05:13:39,331 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775563_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47748, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775563_1015, duration(ns): 159465145
2020-04-02 05:13:39,332 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775561_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775561_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,332 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775564_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775564_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,332 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775568_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775568_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,331 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775562_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34712, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775562_1015, duration(ns): 159977966
2020-04-02 05:13:39,331 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775566_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59834, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775566_1015, duration(ns): 159342186
2020-04-02 05:13:39,331 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775560_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48060, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775560_1015, duration(ns): 157574101
2020-04-02 05:13:39,333 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775566_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775566_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,334 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775560_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775560_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,336 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,333 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775562_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775562_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,333 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775565_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58162, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775565_1015, duration(ns): 157766932
2020-04-02 05:13:39,333 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775567_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51360, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775567_1015, duration(ns): 159733051
2020-04-02 05:13:39,337 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775565_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775565_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,333 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775563_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775563_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,337 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775567_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775567_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,337 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775560_1015 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:39,336 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,336 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,336 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,336 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,336 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,336 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,336 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,336 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,337 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:39,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775560_1015 is received from 127.0.0.1:34415
2020-04-02 05:13:39,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,339 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775567_1015 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:39,339 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:39,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775567_1015 is received from 127.0.0.1:34235
2020-04-02 05:13:39,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,339 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775563_1015 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:39,339 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:39,339 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775563_1015 is received from 127.0.0.1:37829
2020-04-02 05:13:39,340 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,340 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775562_1015 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:39,340 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,340 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_2_1  inodeId 16396 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:39,340 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:39,340 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775562_1015 is received from 127.0.0.1:34710
2020-04-02 05:13:39,340 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,340 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775565_1015 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:39,340 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,340 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:39,340 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775565_1015 is received from 127.0.0.1:39182
2020-04-02 05:13:39,340 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,340 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775564_1015 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:39,340 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,341 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:39,341 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775564_1015 is received from 127.0.0.1:40001
2020-04-02 05:13:39,341 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,341 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775561_1015 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:39,341 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,341 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:39,341 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775561_1015 is received from 127.0.0.1:34393
2020-04-02 05:13:39,341 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,341 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775568_1015 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:39,341 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,341 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:39,341 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775568_1015 is received from 127.0.0.1:37707
2020-04-02 05:13:39,341 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,342 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775566_1015 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:13:39,342 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,342 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775568_1015 (size=0)
2020-04-02 05:13:39,342 [IPC Server handler 6 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:13:39,342 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775566_1015 is received from 127.0.0.1:33115
2020-04-02 05:13:39,342 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,345 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_2_1 with blk_-9223372036854775552_1016 block is added to the in-memory file system
2020-04-02 05:13:39,345 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775552_1016, replicas=127.0.0.1:39182, 127.0.0.1:34415, 127.0.0.1:34710, 127.0.0.1:34393, 127.0.0.1:40001, 127.0.0.1:37829, 127.0.0.1:37707, 127.0.0.1:33115, 127.0.0.1:34235 for /corrupted_2_1
2020-04-02 05:13:39,346 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_2_1 with new block blk_-9223372036854775552_1016, current total block count is 2
2020-04-02 05:13:39,348 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59848 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775545_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775545_1016 src: /127.0.0.1:59848 dest: /127.0.0.1:33115
2020-04-02 05:13:39,348 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50060 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775546_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775546_1016 src: /127.0.0.1:50060 dest: /127.0.0.1:37707
2020-04-02 05:13:39,348 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58174 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775552_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775552_1016 src: /127.0.0.1:58174 dest: /127.0.0.1:39182
2020-04-02 05:13:39,348 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:51376 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016 src: /127.0.0.1:51376 dest: /127.0.0.1:34235
2020-04-02 05:13:39,355 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775552_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58174, dest: /127.0.0.1:39182, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775552_1016, duration(ns): 3170040
2020-04-02 05:13:39,355 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775552_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775552_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,356 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,356 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775552_1016 on 127.0.0.1:39182 size 123 replicaState = FINALIZED
2020-04-02 05:13:39,357 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775546_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50060, dest: /127.0.0.1:37707, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775546_1016, duration(ns): 5044131
2020-04-02 05:13:39,357 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,357 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775546_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775546_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,357 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775552_1016 (size=0)
2020-04-02 05:13:39,358 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775552_1016 is received from 127.0.0.1:39182
2020-04-02 05:13:39,358 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,358 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,358 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775546_1016 on 127.0.0.1:37707 size 123 replicaState = FINALIZED
2020-04-02 05:13:39,358 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,359 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775552_1016 (size=0)
2020-04-02 05:13:39,359 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775545_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59848, dest: /127.0.0.1:33115, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775545_1016, duration(ns): 7262275
2020-04-02 05:13:39,359 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775546_1016 is received from 127.0.0.1:37707
2020-04-02 05:13:39,359 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,359 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775545_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775545_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,359 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,360 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775545_1016 on 127.0.0.1:33115 size 123 replicaState = FINALIZED
2020-04-02 05:13:39,360 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,361 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51376, dest: /127.0.0.1:34235, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016, duration(ns): 8845326
2020-04-02 05:13:39,361 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775552_1016 (size=0)
2020-04-02 05:13:39,361 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:13:39,361 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775545_1016 is received from 127.0.0.1:33115
2020-04-02 05:13:39,361 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,361 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:13:39,361 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775544_1016 on 127.0.0.1:34235 size 123 replicaState = FINALIZED
2020-04-02 05:13:39,362 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:13:39,362 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775552_1016 (size=0)
2020-04-02 05:13:39,362 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775544_1016 is received from 127.0.0.1:34235
2020-04-02 05:13:39,362 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:13:39,362 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_2_1 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:39,363 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_2_1 with 2 blocks is persisted to the file system
2020-04-02 05:13:39,363 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_2_1 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:13:39,363 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_2_1
2020-04-02 05:13:39,364 [IPC Server handler 9 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:13:39,365 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:39,366 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
2020-04-02 05:13:39,367 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,367 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,367 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,368 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,368 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,368 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,369 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,369 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,369 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775549_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,370 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
2020-04-02 05:13:39,370 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,370 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,371 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,371 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,371 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,372 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,372 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,372 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,373 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775550_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,373 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016
2020-04-02 05:13:39,373 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,373 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,374 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,374 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,374 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,375 [Thread-1016] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir1/blk_-9223372036854775544
2020-04-02 05:13:39,375 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,375 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,376 [Thread-1016] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775544_1016
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:13:39,376 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_2_1
2020-04-02 05:13:39,380 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_2_1
2020-04-02 05:13:39,381 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:39,382 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_2_1
2020-04-02 05:13:39,383 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:13:39,383 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:13:39,384 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:39,554 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:39,554 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:39,554 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:39,554 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:39,555 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34393 to delete [blk_-9223372036854775727_1005]
2020-04-02 05:13:39,555 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34415 to delete [blk_-9223372036854775728_1005]
2020-04-02 05:13:39,555 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33115 to delete [blk_-9223372036854775721_1005]
2020-04-02 05:13:40,498 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775721_1005 replica FinalizedReplica, blk_-9223372036854775721_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775721 for deletion
2020-04-02 05:13:40,500 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775721_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775721
2020-04-02 05:13:41,183 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775727_1005 replica FinalizedReplica, blk_-9223372036854775727_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775727 for deletion
2020-04-02 05:13:41,189 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775727_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775727
2020-04-02 05:13:41,512 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775728_1005 replica FinalizedReplica, blk_-9223372036854775728_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775728 for deletion
2020-04-02 05:13:41,516 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775728_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775728
2020-04-02 05:13:42,555 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:42,561 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:42,561 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:42,561 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:42,561 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:39182 to delete [blk_-9223372036854775725_1005]
2020-04-02 05:13:42,561 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34710 to delete [blk_-9223372036854775723_1005]
2020-04-02 05:13:42,561 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37829 to delete [blk_-9223372036854775720_1005]
2020-04-02 05:13:43,496 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775720_1005 replica FinalizedReplica, blk_-9223372036854775720_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775720 for deletion
2020-04-02 05:13:43,496 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775725_1005 replica FinalizedReplica, blk_-9223372036854775725_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775725 for deletion
2020-04-02 05:13:43,498 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775720_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775720
2020-04-02 05:13:43,503 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775725_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775725
2020-04-02 05:13:44,204 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775723_1005 replica FinalizedReplica, blk_-9223372036854775723_1005, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775723 for deletion
2020-04-02 05:13:44,205 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775723_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775723
2020-04-02 05:13:45,561 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:45,567 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:45,567 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:45,567 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:45,568 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:40001 to delete [blk_-9223372036854775722_1005]
2020-04-02 05:13:45,568 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37707 to delete [blk_-9223372036854775726_1005]
2020-04-02 05:13:45,568 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34235 to delete [blk_-9223372036854775724_1005]
2020-04-02 05:13:46,496 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775724_1005 replica FinalizedReplica, blk_-9223372036854775724_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775724 for deletion
2020-04-02 05:13:46,497 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775722_1005 replica FinalizedReplica, blk_-9223372036854775722_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775722 for deletion
2020-04-02 05:13:46,498 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775724_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775724
2020-04-02 05:13:46,499 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775722_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775722
2020-04-02 05:13:46,596 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775726_1005 replica FinalizedReplica, blk_-9223372036854775726_1005, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775726 for deletion
2020-04-02 05:13:46,598 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775726_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775726
2020-04-02 05:13:48,063 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7e5d9a50] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:13:48,568 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:48,569 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:48,569 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:48,569 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:51,569 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:51,569 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:51,569 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:51,569 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:52,025 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_2_1
2020-04-02 05:13:52,029 [IPC Server handler 3 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:13:52,031 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:54,570 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:54,570 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:54,570 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:54,570 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:55,568 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_2_1
2020-04-02 05:13:55,576 [IPC Server handler 3 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:13:55,576 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:13:57,570 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:13:57,571 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:13:57,571 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:13:57,571 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:13:59,221 [Thread-1016] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_2_1
2020-04-02 05:13:59,223 [IPC Server handler 9 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775568_1015, blk_-9223372036854775552_1016]
2020-04-02 05:13:59,227 [IPC Server handler 9 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_2_1	dst=null	perm=null	proto=rpc
2020-04-02 05:14:00,571 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:14:00,571 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:00,571 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:00,572 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:14:03,572 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775712_1006 cannot be reconstructed from any node
2020-04-02 05:14:03,572 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:03,572 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:03,572 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[10]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[10]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[11]
[msx] perform reset as unitTestCounterInClass 11 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:14:04,189 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:testReadWithBlockCorrupted(203)) - testReadWithBlockCorrupted: file = /corrupted_3_0, dataBlkDelNum = 3, parityBlkDelNum = 0, deleteBlockFile? false
2020-04-02 05:14:04,247 [IPC Server handler 3 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:04,249 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:delete(1084)) - *DIR* Namenode.delete: src=/corrupted_3_0, recursive=true
2020-04-02 05:14:04,249 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(180)) - DIR* NameSystem.delete: /corrupted_3_0
2020-04-02 05:14:04,249 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:delete(55)) - DIR* FSDirectory.delete: /corrupted_3_0
2020-04-02 05:14:04,250 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:unprotectedDelete(269)) - DIR* FSDirectory.unprotectedDelete: /corrupted_3_0 is removed
2020-04-02 05:14:04,250 [IPC Server handler 4 on 42662] DEBUG hdfs.StateChange (FSDirDeleteOp.java:deleteInternal(201)) - DIR* Namesystem.delete: /corrupted_3_0 is removed
2020-04-02 05:14:04,251 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 79 Total time for transactions(ms): 46 Number of transactions batched in Syncs: 16 Number of syncs: 63 SyncTimes(ms): 7 9 
2020-04-02 05:14:04,251 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (BlockManager.java:addToInvalidates(1598)) - BLOCK* addToInvalidates: blk_-9223372036854775712_1006 127.0.0.1:37707 127.0.0.1:37829 127.0.0.1:34393 127.0.0.1:39182 127.0.0.1:40001 127.0.0.1:33115 127.0.0.1:34415 127.0.0.1:34710 127.0.0.1:34235 
2020-04-02 05:14:04,251 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775712_1006 from priority queue 0
2020-04-02 05:14:04,251 [IPC Server handler 4 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:04,252 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (NameNodeRpcServer.java:create(757)) - *DIR* NameNode.create: file /corrupted_3_0 for DFSClient_NONMAPREDUCE_-1496653099_1 at 127.0.0.1
2020-04-02 05:14:04,252 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:startFileInt(2385)) - DIR* NameSystem.startFile: src=/corrupted_3_0, holder=DFSClient_NONMAPREDUCE_-1496653099_1, clientMachine=127.0.0.1, createParent=true, replication=3, createFlag=[CREATE, OVERWRITE], blockSize=4194304, supportedVersions=[CryptoProtocolVersion{description='Encryption zones', version=2, unknownValue=null}]
2020-04-02 05:14:04,253 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addFile(585)) - DIR* addFile: corrupted_3_0 is added
2020-04-02 05:14:04,253 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:startFile(416)) - DIR* NameSystem.startFile: added /corrupted_3_0 inode 16397 DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:14:04,253 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/corrupted_3_0	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:14:04,272 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_3_0  inodeId 16397 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:14:04,273 [IPC Server handler 5 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:14:04,274 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_3_0 with blk_-9223372036854775536_1017 block is added to the in-memory file system
2020-04-02 05:14:04,274 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775536_1017, replicas=127.0.0.1:34393, 127.0.0.1:39182, 127.0.0.1:34710, 127.0.0.1:40001, 127.0.0.1:34415, 127.0.0.1:34235, 127.0.0.1:33115, 127.0.0.1:37707, 127.0.0.1:37829 for /corrupted_3_0
2020-04-02 05:14:04,274 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_3_0 with new block blk_-9223372036854775536_1017, current total block count is 1
2020-04-02 05:14:04,277 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58820 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775536_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775536_1017 src: /127.0.0.1:58820 dest: /127.0.0.1:34393
2020-04-02 05:14:04,282 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58256 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775535_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775535_1017 src: /127.0.0.1:58256 dest: /127.0.0.1:39182
2020-04-02 05:14:04,295 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:34802 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775534_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775534_1017 src: /127.0.0.1:34802 dest: /127.0.0.1:34710
2020-04-02 05:14:04,317 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:36182 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775533_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775533_1017 src: /127.0.0.1:36182 dest: /127.0.0.1:40001
2020-04-02 05:14:04,326 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:48150 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775532_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775532_1017 src: /127.0.0.1:48150 dest: /127.0.0.1:34415
2020-04-02 05:14:04,335 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:51466 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775531_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775531_1017 src: /127.0.0.1:51466 dest: /127.0.0.1:34235
2020-04-02 05:14:04,382 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59940 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775530_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775530_1017 src: /127.0.0.1:59940 dest: /127.0.0.1:33115
2020-04-02 05:14:04,398 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50154 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775529_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775529_1017 src: /127.0.0.1:50154 dest: /127.0.0.1:37707
2020-04-02 05:14:04,409 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:47852 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775528_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775528_1017 src: /127.0.0.1:47852 dest: /127.0.0.1:37829
2020-04-02 05:14:04,500 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,500 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,500 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775535_1017 on 127.0.0.1:39182 size 4194304 replicaState = RBW
2020-04-02 05:14:04,500 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,500 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,500 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,500 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,501 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775535_1017 is received from 127.0.0.1:39182
2020-04-02 05:14:04,501 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 1, received: 0, deleted: 0
2020-04-02 05:14:04,501 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775531_1017 on 127.0.0.1:34235 size 4194304 replicaState = RBW
2020-04-02 05:14:04,501 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,501 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775531_1017 is received from 127.0.0.1:34235
2020-04-02 05:14:04,501 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 1, received: 0, deleted: 0
2020-04-02 05:14:04,501 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775528_1017 on 127.0.0.1:37829 size 4194304 replicaState = RBW
2020-04-02 05:14:04,501 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,501 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775528_1017 is received from 127.0.0.1:37829
2020-04-02 05:14:04,502 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 1, received: 0, deleted: 0
2020-04-02 05:14:04,502 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775533_1017 on 127.0.0.1:40001 size 4194304 replicaState = RBW
2020-04-02 05:14:04,502 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,502 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775533_1017 is received from 127.0.0.1:40001
2020-04-02 05:14:04,502 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 1, received: 0, deleted: 0
2020-04-02 05:14:04,502 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775530_1017 on 127.0.0.1:33115 size 4194304 replicaState = RBW
2020-04-02 05:14:04,502 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,502 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775530_1017 is received from 127.0.0.1:33115
2020-04-02 05:14:04,502 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 1, received: 0, deleted: 0
2020-04-02 05:14:04,608 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775533_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36182, dest: /127.0.0.1:40001, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 56e1ca3a-367a-47af-9e27-26584ae1102e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775533_1017, duration(ns): 287435989
2020-04-02 05:14:04,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775534_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34802, dest: /127.0.0.1:34710, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: a2660b52-86f3-40c5-94b0-9d1be84af49e, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775534_1017, duration(ns): 309601916
2020-04-02 05:14:04,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775533_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775533_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,612 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34235, datanodeUuid=3d79862e-baf0-436b-a0a8-9028da1ac3a8, infoPort=46203, infoSecurePort=0, ipcPort=33614, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775529_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50154, dest: /127.0.0.1:37707, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775529_1017, duration(ns): 206325926
2020-04-02 05:14:04,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775532_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48150, dest: /127.0.0.1:34415, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 16d40bdc-9ce5-4b23-8a8c-b7603581f803, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775532_1017, duration(ns): 278376245
2020-04-02 05:14:04,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775536_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58820, dest: /127.0.0.1:34393, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775536_1017, duration(ns): 320696169
2020-04-02 05:14:04,613 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775532_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775532_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,613 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775531_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51466, dest: /127.0.0.1:34235, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 3d79862e-baf0-436b-a0a8-9028da1ac3a8, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775531_1017, duration(ns): 269470633
2020-04-02 05:14:04,613 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,613 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775536_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775536_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,613 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775529_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775529_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,613 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34415, datanodeUuid=16d40bdc-9ce5-4b23-8a8c-b7603581f803, infoPort=32943, infoSecurePort=0, ipcPort=34250, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,613 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37829, datanodeUuid=0b1a99b1-285a-4d40-aaa2-947eb8093a05, infoPort=43541, infoSecurePort=0, ipcPort=40489, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,613 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775531_1017 on 127.0.0.1:34235 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:04,613 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775530_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59940, dest: /127.0.0.1:33115, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775530_1017, duration(ns): 222464867
2020-04-02 05:14:04,613 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34710, datanodeUuid=a2660b52-86f3-40c5-94b0-9d1be84af49e, infoPort=45183, infoSecurePort=0, ipcPort=40541, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,612 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40001, datanodeUuid=56e1ca3a-367a-47af-9e27-26584ae1102e, infoPort=42142, infoSecurePort=0, ipcPort=34155, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,612 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775534_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775534_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775535_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58256, dest: /127.0.0.1:39182, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775535_1017, duration(ns): 316552749
2020-04-02 05:14:04,612 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775528_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47852, dest: /127.0.0.1:37829, bytes: 4194304, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 0b1a99b1-285a-4d40-aaa2-947eb8093a05, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775528_1017, duration(ns): 194626580
2020-04-02 05:14:04,615 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775535_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775535_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,614 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775530_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775530_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,614 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,613 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775531_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775531_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,615 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34235 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:04,615 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775528_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775528_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,615 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775531_1017 is received from 127.0.0.1:34235
2020-04-02 05:14:04,616 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,616 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775535_1017 on 127.0.0.1:39182 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:04,616 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,616 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:getAdditionalBlock(2680)) - BLOCK* getAdditionalBlock: /corrupted_3_0  inodeId 16397 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:14:04,616 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:04,616 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775535_1017 is received from 127.0.0.1:39182
2020-04-02 05:14:04,616 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,616 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775530_1017 on 127.0.0.1:33115 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:04,616 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,616 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:04,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775530_1017 is received from 127.0.0.1:33115
2020-04-02 05:14:04,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,617 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775532_1017 on 127.0.0.1:34415 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:04,617 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34415 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:04,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775532_1017 is received from 127.0.0.1:34415
2020-04-02 05:14:04,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34415 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,617 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775528_1017 on 127.0.0.1:37829 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:04,617 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37829 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:04,617 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775528_1017 is received from 127.0.0.1:37829
2020-04-02 05:14:04,618 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37829 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,618 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775534_1017 on 127.0.0.1:34710 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:04,618 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,618 [IPC Server handler 7 on 42662] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:14:04,618 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34710 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:04,618 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775534_1017 is received from 127.0.0.1:34710
2020-04-02 05:14:04,618 [IPC Server handler 1 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,618 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34710 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,619 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775533_1017 on 127.0.0.1:40001 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:04,619 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,619 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40001 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:04,619 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775533_1017 is received from 127.0.0.1:40001
2020-04-02 05:14:04,619 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40001 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,619 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775536_1017 on 127.0.0.1:34393 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:04,619 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,619 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:04,619 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775536_1017 is received from 127.0.0.1:34393
2020-04-02 05:14:04,619 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,619 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775529_1017 on 127.0.0.1:37707 size 4194304 replicaState = FINALIZED
2020-04-02 05:14:04,619 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,620 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775536_1017 (size=0)
2020-04-02 05:14:04,620 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775529_1017 is received from 127.0.0.1:37707
2020-04-02 05:14:04,620 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,620 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:addBlock(525)) - DIR* FSDirectory.addBlock: /corrupted_3_0 with blk_-9223372036854775520_1018 block is added to the in-memory file system
2020-04-02 05:14:04,620 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775520_1018, replicas=127.0.0.1:39182, 127.0.0.1:34710, 127.0.0.1:34235, 127.0.0.1:34415, 127.0.0.1:40001, 127.0.0.1:37829, 127.0.0.1:33115, 127.0.0.1:37707, 127.0.0.1:34393 for /corrupted_3_0
2020-04-02 05:14:04,620 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:persistNewBlock(764)) - persistNewBlock: /corrupted_3_0 with new block blk_-9223372036854775520_1018, current total block count is 2
2020-04-02 05:14:04,622 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58272 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 src: /127.0.0.1:58272 dest: /127.0.0.1:39182
2020-04-02 05:14:04,624 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:50162 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775513_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775513_1018 src: /127.0.0.1:50162 dest: /127.0.0.1:37707
2020-04-02 05:14:04,624 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:59948 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775514_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775514_1018 src: /127.0.0.1:59948 dest: /127.0.0.1:33115
2020-04-02 05:14:04,624 [DataXceiver for client DFSClient_NONMAPREDUCE_-1496653099_1 at /127.0.0.1:58842 [Receiving block BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775512_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775512_1018 src: /127.0.0.1:58842 dest: /127.0.0.1:34393
2020-04-02 05:14:04,632 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58272, dest: /127.0.0.1:39182, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 7ef49c98-3053-4533-a2a0-b3306760451d, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018, duration(ns): 6102500
2020-04-02 05:14:04,632 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,632 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39182, datanodeUuid=7ef49c98-3053-4533-a2a0-b3306760451d, infoPort=35339, infoSecurePort=0, ipcPort=42715, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,633 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775520_1018 on 127.0.0.1:39182 size 123 replicaState = FINALIZED
2020-04-02 05:14:04,633 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,633 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39182 is added to blk_-9223372036854775520_1018 (size=0)
2020-04-02 05:14:04,633 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775520_1018 is received from 127.0.0.1:39182
2020-04-02 05:14:04,633 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39182 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,634 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775514_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59948, dest: /127.0.0.1:33115, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: cdf1e358-9297-4c05-a11a-c18f14af501f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775514_1018, duration(ns): 5809068
2020-04-02 05:14:04,634 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775514_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775514_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,635 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33115, datanodeUuid=cdf1e358-9297-4c05-a11a-c18f14af501f, infoPort=42886, infoSecurePort=0, ipcPort=34460, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,635 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775514_1018 on 127.0.0.1:33115 size 123 replicaState = FINALIZED
2020-04-02 05:14:04,635 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,635 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33115 is added to blk_-9223372036854775520_1018 (size=0)
2020-04-02 05:14:04,635 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775514_1018 is received from 127.0.0.1:33115
2020-04-02 05:14:04,636 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33115 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,636 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775513_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50162, dest: /127.0.0.1:37707, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 8008a631-dd3a-486b-bb6f-3e3169812d8f, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775513_1018, duration(ns): 6147880
2020-04-02 05:14:04,636 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775513_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775513_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,636 [IPC Server handler 4 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37707, datanodeUuid=8008a631-dd3a-486b-bb6f-3e3169812d8f, infoPort=35335, infoSecurePort=0, ipcPort=42874, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,636 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775513_1018 on 127.0.0.1:37707 size 123 replicaState = FINALIZED
2020-04-02 05:14:04,637 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,637 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37707 is added to blk_-9223372036854775520_1018 (size=0)
2020-04-02 05:14:04,637 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775513_1018 is received from 127.0.0.1:37707
2020-04-02 05:14:04,638 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37707 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,638 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775512_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58842, dest: /127.0.0.1:34393, bytes: 123, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1496653099_1, offset: 0, srvID: 1cda337e-92c5-4d2b-a450-460ae3b1f996, blockid: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775512_1018, duration(ns): 9661266
2020-04-02 05:14:04,638 [PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775512_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775512_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:14:04,640 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34393, datanodeUuid=1cda337e-92c5-4d2b-a450-460ae3b1f996, infoPort=41499, infoSecurePort=0, ipcPort=45640, storageInfo=lv=-57;cid=testClusterID;nsid=1548675985;c=1585804125723) 1 blocks.
2020-04-02 05:14:04,642 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775512_1018 on 127.0.0.1:34393 size 123 replicaState = FINALIZED
2020-04-02 05:14:04,643 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:14:04,643 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34393 is added to blk_-9223372036854775520_1018 (size=0)
2020-04-02 05:14:04,644 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775512_1018 is received from 127.0.0.1:34393
2020-04-02 05:14:04,644 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34393 receiving: 0, received: 1, deleted: 0
2020-04-02 05:14:04,644 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSDirWriteFileOp.java:completeFile(680)) - DIR* NameSystem.completeFile: /corrupted_3_0 for DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:14:04,644 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (FSNamesystem.java:closeFile(3947)) - closeFile: /corrupted_3_0 with 2 blocks is persisted to the file system
2020-04-02 05:14:04,644 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /corrupted_3_0 is closed by DFSClient_NONMAPREDUCE_-1496653099_1
2020-04-02 05:14:04,645 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(231)) - corruptBlocks on path /corrupted_3_0
2020-04-02 05:14:04,646 [IPC Server handler 0 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:04,646 [IPC Server handler 0 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:04,647 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018
2020-04-02 05:14:04,647 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,647 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,648 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,648 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,648 [Thread-1077] INFO  impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:corruptData(123)) - Corrupting block file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir1/blk_-9223372036854775520
2020-04-02 05:14:04,649 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,649 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,649 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,649 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,650 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
2020-04-02 05:14:04,650 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,650 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,650 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,651 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,651 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,651 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,651 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,652 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,652 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775516_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,652 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:corruptBlocks(262)) - Corrupting block file BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
2020-04-02 05:14:04,652 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,652 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,653 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,653 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,653 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,653 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,654 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,654 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,654 [Thread-1077] ERROR impl.FsDatasetImplTestUtils (FsDatasetImplTestUtils.java:getMaterializedReplica(230)) - Block file for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018 does not existed:
org.apache.hadoop.hdfs.server.datanode.ReplicaNotFoundException: Replica does not exist BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775518_1018
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.getReplicaInfo(FsDatasetImpl.java:811)
	at org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImplTestUtils.getMaterializedReplica(FsDatasetImplTestUtils.java:227)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodesHelper(MiniDFSCluster.java:2151)
	at org.apache.hadoop.hdfs.MiniDFSCluster.corruptBlockOnDataNodes(MiniDFSCluster.java:2172)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.corruptBlocks(ReadStripedFileWithDecodingHelper.java:263)
	at org.apache.hadoop.hdfs.ReadStripedFileWithDecodingHelper.testReadWithBlockCorrupted(ReadStripedFileWithDecodingHelper.java:220)
	at org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData.testReadCorruptedData(TestReadStripedFileWithDecodingCorruptData.java:85)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:14:04,654 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(137)) - verifyRead on path /corrupted_3_0
2020-04-02 05:14:04,659 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(139)) - verifyRead verifyLength on path /corrupted_3_0
2020-04-02 05:14:04,660 [IPC Server handler 2 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:04,660 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(141)) - verifyRead verifyPread on path /corrupted_3_0
2020-04-02 05:14:04,661 [IPC Server handler 5 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getErasureCodingPolicy	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:14:04,662 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:04,662 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:04,677 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:04,680 [IPC Server handler 7 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:04,680 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(88)) - BLOCK NameSystem.addToCorruptReplicasMap: blk_-9223372036854775520_1018 added as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:04,680 [IPC Server handler 7 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:04,680 [IPC Server handler 7 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:06,043 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:06,044 [IPC Server handler 8 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:06,045 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775520_1018 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:06,045 [IPC Server handler 8 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:06,045 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775520_1018 from priority queue 2
2020-04-02 05:14:06,045 [IPC Server handler 8 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:06,572 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:06,573 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:06,573 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:06,573 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:14:06,573 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:40001 to delete [blk_-9223372036854775708_1006]
2020-04-02 05:14:06,573 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:33115 to delete [blk_-9223372036854775707_1006]
2020-04-02 05:14:06,573 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34415 to delete [blk_-9223372036854775706_1006]
2020-04-02 05:14:07,498 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775707_1006 replica FinalizedReplica, blk_-9223372036854775707_1006, FINALIZED
  getNumBytes()     = 4194181
  getBytesOnDisk()  = 4194181
  getVisibleLength()= 4194181
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775707 for deletion
2020-04-02 05:14:07,499 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775708_1006 replica FinalizedReplica, blk_-9223372036854775708_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775708 for deletion
2020-04-02 05:14:07,501 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775708_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775708
2020-04-02 05:14:07,501 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775707_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775707
2020-04-02 05:14:07,547 [StripedRead-2] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:07,549 [IPC Server handler 5 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:07,549 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775520_1018 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:07,550 [IPC Server handler 5 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:07,550 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775520_1018 from priority queue 2
2020-04-02 05:14:07,550 [IPC Server handler 5 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:08,515 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775706_1006 replica FinalizedReplica, blk_-9223372036854775706_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775706 for deletion
2020-04-02 05:14:08,516 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775706_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775706
2020-04-02 05:14:09,442 [StripedRead-5] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:09,445 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:09,445 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775520_1018 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:09,445 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:09,445 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775520_1018 from priority queue 2
2020-04-02 05:14:09,445 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:09,573 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:09,573 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:09,574 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:09,574 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:14:09,574 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:39182 to delete [blk_-9223372036854775709_1006]
2020-04-02 05:14:09,574 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34710 to delete [blk_-9223372036854775705_1006]
2020-04-02 05:14:09,574 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37707 to delete [blk_-9223372036854775712_1006]
2020-04-02 05:14:10,500 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775709_1006 replica FinalizedReplica, blk_-9223372036854775709_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775709 for deletion
2020-04-02 05:14:10,501 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775709_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775709
2020-04-02 05:14:10,608 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775712_1006 replica FinalizedReplica, blk_-9223372036854775712_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775712 for deletion
2020-04-02 05:14:10,612 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775712_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775712
2020-04-02 05:14:11,230 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775705_1006 replica FinalizedReplica, blk_-9223372036854775705_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775705 for deletion
2020-04-02 05:14:11,235 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775705_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775705
2020-04-02 05:14:11,285 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:11,287 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:11,287 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775520_1018 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:11,287 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:11,288 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775520_1018 from priority queue 2
2020-04-02 05:14:11,288 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:12,574 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:12,575 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:12,575 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:12,575 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:14:12,575 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:37829 to delete [blk_-9223372036854775711_1006]
2020-04-02 05:14:12,575 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34393 to delete [blk_-9223372036854775710_1006]
2020-04-02 05:14:12,575 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34235 to delete [blk_-9223372036854775704_1006]
2020-04-02 05:14:13,125 [StripedRead-4] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:13,128 [IPC Server handler 3 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:13,129 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775520_1018 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:13,129 [IPC Server handler 3 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:13,129 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775520_1018 from priority queue 2
2020-04-02 05:14:13,129 [IPC Server handler 3 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:13,499 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775704_1006 replica FinalizedReplica, blk_-9223372036854775704_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775704 for deletion
2020-04-02 05:14:13,499 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775711_1006 replica FinalizedReplica, blk_-9223372036854775711_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775711 for deletion
2020-04-02 05:14:13,501 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775704_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775704
2020-04-02 05:14:13,501 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775711_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775711
2020-04-02 05:14:14,230 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775710_1006 replica FinalizedReplica, blk_-9223372036854775710_1006, FINALIZED
  getNumBytes()     = 4194304
  getBytesOnDisk()  = 4194304
  getVisibleLength()= 4194304
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775710 for deletion
2020-04-02 05:14:14,232 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1076427830-172.17.0.10-1585804125723 blk_-9223372036854775710_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723/current/finalized/subdir0/subdir0/blk_-9223372036854775710
2020-04-02 05:14:14,598 [StripedRead-3] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:14,602 [IPC Server handler 0 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:14,602 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775520_1018 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:14,602 [IPC Server handler 0 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:14,602 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775520_1018 from priority queue 2
2020-04-02 05:14:14,602 [IPC Server handler 0 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:15,575 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:15,576 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:15,576 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:15,576 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:14:16,073 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:16,076 [IPC Server handler 9 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:16,076 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775520_1018 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:16,076 [IPC Server handler 9 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:16,076 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775520_1018 from priority queue 2
2020-04-02 05:14:16,076 [IPC Server handler 9 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:17,668 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:17,670 [IPC Server handler 6 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:17,671 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775520_1018 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:17,671 [IPC Server handler 6 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:17,671 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775520_1018 from priority queue 2
2020-04-02 05:14:17,671 [IPC Server handler 6 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:17,672 [StripedRead-1] WARN  hdfs.DFSClient (StripeReader.java:readToBuffer(247)) - Found Checksum error for BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 from DatanodeInfoWithStorage[127.0.0.1:39182,DS-3c0d1081-362b-4414-9407-4b5365359f1f,DISK] at 0
2020-04-02 05:14:17,674 [IPC Server handler 2 on 42662] INFO  hdfs.StateChange (FSNamesystem.java:reportBadBlocks(5275)) - *DIR* reportBadBlocks for block: BP-1076427830-172.17.0.10-1585804125723:blk_-9223372036854775520_1018 on datanode: 127.0.0.1:39182
2020-04-02 05:14:17,674 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (CorruptReplicasMap.java:addToCorruptReplicasMap(93)) - BLOCK NameSystem.addToCorruptReplicasMap: duplicate requested for blk_-9223372036854775520_1018 to add as corrupt on 127.0.0.1:39182 by /127.0.0.1  because client machine reported it
2020-04-02 05:14:17,674 [IPC Server handler 2 on 42662] DEBUG hdfs.StateChange (LowRedundancyBlocks.java:update(453)) - LowRedundancyBlocks.update blk_-9223372036854775520_1018 curReplicas 3 curExpectedReplicas 4 oldReplicas 4 oldExpectedReplicas  4 curPri  2 oldPri  3
2020-04-02 05:14:17,674 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(387)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775520_1018 from priority queue 2
2020-04-02 05:14:17,675 [IPC Server handler 2 on 42662] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775520_1018 has only 3 replicas and needs 4 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:14:17,675 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(143)) - verifyRead verifyStatefulRead on path /corrupted_3_0
2020-04-02 05:14:17,676 [IPC Server handler 1 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:17,677 [IPC Server handler 1 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:18,577 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:18,578 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:18,578 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:18,578 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:14:21,431 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(146)) - verifyRead verifyStatefulRead2 on path /corrupted_3_0
2020-04-02 05:14:21,445 [IPC Server handler 8 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:21,446 [IPC Server handler 8 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:21,578 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:21,578 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:21,579 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:21,579 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:14:24,579 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:24,579 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:24,579 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:24,579 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:14:25,239 [Thread-1077] INFO  hdfs.ReadStripedFileWithDecodingHelper (ReadStripedFileWithDecodingHelper.java:verifyRead(149)) - verifyRead verifySeek on path /corrupted_3_0
2020-04-02 05:14:25,240 [IPC Server handler 7 on 42662] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775536_1017, blk_-9223372036854775520_1018]
2020-04-02 05:14:25,240 [IPC Server handler 7 on 42662] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/corrupted_3_0	dst=null	perm=null	proto=rpc
2020-04-02 05:14:27,579 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:27,580 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:27,580 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:27,580 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
[msx] test Finished org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[11]
[msx] writeFile testName = org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData#testReadCorruptedData[11]
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:14:30,011 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:14:30,012 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:14:30,012 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34250 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,013 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:30,014 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@71a9b4c7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:30,015 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-d92d5b9c-fc0d-474f-b471-8a630e4c3c2b) exiting.
2020-04-02 05:14:30,015 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-2102a24e-9df3-4b8c-800c-2ae0132bfcda) exiting.
2020-04-02 05:14:30,045 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2c5d601e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:30,051 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fe083b1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:30,051 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52350abb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:30,051 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d61eccf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:30,054 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34250
2020-04-02 05:14:30,059 [IPC Server listener on 34250] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34250
2020-04-02 05:14:30,063 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,064 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:30,068 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 16d40bdc-9ce5-4b23-8a8c-b7603581f803) service to localhost/127.0.0.1:42662
2020-04-02 05:14:30,069 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 16d40bdc-9ce5-4b23-8a8c-b7603581f803)
2020-04-02 05:14:30,069 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:14:30,083 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,090 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,094 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:30,094 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:30,096 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:30,096 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:30,105 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:30,106 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:14:30,106 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45640 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,106 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:30,106 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1095f122] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:30,108 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-1dc906f4-cfea-4a68-93a3-8ae61be727e0) exiting.
2020-04-02 05:14:30,108 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-abe0dd56-f350-4914-a7a9-ac579897ae0c) exiting.
2020-04-02 05:14:30,137 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@10b892d5{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:30,137 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3d3f761a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:30,138 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@410954b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:30,138 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7927bd9f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:30,139 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45640
2020-04-02 05:14:30,152 [IPC Server listener on 45640] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45640
2020-04-02 05:14:30,155 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,155 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:30,167 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 1cda337e-92c5-4d2b-a450-460ae3b1f996) service to localhost/127.0.0.1:42662
2020-04-02 05:14:30,167 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 1cda337e-92c5-4d2b-a450-460ae3b1f996)
2020-04-02 05:14:30,167 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:14:30,178 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,190 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,192 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:30,193 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:30,194 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:30,195 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:30,200 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:30,200 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:14:30,200 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40541 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,200 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:30,200 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7db534f2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:30,202 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-00abaa25-d804-45a0-be08-3b0d3cda7f91) exiting.
2020-04-02 05:14:30,202 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-13c6ccfb-8066-4557-9355-42241365fc0c) exiting.
2020-04-02 05:14:30,222 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@56db847e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:30,222 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@740abb5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:30,223 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6de54b40{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:30,223 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e70bd39{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:30,224 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40541
2020-04-02 05:14:30,230 [IPC Server listener on 40541] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40541
2020-04-02 05:14:30,230 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:30,231 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid a2660b52-86f3-40c5-94b0-9d1be84af49e) service to localhost/127.0.0.1:42662
2020-04-02 05:14:30,233 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,233 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid a2660b52-86f3-40c5-94b0-9d1be84af49e)
2020-04-02 05:14:30,233 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:14:30,244 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,254 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,258 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:30,258 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:30,260 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:30,261 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:30,267 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:30,267 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:14:30,268 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33614 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,268 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:30,268 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@22c86919] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:30,270 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5412fb3d-8ec7-47da-835d-e5d2232a2aef) exiting.
2020-04-02 05:14:30,270 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-4188b01d-cb51-4778-873f-1c29b449b256) exiting.
2020-04-02 05:14:30,296 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2f2bf0e2{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:30,297 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1eba372c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:30,297 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53499d85{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:30,298 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@759fad4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:30,299 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33614
2020-04-02 05:14:30,306 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,306 [IPC Server listener on 33614] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33614
2020-04-02 05:14:30,306 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:30,307 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 3d79862e-baf0-436b-a0a8-9028da1ac3a8) service to localhost/127.0.0.1:42662
2020-04-02 05:14:30,310 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 3d79862e-baf0-436b-a0a8-9028da1ac3a8)
2020-04-02 05:14:30,311 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:14:30,322 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,329 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,338 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:30,339 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:30,341 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:30,343 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:30,349 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:30,349 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:14:30,349 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42715 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,350 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:30,350 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@f19c9d2] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:30,352 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-3c0d1081-362b-4414-9407-4b5365359f1f) exiting.
2020-04-02 05:14:30,352 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-c773e217-cd00-44d0-be1e-2c9c992c3ecf) exiting.
2020-04-02 05:14:30,373 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3bffddff{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:30,374 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@66971f6b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:30,374 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@523424b5{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:30,374 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a1217f9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:30,375 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42715
2020-04-02 05:14:30,379 [IPC Server listener on 42715] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42715
2020-04-02 05:14:30,384 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,384 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:30,385 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 7ef49c98-3053-4533-a2a0-b3306760451d) service to localhost/127.0.0.1:42662
2020-04-02 05:14:30,385 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 7ef49c98-3053-4533-a2a0-b3306760451d)
2020-04-02 05:14:30,387 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:14:30,399 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,410 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,417 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:30,418 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:30,420 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:30,423 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:30,429 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:30,429 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:14:30,429 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40489 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,429 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:30,430 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@71104a4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:30,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-954d6dd5-dfbe-4b27-8034-9360f5005f7c) exiting.
2020-04-02 05:14:30,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-faac3c39-e24d-489d-89c7-3f7aafb6128e) exiting.
2020-04-02 05:14:30,455 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@c65a5ef{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:30,456 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b5176f2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:30,456 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37ebc9d8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:30,456 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32232e55{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:30,457 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40489
2020-04-02 05:14:30,461 [IPC Server listener on 40489] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40489
2020-04-02 05:14:30,465 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,466 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:30,466 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 0b1a99b1-285a-4d40-aaa2-947eb8093a05) service to localhost/127.0.0.1:42662
2020-04-02 05:14:30,466 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 0b1a99b1-285a-4d40-aaa2-947eb8093a05)
2020-04-02 05:14:30,466 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:14:30,477 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,485 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,506 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:30,506 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:30,508 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:30,509 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:30,515 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:30,515 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:14:30,515 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34155 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,515 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:30,515 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@37f21974] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:30,517 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-1944b14f-74e6-4e06-b100-58bcc8482d77) exiting.
2020-04-02 05:14:30,517 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-be6a1974-1295-47b9-8f93-ef3b934316bb) exiting.
2020-04-02 05:14:30,544 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@72ccd81a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:30,544 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d8792db{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:30,545 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10c8f62{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:30,545 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d9bec4d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:30,547 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34155
2020-04-02 05:14:30,560 [IPC Server listener on 34155] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34155
2020-04-02 05:14:30,560 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,564 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:30,564 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 56e1ca3a-367a-47af-9e27-26584ae1102e) service to localhost/127.0.0.1:42662
2020-04-02 05:14:30,564 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 56e1ca3a-367a-47af-9e27-26584ae1102e)
2020-04-02 05:14:30,564 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:14:30,574 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,583 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,587 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:30,587 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775680_1008 cannot be reconstructed from any node
2020-04-02 05:14:30,587 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:30,587 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775584_1014 cannot be reconstructed from any node
2020-04-02 05:14:30,608 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:30,608 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:30,608 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:scheduleReconstruction(1939)) - Block blk_-9223372036854775520_1018 cannot be reconstructed from any node
2020-04-02 05:14:30,611 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 3 pendingReconstruction = 0
2020-04-02 05:14:30,617 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:30,617 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:14:30,618 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42874 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,618 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:30,618 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5e8f9e2d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:30,621 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-28e2733b-dae3-4c87-8f5d-eaf7f71a8277) exiting.
2020-04-02 05:14:30,621 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-8edadad1-bdcd-4481-9522-bd34697c24fd) exiting.
2020-04-02 05:14:30,695 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@35fe2125{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:30,696 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@94f6bfb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:30,697 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@79e18e38{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:30,697 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60fa3495{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:30,699 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42874
2020-04-02 05:14:30,705 [IPC Server listener on 42874] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42874
2020-04-02 05:14:30,710 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,710 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:30,711 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 8008a631-dd3a-486b-bb6f-3e3169812d8f) service to localhost/127.0.0.1:42662
2020-04-02 05:14:30,711 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid 8008a631-dd3a-486b-bb6f-3e3169812d8f)
2020-04-02 05:14:30,711 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:14:30,723 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,738 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,738 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:30,739 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:30,746 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:30,746 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:30,757 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:30,757 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:14:30,757 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34460 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,757 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:14:30,757 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@549949be] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:14:30,763 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-2f3b72e1-12fc-47d7-a350-5539188d4e05) exiting.
2020-04-02 05:14:30,763 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-99be8a6c-9a79-4efb-bfda-3855f9256956) exiting.
2020-04-02 05:14:30,782 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@40cb698e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:14:30,782 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3382f8ae{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:30,783 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4044fb95{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:30,783 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@665df3c6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:30,784 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34460
2020-04-02 05:14:30,798 [IPC Server listener on 34460] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34460
2020-04-02 05:14:30,803 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:14:30,803 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,803 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid cdf1e358-9297-4c05-a11a-c18f14af501f) service to localhost/127.0.0.1:42662
2020-04-02 05:14:30,904 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1076427830-172.17.0.10-1585804125723 (Datanode Uuid cdf1e358-9297-4c05-a11a-c18f14af501f)
2020-04-02 05:14:30,904 [BP-1076427830-172.17.0.10-1585804125723 heartbeating to localhost/127.0.0.1:42662] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1076427830-172.17.0.10-1585804125723
2020-04-02 05:14:30,916 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,928 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1076427830-172.17.0.10-1585804125723] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:14:30,947 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:14:30,947 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:14:30,952 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:14:30,952 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:14:30,962 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:14:30,963 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:14:30,963 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 42662 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:14:30,963 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:14:30,964 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 87
2020-04-02 05:14:30,964 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6bb2d00b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:14:30,964 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@555cf22] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:14:30,964 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 88 Total time for transactions(ms): 48 Number of transactions batched in Syncs: 18 Number of syncs: 71 SyncTimes(ms): 7 9 
2020-04-02 05:14:30,966 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000088
2020-04-02 05:14:30,967 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000088
2020-04-02 05:14:30,968 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:14:30,968 [CacheReplicationMonitor(735212060)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:14:30,969 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42662
2020-04-02 05:14:30,974 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:14:30,974 [IPC Server listener on 42662] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42662
2020-04-02 05:14:30,979 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:14:30,979 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:14:30,985 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@7e5d9a50] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:14:31,040 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:14:31,040 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:14:31,041 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@797b0699{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:14:31,043 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4f704591{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:14:31,043 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f49f6af{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:14:31,043 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d322cad{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:14:31,045 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:14:31,069 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:14:31,070 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

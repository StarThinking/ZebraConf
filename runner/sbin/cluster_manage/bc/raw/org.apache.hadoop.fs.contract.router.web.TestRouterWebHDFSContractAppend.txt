[msx] before_class
2020-04-02 05:03:30,829 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-04-02 05:03:30,847 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(874)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-04-02 05:03:30,848 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(880)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-04-02 05:03:31,893 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:31,925 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:31,928 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:31,930 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:31,947 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:31,947 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:31,948 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:31,953 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:31,958 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:32,042 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:32,055 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:03:32,056 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:32,057 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:32,079 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:32,080 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:32
2020-04-02 05:03:32,083 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:32,083 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:32,086 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:03:32,086 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:32,116 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:32,125 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:32,126 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:32,130 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:32,131 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:32,135 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:32,135 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:32,136 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:32,136 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:32,136 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:32,137 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:32,137 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:32,178 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:03:32,202 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:32,202 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:32,203 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:03:32,204 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:32,211 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:32,212 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:32,212 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:32,213 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:32,221 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:32,224 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:32,242 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:32,243 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:32,244 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:03:32,244 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:32,259 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:32,260 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:32,260 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:32,267 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:32,267 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:32,270 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:32,274 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:32,275 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:03:32,275 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:32,329 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:32,354 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:03:32,366 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:03:32,372 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-04-02 05:03:32,382 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:32,385 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:32,538 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 388 bytes saved in 0 seconds .
2020-04-02 05:03:32,538 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 388 bytes saved in 0 seconds .
2020-04-02 05:03:32,558 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:32,647 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-04-02 05:03:32,673 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-04-02 05:03:32,680 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:33,341 [JUnit] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:03:33,418 [JUnit] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:03:33,574 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:03:33,574 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:03:33,580 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:33,583 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:33,583 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:03:33,630 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5a59ca5e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:33,647 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:33,674 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @4285ms
2020-04-02 05:03:33,794 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:33,812 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:33,826 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:33,828 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:33,828 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:33,829 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:33,874 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:33,875 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:33,885 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34174
2020-04-02 05:03:33,887 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:33,985 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b7fdc8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:33,990 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a57ae10{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:34,099 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@73d983ea{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:34,108 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@d771cc9{HTTP/1.1,[http/1.1]}{localhost:34174}
2020-04-02 05:03:34,109 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4721ms
2020-04-02 05:03:34,123 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:34,125 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:34,127 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:34,128 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:34,129 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:34,130 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:34,130 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:34,131 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:34,131 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:34,132 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:34,133 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:34,133 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:34,134 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:34,135 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:34
2020-04-02 05:03:34,135 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:34,138 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:34,146 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:34,148 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:34,165 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:34,166 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:34,167 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:34,167 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:34,168 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:34,168 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:34,169 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:34,170 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:34,173 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:34,179 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:34,179 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:34,180 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:34,181 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:34,181 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:34,202 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:34,203 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:34,205 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:34,205 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:34,205 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:34,207 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:34,207 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:34,208 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:34,208 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:34,208 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:34,209 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:34,209 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:34,213 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:34,213 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:34,217 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:34,218 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:34,218 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:34,218 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:34,218 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:34,219 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:34,219 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:34,227 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:34,232 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:34,233 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:34,238 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:34,239 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:34,290 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:34,298 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:34,299 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:03:34,305 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:34,310 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:34,311 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 89 msecs
2020-04-02 05:03:34,498 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:34,518 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:34,536 [Socket Reader #1 for port 39089] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39089
2020-04-02 05:03:34,878 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:35,022 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:35,038 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:35,039 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:35,039 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:35,114 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:35,123 [IPC Server listener on 39089] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39089: starting
2020-04-02 05:03:35,284 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:39089
2020-04-02 05:03:35,305 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:35,308 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:35,308 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:35,315 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 39089 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:35,320 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:35,321 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:35,321 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:35,322 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:35,322 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:03:35,342 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:35,345 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:35,354 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4504d271] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:35,366 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:35,369 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:35,370 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:35,371 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:35,371 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:35,391 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:35,392 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:35,393 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45171
2020-04-02 05:03:35,394 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:35,447 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53d1b9b3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:35,448 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@163d04ff{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:35,459 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4c4d27c8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:35,480 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6821ea29{HTTP/1.1,[http/1.1]}{localhost:45171}
2020-04-02 05:03:35,481 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6092ms
2020-04-02 05:03:35,486 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:35,487 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:35,487 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:35,487 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:35,488 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:35,488 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:35,488 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:35,489 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:35,489 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:35,491 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:35,503 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:35,503 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:35,504 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:35,504 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:35
2020-04-02 05:03:35,505 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:35,505 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:35,505 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:35,510 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:35,536 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:35,537 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:35,538 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:35,538 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:35,538 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:35,539 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:35,539 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:35,539 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:35,539 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:35,545 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:35,545 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:35,546 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:35,546 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:35,547 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:35,547 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:35,547 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:35,555 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:35,556 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:35,556 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:35,556 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:35,557 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:35,557 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:35,557 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:35,558 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:35,559 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:35,560 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:35,562 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:35,563 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:35,563 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:35,564 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:35,564 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:35,564 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:35,565 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:35,565 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:35,566 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:35,571 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:35,589 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:35,590 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:35,593 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:35,597 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:35,600 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:35,602 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:35,606 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-04-02 05:03:35,607 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:35,608 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:35,608 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 40 msecs
2020-04-02 05:03:35,609 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:35,610 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:35,611 [Socket Reader #1 for port 42512] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42512
2020-04-02 05:03:35,655 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:35,763 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:35,765 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:35,766 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:35,766 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:35,810 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:35,810 [IPC Server listener on 42512] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42512: starting
2020-04-02 05:03:35,812 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:42512
2020-04-02 05:03:35,821 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:35,826 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:35,826 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:35,827 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 42512 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
Formatting using clusterid: testClusterID
2020-04-02 05:03:35,839 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:35,840 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:35,840 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:35,840 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:35,840 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:35,841 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:35,841 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:35,841 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:35,841 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:35,842 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:35,842 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:35,842 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:35,843 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:35,843 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:35
2020-04-02 05:03:35,843 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:35,843 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:35,844 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:35,844 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:35,856 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:35,866 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:35,866 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:35,867 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:35,867 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:35,867 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:35,867 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:35,867 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:35,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:35,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:35,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:35,868 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:35,869 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:35,869 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:35,869 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:35,873 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:35,884 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:35,885 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:35,885 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:35,886 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:35,894 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:35,894 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:35,895 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:35,895 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:35,905 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:35,906 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:35,908 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:35,909 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:35,909 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:35,909 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:35,910 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:35,910 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:35,910 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:35,911 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:35,911 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:35,915 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:35,918 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-04-02 05:03:35,921 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-04-02 05:03:35,923 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-04-02 05:03:35,935 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:35,938 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:35,942 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 388 bytes saved in 0 seconds .
2020-04-02 05:03:35,954 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 388 bytes saved in 0 seconds .
2020-04-02 05:03:35,959 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:35,965 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-04-02 05:03:35,974 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-04-02 05:03:35,982 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:35,989 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:35,990 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:35,991 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:35,992 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:36,006 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:36,009 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:36,006 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@fd8294b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:36,015 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:36,018 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:36,019 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:36,019 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:36,019 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:36,021 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:36,022 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:36,022 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40248
2020-04-02 05:03:36,023 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:36,087 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75c9e76b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:36,089 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c3b6c6e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:36,100 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6b9ce1bf{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:36,101 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@61884cb1{HTTP/1.1,[http/1.1]}{localhost:40248}
2020-04-02 05:03:36,101 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6713ms
2020-04-02 05:03:36,102 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:36,103 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:36,103 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:36,103 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:36,103 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:36,103 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:36,103 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:36,104 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:36,104 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:36,104 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:36,104 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:36,105 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:36,105 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:36,105 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:36
2020-04-02 05:03:36,105 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:36,107 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:36,108 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:36,108 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:36,134 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:36,135 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:36,135 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:36,135 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:36,135 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:36,148 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:36,148 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:36,148 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:36,149 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:36,149 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:36,149 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:36,150 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:36,150 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:36,150 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:36,151 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:36,151 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:36,202 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:36,203 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:36,203 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:36,204 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:36,204 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:36,204 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:36,204 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:36,204 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:36,205 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:36,205 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:36,207 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:36,207 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:36,207 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:36,207 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:36,208 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:36,208 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:36,208 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:36,208 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:36,208 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:36,213 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:36,214 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:36,215 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:36,218 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:36,219 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:36,221 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:36,222 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:36,223 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-04-02 05:03:36,223 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:36,224 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:36,224 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 13 msecs
2020-04-02 05:03:36,225 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:36,231 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:36,233 [Socket Reader #1 for port 33531] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33531
2020-04-02 05:03:36,291 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:36,370 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:36,391 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:36,392 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:36,392 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:36,404 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:36,418 [IPC Server listener on 33531] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33531: starting
2020-04-02 05:03:36,422 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33531
2020-04-02 05:03:36,430 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:36,430 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:36,430 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:36,431 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33531 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:36,432 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:36,433 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:36,433 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:36,450 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:36,463 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:36,478 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:36,497 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@36546a22] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:36,500 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:36,503 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:36,506 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:36,507 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:36,507 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:36,508 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:36,510 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:36,510 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:36,511 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33405
2020-04-02 05:03:36,511 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:36,532 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@47605f2f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:36,533 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1dd0e7c4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:36,554 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@650eab8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:36,560 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30f5a68a{HTTP/1.1,[http/1.1]}{localhost:33405}
2020-04-02 05:03:36,561 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7173ms
2020-04-02 05:03:36,564 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:36,569 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:36,569 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:36,570 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:36,570 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:36,570 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:36,570 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:36,571 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:36,571 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:36,572 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:36,572 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:36,572 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:36,573 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:36,573 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:36
2020-04-02 05:03:36,573 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:36,573 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:36,574 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:36,574 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:36,589 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:36,597 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:36,598 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:36,599 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:36,599 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:36,599 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:36,599 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:36,599 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:36,600 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:36,600 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:36,600 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:36,601 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:36,601 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:36,602 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:36,602 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:36,602 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:36,609 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:36,609 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:36,609 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:36,609 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:36,610 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:36,610 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:36,610 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:36,610 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:36,611 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:36,611 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:36,613 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:36,613 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:36,613 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:36,613 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:36,614 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:36,614 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:36,614 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:36,614 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:36,615 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:36,618 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:36,619 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:36,620 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:36,622 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:36,622 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:36,624 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:36,625 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:36,625 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-04-02 05:03:36,625 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:36,625 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:36,625 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 10 msecs
2020-04-02 05:03:36,626 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:36,626 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:36,627 [Socket Reader #1 for port 34357] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34357
2020-04-02 05:03:36,633 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:36,677 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:36,918 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:36,918 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:36,919 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:36,968 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:37,012 [IPC Server listener on 34357] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34357: starting
2020-04-02 05:03:37,013 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:34357
2020-04-02 05:03:37,013 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:37,014 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:37,014 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:37,014 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 34357 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:37,031 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:37,076 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:37,100 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:37,126 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:37,127 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:37,136 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:37,139 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:37,142 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:37,143 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:37,147 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:37,153 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34609
2020-04-02 05:03:37,156 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:37,157 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:37,187 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:37,188 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:37,190 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:37,191 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:37,191 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:37,191 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:37,194 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39752
2020-04-02 05:03:37,194 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:37,219 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ef0d29e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:37,226 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51850751{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:37,264 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5860f3d7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:37,265 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1d7f7be7{HTTP/1.1,[http/1.1]}{localhost:39752}
2020-04-02 05:03:37,266 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7877ms
2020-04-02 05:03:38,332 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43507
2020-04-02 05:03:38,335 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:38,335 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:38,338 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@182f1e9a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:38,360 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:38,361 [Socket Reader #1 for port 42396] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42396
2020-04-02 05:03:38,379 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42396
2020-04-02 05:03:38,398 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:38,401 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:38,435 [Thread-153] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39089 starting to offer service
2020-04-02 05:03:38,443 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34357 starting to offer service
2020-04-02 05:03:38,436 [Thread-155] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33531 starting to offer service
2020-04-02 05:03:38,437 [Thread-154] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42512 starting to offer service
2020-04-02 05:03:38,472 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:38,502 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42396 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:38,504 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:38,506 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:38,506 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:38,508 [IPC Server listener on 42396] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42396: starting
2020-04-02 05:03:38,522 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:38,522 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:38,522 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:38,523 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:38,523 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:38,523 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:38,524 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:38,525 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40363
2020-04-02 05:03:38,525 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:38,525 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:38,540 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:38,550 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:38,560 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:38,561 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:38,561 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:38,576 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:38,579 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33710
2020-04-02 05:03:38,579 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:38,581 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@466cf502{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:38,596 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e185cd7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:38,624 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4b629f13{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:38,638 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70925b45{HTTP/1.1,[http/1.1]}{localhost:33710}
2020-04-02 05:03:38,639 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @9251ms
2020-04-02 05:03:38,790 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43482
2020-04-02 05:03:38,791 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:38,791 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:38,792 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:38,791 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@aa22f1c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:38,793 [Socket Reader #1 for port 33760] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33760
2020-04-02 05:03:38,796 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33760
2020-04-02 05:03:38,814 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:38,829 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:38,849 [Thread-180] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42512 starting to offer service
2020-04-02 05:03:38,855 [Thread-182] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34357 starting to offer service
2020-04-02 05:03:38,856 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:38,856 [IPC Server listener on 33760] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33760: starting
2020-04-02 05:03:38,851 [Thread-181] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33531 starting to offer service
2020-04-02 05:03:38,876 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33760 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:38,878 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:38,878 [Thread-179] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39089 starting to offer service
2020-04-02 05:03:38,880 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:38,881 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:38,909 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:38,910 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:38,910 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:38,911 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:38,911 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:38,911 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:38,912 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:38,912 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34410
2020-04-02 05:03:38,913 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:38,913 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:38,926 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:38,929 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:38,931 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:38,932 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:38,933 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:38,933 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:38,938 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33786
2020-04-02 05:03:38,938 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:38,940 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@226f885f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:38,942 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d61eccf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:38,983 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5aa0dbf4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:39,054 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@16afbd92{HTTP/1.1,[http/1.1]}{localhost:33786}
2020-04-02 05:03:39,054 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @9666ms
2020-04-02 05:03:39,223 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42733
2020-04-02 05:03:39,224 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:39,224 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:39,225 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:39,225 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7fe083b1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:39,228 [Socket Reader #1 for port 36661] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36661
2020-04-02 05:03:39,232 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36661
2020-04-02 05:03:39,252 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:39,258 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:39,266 [Thread-211] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39089 starting to offer service
2020-04-02 05:03:39,274 [Thread-213] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33531 starting to offer service
2020-04-02 05:03:39,287 [Thread-214] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34357 starting to offer service
2020-04-02 05:03:39,290 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:39,286 [Thread-212] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42512 starting to offer service
2020-04-02 05:03:39,291 [IPC Server listener on 36661] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36661: starting
2020-04-02 05:03:39,303 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36661 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:39,304 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:39,305 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:39,310 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:39,333 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:39,354 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:39,354 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:39,354 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:39,355 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:39,355 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:39,355 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:39,356 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35930
2020-04-02 05:03:39,356 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:39,356 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:39,411 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:39,413 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:39,424 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:39,424 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:39,425 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:39,425 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:39,426 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43972
2020-04-02 05:03:39,426 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:39,428 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d1f74b8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:39,429 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a0807b7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:39,479 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@72efb5c1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:39,479 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d511b5f{HTTP/1.1,[http/1.1]}{localhost:43972}
2020-04-02 05:03:39,480 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @10092ms
2020-04-02 05:03:39,598 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45627
2020-04-02 05:03:39,610 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:39,610 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:39,610 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:39,617 [Socket Reader #1 for port 44396] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44396
2020-04-02 05:03:39,630 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40f33492] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:39,641 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44396
2020-04-02 05:03:39,646 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:39,647 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:39,650 [Thread-237] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39089 starting to offer service
2020-04-02 05:03:39,650 [Thread-238] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42512 starting to offer service
2020-04-02 05:03:39,651 [Thread-239] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33531 starting to offer service
2020-04-02 05:03:39,651 [Thread-240] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34357 starting to offer service
2020-04-02 05:03:39,670 [IPC Server listener on 44396] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44396: starting
2020-04-02 05:03:39,672 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44396 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:39,686 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:39,900 [Thread-156] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:39,901 [Thread-212] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:39,930 [Thread-180] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:39,932 [Thread-238] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:39,933 [Thread-180] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:39,934 [Thread-180] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 235278558. Formatting...
2020-04-02 05:03:39,944 [Thread-156] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:39,944 [Thread-156] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 7255333. Formatting...
2020-04-02 05:03:39,945 [Thread-212] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:39,945 [Thread-212] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 235278558. Formatting...
2020-04-02 05:03:39,946 [Thread-156] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3b50b712-dbb6-45da-8e43-f78711a80c9a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-04-02 05:03:39,947 [Thread-212] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-04-02 05:03:39,948 [Thread-238] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:39,948 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 235278558. Formatting...
2020-04-02 05:03:39,949 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1fefa900-398c-47d6-843d-2aae5a994ad0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-04-02 05:03:39,949 [Thread-180] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-04-02 05:03:39,953 [Thread-212] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:39,954 [Thread-212] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 235278558. Formatting...
2020-04-02 05:03:39,954 [Thread-212] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5d628413-2464-428d-9976-96d4a321563f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-04-02 05:03:39,956 [Thread-238] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:39,956 [Thread-238] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 235278558. Formatting...
2020-04-02 05:03:39,956 [Thread-238] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-20108e8b-15ae-43dc-9b61-592b455301ea for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-04-02 05:03:39,957 [Thread-156] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:39,957 [Thread-156] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 7255333. Formatting...
2020-04-02 05:03:39,957 [Thread-156] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-04-02 05:03:39,970 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:39,971 [Thread-212] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:39,972 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-315731430-172.17.0.4-1585803812311 is not formatted. Formatting ...
2020-04-02 05:03:39,972 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-315731430-172.17.0.4-1585803812311 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-315731430-172.17.0.4-1585803812311/current
2020-04-02 05:03:39,974 [Thread-180] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 6475@5b1ca12d458b
2020-04-02 05:03:39,975 [Thread-180] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 235278558. Formatting...
2020-04-02 05:03:39,975 [Thread-180] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8240a105-45a0-40f6-a0fc-97bf67e991fa for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-04-02 05:03:39,990 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:39,992 [Thread-212] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:39,992 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-315731430-172.17.0.4-1585803812311 is not formatted. Formatting ...
2020-04-02 05:03:39,992 [Thread-212] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-315731430-172.17.0.4-1585803812311 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-315731430-172.17.0.4-1585803812311/current
2020-04-02 05:03:39,992 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:39,993 [Thread-180] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:39,993 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-315731430-172.17.0.4-1585803812311 is not formatted. Formatting ...
2020-04-02 05:03:39,994 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-315731430-172.17.0.4-1585803812311 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-315731430-172.17.0.4-1585803812311/current
2020-04-02 05:03:40,005 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,005 [Thread-214] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:40,006 [Thread-214] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-04-02 05:03:40,006 [Thread-214] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-04-02 05:03:40,015 [Thread-212] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=235278558;bpid=BP-315731430-172.17.0.4-1585803812311;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=235278558;c=1585803812311;bpid=BP-315731430-172.17.0.4-1585803812311;dnuuid=null
2020-04-02 05:03:40,015 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,015 [Thread-156] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,015 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1747966108-172.17.0.4-1585803815914 is not formatted. Formatting ...
2020-04-02 05:03:40,015 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1747966108-172.17.0.4-1585803815914 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1747966108-172.17.0.4-1585803815914/current
2020-04-02 05:03:40,018 [Thread-238] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,018 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-315731430-172.17.0.4-1585803812311 is not formatted. Formatting ...
2020-04-02 05:03:40,019 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-315731430-172.17.0.4-1585803812311 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-315731430-172.17.0.4-1585803812311/current
2020-04-02 05:03:40,027 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,028 [Thread-180] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,028 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-315731430-172.17.0.4-1585803812311 is not formatted. Formatting ...
2020-04-02 05:03:40,029 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-315731430-172.17.0.4-1585803812311 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-315731430-172.17.0.4-1585803812311/current
2020-04-02 05:03:40,029 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,054 [Thread-214] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,054 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1747966108-172.17.0.4-1585803815914 is not formatted. Formatting ...
2020-04-02 05:03:40,054 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1747966108-172.17.0.4-1585803815914 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1747966108-172.17.0.4-1585803815914/current
2020-04-02 05:03:40,046 [Thread-182] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:40,056 [Thread-182] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-04-02 05:03:40,056 [Thread-182] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-04-02 05:03:40,033 [Thread-180] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=235278558;bpid=BP-315731430-172.17.0.4-1585803812311;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=235278558;c=1585803812311;bpid=BP-315731430-172.17.0.4-1585803812311;dnuuid=null
2020-04-02 05:03:40,080 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,081 [Thread-238] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,081 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-315731430-172.17.0.4-1585803812311 is not formatted. Formatting ...
2020-04-02 05:03:40,081 [Thread-238] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-315731430-172.17.0.4-1585803812311 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-315731430-172.17.0.4-1585803812311/current
2020-04-02 05:03:40,081 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,086 [Thread-182] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,086 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1747966108-172.17.0.4-1585803815914 is not formatted. Formatting ...
2020-04-02 05:03:40,086 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1747966108-172.17.0.4-1585803815914 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1747966108-172.17.0.4-1585803815914/current
2020-04-02 05:03:40,096 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,097 [Thread-214] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,097 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1747966108-172.17.0.4-1585803815914 is not formatted. Formatting ...
2020-04-02 05:03:40,097 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1747966108-172.17.0.4-1585803815914 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1747966108-172.17.0.4-1585803815914/current
2020-04-02 05:03:40,099 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,100 [Thread-156] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,100 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1747966108-172.17.0.4-1585803815914 is not formatted. Formatting ...
2020-04-02 05:03:40,100 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1747966108-172.17.0.4-1585803815914 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1747966108-172.17.0.4-1585803815914/current
2020-04-02 05:03:40,101 [Thread-214] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=7255333;bpid=BP-1747966108-172.17.0.4-1585803815914;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=7255333;c=1585803815915;bpid=BP-1747966108-172.17.0.4-1585803815914;dnuuid=null
2020-04-02 05:03:40,102 [Thread-156] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=7255333;bpid=BP-1747966108-172.17.0.4-1585803815914;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=7255333;c=1585803815915;bpid=BP-1747966108-172.17.0.4-1585803815914;dnuuid=null
2020-04-02 05:03:40,125 [Thread-239] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:40,126 [Thread-239] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-04-02 05:03:40,133 [Thread-239] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-04-02 05:03:40,108 [Thread-154] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:40,143 [Thread-154] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-04-02 05:03:40,143 [Thread-154] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-04-02 05:03:40,106 [Thread-238] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=235278558;bpid=BP-315731430-172.17.0.4-1585803812311;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=235278558;c=1585803812311;bpid=BP-315731430-172.17.0.4-1585803812311;dnuuid=null
2020-04-02 05:03:40,133 [Thread-214] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:40,145 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,165 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,170 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,174 [Thread-239] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,174 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1747966108-172.17.0.4-1585803815914 is not formatted. Formatting ...
2020-04-02 05:03:40,174 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1747966108-172.17.0.4-1585803815914 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1747966108-172.17.0.4-1585803815914/current
2020-04-02 05:03:40,178 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,178 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-315731430-172.17.0.4-1585803812311 is not formatted. Formatting ...
2020-04-02 05:03:40,178 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-315731430-172.17.0.4-1585803812311 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-315731430-172.17.0.4-1585803812311/current
2020-04-02 05:03:40,194 [Thread-182] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,194 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1747966108-172.17.0.4-1585803815914 is not formatted. Formatting ...
2020-04-02 05:03:40,194 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1747966108-172.17.0.4-1585803815914 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1747966108-172.17.0.4-1585803815914/current
2020-04-02 05:03:40,203 [Thread-182] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=7255333;bpid=BP-1747966108-172.17.0.4-1585803815914;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=7255333;c=1585803815915;bpid=BP-1747966108-172.17.0.4-1585803815914;dnuuid=null
2020-04-02 05:03:40,216 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,217 [Thread-182] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:40,217 [Thread-239] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,222 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1747966108-172.17.0.4-1585803815914 is not formatted. Formatting ...
2020-04-02 05:03:40,222 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1747966108-172.17.0.4-1585803815914 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1747966108-172.17.0.4-1585803815914/current
2020-04-02 05:03:40,217 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,225 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,225 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-315731430-172.17.0.4-1585803812311 is not formatted. Formatting ...
2020-04-02 05:03:40,225 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-315731430-172.17.0.4-1585803812311 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-315731430-172.17.0.4-1585803812311/current
2020-04-02 05:03:40,227 [Thread-239] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=7255333;bpid=BP-1747966108-172.17.0.4-1585803815914;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=7255333;c=1585803815915;bpid=BP-1747966108-172.17.0.4-1585803815914;dnuuid=null
2020-04-02 05:03:40,231 [Thread-154] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=235278558;bpid=BP-315731430-172.17.0.4-1585803812311;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=235278558;c=1585803812311;bpid=BP-315731430-172.17.0.4-1585803812311;dnuuid=null
2020-04-02 05:03:40,232 [Thread-239] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:40,235 [Thread-156] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:40,442 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a
2020-04-02 05:03:40,442 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:03:40,444 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5d628413-2464-428d-9976-96d4a321563f
2020-04-02 05:03:40,444 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:03:40,485 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6
2020-04-02 05:03:40,486 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:03:40,449 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3b50b712-dbb6-45da-8e43-f78711a80c9a
2020-04-02 05:03:40,487 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:03:40,485 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1fefa900-398c-47d6-843d-2aae5a994ad0
2020-04-02 05:03:40,488 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8240a105-45a0-40f6-a0fc-97bf67e991fa
2020-04-02 05:03:40,488 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:03:40,489 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913
2020-04-02 05:03:40,566 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:03:40,567 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:40,540 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:40,489 [Thread-239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:03:40,566 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:40,587 [Thread-154] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:40,599 [Thread-214] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:40,599 [Thread-212] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,602 [Thread-182] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:40,602 [Thread-180] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,587 [Thread-156] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:40,610 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:40,611 [Thread-156] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:40,613 [Thread-156] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:40,613 [Thread-156] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:40,654 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-20108e8b-15ae-43dc-9b61-592b455301ea
2020-04-02 05:03:40,698 [Thread-239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:03:40,698 [Thread-239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:40,681 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:40,675 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:40,675 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:40,675 [Thread-182] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:40,701 [Thread-182] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:40,701 [Thread-182] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:40,649 [Thread-214] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:40,727 [Thread-214] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:40,727 [Thread-214] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:40,723 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,731 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,736 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:40,736 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:40,736 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,737 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:40,737 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:40,741 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:40,747 [Thread-239] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:40,747 [Thread-238] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:40,750 [Thread-239] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:40,750 [Thread-239] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:40,774 [Thread-239] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:40,794 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:40,796 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:40,834 [Thread-239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:41,081 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-315731430-172.17.0.4-1585803812311 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 380ms
2020-04-02 05:03:41,089 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-315731430-172.17.0.4-1585803812311 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 352ms
2020-04-02 05:03:41,107 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-315731430-172.17.0.4-1585803812311 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 496ms
2020-04-02 05:03:41,110 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-315731430-172.17.0.4-1585803812311: 511ms
2020-04-02 05:03:41,113 [Thread-260] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-315731430-172.17.0.4-1585803812311 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 412ms
2020-04-02 05:03:41,115 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-315731430-172.17.0.4-1585803812311 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 319ms
2020-04-02 05:03:41,120 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:41,120 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:41,121 [Thread-277] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-315731430-172.17.0.4-1585803812311/current/replicas doesn't exist 
2020-04-02 05:03:41,146 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-315731430-172.17.0.4-1585803812311 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 352ms
2020-04-02 05:03:41,121 [Thread-275] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-315731430-172.17.0.4-1585803812311/current/replicas doesn't exist 
2020-04-02 05:03:41,150 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-315731430-172.17.0.4-1585803812311 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 412ms
2020-04-02 05:03:41,151 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-315731430-172.17.0.4-1585803812311: 414ms
2020-04-02 05:03:41,151 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-315731430-172.17.0.4-1585803812311: 404ms
2020-04-02 05:03:41,167 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:41,168 [Thread-278] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-315731430-172.17.0.4-1585803812311/current/replicas doesn't exist 
2020-04-02 05:03:41,172 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:41,174 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:41,175 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-315731430-172.17.0.4-1585803812311 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 476ms
2020-04-02 05:03:41,178 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:41,179 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:41,180 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:41,180 [Thread-279] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-315731430-172.17.0.4-1585803812311/current/replicas doesn't exist 
2020-04-02 05:03:41,182 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-315731430-172.17.0.4-1585803812311: 579ms
2020-04-02 05:03:41,219 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:41,219 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:41,262 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:41,263 [Thread-280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-315731430-172.17.0.4-1585803812311/current/replicas doesn't exist 
2020-04-02 05:03:41,266 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:41,266 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-315731430-172.17.0.4-1585803812311/current/replicas doesn't exist 
2020-04-02 05:03:41,268 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 147ms
2020-04-02 05:03:41,269 [Thread-275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 148ms
2020-04-02 05:03:41,274 [Thread-212] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-315731430-172.17.0.4-1585803812311: 161ms
2020-04-02 05:03:41,281 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 19ms
2020-04-02 05:03:41,298 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:41,300 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:41,304 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:41,305 [Thread-286] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-315731430-172.17.0.4-1585803812311/current/replicas doesn't exist 
2020-04-02 05:03:41,319 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 139ms
2020-04-02 05:03:41,320 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 16ms
2020-04-02 05:03:41,321 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 152ms
2020-04-02 05:03:41,362 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:41,362 [Thread-297] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-315731430-172.17.0.4-1585803812311/current/replicas doesn't exist 
2020-04-02 05:03:41,391 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 125ms
2020-04-02 05:03:41,391 [Thread-238] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-315731430-172.17.0.4-1585803812311: 239ms
2020-04-02 05:03:41,393 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-315731430-172.17.0.4-1585803812311: 243ms
2020-04-02 05:03:41,421 [Thread-297] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 60ms
2020-04-02 05:03:41,422 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:41,422 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-315731430-172.17.0.4-1585803812311: 240ms
2020-04-02 05:03:41,422 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:41,441 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a): finished scanning block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:41,422 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:41,442 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-20108e8b-15ae-43dc-9b61-592b455301ea): finished scanning block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:41,422 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:41,457 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-1fefa900-398c-47d6-843d-2aae5a994ad0): finished scanning block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:41,433 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:41,430 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:41,447 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1747966108-172.17.0.4-1585803815914 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 269ms
2020-04-02 05:03:41,458 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-3b50b712-dbb6-45da-8e43-f78711a80c9a): finished scanning block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:41,459 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913): finished scanning block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:41,460 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1747966108-172.17.0.4-1585803815914 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 286ms
2020-04-02 05:03:41,462 [Thread-154] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:04 AM with interval of 21600000ms
2020-04-02 05:03:41,447 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:41,446 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-315731430-172.17.0.4-1585803812311 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:41,466 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8240a105-45a0-40f6-a0fc-97bf67e991fa): finished scanning block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:41,466 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6): finished scanning block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:41,466 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-5d628413-2464-428d-9976-96d4a321563f): finished scanning block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:03:41,462 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1747966108-172.17.0.4-1585803815914 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 244ms
2020-04-02 05:03:41,459 [Thread-276] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1747966108-172.17.0.4-1585803815914 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 286ms
2020-04-02 05:03:41,465 [Thread-180] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:38 AM with interval of 21600000ms
2020-04-02 05:03:41,463 [Thread-238] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:24 AM with interval of 21600000ms
2020-04-02 05:03:41,463 [Thread-212] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:45 AM with interval of 21600000ms
2020-04-02 05:03:41,506 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1747966108-172.17.0.4-1585803815914: 393ms
2020-04-02 05:03:41,586 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1747966108-172.17.0.4-1585803815914 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 408ms
2020-04-02 05:03:41,603 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:42512 beginning handshake with NN
2020-04-02 05:03:41,605 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:39089 beginning handshake with NN
2020-04-02 05:03:41,606 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:39089 beginning handshake with NN
2020-04-02 05:03:41,606 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:42512 beginning handshake with NN
2020-04-02 05:03:41,607 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:39089 beginning handshake with NN
2020-04-02 05:03:41,607 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:42512 beginning handshake with NN
2020-04-02 05:03:41,607 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:39089 beginning handshake with NN
2020-04-02 05:03:41,606 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:42512 beginning handshake with NN
2020-04-02 05:03:41,610 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1747966108-172.17.0.4-1585803815914 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 383ms
2020-04-02 05:03:41,613 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1747966108-172.17.0.4-1585803815914: 462ms
2020-04-02 05:03:41,614 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1747966108-172.17.0.4-1585803815914 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 316ms
2020-04-02 05:03:41,615 [Thread-295] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1747966108-172.17.0.4-1585803815914 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 315ms
2020-04-02 05:03:41,614 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:41,618 [Thread-313] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1747966108-172.17.0.4-1585803815914/current/replicas doesn't exist 
2020-04-02 05:03:41,618 [Thread-313] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:03:41,632 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:41,632 [Thread-314] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1747966108-172.17.0.4-1585803815914/current/replicas doesn't exist 
2020-04-02 05:03:41,633 [Thread-314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 1ms
2020-04-02 05:03:41,637 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1747966108-172.17.0.4-1585803815914: 486ms
2020-04-02 05:03:41,638 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:41,639 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1747966108-172.17.0.4-1585803815914/current/replicas doesn't exist 
2020-04-02 05:03:41,657 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1747966108-172.17.0.4-1585803815914: 471ms
2020-04-02 05:03:41,661 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914: 112ms
2020-04-02 05:03:41,675 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:34357 beginning handshake with NN
2020-04-02 05:03:41,674 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:41,676 [Thread-320] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1747966108-172.17.0.4-1585803815914/current/replicas doesn't exist 
2020-04-02 05:03:41,676 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:41,676 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1747966108-172.17.0.4-1585803815914/current/replicas doesn't exist 
2020-04-02 05:03:41,676 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:33531 beginning handshake with NN
2020-04-02 05:03:41,682 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 43ms
2020-04-02 05:03:41,694 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 18ms
2020-04-02 05:03:41,697 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 22ms
2020-04-02 05:03:41,698 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914: 41ms
2020-04-02 05:03:41,698 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:34357 beginning handshake with NN
2020-04-02 05:03:41,745 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:41,745 [Thread-315] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1747966108-172.17.0.4-1585803815914/current/replicas doesn't exist 
2020-04-02 05:03:41,746 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:41,746 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1747966108-172.17.0.4-1585803815914/current/replicas doesn't exist 
2020-04-02 05:03:41,746 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:03:41,747 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 2ms
2020-04-02 05:03:41,748 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:41,749 [Thread-321] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1747966108-172.17.0.4-1585803815914/current/replicas doesn't exist 
2020-04-02 05:03:41,749 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 0ms
2020-04-02 05:03:41,749 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914: 112ms
2020-04-02 05:03:41,778 [IPC Server handler 9 on 34357] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915) storage fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:41,779 [IPC Server handler 3 on 33531] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915) storage fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:41,763 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:41,782 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a): finished scanning block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:41,783 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a): no suitable block pools found to scan.  Waiting 1814399637 ms.
2020-04-02 05:03:41,762 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:33531 beginning handshake with NN
2020-04-02 05:03:41,761 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-1fefa900-398c-47d6-843d-2aae5a994ad0): no suitable block pools found to scan.  Waiting 1814399661 ms.
2020-04-02 05:03:41,761 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:41,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-5d628413-2464-428d-9976-96d4a321563f): finished scanning block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:41,785 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-5d628413-2464-428d-9976-96d4a321563f): no suitable block pools found to scan.  Waiting 1814399635 ms.
2020-04-02 05:03:41,761 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:41,785 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6): finished scanning block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:41,786 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6): no suitable block pools found to scan.  Waiting 1814399660 ms.
2020-04-02 05:03:41,760 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:41,786 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8240a105-45a0-40f6-a0fc-97bf67e991fa): finished scanning block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:41,786 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8240a105-45a0-40f6-a0fc-97bf67e991fa): no suitable block pools found to scan.  Waiting 1814399660 ms.
2020-04-02 05:03:41,760 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913): no suitable block pools found to scan.  Waiting 1814399670 ms.
2020-04-02 05:03:41,760 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-20108e8b-15ae-43dc-9b61-592b455301ea): no suitable block pools found to scan.  Waiting 1814399662 ms.
2020-04-02 05:03:41,760 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-3b50b712-dbb6-45da-8e43-f78711a80c9a): no suitable block pools found to scan.  Waiting 1814399671 ms.
2020-04-02 05:03:41,759 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1747966108-172.17.0.4-1585803815914: 146ms
2020-04-02 05:03:41,790 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:41,791 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-20108e8b-15ae-43dc-9b61-592b455301ea): finished scanning block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:41,791 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-20108e8b-15ae-43dc-9b61-592b455301ea): no suitable block pools found to scan.  Waiting 1814399631 ms.
2020-04-02 05:03:41,759 [IPC Server handler 1 on 39089] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311) storage c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:41,755 [IPC Server handler 0 on 42512] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311) storage fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:41,790 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:33531 beginning handshake with NN
2020-04-02 05:03:41,790 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:34357 beginning handshake with NN
2020-04-02 05:03:41,792 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:41,794 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-1fefa900-398c-47d6-843d-2aae5a994ad0): finished scanning block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:41,795 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-1fefa900-398c-47d6-843d-2aae5a994ad0): no suitable block pools found to scan.  Waiting 1814399627 ms.
2020-04-02 05:03:41,798 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:34357 beginning handshake with NN
2020-04-02 05:03:41,798 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:41,799 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-3b50b712-dbb6-45da-8e43-f78711a80c9a): finished scanning block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:41,798 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1747966108-172.17.0.4-1585803815914 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:41,801 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913): finished scanning block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:03:41,801 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913): no suitable block pools found to scan.  Waiting 1814399629 ms.
2020-04-02 05:03:41,800 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:33531 beginning handshake with NN
2020-04-02 05:03:41,802 [IPC Server handler 9 on 34357] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34410
2020-04-02 05:03:41,803 [IPC Server handler 9 on 34357] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15 (127.0.0.1:34410).
2020-04-02 05:03:41,804 [IPC Server handler 3 on 33531] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34410
2020-04-02 05:03:41,804 [IPC Server handler 3 on 33531] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15 (127.0.0.1:34410).
2020-04-02 05:03:41,813 [IPC Server handler 1 on 39089] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40363
2020-04-02 05:03:41,813 [IPC Server handler 1 on 39089] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c682ebfe-e964-4eb8-9760-1bd1d1d170b0 (127.0.0.1:40363).
2020-04-02 05:03:41,813 [IPC Server handler 0 on 42512] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34410
2020-04-02 05:03:41,814 [IPC Server handler 0 on 42512] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15 (127.0.0.1:34410).
2020-04-02 05:03:41,814 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-3b50b712-dbb6-45da-8e43-f78711a80c9a): no suitable block pools found to scan.  Waiting 1814399616 ms.
2020-04-02 05:03:41,844 [IPC Server handler 6 on 39089] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311) storage 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:41,845 [IPC Server handler 6 on 39089] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35930
2020-04-02 05:03:41,850 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:39089 successfully registered with NN
2020-04-02 05:03:41,851 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:42512 successfully registered with NN
2020-04-02 05:03:41,851 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39089 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,851 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42512 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,854 [IPC Server handler 8 on 42512] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311) storage ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:41,854 [IPC Server handler 8 on 42512] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34609
2020-04-02 05:03:41,887 [IPC Server handler 6 on 39089] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7caf239b-3ea0-49b6-b1d0-2b70276405ad (127.0.0.1:35930).
2020-04-02 05:03:41,890 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:34357 successfully registered with NN
2020-04-02 05:03:41,890 [IPC Server handler 8 on 42512] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ee2c4eda-af56-4a87-9fba-333dd3d7e97b (127.0.0.1:34609).
2020-04-02 05:03:41,891 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:42512 successfully registered with NN
2020-04-02 05:03:41,892 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42512 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,890 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34357 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,890 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:39089 successfully registered with NN
2020-04-02 05:03:41,892 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39089 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,896 [IPC Server handler 1 on 42512] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311) storage 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:41,897 [IPC Server handler 1 on 42512] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35930
2020-04-02 05:03:41,897 [IPC Server handler 1 on 42512] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7caf239b-3ea0-49b6-b1d0-2b70276405ad (127.0.0.1:35930).
2020-04-02 05:03:41,898 [IPC Server handler 5 on 42512] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311) storage c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:41,898 [IPC Server handler 0 on 39089] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311) storage fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:41,899 [IPC Server handler 0 on 39089] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34410
2020-04-02 05:03:41,899 [IPC Server handler 0 on 39089] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15 (127.0.0.1:34410).
2020-04-02 05:03:41,900 [IPC Server handler 5 on 42512] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40363
2020-04-02 05:03:41,900 [IPC Server handler 5 on 42512] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c682ebfe-e964-4eb8-9760-1bd1d1d170b0 (127.0.0.1:40363).
2020-04-02 05:03:41,901 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:39089 successfully registered with NN
2020-04-02 05:03:41,901 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39089 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,902 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:42512 successfully registered with NN
2020-04-02 05:03:41,902 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42512 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,901 [IPC Server handler 2 on 39089] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311) storage ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:41,914 [IPC Server handler 2 on 39089] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34609
2020-04-02 05:03:41,914 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:42512 successfully registered with NN
2020-04-02 05:03:41,927 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42512 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,934 [IPC Server handler 7 on 34357] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915) storage c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:41,934 [IPC Server handler 7 on 34357] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40363
2020-04-02 05:03:41,944 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:33531 successfully registered with NN
2020-04-02 05:03:41,944 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33531 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,950 [IPC Server handler 6 on 33531] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915) storage c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:41,950 [IPC Server handler 7 on 34357] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c682ebfe-e964-4eb8-9760-1bd1d1d170b0 (127.0.0.1:40363).
2020-04-02 05:03:41,958 [IPC Server handler 6 on 34357] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915) storage 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:41,960 [IPC Server handler 6 on 33531] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40363
2020-04-02 05:03:41,962 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:34357 successfully registered with NN
2020-04-02 05:03:41,962 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34357 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,976 [IPC Server handler 6 on 33531] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN c682ebfe-e964-4eb8-9760-1bd1d1d170b0 (127.0.0.1:40363).
2020-04-02 05:03:41,977 [IPC Server handler 4 on 42512] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3b50b712-dbb6-45da-8e43-f78711a80c9a for DN 127.0.0.1:34609
2020-04-02 05:03:41,978 [IPC Server handler 4 on 42512] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 for DN 127.0.0.1:34609
2020-04-02 05:03:41,980 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:33531 successfully registered with NN
2020-04-02 05:03:41,999 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33531 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,977 [IPC Server handler 5 on 33531] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915) storage ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,001 [IPC Server handler 5 on 33531] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34609
2020-04-02 05:03:42,001 [IPC Server handler 5 on 33531] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ee2c4eda-af56-4a87-9fba-333dd3d7e97b (127.0.0.1:34609).
2020-04-02 05:03:42,002 [IPC Server handler 2 on 33531] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915) storage 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:42,002 [IPC Server handler 2 on 33531] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35930
2020-04-02 05:03:42,002 [IPC Server handler 2 on 33531] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7caf239b-3ea0-49b6-b1d0-2b70276405ad (127.0.0.1:35930).
2020-04-02 05:03:42,003 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:33531 successfully registered with NN
2020-04-02 05:03:42,003 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33531 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:42,004 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:33531 successfully registered with NN
2020-04-02 05:03:42,004 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33531 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:41,998 [IPC Server handler 2 on 39089] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ee2c4eda-af56-4a87-9fba-333dd3d7e97b (127.0.0.1:34609).
2020-04-02 05:03:42,009 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:39089 successfully registered with NN
2020-04-02 05:03:42,010 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39089 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:42,038 [IPC Server handler 6 on 34357] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35930
2020-04-02 05:03:42,038 [IPC Server handler 6 on 34357] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7caf239b-3ea0-49b6-b1d0-2b70276405ad (127.0.0.1:35930).
2020-04-02 05:03:42,039 [IPC Server handler 0 on 34357] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915) storage ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,039 [IPC Server handler 0 on 34357] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34609
2020-04-02 05:03:42,039 [IPC Server handler 0 on 34357] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ee2c4eda-af56-4a87-9fba-333dd3d7e97b (127.0.0.1:34609).
2020-04-02 05:03:42,042 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:34357 successfully registered with NN
2020-04-02 05:03:42,042 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34357 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:42,043 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:34357 successfully registered with NN
2020-04-02 05:03:42,043 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34357 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:42,044 [IPC Server handler 8 on 33531] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a for DN 127.0.0.1:34410
2020-04-02 05:03:42,044 [IPC Server handler 8 on 33531] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5d628413-2464-428d-9976-96d4a321563f for DN 127.0.0.1:34410
2020-04-02 05:03:42,010 [IPC Server handler 9 on 42512] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 for DN 127.0.0.1:40363
2020-04-02 05:03:42,093 [IPC Server handler 8 on 34357] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 for DN 127.0.0.1:40363
2020-04-02 05:03:42,093 [IPC Server handler 8 on 34357] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8240a105-45a0-40f6-a0fc-97bf67e991fa for DN 127.0.0.1:40363
2020-04-02 05:03:42,095 [IPC Server handler 8 on 39089] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 for DN 127.0.0.1:40363
2020-04-02 05:03:42,095 [IPC Server handler 8 on 39089] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8240a105-45a0-40f6-a0fc-97bf67e991fa for DN 127.0.0.1:40363
2020-04-02 05:03:42,107 [IPC Server handler 9 on 39089] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3b50b712-dbb6-45da-8e43-f78711a80c9a for DN 127.0.0.1:34609
2020-04-02 05:03:42,113 [IPC Server handler 5 on 34357] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a for DN 127.0.0.1:34410
2020-04-02 05:03:42,115 [IPC Server handler 9 on 42512] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8240a105-45a0-40f6-a0fc-97bf67e991fa for DN 127.0.0.1:40363
2020-04-02 05:03:42,126 [IPC Server handler 4 on 33531] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 for DN 127.0.0.1:40363
2020-04-02 05:03:42,127 [IPC Server handler 2 on 42512] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1fefa900-398c-47d6-843d-2aae5a994ad0 for DN 127.0.0.1:35930
2020-04-02 05:03:42,127 [IPC Server handler 2 on 42512] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20108e8b-15ae-43dc-9b61-592b455301ea for DN 127.0.0.1:35930
2020-04-02 05:03:42,132 [IPC Server handler 5 on 34357] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5d628413-2464-428d-9976-96d4a321563f for DN 127.0.0.1:34410
2020-04-02 05:03:42,132 [IPC Server handler 6 on 42512] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a for DN 127.0.0.1:34410
2020-04-02 05:03:42,132 [IPC Server handler 6 on 42512] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5d628413-2464-428d-9976-96d4a321563f for DN 127.0.0.1:34410
2020-04-02 05:03:42,133 [IPC Server handler 9 on 39089] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 for DN 127.0.0.1:34609
2020-04-02 05:03:42,139 [IPC Server handler 4 on 33531] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8240a105-45a0-40f6-a0fc-97bf67e991fa for DN 127.0.0.1:40363
2020-04-02 05:03:42,140 [IPC Server handler 3 on 39089] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a for DN 127.0.0.1:34410
2020-04-02 05:03:42,140 [IPC Server handler 3 on 39089] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5d628413-2464-428d-9976-96d4a321563f for DN 127.0.0.1:34410
2020-04-02 05:03:42,162 [IPC Server handler 5 on 39089] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1fefa900-398c-47d6-843d-2aae5a994ad0 for DN 127.0.0.1:35930
2020-04-02 05:03:42,162 [IPC Server handler 5 on 39089] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20108e8b-15ae-43dc-9b61-592b455301ea for DN 127.0.0.1:35930
2020-04-02 05:03:42,163 [IPC Server handler 9 on 33531] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3b50b712-dbb6-45da-8e43-f78711a80c9a for DN 127.0.0.1:34609
2020-04-02 05:03:42,163 [IPC Server handler 9 on 33531] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 for DN 127.0.0.1:34609
2020-04-02 05:03:42,171 [IPC Server handler 1 on 34357] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3b50b712-dbb6-45da-8e43-f78711a80c9a for DN 127.0.0.1:34609
2020-04-02 05:03:42,171 [IPC Server handler 1 on 34357] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 for DN 127.0.0.1:34609
2020-04-02 05:03:42,172 [IPC Server handler 1 on 33531] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1fefa900-398c-47d6-843d-2aae5a994ad0 for DN 127.0.0.1:35930
2020-04-02 05:03:42,172 [IPC Server handler 1 on 33531] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20108e8b-15ae-43dc-9b61-592b455301ea for DN 127.0.0.1:35930
2020-04-02 05:03:42,179 [IPC Server handler 3 on 34357] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1fefa900-398c-47d6-843d-2aae5a994ad0 for DN 127.0.0.1:35930
2020-04-02 05:03:42,179 [IPC Server handler 3 on 34357] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20108e8b-15ae-43dc-9b61-592b455301ea for DN 127.0.0.1:35930
2020-04-02 05:03:42,184 [IPC Server handler 4 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:42,194 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x8e61f5902bef557a: Processing first storage report for DS-1fefa900-398c-47d6-843d-2aae5a994ad0 from datanode 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:42,196 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x8e61f5902bef557a: from storage DS-1fefa900-398c-47d6-843d-2aae5a994ad0 node DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,197 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfdc239f2d9abbbb7: Processing first storage report for DS-1fefa900-398c-47d6-843d-2aae5a994ad0 from datanode 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:42,198 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3aac60546e5f7bd5: Processing first storage report for DS-3b50b712-dbb6-45da-8e43-f78711a80c9a from datanode ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,198 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3aac60546e5f7bd5: from storage DS-3b50b712-dbb6-45da-8e43-f78711a80c9a node DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,198 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x8e61f5902bef557a: Processing first storage report for DS-20108e8b-15ae-43dc-9b61-592b455301ea from datanode 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:42,198 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x8e61f5902bef557a: from storage DS-20108e8b-15ae-43dc-9b61-592b455301ea node DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,200 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3aac60546e5f7bd5: Processing first storage report for DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 from datanode ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,200 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3aac60546e5f7bd5: from storage DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 node DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,202 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfdc239f2d9abbbb7: from storage DS-1fefa900-398c-47d6-843d-2aae5a994ad0 node DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,202 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf6e8f70b7c06a73: Processing first storage report for DS-3b50b712-dbb6-45da-8e43-f78711a80c9a from datanode ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,202 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf6e8f70b7c06a73: from storage DS-3b50b712-dbb6-45da-8e43-f78711a80c9a node DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,202 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfdc239f2d9abbbb7: Processing first storage report for DS-20108e8b-15ae-43dc-9b61-592b455301ea from datanode 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:42,202 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfdc239f2d9abbbb7: from storage DS-20108e8b-15ae-43dc-9b61-592b455301ea node DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,202 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc0e39b3b3a818223: Processing first storage report for DS-3b50b712-dbb6-45da-8e43-f78711a80c9a from datanode ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,203 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc0e39b3b3a818223: from storage DS-3b50b712-dbb6-45da-8e43-f78711a80c9a node DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,203 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x867d4ada655d5408: Processing first storage report for DS-1fefa900-398c-47d6-843d-2aae5a994ad0 from datanode 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:42,203 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x867d4ada655d5408: from storage DS-1fefa900-398c-47d6-843d-2aae5a994ad0 node DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,203 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x123855418f8f7367: Processing first storage report for DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 from datanode c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:42,203 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x123855418f8f7367: from storage DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 node DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,203 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x123855418f8f7367: Processing first storage report for DS-8240a105-45a0-40f6-a0fc-97bf67e991fa from datanode c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:42,204 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x123855418f8f7367: from storage DS-8240a105-45a0-40f6-a0fc-97bf67e991fa node DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,204 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x867d4ada655d5408: Processing first storage report for DS-20108e8b-15ae-43dc-9b61-592b455301ea from datanode 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:42,204 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x867d4ada655d5408: from storage DS-20108e8b-15ae-43dc-9b61-592b455301ea node DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,202 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf6e8f70b7c06a73: Processing first storage report for DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 from datanode ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,204 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf6e8f70b7c06a73: from storage DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 node DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,205 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc0e39b3b3a818223: Processing first storage report for DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 from datanode ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,237 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc0e39b3b3a818223: from storage DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 node DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: false, processing time: 32 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,237 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfdc239f2d9abbbb7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 64 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,259 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x123855418f8f7367,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 27 msec to generate and 92 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,259 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf6e8f70b7c06a73,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 88 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,237 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb952073f98a3eae3: Processing first storage report for DS-5d628413-2464-428d-9976-96d4a321563f from datanode fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:42,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb952073f98a3eae3: from storage DS-5d628413-2464-428d-9976-96d4a321563f node DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: true, processing time: 23 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x769b756f124a708d: Processing first storage report for DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 from datanode c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:42,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x769b756f124a708d: from storage DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 node DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,215 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x315abda8d187946d: Processing first storage report for DS-3b50b712-dbb6-45da-8e43-f78711a80c9a from datanode ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x315abda8d187946d: from storage DS-3b50b712-dbb6-45da-8e43-f78711a80c9a node DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: true, processing time: 46 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2f1d39b9ea8d1fb4: Processing first storage report for DS-5d628413-2464-428d-9976-96d4a321563f from datanode fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:42,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2f1d39b9ea8d1fb4: from storage DS-5d628413-2464-428d-9976-96d4a321563f node DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,260 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa68dc94a4894cfe4: Processing first storage report for DS-5d628413-2464-428d-9976-96d4a321563f from datanode fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:42,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa68dc94a4894cfe4: from storage DS-5d628413-2464-428d-9976-96d4a321563f node DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,260 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x8e61f5902bef557a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 79 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,259 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x867d4ada655d5408,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 65 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,261 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2f1d39b9ea8d1fb4: Processing first storage report for DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a from datanode fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:42,262 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2f1d39b9ea8d1fb4: from storage DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a node DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,262 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x315abda8d187946d: Processing first storage report for DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 from datanode ee2c4eda-af56-4a87-9fba-333dd3d7e97b
2020-04-02 05:03:42,262 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x315abda8d187946d: from storage DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913 node DatanodeRegistration(127.0.0.1:34609, datanodeUuid=ee2c4eda-af56-4a87-9fba-333dd3d7e97b, infoPort=43507, infoSecurePort=0, ipcPort=42396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,262 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2f1d39b9ea8d1fb4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 98 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,263 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa68dc94a4894cfe4: Processing first storage report for DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a from datanode fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:42,263 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa68dc94a4894cfe4: from storage DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a node DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,264 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x769b756f124a708d: Processing first storage report for DS-8240a105-45a0-40f6-a0fc-97bf67e991fa from datanode c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:42,264 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x769b756f124a708d: from storage DS-8240a105-45a0-40f6-a0fc-97bf67e991fa node DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,264 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb952073f98a3eae3: Processing first storage report for DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a from datanode fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:42,264 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb952073f98a3eae3: from storage DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a node DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,265 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xddb05bb7396ba134: Processing first storage report for DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 from datanode c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:42,265 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xddb05bb7396ba134: from storage DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 node DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,265 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xddb05bb7396ba134: Processing first storage report for DS-8240a105-45a0-40f6-a0fc-97bf67e991fa from datanode c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:42,266 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xddb05bb7396ba134: from storage DS-8240a105-45a0-40f6-a0fc-97bf67e991fa node DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,266 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x908c0361e477f31c: Processing first storage report for DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 from datanode c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:42,266 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x908c0361e477f31c: from storage DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6 node DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,267 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xba813ab76a2645d8: Processing first storage report for DS-1fefa900-398c-47d6-843d-2aae5a994ad0 from datanode 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:42,267 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xba813ab76a2645d8: from storage DS-1fefa900-398c-47d6-843d-2aae5a994ad0 node DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,267 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x908c0361e477f31c: Processing first storage report for DS-8240a105-45a0-40f6-a0fc-97bf67e991fa from datanode c682ebfe-e964-4eb8-9760-1bd1d1d170b0
2020-04-02 05:03:42,267 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x908c0361e477f31c: from storage DS-8240a105-45a0-40f6-a0fc-97bf67e991fa node DatanodeRegistration(127.0.0.1:40363, datanodeUuid=c682ebfe-e964-4eb8-9760-1bd1d1d170b0, infoPort=43482, infoSecurePort=0, ipcPort=33760, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,267 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xba813ab76a2645d8: Processing first storage report for DS-20108e8b-15ae-43dc-9b61-592b455301ea from datanode 7caf239b-3ea0-49b6-b1d0-2b70276405ad
2020-04-02 05:03:42,267 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xba813ab76a2645d8: from storage DS-20108e8b-15ae-43dc-9b61-592b455301ea node DatanodeRegistration(127.0.0.1:35930, datanodeUuid=7caf239b-3ea0-49b6-b1d0-2b70276405ad, infoPort=45627, infoSecurePort=0, ipcPort=44396, storageInfo=lv=-57;cid=testClusterID;nsid=235278558;c=1585803812311), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,257 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xededbc03cc958939: Processing first storage report for DS-5d628413-2464-428d-9976-96d4a321563f from datanode fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:42,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xededbc03cc958939: from storage DS-5d628413-2464-428d-9976-96d4a321563f node DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: true, processing time: 30 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,268 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xba813ab76a2645d8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 136 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xededbc03cc958939: Processing first storage report for DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a from datanode fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15
2020-04-02 05:03:42,268 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xededbc03cc958939: from storage DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a node DatanodeRegistration(127.0.0.1:34410, datanodeUuid=fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, infoPort=42733, infoSecurePort=0, ipcPort=36661, storageInfo=lv=-57;cid=testClusterID;nsid=7255333;c=1585803815915), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:42,308 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x3aac60546e5f7bd5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 87 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,315 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x315abda8d187946d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 122 msec to generate and 131 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,315 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x908c0361e477f31c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 12 msec to generate and 128 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,315 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xddb05bb7396ba134,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 133 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,316 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc0e39b3b3a818223,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 96 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,316 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb952073f98a3eae3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 104 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,316 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xededbc03cc958939,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 45 msec to generate and 133 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,315 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x769b756f124a708d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 17 msec to generate and 137 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,315 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa68dc94a4894cfe4,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 102 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:42,359 [IPC Server handler 1 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:42,398 [IPC Server handler 5 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:42,465 [IPC Server handler 6 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:42,468 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:42,486 [IPC Server handler 2 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:42,506 [IPC Server handler 4 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:42,526 [IPC Server handler 2 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:42,543 [IPC Server handler 0 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:42,567 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:42,641 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:42,650 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:42,658 [Socket Reader #1 for port 39109] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39109
2020-04-02 05:03:42,707 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:42,707 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:42,715 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:42,740 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:42,740 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:42,741 [Socket Reader #1 for port 46059] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46059
2020-04-02 05:03:42,760 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:42,763 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:42,763 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:42,763 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:42,763 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:42,764 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:42,786 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-04-02 05:03:42,786 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:42,798 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-04-02 05:03:42,804 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:33531
2020-04-02 05:03:42,804 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:33531
2020-04-02 05:03:42,804 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:33531
2020-04-02 05:03:42,804 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:40248
2020-04-02 05:03:42,805 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:39089
2020-04-02 05:03:42,805 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:39089
2020-04-02 05:03:42,805 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:39089
2020-04-02 05:03:42,810 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:34174
2020-04-02 05:03:42,811 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:34357
2020-04-02 05:03:42,811 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:34357
2020-04-02 05:03:42,811 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:34357
2020-04-02 05:03:42,811 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:33405
2020-04-02 05:03:42,812 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42512
2020-04-02 05:03:42,812 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42512
2020-04-02 05:03:42,812 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42512
2020-04-02 05:03:42,812 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:45171
2020-04-02 05:03:42,836 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:42,837 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:42,842 [Socket Reader #1 for port 42194] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42194
2020-04-02 05:03:42,845 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:42,845 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:42,849 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:42,856 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:42,856 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:42,857 [Socket Reader #1 for port 35655] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35655
2020-04-02 05:03:42,870 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:42,870 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:42,871 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:42,871 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:42,871 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:42,871 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:42,872 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-04-02 05:03:42,873 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:42,875 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-04-02 05:03:42,876 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:33531
2020-04-02 05:03:42,876 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:33531
2020-04-02 05:03:42,876 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:33531
2020-04-02 05:03:42,877 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:40248
2020-04-02 05:03:42,879 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:39089
2020-04-02 05:03:42,879 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:39089
2020-04-02 05:03:42,879 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:39089
2020-04-02 05:03:42,880 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:34174
2020-04-02 05:03:42,880 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:34357
2020-04-02 05:03:42,881 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:34357
2020-04-02 05:03:42,881 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:34357
2020-04-02 05:03:42,881 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:33405
2020-04-02 05:03:42,882 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42512
2020-04-02 05:03:42,882 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42512
2020-04-02 05:03:42,882 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42512
2020-04-02 05:03:42,882 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:45171
2020-04-02 05:03:42,896 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:42,898 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:42,899 [Socket Reader #1 for port 46826] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46826
2020-04-02 05:03:42,933 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:42,933 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:42,937 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:42,941 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:42,941 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:42,946 [Socket Reader #1 for port 46549] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46549
2020-04-02 05:03:42,958 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:42,958 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:42,958 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:42,958 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:42,959 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:42,959 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:42,960 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-04-02 05:03:42,960 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:42,969 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-04-02 05:03:42,969 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:33531
2020-04-02 05:03:42,970 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:33531
2020-04-02 05:03:42,970 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:33531
2020-04-02 05:03:42,970 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:40248
2020-04-02 05:03:42,970 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:39089
2020-04-02 05:03:42,970 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:39089
2020-04-02 05:03:42,970 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:39089
2020-04-02 05:03:42,970 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:34174
2020-04-02 05:03:42,971 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:34357
2020-04-02 05:03:42,971 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:34357
2020-04-02 05:03:42,971 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:34357
2020-04-02 05:03:42,971 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:33405
2020-04-02 05:03:42,971 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42512
2020-04-02 05:03:42,972 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42512
2020-04-02 05:03:42,972 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42512
2020-04-02 05:03:42,972 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:45171
2020-04-02 05:03:43,026 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:43,034 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:43,042 [Socket Reader #1 for port 37203] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37203
2020-04-02 05:03:43,072 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:43,072 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:43,077 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:43,082 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:43,083 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:43,084 [Socket Reader #1 for port 41227] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41227
2020-04-02 05:03:43,090 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:43,092 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:43,093 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:43,093 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:43,095 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:43,095 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:43,131 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-04-02 05:03:43,132 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:43,134 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-04-02 05:03:43,148 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:33531
2020-04-02 05:03:43,148 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:33531
2020-04-02 05:03:43,148 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:33531
2020-04-02 05:03:43,175 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:40248
2020-04-02 05:03:43,197 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:34357
2020-04-02 05:03:43,197 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:34357
2020-04-02 05:03:43,197 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:34357
2020-04-02 05:03:43,201 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:33405
2020-04-02 05:03:43,202 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:39089
2020-04-02 05:03:43,203 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:39089
2020-04-02 05:03:43,203 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:39089
2020-04-02 05:03:43,203 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:34174
2020-04-02 05:03:43,203 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42512
2020-04-02 05:03:43,203 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42512
2020-04-02 05:03:43,203 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42512
2020-04-02 05:03:43,204 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:45171
2020-04-02 05:03:43,224 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:39109: State Store unavailable
2020-04-02 05:03:43,224 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:43,228 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.createCluster(TestRouterWebHDFSContractAppend.java:34)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:43,230 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:43,230 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:43,231 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:43,231 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3d526ad9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:43,232 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:43,232 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:43,233 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:43,233 [IPC Server listener on 39109] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39109: starting
2020-04-02 05:03:43,234 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:39109
2020-04-02 05:03:43,234 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:43,235 [IPC Server listener on 46059] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46059: starting
2020-04-02 05:03:43,253 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:43,232 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:43,255 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:43,255 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:43,256 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:43,258 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:43,258 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:43,260 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:43,261 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:43,261 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:43,262 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:43,263 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:43,263 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:43,263 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:43,274 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:43,275 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:43,275 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33559
2020-04-02 05:03:43,275 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:43,296 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25243bc1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:43,296 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e6ee0bc{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:43,313 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1556f2dd{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:43,318 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@35e52059{HTTP/1.1,[http/1.1]}{0.0.0.0:33559}
2020-04-02 05:03:43,318 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @13930ms
2020-04-02 05:03:43,319 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:43,320 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:43,321 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:43,322 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:43,330 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:43,393 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-04-02 05:03:43,394 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-04-02 05:03:43,395 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-04-02 05:03:43,395 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-04-02 05:03:43,416 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-04-02 05:03:43,418 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:39109: State Store unavailable
2020-04-02 05:03:43,423 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:43,424 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.createCluster(TestRouterWebHDFSContractAppend.java:34)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:43,425 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:43,425 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:43,425 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:43,424 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71652c98] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:43,426 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:43,426 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:43,427 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:43,427 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:43,427 [IPC Server listener on 42194] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42194: starting
2020-04-02 05:03:43,429 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:42194
2020-04-02 05:03:43,429 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:43,430 [IPC Server listener on 35655] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35655: starting
2020-04-02 05:03:43,471 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:43,422 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:42194: State Store unavailable
2020-04-02 05:03:43,475 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:43,475 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:43,477 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:43,485 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:43,485 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:43,486 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:43,496 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:43,497 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:43,498 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:43,498 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:43,499 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:43,499 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:43,506 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:43,506 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:43,507 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33969
2020-04-02 05:03:43,507 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:43,519 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@159e366{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:43,538 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24528a25{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:43,545 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@36b6964d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:43,558 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@31198ceb{HTTP/1.1,[http/1.1]}{0.0.0.0:33969}
2020-04-02 05:03:43,559 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @14171ms
2020-04-02 05:03:43,559 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:43,562 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:43,598 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:43,602 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:43,603 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:43,675 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:42194: State Store unavailable
2020-04-02 05:03:43,676 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-04-02 05:03:43,676 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-04-02 05:03:43,676 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-04-02 05:03:43,676 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-04-02 05:03:43,677 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-04-02 05:03:43,677 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:46826: State Store unavailable
2020-04-02 05:03:43,681 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:43,681 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.createCluster(TestRouterWebHDFSContractAppend.java:34)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:43,682 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:43,682 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:43,682 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:43,683 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5dda14d0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:43,683 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:43,683 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:43,684 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:43,684 [IPC Server listener on 46826] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46826: starting
2020-04-02 05:03:43,714 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:46826
2020-04-02 05:03:43,715 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:43,778 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:43,683 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:43,715 [IPC Server listener on 46549] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46549: starting
2020-04-02 05:03:43,781 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:43,805 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:43,808 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:43,814 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:43,814 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:43,826 [IPC Server handler 6 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:43,826 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:43,842 [IPC Server handler 5 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:43,867 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:43,868 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:43,868 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:43,871 [IPC Server handler 7 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:43,879 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:43,879 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:43,879 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:43,879 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:43,881 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:43,881 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:43,882 [IPC Server handler 4 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:43,883 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43696
2020-04-02 05:03:43,884 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:43,886 [IPC Server handler 1 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:43,909 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:43,913 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25230246{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:43,961 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a8b5227{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:43,962 [IPC Server handler 1 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:43,966 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2237bada{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:43,967 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@77e2a6e2{HTTP/1.1,[http/1.1]}{0.0.0.0:43696}
2020-04-02 05:03:43,968 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @14580ms
2020-04-02 05:03:43,968 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:43,968 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:43,969 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:43,970 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:43,971 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:43,975 [IPC Server handler 4 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:43,980 [IPC Server handler 3 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:44,009 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-04-02 05:03:44,009 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-04-02 05:03:44,010 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-04-02 05:03:44,010 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-04-02 05:03:44,010 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-04-02 05:03:44,013 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:46826: State Store unavailable
2020-04-02 05:03:44,015 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:37203: State Store unavailable
2020-04-02 05:03:44,015 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:44,015 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.web.RouterWebHDFSContract.createCluster(RouterWebHDFSContract.java:69)
	at org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend.createCluster(TestRouterWebHDFSContractAppend.java:34)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:44,016 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:44,016 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:44,016 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:44,022 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5bb3d42d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:44,022 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:44,022 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:44,026 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:44,026 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:44,026 [IPC Server listener on 37203] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37203: starting
2020-04-02 05:03:44,028 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:37203
2020-04-02 05:03:44,028 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:44,028 [IPC Server listener on 41227] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41227: starting
2020-04-02 05:03:44,031 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:44,031 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:44,033 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:44,043 [IPC Server handler 3 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:44,044 [IPC Server handler 7 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:44,125 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:44,126 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:44,127 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:44,128 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:44,128 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:44,128 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:44,134 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:44,134 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:44,135 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34436
2020-04-02 05:03:44,135 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:44,137 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:44,137 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1162410a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:44,138 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62df0ff3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:44,179 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2a415aa9{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:44,220 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@53cdecf6{HTTP/1.1,[http/1.1]}{0.0.0.0:34436}
2020-04-02 05:03:44,220 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @14832ms
2020-04-02 05:03:44,221 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:44,221 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:44,226 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:44,227 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:44,227 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:44,228 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:44,229 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:44,237 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:44,239 [IPC Server handler 7 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:44,242 [IPC Server handler 6 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:44,243 [IPC Server handler 5 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:44,322 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:37203: State Store unavailable
2020-04-02 05:03:44,322 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-04-02 05:03:44,323 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-04-02 05:03:44,323 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-04-02 05:03:44,323 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-04-02 05:03:44,324 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-04-02 05:03:44,356 [IPC Server handler 2 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:44,371 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:44,374 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:44,394 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:44,396 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-04-02 05:03:44,397 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-04-02 05:03:44,397 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-04-02 05:03:44,398 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:44,450 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:44,599 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:44,599 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:44,600 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:44,601 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:44,785 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:45,012 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 226 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:45,077 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:45,078 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:45,078 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:45,078 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:45,078 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:45,079 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 479 msec
2020-04-02 05:03:45,118 [CacheReplicationMonitor(307907047)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:45,122 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:39089 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:45,122 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:39089
2020-04-02 05:03:45,158 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:45,159 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:45,184 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:45,185 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-04-02 05:03:45,185 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-04-02 05:03:45,186 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-04-02 05:03:45,186 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:45,187 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:39089 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:45,187 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:39089
2020-04-02 05:03:45,198 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:45,234 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:39089 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:45,235 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:39089
2020-04-02 05:03:45,235 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:39089 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:45,235 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:39089
2020-04-02 05:03:45,284 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:45,284 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:45,317 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:45,346 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:45,422 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:45,438 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 15 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:45,510 [CacheReplicationMonitor(1262399993)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:45,568 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:33531 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:45,568 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:33531
2020-04-02 05:03:45,613 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:45,614 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:45,614 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:45,614 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:45,614 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:45,614 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 323 msec
2020-04-02 05:03:45,742 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:33531 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:45,742 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:33531
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testRenameFileBeingAppended
[msx] unitTestCounterInClass = 0
2020-04-02 05:03:47,492 [Thread-475] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:34436 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@55128aa7
Apr 02, 2020 5:03:47 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:03:47 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Apr 02, 2020 5:03:47 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Apr 02, 2020 5:03:47 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2020-04-02 05:03:48,068 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:33531 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:48,068 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:33531
2020-04-02 05:03:48,118 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:33531 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:48,118 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:33531
2020-04-02 05:03:48,253 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:48,419 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:39109: State Store unavailable
2020-04-02 05:03:48,429 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:48,678 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:42194: State Store unavailable
2020-04-02 05:03:48,685 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:49,014 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:46826: State Store unavailable
2020-04-02 05:03:49,029 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:49,324 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:37203: State Store unavailable
Apr 02, 2020 5:03:50 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:03:50,408 [IPC Server handler 2 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
Apr 02, 2020 5:03:50 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:03:50 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Apr 02, 2020 5:03:50 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Apr 02, 2020 5:03:50 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Apr 02, 2020 5:03:51 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:03:51,730 [IPC Server handler 8 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:51,796 [nioEventLoopGroup-5-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/test/target?op=CREATE&user.name=root&namenoderpcaddress=5b1ca12d458b:37203&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:03:51,819 [IPC Server handler 5 on 39089] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_1052846211_492
2020-04-02 05:03:51,850 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
Apr 02, 2020 5:03:51 AM com.sun.jersey.spi.container.servlet.WebComponent filterFormParameters
WARNING: A servlet request, to the URI http://0.0.0.0:34436/webhdfs/v1/test/test/target?op=APPEND&user.name=root&buffersize=4096, contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected.
2020-04-02 05:03:51,902 [IPC Server handler 0 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:51,922 [IPC Server handler 4 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:51,961 [IPC Server handler 8 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:51,969 [IPC Server handler 9 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:51,970 [IPC Server handler 9 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:51,973 [IPC Server handler 4 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:51,973 [IPC Server handler 2 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:51,973 [IPC Server handler 9 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,046 [IPC Server handler 0 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,050 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,051 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,051 [IPC Server handler 2 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,051 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,052 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,116 [IPC Server handler 9 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,123 [IPC Server handler 6 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,199 [IPC Server handler 1 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,253 [IPC Server handler 4 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,266 [IPC Server handler 7 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,515 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/test/test/target	dst=/test/test/renamed	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:52,623 [IPC Server handler 9 on 39089] WARN  hdfs.StateChange (FSDirAppendOp.java:appendFile(145)) - DIR* NameSystem.append: Failed to append to non-existent file /test/test/target for client 127.0.0.1
2020-04-02 05:03:52,624 [IPC Server handler 9 on 39089] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 39089, call Call#226 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.append from 127.0.0.1:37166: java.io.FileNotFoundException: Failed to append to non-existent file /test/test/target for client 127.0.0.1
2020-04-02 05:03:52,673 [IPC Server handler 2 on 37203] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 37203, call Call#225 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.append from 172.17.0.4:47874: java.io.FileNotFoundException: Failed to append to non-existent file /test/test/target for client 127.0.0.1
2020-04-02 05:03:52,691 [nioEventLoopGroup-7-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 POST /webhdfs/v1/test/test/target?op=APPEND&user.name=root&namenoderpcaddress=5b1ca12d458b:37203&buffersize=4096 500
2020-04-02 05:03:52,740 [IPC Server handler 1 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:52,800 [IPC Server handler 7 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Failure org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testRenameFileBeingAppended
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testRenameFileBeingAppended
[msx] failed
[msx] failureMessage: Failed to append to non-existent file /test/test/target for client 127.0.0.1
	at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2635)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:805)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:487)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

[msx] stackTrace: java.io.FileNotFoundException: Failed to append to non-existent file /test/test/target for client 127.0.0.1
	at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2635)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:805)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:487)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:110)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toIOException(WebHdfsFileSystem.java:549)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:527)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$200(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$FsPathOutputStreamRunner$1.close(WebHdfsFileSystem.java:1020)
	at org.apache.hadoop.fs.contract.AbstractContractAppendTest.testRenameFileBeingAppended(AbstractContractAppendTest.java:139)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): Failed to append to non-existent file /test/test/target for client 127.0.0.1
	at org.apache.hadoop.hdfs.server.namenode.FSDirAppendOp.appendFile(FSDirAppendOp.java:104)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.appendFile(FSNamesystem.java:2635)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.append(NameNodeRpcServer.java:805)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.append(ClientNamenodeProtocolServerSideTranslatorPB.java:487)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:85)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:510)
	... 15 more

[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testRenameFileBeingAppended
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testRenameFileBeingAppended
[msx] Info : file existed /root/parameter_test_controller/shared/test_results/org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testRenameFileBeingAppended
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendToEmptyFile
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:52,880 [Thread-484] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:33559 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@cf05280
Apr 02, 2020 5:03:52 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:03:52 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Apr 02, 2020 5:03:52 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Apr 02, 2020 5:03:52 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2020-04-02 05:03:53,258 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
Apr 02, 2020 5:03:53 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:03:53,410 [IPC Server handler 2 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:53,420 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:39109: State Store unavailable
2020-04-02 05:03:53,431 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:54,646 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:37203: State Store unavailable
2020-04-02 05:03:54,659 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:54,660 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:46826: State Store unavailable
2020-04-02 05:03:54,714 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:54,716 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71652c98] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1038ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=859ms
GC pool 'PS Scavenge' had collection(s): count=1 time=198ms
2020-04-02 05:03:54,716 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:42194: State Store unavailable
2020-04-02 05:03:54,716 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@182f1e9a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1046ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=859ms
GC pool 'PS Scavenge' had collection(s): count=1 time=198ms
2020-04-02 05:03:54,717 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4504d271] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1062ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=859ms
GC pool 'PS Scavenge' had collection(s): count=1 time=198ms
2020-04-02 05:03:54,717 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5bb3d42d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1083ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=859ms
GC pool 'PS Scavenge' had collection(s): count=1 time=198ms
2020-04-02 05:03:54,717 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@aa22f1c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(205)) - Detected pause in JVM or host machine (eg GC): pause of approximately 1081ms
GC pool 'PS MarkSweep' had collection(s): count=1 time=859ms
GC pool 'PS Scavenge' had collection(s): count=1 time=198ms
2020-04-02 05:03:54,742 [IPC Server handler 9 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:54,774 [nioEventLoopGroup-3-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/test/target?op=CREATE&user.name=root&namenoderpcaddress=5b1ca12d458b:39109&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:03:54,842 [IPC Server handler 2 on 39089] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_283557453_298
Apr 02, 2020 5:03:54 AM com.sun.jersey.spi.container.servlet.WebComponent filterFormParameters
WARNING: A servlet request, to the URI http://0.0.0.0:33559/webhdfs/v1/test/test/target?op=APPEND&user.name=root&buffersize=4096, contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected.
2020-04-02 05:03:54,930 [IPC Server handler 6 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:54,970 [IPC Server handler 4 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:54,980 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,025 [IPC Server handler 7 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,038 [nioEventLoopGroup-9-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 POST /webhdfs/v1/test/test/target?op=APPEND&user.name=root&namenoderpcaddress=5b1ca12d458b:39109&buffersize=4096 200
2020-04-02 05:03:55,106 [IPC Server handler 1 on 39089] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40363, 127.0.0.1:35930, 127.0.0.1:34609 for /test/test/target
2020-04-02 05:03:55,305 [DataXceiver for client DFSClient_NONMAPREDUCE_1766275991_890 at /127.0.0.1:36732 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001 src: /127.0.0.1:36732 dest: /127.0.0.1:40363
2020-04-02 05:03:55,376 [DataXceiver for client DFSClient_NONMAPREDUCE_1766275991_890 at /127.0.0.1:57152 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001 src: /127.0.0.1:57152 dest: /127.0.0.1:35930
2020-04-02 05:03:55,400 [DataXceiver for client DFSClient_NONMAPREDUCE_1766275991_890 at /127.0.0.1:55732 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001 src: /127.0.0.1:55732 dest: /127.0.0.1:34609
2020-04-02 05:03:55,541 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55732, dest: /127.0.0.1:34609, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1766275991_890, offset: 0, srvID: ee2c4eda-af56-4a87-9fba-333dd3d7e97b, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, duration(ns): 81921214
2020-04-02 05:03:55,542 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:55,561 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34609]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57152, dest: /127.0.0.1:35930, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1766275991_890, offset: 0, srvID: 7caf239b-3ea0-49b6-b1d0-2b70276405ad, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, duration(ns): 92669935
2020-04-02 05:03:55,564 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34609]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34609] terminating
2020-04-02 05:03:55,571 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:34609]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36732, dest: /127.0.0.1:40363, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1766275991_890, offset: 0, srvID: c682ebfe-e964-4eb8-9760-1bd1d1d170b0, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, duration(ns): 131599845
2020-04-02 05:03:55,571 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:34609]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:34609] terminating
2020-04-02 05:03:55,578 [IPC Server handler 8 on 39089] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_1766275991_890
2020-04-02 05:03:55,616 [IPC Server handler 7 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,618 [IPC Server handler 2 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,635 [IPC Server handler 6 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,645 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,677 [IPC Server handler 7 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,823 [nioEventLoopGroup-3-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/test/test/target?op=OPEN&user.name=root&namenoderpcaddress=5b1ca12d458b:39109&buffersize=4096&offset=0 200
2020-04-02 05:03:55,835 [IPC Server handler 9 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:55,866 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendToEmptyFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendToEmptyFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendNonexistentFile
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:55,918 [Thread-502] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:43696 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@7a8c7a26
Apr 02, 2020 5:03:55 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:03:55 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Apr 02, 2020 5:03:55 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Apr 02, 2020 5:03:55 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Apr 02, 2020 5:03:56 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:03:56,333 [IPC Server handler 4 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
Apr 02, 2020 5:03:56 AM com.sun.jersey.spi.container.servlet.WebComponent filterFormParameters
WARNING: A servlet request, to the URI http://0.0.0.0:43696/webhdfs/v1/test/test/target?op=APPEND&user.name=root&buffersize=4096, contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected.
2020-04-02 05:03:56,433 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:56,449 [IPC Server handler 7 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:56,462 [IPC Server handler 8 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:56,484 [IPC Server handler 2 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:56,550 [IPC Server handler 6 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendNonexistentFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendNonexistentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testBuilderAppendToExistingFile
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:56,572 [Thread-506] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:43696 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@7a8c7a26
2020-04-02 05:03:56,615 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:56,709 [IPC Server handler 1 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:56,715 [nioEventLoopGroup-9-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/test/target?op=CREATE&user.name=root&namenoderpcaddress=5b1ca12d458b:46826&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:03:56,743 [IPC Server handler 9 on 39089] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:34410, 127.0.0.1:35930, 127.0.0.1:40363 for /test/test/target
2020-04-02 05:03:56,781 [DataXceiver for client DFSClient_NONMAPREDUCE_-1737142781_891 at /127.0.0.1:49016 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002 src: /127.0.0.1:49016 dest: /127.0.0.1:34410
2020-04-02 05:03:56,794 [DataXceiver for client DFSClient_NONMAPREDUCE_-1737142781_891 at /127.0.0.1:57216 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002 src: /127.0.0.1:57216 dest: /127.0.0.1:35930
2020-04-02 05:03:56,813 [DataXceiver for client DFSClient_NONMAPREDUCE_-1737142781_891 at /127.0.0.1:36808 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002 src: /127.0.0.1:36808 dest: /127.0.0.1:40363
2020-04-02 05:03:56,921 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36808, dest: /127.0.0.1:40363, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1737142781_891, offset: 0, srvID: c682ebfe-e964-4eb8-9760-1bd1d1d170b0, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, duration(ns): 99054523
2020-04-02 05:03:56,921 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:56,943 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40363]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57216, dest: /127.0.0.1:35930, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1737142781_891, offset: 0, srvID: 7caf239b-3ea0-49b6-b1d0-2b70276405ad, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, duration(ns): 120256613
2020-04-02 05:03:56,999 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:40363]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49016, dest: /127.0.0.1:34410, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1737142781_891, offset: 0, srvID: fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, duration(ns): 169959134
2020-04-02 05:03:56,999 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:40363]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:40363] terminating
2020-04-02 05:03:57,005 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40363]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40363] terminating
2020-04-02 05:03:57,026 [IPC Server handler 2 on 39089] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_-1737142781_891
Apr 02, 2020 5:03:57 AM com.sun.jersey.spi.container.servlet.WebComponent filterFormParameters
WARNING: A servlet request, to the URI http://0.0.0.0:43696/webhdfs/v1/test/test/target?op=APPEND&user.name=root&buffersize=4096, contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected.
2020-04-02 05:03:57,090 [IPC Server handler 7 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,103 [IPC Server handler 6 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,115 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,120 [IPC Server handler 7 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,176 [IPC Server handler 1 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,186 [nioEventLoopGroup-7-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 POST /webhdfs/v1/test/test/target?op=APPEND&user.name=root&namenoderpcaddress=5b1ca12d458b:46826&buffersize=4096 200
2020-04-02 05:03:57,233 [DataXceiver for client DFSClient_NONMAPREDUCE_-1975514772_697 at /127.0.0.1:36826 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002 src: /127.0.0.1:36826 dest: /127.0.0.1:40363
2020-04-02 05:03:57,234 [DataXceiver for client DFSClient_NONMAPREDUCE_-1975514772_697 at /127.0.0.1:36826 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 8192
  getBytesOnDisk()  = 8192
  getVisibleLength()= 8192
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741826
2020-04-02 05:03:57,346 [DataXceiver for client DFSClient_NONMAPREDUCE_-1975514772_697 at /127.0.0.1:57242 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002 src: /127.0.0.1:57242 dest: /127.0.0.1:35930
2020-04-02 05:03:57,347 [DataXceiver for client DFSClient_NONMAPREDUCE_-1975514772_697 at /127.0.0.1:57242 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 8192
  getBytesOnDisk()  = 8192
  getVisibleLength()= 8192
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741826
2020-04-02 05:03:57,364 [IPC Server handler 9 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,376 [IPC Server handler 2 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,380 [IPC Server handler 4 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,380 [IPC Server handler 0 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,395 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,447 [IPC Server handler 8 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,452 [IPC Server handler 9 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,452 [IPC Server handler 0 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,500 [IPC Server handler 3 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,546 [IPC Server handler 0 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,559 [IPC Server handler 7 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,578 [DataXceiver for client DFSClient_NONMAPREDUCE_-1975514772_697 at /127.0.0.1:49076 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002 src: /127.0.0.1:49076 dest: /127.0.0.1:34410
2020-04-02 05:03:57,579 [DataXceiver for client DFSClient_NONMAPREDUCE_-1975514772_697 at /127.0.0.1:49076 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1002]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 8192
  getBytesOnDisk()  = 8192
  getVisibleLength()= 8192
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741826
2020-04-02 05:03:57,594 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,594 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,595 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,651 [IPC Server handler 9 on 42512] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,850 [IPC Server handler 8 on 39089] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5340)) - updatePipeline(blk_1073741826_1002, newGS=1003, newLength=8192, newNodes=[127.0.0.1:40363, 127.0.0.1:35930, 127.0.0.1:34410], client=DFSClient_NONMAPREDUCE_-1975514772_697)
2020-04-02 05:03:57,853 [IPC Server handler 8 on 39089] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5358)) - updatePipeline(blk_1073741826_1002 => blk_1073741826_1003) success
2020-04-02 05:03:57,900 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 256
  getBytesOnDisk()  = 256
  getVisibleLength()= 256
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2020-04-02 05:03:57,903 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 256
  getBytesOnDisk()  = 256
  getVisibleLength()= 256
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2020-04-02 05:03:57,916 [IPC Server handler 4 on 34357] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:57,962 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-315731430-172.17.0.4-1585803812311 blk_1073741825_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:03:57,960 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-315731430-172.17.0.4-1585803812311 blk_1073741825_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:03:58,076 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49076, dest: /127.0.0.1:34410, bytes: 16384, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1975514772_697, offset: 0, srvID: fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, duration(ns): 229921459
2020-04-02 05:03:58,077 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:58,120 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34410]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57242, dest: /127.0.0.1:35930, bytes: 16384, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1975514772_697, offset: 0, srvID: 7caf239b-3ea0-49b6-b1d0-2b70276405ad, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, duration(ns): 279076397
2020-04-02 05:03:58,120 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34410]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34410] terminating
2020-04-02 05:03:58,163 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:34410]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36826, dest: /127.0.0.1:40363, bytes: 16384, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1975514772_697, offset: 0, srvID: c682ebfe-e964-4eb8-9760-1bd1d1d170b0, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, duration(ns): 323876321
2020-04-02 05:03:58,164 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:34410]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741826_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:34410] terminating
2020-04-02 05:03:58,168 [IPC Server handler 0 on 39089] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_-1975514772_697
2020-04-02 05:03:58,206 [IPC Server handler 7 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,230 [IPC Server handler 0 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,236 [IPC Server handler 1 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,238 [IPC Server handler 8 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,258 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:58,265 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,300 [nioEventLoopGroup-7-3] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/test/test/target?op=OPEN&user.name=root&namenoderpcaddress=5b1ca12d458b:46826&buffersize=4096&offset=0 200
2020-04-02 05:03:58,312 [IPC Server handler 2 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,323 [IPC Server handler 4 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testBuilderAppendToExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testBuilderAppendToExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendToExistingFile
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:58,344 [Thread-534] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:34436 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@55128aa7
2020-04-02 05:03:58,352 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:58,420 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:39109: State Store unavailable
2020-04-02 05:03:58,427 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:58,434 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:58,438 [nioEventLoopGroup-3-3] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/test/target?op=CREATE&user.name=root&namenoderpcaddress=5b1ca12d458b:37203&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:03:58,450 [IPC Server handler 7 on 39089] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1004, replicas=127.0.0.1:35930, 127.0.0.1:34410, 127.0.0.1:34609 for /test/test/target
2020-04-02 05:03:58,458 [DataXceiver for client DFSClient_NONMAPREDUCE_1015604204_300 at /127.0.0.1:57346 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004 src: /127.0.0.1:57346 dest: /127.0.0.1:35930
2020-04-02 05:03:58,480 [DataXceiver for client DFSClient_NONMAPREDUCE_1015604204_300 at /127.0.0.1:49150 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004 src: /127.0.0.1:49150 dest: /127.0.0.1:34410
2020-04-02 05:03:58,494 [DataXceiver for client DFSClient_NONMAPREDUCE_1015604204_300 at /127.0.0.1:55928 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004 src: /127.0.0.1:55928 dest: /127.0.0.1:34609
2020-04-02 05:03:58,576 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55928, dest: /127.0.0.1:34609, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1015604204_300, offset: 0, srvID: ee2c4eda-af56-4a87-9fba-333dd3d7e97b, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, duration(ns): 62790774
2020-04-02 05:03:58,576 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:58,587 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34609]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49150, dest: /127.0.0.1:34410, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1015604204_300, offset: 0, srvID: fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, duration(ns): 23819410
2020-04-02 05:03:58,588 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34609]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34609] terminating
2020-04-02 05:03:58,593 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34410, 127.0.0.1:34609]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57346, dest: /127.0.0.1:35930, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1015604204_300, offset: 0, srvID: 7caf239b-3ea0-49b6-b1d0-2b70276405ad, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, duration(ns): 52277376
2020-04-02 05:03:58,593 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34410, 127.0.0.1:34609]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34410, 127.0.0.1:34609] terminating
2020-04-02 05:03:58,614 [IPC Server handler 2 on 39089] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_1015604204_300
Apr 02, 2020 5:03:58 AM com.sun.jersey.spi.container.servlet.WebComponent filterFormParameters
WARNING: A servlet request, to the URI http://0.0.0.0:34436/webhdfs/v1/test/test/target?op=APPEND&user.name=root&buffersize=4096, contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected.
2020-04-02 05:03:58,646 [IPC Server handler 4 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,666 [IPC Server handler 4 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,670 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,672 [IPC Server handler 9 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,704 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:58,728 [nioEventLoopGroup-3-4] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 POST /webhdfs/v1/test/test/target?op=APPEND&user.name=root&namenoderpcaddress=5b1ca12d458b:37203&buffersize=4096 200
2020-04-02 05:03:58,755 [DataXceiver for client DFSClient_NONMAPREDUCE_-1211083541_301 at /127.0.0.1:55934 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004 src: /127.0.0.1:55934 dest: /127.0.0.1:34609
2020-04-02 05:03:58,756 [DataXceiver for client DFSClient_NONMAPREDUCE_-1211083541_301 at /127.0.0.1:55934 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741827_1004, FINALIZED
  getNumBytes()     = 8192
  getBytesOnDisk()  = 8192
  getVisibleLength()= 8192
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741827
2020-04-02 05:03:58,862 [DataXceiver for client DFSClient_NONMAPREDUCE_-1211083541_301 at /127.0.0.1:49160 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004 src: /127.0.0.1:49160 dest: /127.0.0.1:34410
2020-04-02 05:03:58,863 [DataXceiver for client DFSClient_NONMAPREDUCE_-1211083541_301 at /127.0.0.1:49160 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741827_1004, FINALIZED
  getNumBytes()     = 8192
  getBytesOnDisk()  = 8192
  getVisibleLength()= 8192
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741827
2020-04-02 05:03:58,939 [DataXceiver for client DFSClient_NONMAPREDUCE_-1211083541_301 at /127.0.0.1:57362 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004 src: /127.0.0.1:57362 dest: /127.0.0.1:35930
2020-04-02 05:03:58,941 [DataXceiver for client DFSClient_NONMAPREDUCE_-1211083541_301 at /127.0.0.1:57362 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1004]] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:append(1187)) - Appending to FinalizedReplica, blk_1073741827_1004, FINALIZED
  getNumBytes()     = 8192
  getBytesOnDisk()  = 8192
  getVisibleLength()= 8192
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741827
2020-04-02 05:03:59,021 [IPC Server handler 8 on 39089] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5340)) - updatePipeline(blk_1073741827_1004, newGS=1005, newLength=8192, newNodes=[127.0.0.1:34609, 127.0.0.1:34410, 127.0.0.1:35930], client=DFSClient_NONMAPREDUCE_-1211083541_301)
2020-04-02 05:03:59,042 [IPC Server handler 8 on 39089] INFO  namenode.FSNamesystem (FSNamesystem.java:updatePipeline(5358)) - updatePipeline(blk_1073741827_1004 => blk_1073741827_1005) success
2020-04-02 05:03:59,112 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57362, dest: /127.0.0.1:35930, bytes: 16384, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1211083541_301, offset: 0, srvID: 7caf239b-3ea0-49b6-b1d0-2b70276405ad, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, duration(ns): 81514633
2020-04-02 05:03:59,115 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:59,146 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35930]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49160, dest: /127.0.0.1:34410, bytes: 16384, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1211083541_301, offset: 0, srvID: fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, duration(ns): 114370769
2020-04-02 05:03:59,147 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35930]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35930] terminating
2020-04-02 05:03:59,169 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34410, 127.0.0.1:35930]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55934, dest: /127.0.0.1:34609, bytes: 16384, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1211083541_301, offset: 0, srvID: ee2c4eda-af56-4a87-9fba-333dd3d7e97b, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, duration(ns): 146151545
2020-04-02 05:03:59,169 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34410, 127.0.0.1:35930]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741827_1005, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:34410, 127.0.0.1:35930] terminating
2020-04-02 05:03:59,172 [IPC Server handler 2 on 39089] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_-1211083541_301
2020-04-02 05:03:59,246 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,259 [IPC Server handler 3 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,279 [IPC Server handler 9 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,281 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,298 [IPC Server handler 7 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,324 [nioEventLoopGroup-7-4] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/test/test/target?op=OPEN&user.name=root&namenoderpcaddress=5b1ca12d458b:37203&buffersize=4096&offset=0 200
2020-04-02 05:03:59,329 [IPC Server handler 1 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,338 [IPC Server handler 8 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendToExistingFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendToExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testBuilderAppendToEmptyFile
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:59,360 [Thread-557] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:43696 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@7a8c7a26
2020-04-02 05:03:59,407 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:59,467 [IPC Server handler 4 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/test/target	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:59,479 [nioEventLoopGroup-5-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/test/target?op=CREATE&user.name=root&namenoderpcaddress=5b1ca12d458b:46826&blocksize=134217728&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:03:59,485 [IPC Server handler 2 on 39089] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_-1778286463_493
Apr 02, 2020 5:03:59 AM com.sun.jersey.spi.container.servlet.WebComponent filterFormParameters
WARNING: A servlet request, to the URI http://0.0.0.0:43696/webhdfs/v1/test/test/target?op=APPEND&user.name=root&buffersize=4096, contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected.
2020-04-02 05:03:59,502 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,504 [IPC Server handler 4 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,515 [IPC Server handler 9 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,535 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=append	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,546 [nioEventLoopGroup-3-5] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 POST /webhdfs/v1/test/test/target?op=APPEND&user.name=root&namenoderpcaddress=5b1ca12d458b:46826&buffersize=4096 200
2020-04-02 05:03:59,563 [IPC Server handler 7 on 39089] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1006, replicas=127.0.0.1:34609, 127.0.0.1:35930, 127.0.0.1:34410 for /test/test/target
2020-04-02 05:03:59,602 [DataXceiver for client DFSClient_NONMAPREDUCE_2132338415_302 at /127.0.0.1:55960 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006 src: /127.0.0.1:55960 dest: /127.0.0.1:34609
2020-04-02 05:03:59,612 [DataXceiver for client DFSClient_NONMAPREDUCE_2132338415_302 at /127.0.0.1:57384 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006 src: /127.0.0.1:57384 dest: /127.0.0.1:35930
2020-04-02 05:03:59,635 [DataXceiver for client DFSClient_NONMAPREDUCE_2132338415_302 at /127.0.0.1:49188 [Receiving block BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006 src: /127.0.0.1:49188 dest: /127.0.0.1:34410
2020-04-02 05:03:59,652 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:37203: State Store unavailable
2020-04-02 05:03:59,678 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:59,696 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:49188, dest: /127.0.0.1:34410, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2132338415_302, offset: 0, srvID: fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, duration(ns): 54143427
2020-04-02 05:03:59,698 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:59,716 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:59,716 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34410]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57384, dest: /127.0.0.1:35930, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2132338415_302, offset: 0, srvID: 7caf239b-3ea0-49b6-b1d0-2b70276405ad, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, duration(ns): 46196091
2020-04-02 05:03:59,717 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:42194: State Store unavailable
2020-04-02 05:03:59,730 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34410]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34410] terminating
2020-04-02 05:03:59,735 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:34410]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55960, dest: /127.0.0.1:34609, bytes: 256, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2132338415_302, offset: 0, srvID: ee2c4eda-af56-4a87-9fba-333dd3d7e97b, blockid: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, duration(ns): 51947236
2020-04-02 05:03:59,736 [PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:34410]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-315731430-172.17.0.4-1585803812311:blk_1073741828_1006, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:35930, 127.0.0.1:34410] terminating
2020-04-02 05:03:59,743 [IPC Server handler 4 on 39089] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/test/target is closed by DFSClient_NONMAPREDUCE_2132338415_302
2020-04-02 05:03:59,765 [IPC Server handler 2 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,774 [IPC Server handler 1 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,774 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:46826: State Store unavailable
2020-04-02 05:03:59,779 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,785 [IPC Server handler 9 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,808 [IPC Server handler 0 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,843 [nioEventLoopGroup-9-3] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/test/test/target?op=OPEN&user.name=root&namenoderpcaddress=5b1ca12d458b:46826&buffersize=4096&offset=0 200
2020-04-02 05:03:59,847 [IPC Server handler 1 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:59,860 [IPC Server handler 8 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testBuilderAppendToEmptyFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testBuilderAppendToEmptyFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendMissingTarget
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:59,903 [Thread-568] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = webhdfs://0.0.0.0:33969 implemented by org.apache.hadoop.hdfs.web.WebHdfsFileSystem@56a4de2b
Apr 02, 2020 5:03:59 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.federation.router
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:03:59 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.federation.router.RouterWebHdfsMethods
Apr 02, 2020 5:03:59 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Apr 02, 2020 5:03:59 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Apr 02, 2020 5:04:00 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:04:00,268 [IPC Server handler 5 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
Apr 02, 2020 5:04:00 AM com.sun.jersey.spi.container.servlet.WebComponent filterFormParameters
WARNING: A servlet request, to the URI http://0.0.0.0:33969/webhdfs/v1/test/test/target?op=APPEND&user.name=root&buffersize=4096, contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected.
2020-04-02 05:04:00,351 [IPC Server handler 4 on 33531] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:00,363 [IPC Server handler 6 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:04:00,370 [IPC Server handler 4 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/test/target	dst=null	perm=null	proto=rpc
2020-04-02 05:04:00,401 [IPC Server handler 2 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:04:00,413 [IPC Server handler 3 on 39089] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendMissingTarget
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.web.TestRouterWebHDFSContractAppend#testAppendMissingTarget
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:04:00,423 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:04:00,423 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:04:00,423 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44396 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:00,424 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:00,424 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@51768776] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:00,430 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-1fefa900-398c-47d6-843d-2aae5a994ad0) exiting.
2020-04-02 05:04:00,432 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-20108e8b-15ae-43dc-9b61-592b455301ea) exiting.
2020-04-02 05:04:00,662 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:34357
2020-04-02 05:04:00,681 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:39089
2020-04-02 05:04:00,686 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:33531
2020-04-02 05:04:00,686 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad)
2020-04-02 05:04:00,686 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:04:00,734 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad) service to localhost/127.0.0.1:42512
2020-04-02 05:04:00,734 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid 7caf239b-3ea0-49b6-b1d0-2b70276405ad)
2020-04-02 05:04:00,755 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@72efb5c1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:00,762 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1747966108-172.17.0.4-1585803815914] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:00,767 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741826_1003 replica FinalizedReplica, blk_1073741826_1003, FINALIZED
  getNumBytes()     = 16384
  getBytesOnDisk()  = 16384
  getVisibleLength()= 16384
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2020-04-02 05:04:00,780 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d511b5f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:00,780 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a0807b7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:00,790 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d1f74b8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:00,796 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-315731430-172.17.0.4-1585803812311 blk_1073741826_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-315731430-172.17.0.4-1585803812311/current/finalized/subdir0/subdir0/blk_1073741826
2020-04-02 05:04:00,825 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44396
2020-04-02 05:04:00,828 [IPC Server listener on 44396] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44396
2020-04-02 05:04:00,829 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:04:00,862 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-315731430-172.17.0.4-1585803812311] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:00,870 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:00,840 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1747966108-172.17.0.4-1585803815914] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:00,873 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-315731430-172.17.0.4-1585803812311] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:00,893 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:00,893 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:00,895 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:00,895 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:00,902 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:00,903 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:04:00,903 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36661 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:00,903 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:00,904 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1494b84d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:00,915 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-5d628413-2464-428d-9976-96d4a321563f) exiting.
2020-04-02 05:04:00,916 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-9c51bb7e-ad45-4e47-9747-8fd65e86018a) exiting.
2020-04-02 05:04:01,133 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5aa0dbf4{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:01,136 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@16afbd92{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:01,151 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d61eccf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:01,151 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@226f885f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:01,156 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36661
2020-04-02 05:04:01,187 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:01,205 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,205 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:42512
2020-04-02 05:04:01,207 [IPC Server listener on 36661] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36661
2020-04-02 05:04:01,207 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,234 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:33531
2020-04-02 05:04:01,207 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,235 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:39089
2020-04-02 05:04:01,235 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15)
2020-04-02 05:04:01,235 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:04:01,237 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,238 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15) service to localhost/127.0.0.1:34357
2020-04-02 05:04:01,238 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid fede55d3-3ff7-4f4e-8d6f-c71e1abd3d15)
2020-04-02 05:04:01,251 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-315731430-172.17.0.4-1585803812311] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,261 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:04:01,262 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-315731430-172.17.0.4-1585803812311] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,277 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:01,278 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:01,281 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1747966108-172.17.0.4-1585803815914] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,292 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:01,292 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:01,301 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1747966108-172.17.0.4-1585803815914] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,312 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:01,312 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:04:01,312 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33760 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:01,312 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:01,313 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@514eedd8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:01,314 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-7a22a737-6b3c-4dc2-9126-3776ab6057a6) exiting.
2020-04-02 05:04:01,314 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-8240a105-45a0-40f6-a0fc-97bf67e991fa) exiting.
2020-04-02 05:04:01,444 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4b629f13{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:01,445 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70925b45{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:01,446 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e185cd7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:01,446 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@466cf502{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:01,505 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33760
2020-04-02 05:04:01,512 [IPC Server listener on 33760] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33760
2020-04-02 05:04:01,519 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:01,519 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,519 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:39089
2020-04-02 05:04:01,519 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,520 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:42512
2020-04-02 05:04:01,520 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0)
2020-04-02 05:04:01,520 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:04:01,542 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,542 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:34357
2020-04-02 05:04:01,545 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,546 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0) service to localhost/127.0.0.1:33531
2020-04-02 05:04:01,546 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid c682ebfe-e964-4eb8-9760-1bd1d1d170b0)
2020-04-02 05:04:01,560 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-315731430-172.17.0.4-1585803812311] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,572 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-315731430-172.17.0.4-1585803812311] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,573 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:04:01,582 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1747966108-172.17.0.4-1585803815914] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,600 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1747966108-172.17.0.4-1585803815914] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,627 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:01,627 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:01,631 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:01,631 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:01,643 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:01,643 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:04:01,643 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42396 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:01,643 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:04:01,645 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@74cadd41] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:04:01,649 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-3b50b712-dbb6-45da-8e43-f78711a80c9a) exiting.
2020-04-02 05:04:01,654 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-7ce08bf0-f62a-4539-b87e-d66b6e5d9913) exiting.
2020-04-02 05:04:01,815 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5860f3d7{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:04:01,818 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1d7f7be7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:01,825 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51850751{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:01,826 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ef0d29e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:01,841 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42396
2020-04-02 05:04:01,883 [IPC Server listener on 42396] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42396
2020-04-02 05:04:01,884 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,890 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:39089] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:39089
2020-04-02 05:04:01,891 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,891 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:34357] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:34357
2020-04-02 05:04:01,890 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:01,884 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,891 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:04:01,892 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:33531
2020-04-02 05:04:01,892 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b) service to localhost/127.0.0.1:42512
2020-04-02 05:04:01,892 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1747966108-172.17.0.4-1585803815914 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b)
2020-04-02 05:04:01,892 [BP-1747966108-172.17.0.4-1585803815914 heartbeating to localhost/127.0.0.1:33531] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1747966108-172.17.0.4-1585803815914
2020-04-02 05:04:01,892 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-315731430-172.17.0.4-1585803812311 (Datanode Uuid ee2c4eda-af56-4a87-9fba-333dd3d7e97b)
2020-04-02 05:04:01,902 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1747966108-172.17.0.4-1585803815914] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,922 [BP-315731430-172.17.0.4-1585803812311 heartbeating to localhost/127.0.0.1:42512] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-315731430-172.17.0.4-1585803812311
2020-04-02 05:04:01,923 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1747966108-172.17.0.4-1585803815914] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,933 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-315731430-172.17.0.4-1585803812311] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,958 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-315731430-172.17.0.4-1585803812311] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:04:01,968 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:04:01,969 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:04:01,986 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:04:01,986 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:04:01,998 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:04:01,998 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:01,998 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 39089 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:01,998 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:01,999 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 55
2020-04-02 05:04:02,000 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 56 Total time for transactions(ms): 56 Number of transactions batched in Syncs: 10 Number of syncs: 47 SyncTimes(ms): 45 4 4 
2020-04-02 05:04:02,002 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5298dead] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:02,003 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@553f3b6e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:02,004 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000056
2020-04-02 05:04:02,004 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000056
2020-04-02 05:04:02,006 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000056
2020-04-02 05:04:02,007 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:02,008 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39089
2020-04-02 05:04:02,009 [CacheReplicationMonitor(307907047)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:02,040 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:02,053 [IPC Server listener on 39089] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39089
2020-04-02 05:04:02,053 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:02,044 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:02,054 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(483)) - Namesystem is not running, skipping decommissioning/maintenance checks.
2020-04-02 05:04:02,134 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:02,134 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:02,136 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@73d983ea{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:02,168 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@d771cc9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:02,168 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a57ae10{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:02,169 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b7fdc8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:02,186 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:02,187 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 42512 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:02,187 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:02,188 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:04:02,190 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42512
2020-04-02 05:04:02,195 [IPC Server listener on 42512] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42512
2020-04-02 05:04:02,195 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:02,195 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:02,205 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:02,227 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:02,228 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:02,233 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4c4d27c8{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:02,269 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6821ea29{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:02,269 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@163d04ff{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:02,270 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53d1b9b3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:02,295 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:02,296 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33531 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:02,296 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:02,297 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 1
2020-04-02 05:04:02,298 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@76f10035] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:04:02,302 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5ab9b447] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:04:02,341 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 57 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 5 5 8 
2020-04-02 05:04:02,342 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:04:02,343 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:04:02,344 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:04:02,344 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:04:02,346 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33531
2020-04-02 05:04:02,347 [CacheReplicationMonitor(1262399993)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:04:02,348 [IPC Server listener on 33531] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33531
2020-04-02 05:04:02,349 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:02,377 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:02,378 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:02,402 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:02,402 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:02,407 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6b9ce1bf{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:02,431 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@61884cb1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:02,432 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c3b6c6e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:02,433 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75c9e76b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:02,462 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:04:02,463 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 34357 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:04:02,463 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:02,470 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:04:02,470 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34357
2020-04-02 05:04:02,476 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:04:02,477 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:04:02,492 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:02,502 [IPC Server listener on 34357] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34357
2020-04-02 05:04:02,574 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:04:02,574 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:04:02,583 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@650eab8{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:04:02,589 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:34357: End of File Exception between local host is: "5b1ca12d458b/172.17.0.4"; destination host is: "localhost":34357; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:04:02,590 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:34357
2020-04-02 05:04:02,602 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30f5a68a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:04:02,602 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1dd0e7c4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:02,603 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@47605f2f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:02,655 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:39109: State Store unavailable
2020-04-02 05:04:02,688 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:33531: End of File Exception between local host is: "5b1ca12d458b/172.17.0.4"; destination host is: "localhost":33531; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:04:02,727 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:33531
2020-04-02 05:04:02,808 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:04:02,816 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:04:02,826 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:42512: End of File Exception between local host is: "5b1ca12d458b/172.17.0.4"; destination host is: "localhost":42512; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:04:02,826 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:42512
2020-04-02 05:04:02,868 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:04:02,869 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:04:02,900 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:04:02,900 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:04:02,928 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:04:02,928 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:04:02,949 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:04:02,950 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:04:02,968 [Thread-583] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1556f2dd{/,null,UNAVAILABLE}{/router}
2020-04-02 05:04:02,987 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:39089: End of File Exception between local host is: "5b1ca12d458b/172.17.0.4"; destination host is: "localhost":39089; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:04:02,987 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:39089
2020-04-02 05:04:02,998 [Thread-583] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@35e52059{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:04:03,042 [Thread-583] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e6ee0bc{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:03,046 [Thread-583] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25243bc1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:03,068 [Thread-583] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46059
2020-04-02 05:04:03,070 [IPC Server listener on 46059] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46059
2020-04-02 05:04:03,072 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:03,094 [Thread-583] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39109
2020-04-02 05:04:03,095 [IPC Server listener on 39109] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39109
2020-04-02 05:04:03,095 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:03,145 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:04:03,146 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:04:03,162 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:04:03,162 [Thread-583] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:04:03,434 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:03,651 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:42194: State Store unavailable
2020-04-02 05:04:03,654 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:04:03,655 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:04:03,659 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:04:03,660 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:04:03,667 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:04:03,667 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:04:03,683 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:04:03,683 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:04:03,686 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:04:03,686 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:04:03,690 [NamenodeHeartbeatService ns1 nn0-0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:33531. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:03,730 [Thread-590] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@36b6964d{/,null,UNAVAILABLE}{/router}
2020-04-02 05:04:03,752 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:42512: DestHost:destPort localhost:42512 , LocalHost:localPort 5b1ca12d458b/172.17.0.4:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:03,754 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:42512
2020-04-02 05:04:03,774 [Thread-590] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@31198ceb{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:04:03,781 [Thread-590] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24528a25{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:03,783 [Thread-590] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@159e366{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:03,806 [Thread-590] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35655
2020-04-02 05:04:03,813 [IPC Server listener on 35655] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35655
2020-04-02 05:04:03,814 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:03,821 [Thread-590] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42194
2020-04-02 05:04:03,839 [Thread-590] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-04-02 05:04:03,841 [IPC Server listener on 42194] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42194
2020-04-02 05:04:03,842 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:03,854 [Thread-590] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-04-02 05:04:03,855 [Thread-590] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-04-02 05:04:03,859 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:04:03,859 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:04:03,861 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:04:03,862 [Thread-590] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:04:03,878 [NamenodeHeartbeatService ns1 nn1-0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:34357. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:03,904 [NamenodeHeartbeatService ns0 nn0-0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:39089. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:04,637 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:46826: State Store unavailable
2020-04-02 05:04:04,637 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:04:04,637 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:04:04,638 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:04:04,638 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:04:04,639 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:04:04,639 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:04:04,640 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:04:04,640 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:04:04,641 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:04:04,641 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:04:04,643 [Thread-592] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2237bada{/,null,UNAVAILABLE}{/router}
2020-04-02 05:04:04,643 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:34357: DestHost:destPort localhost:34357 , LocalHost:localPort 5b1ca12d458b/172.17.0.4:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:04,644 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:34357
2020-04-02 05:04:04,645 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:39089: DestHost:destPort localhost:39089 , LocalHost:localPort 5b1ca12d458b/172.17.0.4:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:04,645 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:39089
2020-04-02 05:04:04,646 [NamenodeHeartbeatService ns1 nn1-0] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2020-04-02 05:04:04,647 [NamenodeHeartbeatService ns1 nn1-0] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy32.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.versionRequest(NamenodeProtocolTranslatorPB.java:160)
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy33.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.getNamenodeStatusReport(NamenodeHeartbeatService.java:252)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.updateState(NamenodeHeartbeatService.java:205)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.periodicInvoke(NamenodeHeartbeatService.java:159)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:04:04,647 [NamenodeHeartbeatService ns1 nn1-0] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy32.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.versionRequest(NamenodeProtocolTranslatorPB.java:160)
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy33.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.getNamenodeStatusReport(NamenodeHeartbeatService.java:252)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.updateState(NamenodeHeartbeatService.java:205)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.periodicInvoke(NamenodeHeartbeatService.java:159)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:04:04,649 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:34357: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: "5b1ca12d458b/172.17.0.4"; destination host is: "localhost":34357; 
2020-04-02 05:04:04,649 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:34357
2020-04-02 05:04:04,648 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:34357: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: "5b1ca12d458b/172.17.0.4"; destination host is: "localhost":34357; 
2020-04-02 05:04:04,649 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:34357
2020-04-02 05:04:04,650 [Thread-592] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@77e2a6e2{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:04:04,651 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:33531: DestHost:destPort localhost:33531 , LocalHost:localPort 5b1ca12d458b/172.17.0.4:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:04,651 [Thread-592] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a8b5227{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:04,651 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:33531
2020-04-02 05:04:04,652 [Thread-592] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25230246{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:04,652 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:37203: State Store unavailable
2020-04-02 05:04:04,654 [NamenodeHeartbeatService ns1 nn0-0] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2020-04-02 05:04:04,654 [NamenodeHeartbeatService ns1 nn0-0] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy32.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolTranslatorPB.versionRequest(NamenodeProtocolTranslatorPB.java:160)
	at sun.reflect.GeneratedMethodAccessor17.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:422)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:165)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:157)
	at org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:95)
	at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:359)
	at com.sun.proxy.$Proxy33.versionRequest(Unknown Source)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.getNamenodeStatusReport(NamenodeHeartbeatService.java:252)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.updateState(NamenodeHeartbeatService.java:205)
	at org.apache.hadoop.hdfs.server.federation.router.NamenodeHeartbeatService.periodicInvoke(NamenodeHeartbeatService.java:159)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:04:04,655 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:33531: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: "5b1ca12d458b/172.17.0.4"; destination host is: "localhost":33531; 
2020-04-02 05:04:04,655 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:33531
2020-04-02 05:04:04,665 [Thread-592] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46549
2020-04-02 05:04:04,666 [IPC Server listener on 46549] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46549
2020-04-02 05:04:04,667 [Thread-592] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46826
2020-04-02 05:04:04,667 [IPC Server listener on 46826] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46826
2020-04-02 05:04:04,668 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:04:04,669 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:04:04,669 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:04,670 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:04,671 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:04:04,671 [Thread-592] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:04:04,679 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:04:04,770 [NamenodeHeartbeatService ns0 nn1-0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: localhost/127.0.0.1:42512. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:05,637 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 5b1ca12d458b:37203: State Store unavailable
2020-04-02 05:04:05,639 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:04:05,639 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:04:05,640 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:04:05,640 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:04:05,641 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:42512: DestHost:destPort localhost:42512 , LocalHost:localPort 5b1ca12d458b/172.17.0.4:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:05,642 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:42512
2020-04-02 05:04:05,642 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:04:05,644 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:04:05,644 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:04:05,644 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:39089: DestHost:destPort localhost:39089 , LocalHost:localPort 5b1ca12d458b/172.17.0.4:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:05,644 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:04:05,645 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:39089
2020-04-02 05:04:05,647 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:04:05,647 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:04:05,648 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:33531: DestHost:destPort localhost:33531 , LocalHost:localPort 5b1ca12d458b/172.17.0.4:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2020-04-02 05:04:05,649 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:33531
2020-04-02 05:04:05,651 [Thread-603] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2a415aa9{/,null,UNAVAILABLE}{/router}
2020-04-02 05:04:05,653 [Thread-603] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@53cdecf6{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:04:05,655 [Thread-603] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62df0ff3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:04:05,656 [Thread-603] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1162410a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:04:05,674 [Thread-603] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41227
2020-04-02 05:04:05,674 [IPC Server listener on 41227] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41227
2020-04-02 05:04:05,675 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:05,677 [Thread-603] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37203
2020-04-02 05:04:05,681 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:04:05,685 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:04:05,685 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:04:05,682 [IPC Server listener on 37203] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37203
2020-04-02 05:04:05,688 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:04:05,688 [Thread-603] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
[msx] all testRunFinished

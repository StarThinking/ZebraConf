[msx] before_class
2020-04-02 05:03:00,274 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=4, numDataNodes=4
2020-04-02 05:03:00,291 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(874)) - MiniDFSCluster disabling checkpointing in the Standby node since no HTTP ports have been specified.
2020-04-02 05:03:00,292 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:initMiniDFSCluster(880)) - MiniDFSCluster disabling log-roll triggering in the Standby node since no IPC ports have been specified.
Formatting using clusterid: testClusterID
2020-04-02 05:03:01,106 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:01,132 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:01,134 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:01,136 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:01,145 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:01,150 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:01,150 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:01,156 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:01,157 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:01,236 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:01,242 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:03:01,242 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:01,243 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:01,251 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:01,253 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:01
2020-04-02 05:03:01,256 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:01,256 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,258 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:03:01,259 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:01,279 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:01,288 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:01,289 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:01,289 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:01,289 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:01,290 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:01,290 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:01,291 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:01,291 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:01,291 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:01,292 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:01,292 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:01,323 [JUnit] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:03:01,344 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:01,344 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,345 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:03:01,345 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:01,352 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:01,353 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:01,353 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:01,356 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:01,363 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:01,367 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:01,374 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:01,374 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,375 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:03:01,376 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:01,387 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:01,388 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:01,388 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:01,395 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:01,396 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:01,399 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:01,399 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:01,400 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:03:01,400 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:01,436 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:01,450 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:03:01,453 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:03:01,456 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1 has been successfully formatted.
2020-04-02 05:03:01,469 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:01,469 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:01,644 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:01,644 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:01,667 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:01,761 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3
2020-04-02 05:03:01,784 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4
2020-04-02 05:03:01,790 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:02,159 [JUnit] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:03:02,216 [JUnit] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:03:02,315 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:03:02,316 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:03:02,321 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:02,323 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:02,323 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:03:02,402 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@70cf32e3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:02,407 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:02,428 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3451ms
2020-04-02 05:03:02,533 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:02,538 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:02,548 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:02,550 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:02,551 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:02,551 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:02,587 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:02,588 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:02,595 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42358
2020-04-02 05:03:02,597 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:02,663 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@a82c5f1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:02,664 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51c693d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:02,763 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71e9ebae{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:02,774 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5ef5c734{HTTP/1.1,[http/1.1]}{localhost:42358}
2020-04-02 05:03:02,777 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3800ms
2020-04-02 05:03:02,793 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:02,794 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:02,795 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:02,796 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:02,796 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:02,796 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:02,797 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:02,799 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:02,801 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:02,802 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:02,802 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:02,803 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:02,804 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:02,805 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:02
2020-04-02 05:03:02,805 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:02,805 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:02,807 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:02,807 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:02,813 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:02,817 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:02,818 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:02,818 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:02,818 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:02,818 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:02,819 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:02,819 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:02,820 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:02,821 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:02,822 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:02,822 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:02,823 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:02,823 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:02,823 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:02,824 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:02,826 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:02,826 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:02,826 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:02,827 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:02,827 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:02,827 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:02,827 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:02,827 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:02,828 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:02,828 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:02,829 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:02,829 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:02,829 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:02,829 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:02,830 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:02,830 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:02,830 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:02,830 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:02,830 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:02,838 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:02,841 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:02,842 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:02,846 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:02,847 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:02,883 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:02,891 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:02,892 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:03:02,898 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:02,898 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:02,899 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 67 msecs
2020-04-02 05:03:03,050 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:03,069 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:03,094 [Socket Reader #1 for port 33689] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33689
2020-04-02 05:03:03,474 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:03,505 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:03,520 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:03,537 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:03,538 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:03,604 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:03,624 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33689
2020-04-02 05:03:03,624 [IPC Server listener on 33689] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33689: starting
2020-04-02 05:03:03,648 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:03,650 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:03,650 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:03,652 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33689 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:03,657 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:03,662 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:03,662 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:03,663 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:03,663 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns0 to access this namenode/service.
2020-04-02 05:03:03,680 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1698fc68] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:03,682 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:03,688 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:03,689 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:03,692 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:03,693 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:03,694 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:03,694 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:03,696 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:03,697 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:03,697 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40540
2020-04-02 05:03:03,698 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:03,711 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b5825fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:03,712 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2cae1042{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:03,722 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1f2f9244{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:03,725 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5f0e333d{HTTP/1.1,[http/1.1]}{localhost:40540}
2020-04-02 05:03:03,726 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4749ms
2020-04-02 05:03:03,729 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:03,730 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:03,731 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:03,731 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:03,731 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:03,732 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:03,732 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:03,735 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns0
2020-04-02 05:03:03,735 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:03,752 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:03,754 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:03,755 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:03,757 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:03,758 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:03
2020-04-02 05:03:03,758 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:03,759 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,759 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:03,760 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:03,772 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:03,774 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:03,777 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:03,777 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:03,778 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:03,778 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:03,778 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:03,778 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:03,778 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:03,779 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:03,779 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:03,780 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:03,781 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:03,781 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,782 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:03,782 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:03,787 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:03,788 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:03,794 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:03,794 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:03,798 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:03,798 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:03,798 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:03,799 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,800 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:03,800 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:03,803 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:03,803 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:03,803 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:03,804 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:03,804 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:03,804 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:03,804 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,804 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:03,805 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:03,818 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:03,821 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-4/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:03,822 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1
2020-04-02 05:03:03,825 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:03,825 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:03,827 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:03,828 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:03,829 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-3/current/fsimage_0000000000000000000
2020-04-02 05:03:03,829 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:03,829 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:03,829 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 22 msecs
2020-04-02 05:03:03,830 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:03,830 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:03,831 [Socket Reader #1 for port 42246] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42246
2020-04-02 05:03:03,838 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:03,878 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:03,880 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:03,880 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:03,880 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:03,886 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:03,886 [IPC Server listener on 42246] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42246: starting
2020-04-02 05:03:03,892 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:42246
2020-04-02 05:03:03,893 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:03,893 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:03,893 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:03,894 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 42246 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
Formatting using clusterid: testClusterID
2020-04-02 05:03:03,909 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:03,910 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:03,911 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:03,911 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:03,911 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:03,912 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:03,912 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:03,913 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:03,913 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:03,914 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:03,914 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:03,915 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:03,915 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:03,916 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:03
2020-04-02 05:03:03,916 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:03,917 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,917 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:03,917 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:03,930 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:03,931 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:03,932 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:03,932 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:03,932 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:03,932 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:03,932 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:03,933 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:03,933 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:03,933 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:03,933 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:03,934 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:03,935 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:03,935 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,935 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:03,936 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:03,945 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:03,945 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:03,946 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:03,946 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:03,946 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:03,946 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:03,946 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:03,947 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,947 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:03,948 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:03,950 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:03,950 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:03,950 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:03,950 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:03,951 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:03,951 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:03,951 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:03,951 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:03,951 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:03,954 [JUnit] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:03,959 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 has been successfully formatted.
2020-04-02 05:03:03,966 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 has been successfully formatted.
2020-04-02 05:03:03,969 [JUnit] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3 has been successfully formatted.
2020-04-02 05:03:03,973 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:03,973 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:03:03,979 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:03,990 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:03:03,996 [JUnit] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:03:03,999 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7
2020-04-02 05:03:04,009 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:copyNameDirs(1263)) - Copying namedir from primary node dir file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5 to file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8
2020-04-02 05:03:04,025 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:04,025 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:04,025 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:04,026 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:04,026 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:04,040 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:04,040 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@60dce7ea] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:04,043 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:04,044 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:04,047 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:04,049 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:04,050 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:04,050 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:04,054 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:04,055 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:04,055 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33865
2020-04-02 05:03:04,056 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:04,070 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@502f1f4c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:04,071 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75c9e76b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:04,079 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@14c01636{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:04,080 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@590c73d3{HTTP/1.1,[http/1.1]}{localhost:33865}
2020-04-02 05:03:04,080 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5103ms
2020-04-02 05:03:04,085 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:04,086 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:04,086 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:04,086 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:04,086 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:04,086 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:04,086 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:04,087 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:04,087 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:04,095 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:04,099 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:04,100 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:04,100 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:04,101 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:04
2020-04-02 05:03:04,101 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:04,101 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,101 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:04,102 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:04,137 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:04,139 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:04,139 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:04,139 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:04,140 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:04,145 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:04,145 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:04,146 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:04,146 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:04,146 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:04,146 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:04,147 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:04,154 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:04,155 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,155 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:04,155 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:04,173 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:04,173 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:04,173 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:04,174 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:04,174 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:04,174 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:04,174 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:04,174 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,175 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:04,175 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:04,177 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:04,182 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:04,182 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:04,186 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:04,186 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:04,186 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:04,186 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,187 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:04,187 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:04,190 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:04,191 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:04,192 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:04,195 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:04,195 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:04,197 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:04,198 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:04,198 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/fsimage_0000000000000000000
2020-04-02 05:03:04,198 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:04,198 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:04,199 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 10 msecs
2020-04-02 05:03:04,199 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:04,199 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:04,200 [Socket Reader #1 for port 41758] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41758
2020-04-02 05:03:04,205 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:04,246 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:04,248 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:04,248 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:04,248 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:04,270 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:04,282 [IPC Server listener on 41758] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41758: starting
2020-04-02 05:03:04,305 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:41758
2020-04-02 05:03:04,305 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:04,305 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:04,312 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:04,312 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 41758 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:04,320 [JUnit] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:03:04,321 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:03:04,321 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:03:04,322 [JUnit] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://ns0
2020-04-02 05:03:04,322 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(936)) - Clients should use ns1 to access this namenode/service.
2020-04-02 05:03:04,329 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3b956878] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:04,330 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:03:04,332 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:04,334 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:03:04,339 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:04,340 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:03:04,340 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:04,340 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:04,343 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:04,344 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:04,344 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39735
2020-04-02 05:03:04,344 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:04,354 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@388ba540{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:04,355 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ece4966{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:04,363 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2bef51f2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:03:04,370 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@650eab8{HTTP/1.1,[http/1.1]}{localhost:39735}
2020-04-02 05:03:04,371 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5394ms
2020-04-02 05:03:04,373 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:03:04,376 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:03:04,376 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:03:04,376 [JUnit] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:03:04,376 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:03:04,377 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:03:04,377 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:03:04,377 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(785)) - Determined nameservice ID: ns1
2020-04-02 05:03:04,377 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: true
2020-04-02 05:03:04,378 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:04,378 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:03:04,378 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:03:04,379 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:03:04,379 [JUnit] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:03:04
2020-04-02 05:03:04,379 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:03:04,379 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,380 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:03:04,380 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:03:04,391 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:03:04,392 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:03:04,392 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:03:04,392 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:03:04,392 [JUnit] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:03:04,393 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:03:04,393 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:03:04,393 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:03:04,393 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:03:04,393 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:03:04,393 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:03:04,393 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:03:04,394 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:03:04,394 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,394 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:03:04,395 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:03:04,400 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:03:04,400 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:03:04,400 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:03:04,400 [JUnit] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:03:04,401 [JUnit] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:03:04,401 [JUnit] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:03:04,401 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:03:04,401 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,401 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:03:04,401 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:03:04,403 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:03:04,404 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:03:04,404 [JUnit] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:03:04,404 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:03:04,404 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:03:04,404 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:03:04,405 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:03:04,405 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:03:04,405 [JUnit] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:03:04,408 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:04,410 [JUnit] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-8/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:04,411 [JUnit] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3
2020-04-02 05:03:04,413 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:03:04,413 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:03:04,415 [JUnit] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:03:04,416 [JUnit] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:03:04,416 [JUnit] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-7/current/fsimage_0000000000000000000
2020-04-02 05:03:04,416 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=true, isRollingUpgrade=false)
2020-04-02 05:03:04,416 [JUnit] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:03:04,416 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 9 msecs
2020-04-02 05:03:04,417 [JUnit] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to 0.0.0.0:0
2020-04-02 05:03:04,417 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:04,418 [Socket Reader #1 for port 44914] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44914
2020-04-02 05:03:04,423 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:03:04,576 [JUnit] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:03:04,577 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:03:04,578 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:03:04,578 [JUnit] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:03:04,594 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:04,594 [IPC Server listener on 44914] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44914: starting
2020-04-02 05:03:04,611 [JUnit] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:44914
2020-04-02 05:03:04,611 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startStandbyServices(1376)) - Starting services required for standby state
2020-04-02 05:03:04,612 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.ha.log-roll.period(-1) assuming SECONDS
2020-04-02 05:03:04,612 [JUnit] INFO  ha.EditLogTailer (EditLogTailer.java:<init>(189)) - Not going to trigger log rolls on active node because dfs.ha.log-roll.period is negative.
2020-04-02 05:03:04,612 [JUnit] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 44914 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:04,625 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:04,645 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:04,670 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:04,672 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:04,673 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:04,680 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:04,684 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:04,690 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:04,691 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:04,695 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:04,701 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35373
2020-04-02 05:03:04,704 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:04,704 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:04,723 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:04,723 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:04,726 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:04,727 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:04,727 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:04,727 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:04,731 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46839
2020-04-02 05:03:04,731 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:04,733 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@28d6290{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:04,734 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ef0d29e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:04,743 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44e3760b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:04,744 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7909b995{HTTP/1.1,[http/1.1]}{localhost:46839}
2020-04-02 05:03:04,745 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5768ms
2020-04-02 05:03:05,481 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41699
2020-04-02 05:03:05,482 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5cc5b667] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:05,483 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:05,483 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:05,497 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,498 [Socket Reader #1 for port 33205] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33205
2020-04-02 05:03:05,505 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33205
2020-04-02 05:03:05,525 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:05,528 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:05,540 [Thread-153] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33689 starting to offer service
2020-04-02 05:03:05,540 [Thread-155] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41758 starting to offer service
2020-04-02 05:03:05,540 [Thread-156] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44914 starting to offer service
2020-04-02 05:03:05,540 [Thread-154] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42246 starting to offer service
2020-04-02 05:03:05,546 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,546 [IPC Server listener on 33205] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33205: starting
2020-04-02 05:03:05,550 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33205 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:05,552 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:05,553 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:05,553 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:05,554 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:05,554 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:05,555 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,555 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:05,555 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:05,555 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,556 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:05,556 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45627
2020-04-02 05:03:05,557 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:05,557 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:05,574 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:05,574 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:05,596 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:05,598 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:05,598 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:05,599 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:05,599 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36757
2020-04-02 05:03:05,600 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:05,607 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1cf2fed4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:05,608 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@245a26e1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:05,631 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7689ddef{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:05,632 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@687a762c{HTTP/1.1,[http/1.1]}{localhost:36757}
2020-04-02 05:03:05,633 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6656ms
2020-04-02 05:03:05,718 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44930
2020-04-02 05:03:05,718 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@733c423e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:05,719 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:05,719 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:05,719 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,720 [Socket Reader #1 for port 38704] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38704
2020-04-02 05:03:05,728 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38704
2020-04-02 05:03:05,732 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:05,732 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:05,733 [Thread-180] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42246 starting to offer service
2020-04-02 05:03:05,733 [Thread-181] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41758 starting to offer service
2020-04-02 05:03:05,733 [Thread-179] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33689 starting to offer service
2020-04-02 05:03:05,734 [Thread-182] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44914 starting to offer service
2020-04-02 05:03:05,734 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,736 [IPC Server listener on 38704] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38704: starting
2020-04-02 05:03:05,751 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38704 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:05,752 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:05,767 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:05,773 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:05,786 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:05,786 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:05,787 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,787 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:05,787 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:05,787 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,788 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:05,795 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39320
2020-04-02 05:03:05,799 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:05,799 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:05,803 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:05,804 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:05,826 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:05,831 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:05,832 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:05,833 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:05,834 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40361
2020-04-02 05:03:05,834 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:05,838 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@77cf3f8b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:05,839 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21ca139c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:05,894 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@76b74e9c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:05,895 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2d72f75e{HTTP/1.1,[http/1.1]}{localhost:40361}
2020-04-02 05:03:05,895 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6919ms
2020-04-02 05:03:05,942 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44220
2020-04-02 05:03:05,943 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:05,943 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:05,943 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5aa0dbf4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:05,943 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:05,945 [Socket Reader #1 for port 42086] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42086
2020-04-02 05:03:05,959 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42086
2020-04-02 05:03:05,963 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:05,964 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:05,964 [Thread-213] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33689 starting to offer service
2020-04-02 05:03:05,967 [Thread-214] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42246 starting to offer service
2020-04-02 05:03:05,967 [Thread-215] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41758 starting to offer service
2020-04-02 05:03:05,967 [Thread-216] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44914 starting to offer service
2020-04-02 05:03:05,976 [IPC Server listener on 42086] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42086: starting
2020-04-02 05:03:05,976 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:05,978 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42086 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:05,985 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:05,986 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:05,987 [JUnit] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:05,990 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:03:05,991 [JUnit] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:03:05,991 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,991 [JUnit] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:03:05,992 [JUnit] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:03:05,993 [JUnit] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:03:05,993 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:03:05,994 [JUnit] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39976
2020-04-02 05:03:05,994 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:03:05,994 [JUnit] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:03:05,997 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:05,998 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:03:05,999 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:06,000 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:03:06,000 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:06,000 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:06,000 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45252
2020-04-02 05:03:06,001 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:06,002 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d1f74b8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:06,002 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3a0807b7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,AVAILABLE}
2020-04-02 05:03:06,009 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@72efb5c1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:03:06,009 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d511b5f{HTTP/1.1,[http/1.1]}{localhost:45252}
2020-04-02 05:03:06,028 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7033ms
2020-04-02 05:03:06,112 [JUnit] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40751
2020-04-02 05:03:06,118 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:03:06,118 [JUnit] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:03:06,119 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:06,120 [Socket Reader #1 for port 44963] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44963
2020-04-02 05:03:06,130 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@40f33492] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:06,140 [JUnit] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44963
2020-04-02 05:03:06,145 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: ns0,ns1
2020-04-02 05:03:06,146 [JUnit] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: ns0,ns1
2020-04-02 05:03:06,149 [Thread-239] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33689 starting to offer service
2020-04-02 05:03:06,154 [Thread-240] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42246 starting to offer service
2020-04-02 05:03:06,154 [Thread-242] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44914 starting to offer service
2020-04-02 05:03:06,168 [IPC Server listener on 44963] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44963: starting
2020-04-02 05:03:06,168 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:06,168 [Thread-241] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41758 starting to offer service
2020-04-02 05:03:06,169 [JUnit] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44963 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:06,214 [Thread-239] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,214 [Thread-214] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,214 [Thread-156] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,216 [Thread-180] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,217 [Thread-239] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:06,217 [Thread-214] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:06,218 [Thread-214] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 is not formatted for namespace 886978301. Formatting...
2020-04-02 05:03:06,219 [Thread-214] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 
2020-04-02 05:03:06,219 [Thread-180] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:06,218 [Thread-239] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 is not formatted for namespace 886978301. Formatting...
2020-04-02 05:03:06,220 [Thread-180] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 is not formatted for namespace 886978301. Formatting...
2020-04-02 05:03:06,220 [Thread-239] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 
2020-04-02 05:03:06,220 [Thread-156] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:06,220 [Thread-180] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-561d1757-0a55-48fa-93cc-e6956dec9d6b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 
2020-04-02 05:03:06,220 [Thread-156] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 is not formatted for namespace 758218973. Formatting...
2020-04-02 05:03:06,221 [Thread-156] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-33d0d0c0-bed6-4788-a4d0-dd647793abff for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 
2020-04-02 05:03:06,223 [Thread-214] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:06,223 [Thread-214] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 is not formatted for namespace 886978301. Formatting...
2020-04-02 05:03:06,223 [Thread-214] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-531d16cc-6cf0-4602-8f54-6037bc10249b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 
2020-04-02 05:03:06,224 [Thread-239] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:06,224 [Thread-239] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 is not formatted for namespace 886978301. Formatting...
2020-04-02 05:03:06,224 [Thread-239] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d4fe2c9b-6833-4755-bc87-f815c903357e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 
2020-04-02 05:03:06,226 [Thread-156] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:06,226 [Thread-156] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 is not formatted for namespace 758218973. Formatting...
2020-04-02 05:03:06,226 [Thread-180] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 3743@1b26ddd29aee
2020-04-02 05:03:06,226 [Thread-156] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 
2020-04-02 05:03:06,227 [Thread-180] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 is not formatted for namespace 886978301. Formatting...
2020-04-02 05:03:06,227 [Thread-180] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 
2020-04-02 05:03:06,242 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,243 [Thread-214] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,243 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-1887098509-172.17.0.17-1585803781423 is not formatted. Formatting ...
2020-04-02 05:03:06,243 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1887098509-172.17.0.17-1585803781423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1887098509-172.17.0.17-1585803781423/current
2020-04-02 05:03:06,245 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,245 [Thread-156] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,245 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-244807914-172.17.0.17-1585803783954 is not formatted. Formatting ...
2020-04-02 05:03:06,245 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-244807914-172.17.0.17-1585803783954 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-244807914-172.17.0.17-1585803783954/current
2020-04-02 05:03:06,247 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,247 [Thread-239] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,247 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-1887098509-172.17.0.17-1585803781423 is not formatted. Formatting ...
2020-04-02 05:03:06,247 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1887098509-172.17.0.17-1585803781423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1887098509-172.17.0.17-1585803781423/current
2020-04-02 05:03:06,248 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,248 [Thread-180] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,248 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-1887098509-172.17.0.17-1585803781423 is not formatted. Formatting ...
2020-04-02 05:03:06,248 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1887098509-172.17.0.17-1585803781423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1887098509-172.17.0.17-1585803781423/current
2020-04-02 05:03:06,256 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,257 [Thread-214] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,257 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-1887098509-172.17.0.17-1585803781423 is not formatted. Formatting ...
2020-04-02 05:03:06,257 [Thread-214] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1887098509-172.17.0.17-1585803781423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1887098509-172.17.0.17-1585803781423/current
2020-04-02 05:03:06,258 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,258 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,258 [Thread-239] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,258 [Thread-156] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,258 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-1887098509-172.17.0.17-1585803781423 is not formatted. Formatting ...
2020-04-02 05:03:06,258 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-244807914-172.17.0.17-1585803783954 is not formatted. Formatting ...
2020-04-02 05:03:06,259 [Thread-156] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-244807914-172.17.0.17-1585803783954 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-244807914-172.17.0.17-1585803783954/current
2020-04-02 05:03:06,259 [Thread-239] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1887098509-172.17.0.17-1585803781423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1887098509-172.17.0.17-1585803781423/current
2020-04-02 05:03:06,260 [Thread-215] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,260 [Thread-215] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 has already been used.
2020-04-02 05:03:06,261 [Thread-215] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 has already been used.
2020-04-02 05:03:06,262 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,262 [Thread-180] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,263 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-1887098509-172.17.0.17-1585803781423 is not formatted. Formatting ...
2020-04-02 05:03:06,263 [Thread-180] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1887098509-172.17.0.17-1585803781423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1887098509-172.17.0.17-1585803781423/current
2020-04-02 05:03:06,265 [Thread-182] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,266 [Thread-180] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=886978301;bpid=BP-1887098509-172.17.0.17-1585803781423;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=886978301;c=1585803781423;bpid=BP-1887098509-172.17.0.17-1585803781423;dnuuid=null
2020-04-02 05:03:06,266 [Thread-156] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=758218973;bpid=BP-244807914-172.17.0.17-1585803783954;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=758218973;c=1585803783954;bpid=BP-244807914-172.17.0.17-1585803783954;dnuuid=null
2020-04-02 05:03:06,266 [Thread-182] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 has already been used.
2020-04-02 05:03:06,266 [Thread-182] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 has already been used.
2020-04-02 05:03:06,267 [Thread-214] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=886978301;bpid=BP-1887098509-172.17.0.17-1585803781423;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=886978301;c=1585803781423;bpid=BP-1887098509-172.17.0.17-1585803781423;dnuuid=null
2020-04-02 05:03:06,268 [Thread-156] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:06,273 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,268 [Thread-241] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,274 [Thread-241] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 has already been used.
2020-04-02 05:03:06,274 [Thread-241] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 has already been used.
2020-04-02 05:03:06,268 [Thread-239] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=886978301;bpid=BP-1887098509-172.17.0.17-1585803781423;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=886978301;c=1585803781423;bpid=BP-1887098509-172.17.0.17-1585803781423;dnuuid=null
2020-04-02 05:03:06,273 [Thread-215] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,287 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5 and block pool id BP-244807914-172.17.0.17-1585803783954 is not formatted. Formatting ...
2020-04-02 05:03:06,287 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-244807914-172.17.0.17-1585803783954 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-244807914-172.17.0.17-1585803783954/current
2020-04-02 05:03:06,287 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,288 [Thread-241] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,288 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7 and block pool id BP-244807914-172.17.0.17-1585803783954 is not formatted. Formatting ...
2020-04-02 05:03:06,288 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-244807914-172.17.0.17-1585803783954 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-244807914-172.17.0.17-1585803783954/current
2020-04-02 05:03:06,289 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,289 [Thread-182] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,289 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3 and block pool id BP-244807914-172.17.0.17-1585803783954 is not formatted. Formatting ...
2020-04-02 05:03:06,290 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-244807914-172.17.0.17-1585803783954 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-244807914-172.17.0.17-1585803783954/current
2020-04-02 05:03:06,300 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,301 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,301 [Thread-241] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,301 [Thread-182] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,301 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8 and block pool id BP-244807914-172.17.0.17-1585803783954 is not formatted. Formatting ...
2020-04-02 05:03:06,301 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4 and block pool id BP-244807914-172.17.0.17-1585803783954 is not formatted. Formatting ...
2020-04-02 05:03:06,301 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,301 [Thread-182] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-244807914-172.17.0.17-1585803783954 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-244807914-172.17.0.17-1585803783954/current
2020-04-02 05:03:06,301 [Thread-241] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-244807914-172.17.0.17-1585803783954 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-244807914-172.17.0.17-1585803783954/current
2020-04-02 05:03:06,302 [Thread-215] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,302 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6 and block pool id BP-244807914-172.17.0.17-1585803783954 is not formatted. Formatting ...
2020-04-02 05:03:06,307 [Thread-215] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-244807914-172.17.0.17-1585803783954 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-244807914-172.17.0.17-1585803783954/current
2020-04-02 05:03:06,307 [Thread-241] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=758218973;bpid=BP-244807914-172.17.0.17-1585803783954;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=758218973;c=1585803783954;bpid=BP-244807914-172.17.0.17-1585803783954;dnuuid=null
2020-04-02 05:03:06,307 [Thread-182] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=758218973;bpid=BP-244807914-172.17.0.17-1585803783954;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=758218973;c=1585803783954;bpid=BP-244807914-172.17.0.17-1585803783954;dnuuid=null
2020-04-02 05:03:06,309 [Thread-239] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:06,309 [Thread-180] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:06,312 [Thread-215] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=758218973;bpid=BP-244807914-172.17.0.17-1585803783954;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=758218973;c=1585803783954;bpid=BP-244807914-172.17.0.17-1585803783954;dnuuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:06,313 [Thread-214] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:06,395 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-33d0d0c0-bed6-4788-a4d0-dd647793abff
2020-04-02 05:03:06,395 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:03:06,401 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2
2020-04-02 05:03:06,420 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-561d1757-0a55-48fa-93cc-e6956dec9d6b
2020-04-02 05:03:06,421 [Thread-239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:03:06,421 [Thread-180] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:03:06,434 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8
2020-04-02 05:03:06,437 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:03:06,437 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5
2020-04-02 05:03:06,437 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:03:06,445 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba
2020-04-02 05:03:06,446 [Thread-180] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:03:06,460 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d4fe2c9b-6833-4755-bc87-f815c903357e
2020-04-02 05:03:06,460 [Thread-239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:03:06,460 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-531d16cc-6cf0-4602-8f54-6037bc10249b
2020-04-02 05:03:06,462 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:03:06,466 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:06,466 [Thread-239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:06,466 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:06,466 [Thread-180] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:03:06,473 [Thread-214] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:06,473 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:06,474 [Thread-180] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:06,476 [Thread-154] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:03:06,476 [Thread-154] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 has already been used.
2020-04-02 05:03:06,476 [Thread-154] INFO  common.Storage (DataStorage.java:loadDataStorage(421)) - Storage directory [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 has already been used.
2020-04-02 05:03:06,477 [Thread-182] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,479 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:06,479 [Thread-241] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,479 [Thread-239] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:06,479 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:06,479 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:06,480 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:06,481 [Thread-156] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:06,500 [Thread-214] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:06,500 [Thread-180] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:06,501 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:06,500 [Thread-156] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:06,500 [Thread-239] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:06,504 [Thread-215] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:06,504 [Thread-156] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:06,505 [Thread-239] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:06,504 [Thread-215] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:06,504 [Thread-180] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:06,506 [Thread-239] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:06,505 [Thread-156] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:06,505 [Thread-214] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:06,506 [Thread-156] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,506 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,511 [Thread-239] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,511 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,506 [Thread-215] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,512 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1 and block pool id BP-1887098509-172.17.0.17-1585803781423 is not formatted. Formatting ...
2020-04-02 05:03:06,506 [Thread-180] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:06,512 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1887098509-172.17.0.17-1585803781423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1887098509-172.17.0.17-1585803781423/current
2020-04-02 05:03:06,511 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:06,511 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:06,507 [Thread-214] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,512 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:06,512 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:06,512 [Thread-180] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,526 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,527 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,527 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2 and block pool id BP-1887098509-172.17.0.17-1585803781423 is not formatted. Formatting ...
2020-04-02 05:03:06,527 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1887098509-172.17.0.17-1585803781423 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1887098509-172.17.0.17-1585803781423/current
2020-04-02 05:03:06,544 [Thread-154] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=886978301;bpid=BP-1887098509-172.17.0.17-1585803781423;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=886978301;c=1585803781423;bpid=BP-1887098509-172.17.0.17-1585803781423;dnuuid=f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:06,567 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,586 [Thread-262] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-244807914-172.17.0.17-1585803783954 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 106ms
2020-04-02 05:03:06,593 [Thread-261] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-244807914-172.17.0.17-1585803783954 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 114ms
2020-04-02 05:03:06,593 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-244807914-172.17.0.17-1585803783954: 115ms
2020-04-02 05:03:06,600 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:06,601 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:06,602 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:06,602 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:06,603 [Thread-279] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-244807914-172.17.0.17-1585803783954/current/replicas doesn't exist 
2020-04-02 05:03:06,603 [Thread-280] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-244807914-172.17.0.17-1585803783954/current/replicas doesn't exist 
2020-04-02 05:03:06,607 [Thread-279] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 5ms
2020-04-02 05:03:06,611 [Thread-280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 8ms
2020-04-02 05:03:06,616 [Thread-268] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-244807914-172.17.0.17-1585803783954 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 103ms
2020-04-02 05:03:06,625 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-244807914-172.17.0.17-1585803783954 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 106ms
2020-04-02 05:03:06,624 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-244807914-172.17.0.17-1585803783954: 18ms
2020-04-02 05:03:06,622 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-244807914-172.17.0.17-1585803783954 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 143ms
2020-04-02 05:03:06,627 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-244807914-172.17.0.17-1585803783954 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 147ms
2020-04-02 05:03:06,628 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-244807914-172.17.0.17-1585803783954 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 116ms
2020-04-02 05:03:06,628 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-244807914-172.17.0.17-1585803783954: 149ms
2020-04-02 05:03:06,628 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-244807914-172.17.0.17-1585803783954 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 115ms
2020-04-02 05:03:06,629 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-244807914-172.17.0.17-1585803783954: 121ms
2020-04-02 05:03:06,629 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:06,629 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:06,629 [Thread-283] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-244807914-172.17.0.17-1585803783954/current/replicas doesn't exist 
2020-04-02 05:03:06,629 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:06,629 [Thread-285] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-244807914-172.17.0.17-1585803783954/current/replicas doesn't exist 
2020-04-02 05:03:06,629 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:06,630 [Thread-283] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 1ms
2020-04-02 05:03:06,629 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:06,629 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:06,630 [Thread-287] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-244807914-172.17.0.17-1585803783954/current/replicas doesn't exist 
2020-04-02 05:03:06,630 [Thread-286] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-244807914-172.17.0.17-1585803783954/current/replicas doesn't exist 
2020-04-02 05:03:06,630 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:06,630 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:06,630 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:03:06,630 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:03:06,630 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:03:06,631 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-244807914-172.17.0.17-1585803783954: 2ms
2020-04-02 05:03:06,633 [Thread-277] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1887098509-172.17.0.17-1585803781423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 32ms
2020-04-02 05:03:06,633 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-244807914-172.17.0.17-1585803783954: 122ms
2020-04-02 05:03:06,634 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:06,634 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:06,642 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:06,643 [Thread-293] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-244807914-172.17.0.17-1585803783954/current/replicas doesn't exist 
2020-04-02 05:03:06,643 [Thread-293] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 0ms
2020-04-02 05:03:06,644 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:06,646 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba): finished scanning block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,649 [Thread-156] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-244807914-172.17.0.17-1585803783954: 20ms
2020-04-02 05:03:06,650 [Thread-278] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1887098509-172.17.0.17-1585803781423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 50ms
2020-04-02 05:03:06,650 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1887098509-172.17.0.17-1585803781423: 51ms
2020-04-02 05:03:06,653 [Thread-241] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:55 AM with interval of 21600000ms
2020-04-02 05:03:06,656 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:06,657 [Thread-291] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-244807914-172.17.0.17-1585803783954/current/replicas doesn't exist 
2020-04-02 05:03:06,669 [Thread-156] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:48 AM with interval of 21600000ms
2020-04-02 05:03:06,679 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3...
2020-04-02 05:03:06,679 [Thread-303] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1887098509-172.17.0.17-1585803781423/current/replicas doesn't exist 
2020-04-02 05:03:06,680 [Thread-303] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3: 1ms
2020-04-02 05:03:06,659 [Thread-182] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:09 AM with interval of 21600000ms
2020-04-02 05:03:06,650 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:06,682 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5): finished scanning block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,650 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:06,683 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-33d0d0c0-bed6-4788-a4d0-dd647793abff): finished scanning block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,649 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:06,646 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:06,644 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:06,684 [Thread-288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1887098509-172.17.0.17-1585803781423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 54ms
2020-04-02 05:03:06,684 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-561d1757-0a55-48fa-93cc-e6956dec9d6b): finished scanning block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,683 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2): finished scanning block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,684 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d4fe2c9b-6833-4755-bc87-f815c903357e): finished scanning block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,690 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4...
2020-04-02 05:03:06,690 [Thread-310] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1887098509-172.17.0.17-1585803781423/current/replicas doesn't exist 
2020-04-02 05:03:06,691 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:41758 beginning handshake with NN
2020-04-02 05:03:06,692 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:44914 beginning handshake with NN
2020-04-02 05:03:06,693 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4: 3ms
2020-04-02 05:03:06,697 [Thread-292] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1887098509-172.17.0.17-1585803781423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 55ms
2020-04-02 05:03:06,697 [Thread-290] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1887098509-172.17.0.17-1585803781423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 67ms
2020-04-02 05:03:06,703 [Thread-291] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 69ms
2020-04-02 05:03:06,705 [Thread-215] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-244807914-172.17.0.17-1585803783954: 71ms
2020-04-02 05:03:06,706 [Thread-180] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423: 56ms
2020-04-02 05:03:06,706 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:41758 beginning handshake with NN
2020-04-02 05:03:06,706 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:41758 beginning handshake with NN
2020-04-02 05:03:06,706 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:44914 beginning handshake with NN
2020-04-02 05:03:06,711 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:33689 beginning handshake with NN
2020-04-02 05:03:06,711 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:06,706 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:44914 beginning handshake with NN
2020-04-02 05:03:06,721 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-531d16cc-6cf0-4602-8f54-6037bc10249b): finished scanning block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,723 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3
2020-04-02 05:03:06,724 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-561d1757-0a55-48fa-93cc-e6956dec9d6b): finished scanning block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,724 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-33d0d0c0-bed6-4788-a4d0-dd647793abff): no suitable block pools found to scan.  Waiting 1814399925 ms.
2020-04-02 05:03:06,724 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4
2020-04-02 05:03:06,725 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5): no suitable block pools found to scan.  Waiting 1814399925 ms.
2020-04-02 05:03:06,725 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba): finished scanning block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,725 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba): no suitable block pools found to scan.  Waiting 1814399919 ms.
2020-04-02 05:03:06,726 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:42246 beginning handshake with NN
2020-04-02 05:03:06,711 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-244807914-172.17.0.17-1585803783954 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:06,711 [Thread-215] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:14 AM with interval of 21600000ms
2020-04-02 05:03:06,725 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d4fe2c9b-6833-4755-bc87-f815c903357e): no suitable block pools found to scan.  Waiting 1814399921 ms.
2020-04-02 05:03:06,724 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-561d1757-0a55-48fa-93cc-e6956dec9d6b): no suitable block pools found to scan.  Waiting 1814399920 ms.
2020-04-02 05:03:06,724 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-531d16cc-6cf0-4602-8f54-6037bc10249b): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-04-02 05:03:06,724 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2): no suitable block pools found to scan.  Waiting 1814399922 ms.
2020-04-02 05:03:06,730 [Thread-289] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1887098509-172.17.0.17-1585803781423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 100ms
2020-04-02 05:03:06,730 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8): finished scanning block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:06,743 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1887098509-172.17.0.17-1585803781423: 114ms
2020-04-02 05:03:06,743 [IPC Server handler 6 on 33689] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423) storage e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:06,743 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1...
2020-04-02 05:03:06,743 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8): no suitable block pools found to scan.  Waiting 1814399968 ms.
2020-04-02 05:03:06,753 [Thread-315] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1887098509-172.17.0.17-1585803781423/current/replicas doesn't exist 
2020-04-02 05:03:06,753 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:44914 beginning handshake with NN
2020-04-02 05:03:06,753 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:41758 beginning handshake with NN
2020-04-02 05:03:06,753 [Thread-315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:03:06,754 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2...
2020-04-02 05:03:06,754 [Thread-316] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1887098509-172.17.0.17-1585803781423/current/replicas doesn't exist 
2020-04-02 05:03:06,755 [IPC Server handler 6 on 33689] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45627
2020-04-02 05:03:06,755 [Thread-316] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:03:06,755 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423: 12ms
2020-04-02 05:03:06,756 [IPC Server handler 6 on 33689] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e71f8f07-b317-454b-94fe-e7315ef3e9de (127.0.0.1:45627).
2020-04-02 05:03:06,757 [IPC Server handler 8 on 41758] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954) storage 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:06,758 [Thread-294] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1887098509-172.17.0.17-1585803781423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 102ms
2020-04-02 05:03:06,760 [IPC Server handler 7 on 42246] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423) storage e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:06,760 [Thread-284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1887098509-172.17.0.17-1585803781423 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 131ms
2020-04-02 05:03:06,764 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:33689 successfully registered with NN
2020-04-02 05:03:06,765 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33689 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,762 [IPC Server handler 7 on 42246] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45627
2020-04-02 05:03:06,768 [IPC Server handler 7 on 42246] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e71f8f07-b317-454b-94fe-e7315ef3e9de (127.0.0.1:45627).
2020-04-02 05:03:06,761 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:42246 beginning handshake with NN
2020-04-02 05:03:06,761 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:33689 beginning handshake with NN
2020-04-02 05:03:06,761 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1887098509-172.17.0.17-1585803781423: 127ms
2020-04-02 05:03:06,760 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2
2020-04-02 05:03:06,760 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1
2020-04-02 05:03:06,771 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5): finished scanning block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,771 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5...
2020-04-02 05:03:06,760 [IPC Server handler 8 on 41758] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39976
2020-04-02 05:03:06,760 [IPC Server handler 5 on 44914] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954) storage f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:06,772 [IPC Server handler 8 on 41758] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 344abacc-81c9-4c09-b257-1bdb0511d8db (127.0.0.1:39976).
2020-04-02 05:03:06,772 [IPC Server handler 3 on 33689] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423) storage f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:06,772 [Thread-317] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1887098509-172.17.0.17-1585803781423/current/replicas doesn't exist 
2020-04-02 05:03:06,771 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6...
2020-04-02 05:03:06,771 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-33d0d0c0-bed6-4788-a4d0-dd647793abff): finished scanning block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,781 [Thread-317] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5: 9ms
2020-04-02 05:03:06,771 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:42246 successfully registered with NN
2020-04-02 05:03:06,782 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42246 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,782 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-33d0d0c0-bed6-4788-a4d0-dd647793abff): no suitable block pools found to scan.  Waiting 1814399867 ms.
2020-04-02 05:03:06,765 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1887098509-172.17.0.17-1585803781423: 136ms
2020-04-02 05:03:06,781 [Thread-318] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1887098509-172.17.0.17-1585803781423/current/replicas doesn't exist 
2020-04-02 05:03:06,781 [IPC Server handler 7 on 41758] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954) storage f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:06,786 [IPC Server handler 7 on 41758] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35373
2020-04-02 05:03:06,774 [IPC Server handler 5 on 42246] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423) storage f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:06,787 [Thread-318] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6: 6ms
2020-04-02 05:03:06,773 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5): no suitable block pools found to scan.  Waiting 1814399878 ms.
2020-04-02 05:03:06,787 [Thread-214] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423: 16ms
2020-04-02 05:03:06,773 [IPC Server handler 5 on 44914] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35373
2020-04-02 05:03:06,787 [IPC Server handler 5 on 44914] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f64b03c7-b23c-44d1-8521-8915971f7ff5 (127.0.0.1:35373).
2020-04-02 05:03:06,787 [IPC Server handler 5 on 42246] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35373
2020-04-02 05:03:06,788 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:33689 beginning handshake with NN
2020-04-02 05:03:06,787 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5
2020-04-02 05:03:06,787 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6
2020-04-02 05:03:06,788 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8): finished scanning block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,788 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-531d16cc-6cf0-4602-8f54-6037bc10249b): finished scanning block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,789 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8): no suitable block pools found to scan.  Waiting 1814399922 ms.
2020-04-02 05:03:06,789 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:42246 beginning handshake with NN
2020-04-02 05:03:06,789 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-531d16cc-6cf0-4602-8f54-6037bc10249b): no suitable block pools found to scan.  Waiting 1814399922 ms.
2020-04-02 05:03:06,790 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:41758 successfully registered with NN
2020-04-02 05:03:06,790 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41758 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,802 [IPC Server handler 7 on 41758] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f64b03c7-b23c-44d1-8521-8915971f7ff5 (127.0.0.1:35373).
2020-04-02 05:03:06,803 [IPC Server handler 9 on 41758] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954) storage e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:06,803 [IPC Server handler 9 on 41758] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45627
2020-04-02 05:03:06,803 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:41758 successfully registered with NN
2020-04-02 05:03:06,802 [IPC Server handler 5 on 42246] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f64b03c7-b23c-44d1-8521-8915971f7ff5 (127.0.0.1:35373).
2020-04-02 05:03:06,802 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8...
2020-04-02 05:03:06,802 [IPC Server handler 3 on 33689] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35373
2020-04-02 05:03:06,802 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7...
2020-04-02 05:03:06,804 [IPC Server handler 3 on 33689] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f64b03c7-b23c-44d1-8521-8915971f7ff5 (127.0.0.1:35373).
2020-04-02 05:03:06,804 [Thread-320] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1887098509-172.17.0.17-1585803781423/current/replicas doesn't exist 
2020-04-02 05:03:06,803 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41758 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,805 [IPC Server handler 0 on 33689] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423) storage e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:06,805 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8: 1ms
2020-04-02 05:03:06,805 [IPC Server handler 0 on 33689] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39320
2020-04-02 05:03:06,805 [IPC Server handler 0 on 33689] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e9eb8ddb-a9d5-4ece-a845-c4bd22992165 (127.0.0.1:39320).
2020-04-02 05:03:06,803 [IPC Server handler 9 on 41758] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e71f8f07-b317-454b-94fe-e7315ef3e9de (127.0.0.1:45627).
2020-04-02 05:03:06,805 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:42246 successfully registered with NN
2020-04-02 05:03:06,805 [IPC Server handler 5 on 41758] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954) storage e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:06,804 [IPC Server handler 6 on 42246] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423) storage e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:06,804 [Thread-319] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1887098509-172.17.0.17-1585803781423/current/replicas doesn't exist 
2020-04-02 05:03:06,806 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:41758 successfully registered with NN
2020-04-02 05:03:06,806 [IPC Server handler 6 on 42246] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39320
2020-04-02 05:03:06,806 [IPC Server handler 6 on 42246] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e9eb8ddb-a9d5-4ece-a845-c4bd22992165 (127.0.0.1:39320).
2020-04-02 05:03:06,806 [IPC Server handler 5 on 41758] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39320
2020-04-02 05:03:06,806 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42246 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,807 [IPC Server handler 5 on 41758] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e9eb8ddb-a9d5-4ece-a845-c4bd22992165 (127.0.0.1:39320).
2020-04-02 05:03:06,807 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7: 3ms
2020-04-02 05:03:06,806 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41758 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,807 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:42246 successfully registered with NN
2020-04-02 05:03:06,807 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42246 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,808 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:41758 successfully registered with NN
2020-04-02 05:03:06,808 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41758 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,810 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:33689 successfully registered with NN
2020-04-02 05:03:06,810 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33689 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,810 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:33689 successfully registered with NN
2020-04-02 05:03:06,811 [Thread-239] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1887098509-172.17.0.17-1585803781423: 26ms
2020-04-02 05:03:06,812 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33689 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,812 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8
2020-04-02 05:03:06,812 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:33689 beginning handshake with NN
2020-04-02 05:03:06,832 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d4fe2c9b-6833-4755-bc87-f815c903357e): finished scanning block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,833 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d4fe2c9b-6833-4755-bc87-f815c903357e): no suitable block pools found to scan.  Waiting 1814399813 ms.
2020-04-02 05:03:06,842 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:42246 beginning handshake with NN
2020-04-02 05:03:06,846 [IPC Server handler 2 on 44914] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954) storage 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:06,846 [IPC Server handler 1 on 33689] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423) storage 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:06,847 [IPC Server handler 2 on 44914] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39976
2020-04-02 05:03:06,847 [IPC Server handler 1 on 33689] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39976
2020-04-02 05:03:06,847 [IPC Server handler 1 on 33689] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 344abacc-81c9-4c09-b257-1bdb0511d8db (127.0.0.1:39976).
2020-04-02 05:03:06,847 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:44914 successfully registered with NN
2020-04-02 05:03:06,848 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44914 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,848 [IPC Server handler 1 on 42246] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423) storage 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:06,848 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:33689 successfully registered with NN
2020-04-02 05:03:06,848 [IPC Server handler 1 on 42246] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39976
2020-04-02 05:03:06,849 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33689 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,849 [IPC Server handler 1 on 42246] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 344abacc-81c9-4c09-b257-1bdb0511d8db (127.0.0.1:39976).
2020-04-02 05:03:06,850 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:42246 successfully registered with NN
2020-04-02 05:03:06,850 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42246 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,851 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1887098509-172.17.0.17-1585803781423 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7
2020-04-02 05:03:06,851 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2): finished scanning block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:06,852 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2): no suitable block pools found to scan.  Waiting 1814399794 ms.
2020-04-02 05:03:06,854 [IPC Server handler 2 on 44914] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 344abacc-81c9-4c09-b257-1bdb0511d8db (127.0.0.1:39976).
2020-04-02 05:03:06,855 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:44914 successfully registered with NN
2020-04-02 05:03:06,855 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44914 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,857 [IPC Server handler 0 on 44914] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954) storage e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:06,857 [IPC Server handler 0 on 44914] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39320
2020-04-02 05:03:06,857 [IPC Server handler 0 on 44914] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e9eb8ddb-a9d5-4ece-a845-c4bd22992165 (127.0.0.1:39320).
2020-04-02 05:03:06,858 [IPC Server handler 1 on 44914] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954) storage e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:06,858 [IPC Server handler 1 on 44914] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45627
2020-04-02 05:03:06,858 [IPC Server handler 1 on 44914] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e71f8f07-b317-454b-94fe-e7315ef3e9de (127.0.0.1:45627).
2020-04-02 05:03:06,859 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:44914 successfully registered with NN
2020-04-02 05:03:06,860 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44914 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,866 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:44914 successfully registered with NN
2020-04-02 05:03:06,866 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44914 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:03:06,887 [IPC Server handler 3 on 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-561d1757-0a55-48fa-93cc-e6956dec9d6b for DN 127.0.0.1:45627
2020-04-02 05:03:06,887 [IPC Server handler 3 on 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba for DN 127.0.0.1:45627
2020-04-02 05:03:06,889 [IPC Server handler 6 on 44914] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 for DN 127.0.0.1:39320
2020-04-02 05:03:06,901 [IPC Server handler 6 on 44914] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-531d16cc-6cf0-4602-8f54-6037bc10249b for DN 127.0.0.1:39320
2020-04-02 05:03:06,895 [IPC Server handler 2 on 33689] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 for DN 127.0.0.1:39976
2020-04-02 05:03:06,901 [IPC Server handler 2 on 33689] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d4fe2c9b-6833-4755-bc87-f815c903357e for DN 127.0.0.1:39976
2020-04-02 05:03:06,935 [IPC Server handler 9 on 44914] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 for DN 127.0.0.1:39976
2020-04-02 05:03:06,936 [IPC Server handler 9 on 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 for DN 127.0.0.1:39976
2020-04-02 05:03:06,939 [IPC Server handler 9 on 44914] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d4fe2c9b-6833-4755-bc87-f815c903357e for DN 127.0.0.1:39976
2020-04-02 05:03:06,940 [IPC Server handler 9 on 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d4fe2c9b-6833-4755-bc87-f815c903357e for DN 127.0.0.1:39976
2020-04-02 05:03:06,942 [IPC Server handler 8 on 44914] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-33d0d0c0-bed6-4788-a4d0-dd647793abff for DN 127.0.0.1:35373
2020-04-02 05:03:06,944 [IPC Server handler 8 on 44914] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 for DN 127.0.0.1:35373
2020-04-02 05:03:06,944 [IPC Server handler 4 on 44914] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-561d1757-0a55-48fa-93cc-e6956dec9d6b for DN 127.0.0.1:45627
2020-04-02 05:03:06,945 [IPC Server handler 4 on 44914] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba for DN 127.0.0.1:45627
2020-04-02 05:03:06,935 [IPC Server handler 4 on 41758] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 for DN 127.0.0.1:39320
2020-04-02 05:03:06,950 [IPC Server handler 4 on 41758] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-531d16cc-6cf0-4602-8f54-6037bc10249b for DN 127.0.0.1:39320
2020-04-02 05:03:06,944 [IPC Server handler 2 on 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 for DN 127.0.0.1:39320
2020-04-02 05:03:06,937 [IPC Server handler 4 on 33689] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-33d0d0c0-bed6-4788-a4d0-dd647793abff for DN 127.0.0.1:35373
2020-04-02 05:03:06,950 [IPC Server handler 2 on 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-531d16cc-6cf0-4602-8f54-6037bc10249b for DN 127.0.0.1:39320
2020-04-02 05:03:06,961 [IPC Server handler 0 on 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-33d0d0c0-bed6-4788-a4d0-dd647793abff for DN 127.0.0.1:35373
2020-04-02 05:03:06,961 [IPC Server handler 4 on 33689] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 for DN 127.0.0.1:35373
2020-04-02 05:03:06,961 [IPC Server handler 2 on 41758] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-561d1757-0a55-48fa-93cc-e6956dec9d6b for DN 127.0.0.1:45627
2020-04-02 05:03:06,961 [IPC Server handler 0 on 42246] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 for DN 127.0.0.1:35373
2020-04-02 05:03:06,990 [IPC Server handler 2 on 41758] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba for DN 127.0.0.1:45627
2020-04-02 05:03:06,992 [IPC Server handler 0 on 41758] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-33d0d0c0-bed6-4788-a4d0-dd647793abff for DN 127.0.0.1:35373
2020-04-02 05:03:06,992 [IPC Server handler 0 on 41758] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 for DN 127.0.0.1:35373
2020-04-02 05:03:06,998 [IPC Server handler 6 on 41758] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 for DN 127.0.0.1:39976
2020-04-02 05:03:06,998 [IPC Server handler 6 on 41758] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d4fe2c9b-6833-4755-bc87-f815c903357e for DN 127.0.0.1:39976
2020-04-02 05:03:07,014 [IPC Server handler 7 on 33689] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 for DN 127.0.0.1:39320
2020-04-02 05:03:07,026 [IPC Server handler 7 on 33689] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-531d16cc-6cf0-4602-8f54-6037bc10249b for DN 127.0.0.1:39320
2020-04-02 05:03:07,020 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6719ad5954eed76b: Processing first storage report for DS-561d1757-0a55-48fa-93cc-e6956dec9d6b from datanode e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:07,041 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6719ad5954eed76b: from storage DS-561d1757-0a55-48fa-93cc-e6956dec9d6b node DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: true, processing time: 21 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,041 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4b4bd42a8bacf22c: Processing first storage report for DS-d4fe2c9b-6833-4755-bc87-f815c903357e from datanode 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:07,041 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4b4bd42a8bacf22c: from storage DS-d4fe2c9b-6833-4755-bc87-f815c903357e node DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,041 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xbfbb0dedb28fa1bd: Processing first storage report for DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 from datanode e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:07,041 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xbfbb0dedb28fa1bd: from storage DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 node DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,042 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c8f98f4c8fbe57f: Processing first storage report for DS-33d0d0c0-bed6-4788-a4d0-dd647793abff from datanode f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:07,042 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c8f98f4c8fbe57f: from storage DS-33d0d0c0-bed6-4788-a4d0-dd647793abff node DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,042 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4b4bd42a8bacf22c: Processing first storage report for DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 from datanode 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:07,042 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4b4bd42a8bacf22c: from storage DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 node DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,042 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xbfbb0dedb28fa1bd: Processing first storage report for DS-531d16cc-6cf0-4602-8f54-6037bc10249b from datanode e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:07,042 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xbfbb0dedb28fa1bd: from storage DS-531d16cc-6cf0-4602-8f54-6037bc10249b node DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,042 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c8f98f4c8fbe57f: Processing first storage report for DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 from datanode f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:07,042 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c8f98f4c8fbe57f: from storage DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 node DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,019 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd7a5b799b3eb64c7: Processing first storage report for DS-d4fe2c9b-6833-4755-bc87-f815c903357e from datanode 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:07,018 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd98ca9d56d48b94d: Processing first storage report for DS-33d0d0c0-bed6-4788-a4d0-dd647793abff from datanode f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:07,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd98ca9d56d48b94d: from storage DS-33d0d0c0-bed6-4788-a4d0-dd647793abff node DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: true, processing time: 26 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9079095c1c05c494: Processing first storage report for DS-d4fe2c9b-6833-4755-bc87-f815c903357e from datanode 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:07,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9079095c1c05c494: from storage DS-d4fe2c9b-6833-4755-bc87-f815c903357e node DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3506ab1d15970ab6: Processing first storage report for DS-561d1757-0a55-48fa-93cc-e6956dec9d6b from datanode e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:07,044 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3506ab1d15970ab6: from storage DS-561d1757-0a55-48fa-93cc-e6956dec9d6b node DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5a692d0b9eadef0f: Processing first storage report for DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 from datanode e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:07,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5a692d0b9eadef0f: from storage DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 node DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd98ca9d56d48b94d: Processing first storage report for DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 from datanode f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:07,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd98ca9d56d48b94d: from storage DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 node DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5a692d0b9eadef0f: Processing first storage report for DS-531d16cc-6cf0-4602-8f54-6037bc10249b from datanode e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:07,045 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5a692d0b9eadef0f: from storage DS-531d16cc-6cf0-4602-8f54-6037bc10249b node DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,043 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd7a5b799b3eb64c7: from storage DS-d4fe2c9b-6833-4755-bc87-f815c903357e node DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: true, processing time: 23 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,037 [IPC Server handler 5 on 33689] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-561d1757-0a55-48fa-93cc-e6956dec9d6b for DN 127.0.0.1:45627
2020-04-02 05:03:07,046 [IPC Server handler 5 on 33689] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba for DN 127.0.0.1:45627
2020-04-02 05:03:07,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6719ad5954eed76b: Processing first storage report for DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba from datanode e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:07,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x65de7cbbf5f34eb5: Processing first storage report for DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 from datanode e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:07,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x65de7cbbf5f34eb5: from storage DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 node DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa177ce377dd49cb8: Processing first storage report for DS-561d1757-0a55-48fa-93cc-e6956dec9d6b from datanode e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:07,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa177ce377dd49cb8: from storage DS-561d1757-0a55-48fa-93cc-e6956dec9d6b node DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xab0940a1316065c2: Processing first storage report for DS-33d0d0c0-bed6-4788-a4d0-dd647793abff from datanode f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:07,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xab0940a1316065c2: from storage DS-33d0d0c0-bed6-4788-a4d0-dd647793abff node DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd7a5b799b3eb64c7: Processing first storage report for DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 from datanode 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:07,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd7a5b799b3eb64c7: from storage DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 node DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa177ce377dd49cb8: Processing first storage report for DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba from datanode e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:07,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa177ce377dd49cb8: from storage DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba node DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,047 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x65de7cbbf5f34eb5: Processing first storage report for DS-531d16cc-6cf0-4602-8f54-6037bc10249b from datanode e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:07,048 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x65de7cbbf5f34eb5: from storage DS-531d16cc-6cf0-4602-8f54-6037bc10249b node DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6719ad5954eed76b: from storage DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba node DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,046 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9079095c1c05c494: Processing first storage report for DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 from datanode 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:07,049 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9079095c1c05c494: from storage DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 node DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,049 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xab0940a1316065c2: Processing first storage report for DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 from datanode f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:07,049 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xacdd60c29911b624: Processing first storage report for DS-d4fe2c9b-6833-4755-bc87-f815c903357e from datanode 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:07,050 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xacdd60c29911b624: from storage DS-d4fe2c9b-6833-4755-bc87-f815c903357e node DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,050 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x28d4c44bdf772d24: Processing first storage report for DS-33d0d0c0-bed6-4788-a4d0-dd647793abff from datanode f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:07,050 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x28d4c44bdf772d24: from storage DS-33d0d0c0-bed6-4788-a4d0-dd647793abff node DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,050 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x989c8459d4b95a9b: Processing first storage report for DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 from datanode e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:07,050 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x989c8459d4b95a9b: from storage DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8 node DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,049 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3506ab1d15970ab6: Processing first storage report for DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba from datanode e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:07,050 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3506ab1d15970ab6: from storage DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba node DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,050 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3d7657093e47302a: Processing first storage report for DS-561d1757-0a55-48fa-93cc-e6956dec9d6b from datanode e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:07,051 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3d7657093e47302a: from storage DS-561d1757-0a55-48fa-93cc-e6956dec9d6b node DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,051 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x989c8459d4b95a9b: Processing first storage report for DS-531d16cc-6cf0-4602-8f54-6037bc10249b from datanode e9eb8ddb-a9d5-4ece-a845-c4bd22992165
2020-04-02 05:03:07,051 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x989c8459d4b95a9b: from storage DS-531d16cc-6cf0-4602-8f54-6037bc10249b node DatanodeRegistration(127.0.0.1:39320, datanodeUuid=e9eb8ddb-a9d5-4ece-a845-c4bd22992165, infoPort=44220, infoSecurePort=0, ipcPort=42086, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,051 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xacdd60c29911b624: Processing first storage report for DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 from datanode 344abacc-81c9-4c09-b257-1bdb0511d8db
2020-04-02 05:03:07,051 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xacdd60c29911b624: from storage DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2 node DatanodeRegistration(127.0.0.1:39976, datanodeUuid=344abacc-81c9-4c09-b257-1bdb0511d8db, infoPort=40751, infoSecurePort=0, ipcPort=44963, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,051 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x28d4c44bdf772d24: Processing first storage report for DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 from datanode f64b03c7-b23c-44d1-8521-8915971f7ff5
2020-04-02 05:03:07,051 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x28d4c44bdf772d24: from storage DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 node DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,051 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3d7657093e47302a: Processing first storage report for DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba from datanode e71f8f07-b317-454b-94fe-e7315ef3e9de
2020-04-02 05:03:07,051 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3d7657093e47302a: from storage DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba node DatanodeRegistration(127.0.0.1:45627, datanodeUuid=e71f8f07-b317-454b-94fe-e7315ef3e9de, infoPort=44930, infoSecurePort=0, ipcPort=38704, storageInfo=lv=-57;cid=testClusterID;nsid=886978301;c=1585803781423), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,049 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xab0940a1316065c2: from storage DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5 node DatanodeRegistration(127.0.0.1:35373, datanodeUuid=f64b03c7-b23c-44d1-8521-8915971f7ff5, infoPort=41699, infoSecurePort=0, ipcPort=33205, storageInfo=lv=-57;cid=testClusterID;nsid=758218973;c=1585803783954), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:03:07,100 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x28d4c44bdf772d24,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 93 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,100 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xacdd60c29911b624,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 52 msec to generate and 123 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,100 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x3d7657093e47302a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 53 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,101 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x989c8459d4b95a9b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 63 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,143 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x3506ab1d15970ab6,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 99 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,143 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xab0940a1316065c2,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 82 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,147 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x65de7cbbf5f34eb5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 40 msec to generate and 124 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,147 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5a692d0b9eadef0f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 106 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,150 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x4b4bd42a8bacf22c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 139 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,154 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd98ca9d56d48b94d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 106 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,154 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x6719ad5954eed76b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 44 msec to generate and 128 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,154 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa177ce377dd49cb8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 124 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,155 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xbfbb0dedb28fa1bd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 97 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,155 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd7a5b799b3eb64c7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 117 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,155 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9c8f98f4c8fbe57f,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 96 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,156 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9079095c1c05c494,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 111 msecs for RPC and NN processing. Got back no commands.
2020-04-02 05:03:07,158 [IPC Server handler 0 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,197 [IPC Server handler 1 on 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,204 [IPC Server handler 9 on 41758] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,215 [IPC Server handler 0 on 44914] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,216 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:07,227 [IPC Server handler 1 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,246 [IPC Server handler 3 on 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,251 [IPC Server handler 5 on 41758] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,256 [IPC Server handler 1 on 44914] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,258 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:03:07,295 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:07,297 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,298 [Socket Reader #1 for port 36705] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36705
2020-04-02 05:03:07,306 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:07,306 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:07,306 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:07,319 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:07,320 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,321 [Socket Reader #1 for port 36183] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36183
2020-04-02 05:03:07,327 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:07,330 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:07,330 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:07,330 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:07,330 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:07,331 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:07,343 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore
2020-04-02 05:03:07,343 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:07,346 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC
2020-04-02 05:03:07,351 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,351 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,352 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,352 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33865
2020-04-02 05:03:07,352 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,353 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,353 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,353 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42358
2020-04-02 05:03:07,353 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,354 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,354 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,354 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:39735
2020-04-02 05:03:07,354 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,354 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,355 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,355 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:40540
2020-04-02 05:03:07,367 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:07,368 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,372 [Socket Reader #1 for port 37337] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37337
2020-04-02 05:03:07,377 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:07,377 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:07,377 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:07,379 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:07,379 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,380 [Socket Reader #1 for port 43811] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43811
2020-04-02 05:03:07,384 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:07,384 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:07,384 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:07,384 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:07,384 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:07,385 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:07,386 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-1
2020-04-02 05:03:07,386 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:07,387 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-1
2020-04-02 05:03:07,388 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,388 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,388 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,388 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33865
2020-04-02 05:03:07,388 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,388 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,388 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,389 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42358
2020-04-02 05:03:07,389 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,389 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,389 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,389 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:39735
2020-04-02 05:03:07,389 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,390 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,390 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,390 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:40540
2020-04-02 05:03:07,402 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:07,404 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,404 [Socket Reader #1 for port 37424] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37424
2020-04-02 05:03:07,409 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:07,409 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:07,409 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:07,411 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:07,412 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,412 [Socket Reader #1 for port 43074] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43074
2020-04-02 05:03:07,416 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:07,416 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:07,417 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:07,417 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:07,417 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:07,417 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:07,418 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-2
2020-04-02 05:03:07,418 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:07,419 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-2
2020-04-02 05:03:07,420 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,420 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,420 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,420 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33865
2020-04-02 05:03:07,420 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,420 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,420 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,421 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42358
2020-04-02 05:03:07,421 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,421 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,421 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,421 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:39735
2020-04-02 05:03:07,423 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,423 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,423 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,423 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:40540
2020-04-02 05:03:07,434 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:<init>(250)) - RPC server binding to /0.0.0.0:0 with 10 handlers for Router null
2020-04-02 05:03:07,435 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,436 [Socket Reader #1 for port 38944] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38944
2020-04-02 05:03:07,439 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(120)) - Cleaning connection pools every 60 seconds
2020-04-02 05:03:07,439 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:<init>(125)) - Cleaning connections every 10 seconds
2020-04-02 05:03:07,439 [JUnit] INFO  router.ConnectionManager (ConnectionManager.java:start(139)) - Cleaning every 10 seconds
2020-04-02 05:03:07,441 [JUnit] INFO  router.RouterAdminServer (RouterAdminServer.java:<init>(132)) - Admin server binding to 0.0.0.0:0
2020-04-02 05:03:07,442 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 100 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:03:07,443 [Socket Reader #1 for port 45639] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45639
2020-04-02 05:03:07,448 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:07,449 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns0
2020-04-02 05:03:07,449 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns0
2020-04-02 05:03:07,449 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn0 in ns1
2020-04-02 05:03:07,449 [JUnit] INFO  router.Router (Router.java:createNamenodeHearbeatService(488)) - Creating heartbeat service for Namenode nn1 in ns1
2020-04-02 05:03:07,450 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - Router metrics system started (again)
2020-04-02 05:03:07,451 [JUnit] INFO  store.StateStoreService (StateStoreService.java:serviceInit(185)) - Registered StateStoreMBean: Hadoop:service=Router,name=StateStore-3
2020-04-02 05:03:07,451 [JUnit] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.federation.router.cache.ttl(5000) assuming MILLISECONDS
2020-04-02 05:03:07,452 [JUnit] INFO  metrics.FederationRPCPerformanceMonitor (FederationRPCPerformanceMonitor.java:init(91)) - Registered FederationRPCMBean: Hadoop:service=Router,name=FederationRPC-3
2020-04-02 05:03:07,452 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn0 RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,452 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn0 Service RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,452 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn0 Lifeline RPC address: 127.0.0.1:41758
2020-04-02 05:03:07,452 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn0 Web address: 127.0.0.1:33865
2020-04-02 05:03:07,453 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns1-nn1 RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,453 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns1-nn1 Service RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,453 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns1-nn1 Lifeline RPC address: 127.0.0.1:44914
2020-04-02 05:03:07,453 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns1-nn1 Web address: 127.0.0.1:39735
2020-04-02 05:03:07,453 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn0 RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,453 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn0 Service RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,453 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn0 Lifeline RPC address: 127.0.0.1:33689
2020-04-02 05:03:07,453 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn0 Web address: 127.0.0.1:42358
2020-04-02 05:03:07,454 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(124)) - ns0-nn1 RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,454 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(134)) - ns0-nn1 Service RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,454 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(142)) - ns0-nn1 Lifeline RPC address: 127.0.0.1:42246
2020-04-02 05:03:07,454 [JUnit] INFO  router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:serviceInit(147)) - ns0-nn1 Web address: 127.0.0.1:40540
2020-04-02 05:03:07,459 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:36705: State Store unavailable
2020-04-02 05:03:07,462 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:07,462 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5f577419] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:07,465 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete.createCluster(TestRouterHDFSContractDelete.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:07,467 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:07,467 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:07,468 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:07,468 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:07,469 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:07,469 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:07,472 [IPC Server listener on 36705] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36705: starting
2020-04-02 05:03:07,470 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:07,477 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:36705
2020-04-02 05:03:07,470 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:07,478 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:07,479 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:07,480 [IPC Server listener on 36183] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36183: starting
2020-04-02 05:03:07,481 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:07,482 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:07,482 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:07,483 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:07,485 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:07,486 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:07,486 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:07,488 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:07,488 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:07,488 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:07,488 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:07,492 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:07,492 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:07,492 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40527
2020-04-02 05:03:07,493 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:07,495 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5cad8b7d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:07,495 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25243bc1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:07,501 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e27ba81{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:07,501 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@54336c81{HTTP/1.1,[http/1.1]}{0.0.0.0:40527}
2020-04-02 05:03:07,502 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8525ms
2020-04-02 05:03:07,502 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:07,502 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:07,502 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:07,503 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:07,503 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:07,514 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:36705: State Store unavailable
2020-04-02 05:03:07,517 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-4
2020-04-02 05:03:07,518 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-4
2020-04-02 05:03:07,520 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-4
2020-04-02 05:03:07,520 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-4
2020-04-02 05:03:07,524 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState
2020-04-02 05:03:07,524 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:07,524 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete.createCluster(TestRouterHDFSContractDelete.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:07,525 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:07,528 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:07,528 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:07,526 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:37337: State Store unavailable
2020-04-02 05:03:07,528 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:07,528 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:07,531 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e5bfdfc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:07,534 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:07,537 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:07,541 [IPC Server listener on 37337] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37337: starting
2020-04-02 05:03:07,538 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:07,541 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:07,544 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:37337
2020-04-02 05:03:07,544 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:07,544 [IPC Server listener on 43811] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43811: starting
2020-04-02 05:03:07,544 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:07,546 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:07,547 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:07,548 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:07,549 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:07,545 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:07,553 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:07,555 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:07,555 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:07,555 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:07,556 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:07,557 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:07,557 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:07,558 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33920
2020-04-02 05:03:07,558 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:07,560 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a1d3c1a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:07,560 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@159e366{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:07,565 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e34c607{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:07,576 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5215cd9a{HTTP/1.1,[http/1.1]}{0.0.0.0:33920}
2020-04-02 05:03:07,576 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8599ms
2020-04-02 05:03:07,577 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:07,577 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:07,577 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:07,578 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:07,578 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:07,581 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:37337: State Store unavailable
2020-04-02 05:03:07,581 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-5
2020-04-02 05:03:07,581 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-5
2020-04-02 05:03:07,582 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-5
2020-04-02 05:03:07,582 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-5
2020-04-02 05:03:07,582 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-1
2020-04-02 05:03:07,583 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:07,583 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:37424: State Store unavailable
2020-04-02 05:03:07,583 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete.createCluster(TestRouterHDFSContractDelete.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:07,584 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:07,584 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:07,584 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:07,583 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@aa5455e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:07,588 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:07,588 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:07,590 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:07,591 [IPC Server listener on 37424] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37424: starting
2020-04-02 05:03:07,591 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:07,593 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:37424
2020-04-02 05:03:07,594 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:07,594 [IPC Server listener on 43074] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43074: starting
2020-04-02 05:03:07,596 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:07,598 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:07,599 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:07,612 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:07,613 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:07,613 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:07,615 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:07,640 [IPC Server handler 0 on 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,640 [IPC Server handler 7 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,643 [IPC Server handler 8 on 44914] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,648 [IPC Server handler 0 on 41758] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,654 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:07,654 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:07,655 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:07,656 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:07,656 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:07,656 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:07,660 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:07,660 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:07,661 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34938
2020-04-02 05:03:07,661 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:07,664 [IPC Server handler 2 on 44914] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,668 [IPC Server handler 6 on 41758] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,669 [IPC Server handler 7 on 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,673 [IPC Server handler 5 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,682 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bbbdd4b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:07,683 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@25230246{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:07,761 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@12365c88{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:07,765 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6105f8a3{HTTP/1.1,[http/1.1]}{0.0.0.0:34938}
2020-04-02 05:03:07,765 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8788ms
2020-04-02 05:03:07,766 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:07,772 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:07,773 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:07,773 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:07,774 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:07,774 [IPC Server handler 3 on 41758] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,776 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:37424: State Store unavailable
2020-04-02 05:03:07,776 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-6
2020-04-02 05:03:07,776 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-6
2020-04-02 05:03:07,776 [IPC Server handler 5 on 44914] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,777 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-6
2020-04-02 05:03:07,776 [IPC Server handler 8 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,777 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-6
2020-04-02 05:03:07,778 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-2
2020-04-02 05:03:07,778 [IPC Server handler 5 on 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,779 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:38944: State Store unavailable
2020-04-02 05:03:07,779 [JUnit] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:07,779 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@64d7b720] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:03:07,779 [JUnit] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.serviceStart(StateStoreService.java:197)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.service.CompositeService.serviceStart(CompositeService.java:121)
	at org.apache.hadoop.hdfs.server.federation.router.Router.serviceStart(Router.java:265)
	at org.apache.hadoop.service.AbstractService.start(AbstractService.java:194)
	at org.apache.hadoop.hdfs.server.federation.MiniRouterDFSCluster.startRouters(MiniRouterDFSCluster.java:757)
	at org.apache.hadoop.fs.contract.router.RouterHDFSContract.createCluster(RouterHDFSContract.java:53)
	at org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete.createCluster(TestRouterHDFSContractDelete.java:37)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:24)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:377)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:138)
	at org.apache.maven.surefire.booter.ForkedBooter.run(ForkedBooter.java:465)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:451)
2020-04-02 05:03:07,785 [JUnit] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:07,785 [JUnit] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:07,786 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:07,791 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service StateStoreCacheUpdateService
2020-04-02 05:03:07,791 [StateStoreConnectionMonitorService-0] INFO  store.StateStoreConnectionMonitorService (StateStoreConnectionMonitorService.java:periodicInvoke(63)) - Attempting to open state store driver.
2020-04-02 05:03:07,796 [StateStoreConnectionMonitorService-0] INFO  impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(80)) - Initializing ZooKeeper connection
2020-04-02 05:03:07,796 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:07,796 [StateStoreConnectionMonitorService-0] ERROR impl.StateStoreZooKeeperImpl (StateStoreZooKeeperImpl.java:initDriver(91)) - Cannot initialize the ZK connection
java.io.IOException: hadoop.zk.address is not configured.
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:128)
	at org.apache.hadoop.util.curator.ZKCuratorManager.start(ZKCuratorManager.java:115)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreZooKeeperImpl.initDriver(StateStoreZooKeeperImpl.java:88)
	at org.apache.hadoop.hdfs.server.federation.store.driver.StateStoreDriver.init(StateStoreDriver.java:74)
	at org.apache.hadoop.hdfs.server.federation.store.driver.impl.StateStoreSerializableImpl.init(StateStoreSerializableImpl.java:47)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreService.loadDriver(StateStoreService.java:273)
	at org.apache.hadoop.hdfs.server.federation.store.StateStoreConnectionMonitorService.periodicInvoke(StateStoreConnectionMonitorService.java:64)
	at org.apache.hadoop.hdfs.server.federation.router.PeriodicService$1.run(PeriodicService.java:178)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:03:07,796 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:07,797 [JUnit] INFO  router.RouterRpcServer (RouterRpcServer.java:serviceStart(321)) - Router RPC up at: /0.0.0.0:38944
2020-04-02 05:03:07,796 [IPC Server listener on 38944] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38944: starting
2020-04-02 05:03:07,797 [StateStoreConnectionMonitorService-0] ERROR driver.StateStoreDriver (StateStoreDriver.java:init(76)) - Cannot initialize driver for StateStoreZooKeeperImpl
2020-04-02 05:03:07,798 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:03:07,798 [StateStoreConnectionMonitorService-0] ERROR store.StateStoreService (StateStoreService.java:loadDriver(279)) - Cannot initialize State Store driver StateStoreZooKeeperImpl
2020-04-02 05:03:07,799 [IPC Server listener on 45639] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45639: starting
2020-04-02 05:03:07,804 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for router at: http://0.0.0.0:0
2020-04-02 05:03:07,804 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:07,806 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:03:07,806 [JUnit] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.router is not defined
2020-04-02 05:03:07,806 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:03:07,807 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:03:07,808 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context router
2020-04-02 05:03:07,808 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:03:07,808 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:03:07,809 [JUnit] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:03:07,809 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.federation.router;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:03:07,809 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44140
2020-04-02 05:03:07,809 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:03:07,811 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@51671b08{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,AVAILABLE}
2020-04-02 05:03:07,812 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1162410a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:03:07,816 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@232024b9{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/router/,AVAILABLE}{/router}
2020-04-02 05:03:07,822 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ec1a32c{HTTP/1.1,[http/1.1]}{0.0.0.0:44140}
2020-04-02 05:03:07,824 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @8847ms
2020-04-02 05:03:07,824 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:07,824 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:07,825 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:07,825 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:07,825 [JUnit] INFO  router.PeriodicService (PeriodicService.java:serviceStart(141)) - Starting periodic service RouterHeartbeatService
2020-04-02 05:03:07,827 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(117)) - Registered FSNamesystem MBean: Hadoop:service=NameNode,name=FSNamesystem-7
2020-04-02 05:03:07,828 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(126)) - Registered FSNamesystemState MBean: Hadoop:service=NameNode,name=FSNamesystemState-7
2020-04-02 05:03:07,828 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(134)) - Registered NameNodeInfo MBean: Hadoop:service=NameNode,name=NameNodeInfo-7
2020-04-02 05:03:07,828 [JUnit] INFO  metrics.NamenodeBeanMetrics (NamenodeBeanMetrics.java:<init>(143)) - Registered NameNodeStatus MBean: Hadoop:service=NameNode,name=NameNodeStatus-7
2020-04-02 05:03:07,828 [JUnit] INFO  metrics.FederationMetrics (FederationMetrics.java:<init>(126)) - Registered Router MBean: Hadoop:service=Router,name=FederationState-3
2020-04-02 05:03:07,830 [IPC Server handler 0 on 44914] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,834 [IPC Server handler 1 on 41758] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,836 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:38944: State Store unavailable
2020-04-02 05:03:07,845 [IPC Server handler 6 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,850 [IPC Server handler 1 on 42246] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=safemode_get	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:03:07,883 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:07,884 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:07,885 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:07,887 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current
2020-04-02 05:03:07,887 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current
2020-04-02 05:03:07,887 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current
2020-04-02 05:03:07,888 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:07,889 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:07,961 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:07,961 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:07,962 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:07,984 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:08,070 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:08,084 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 14 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:08,116 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:08,121 [CacheReplicationMonitor(650842694)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:03:08,121 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:08,121 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:08,126 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:08,126 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:08,126 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:08,126 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:08,126 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:03:08,129 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current
2020-04-02 05:03:08,130 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current
2020-04-02 05:03:08,130 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current
2020-04-02 05:03:08,131 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1225)) - Catching up to latest edits from old active before taking over writer role in edits logs
2020-04-02 05:03:08,134 [JUnit] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:markAllDatanodesStale(1840)) - Marking all datanodes as stale
2020-04-02 05:03:08,136 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 165 msec
2020-04-02 05:03:08,168 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1236)) - Reprocessing replication and invalidation queues
2020-04-02 05:03:08,169 [JUnit] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:03:08,173 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1247)) - Will take over writing edit logs at txnid 1
2020-04-02 05:03:08,188 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:03:08,309 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:03:08,312 [JUnit] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 2 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:03:08,322 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:03:08,323 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:03:08,323 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:03:08,331 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:03:08,331 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:03:08,331 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 158 msec
2020-04-02 05:03:08,327 [CacheReplicationMonitor(603476104)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonEmptyDirNonRecursive
[msx] unitTestCounterInClass = 0
2020-04-02 05:03:09,352 [Thread-477] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:37337 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1156947707_1326, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:09,393 [IPC Server handler 4 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:09,427 [IPC Server handler 2 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testDeleteNonEmptyDirNonRecursive	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:09,473 [IPC Server handler 7 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testDeleteNonEmptyDirNonRecursive/childfile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:09,524 [IPC Server handler 5 on 33689] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:39320, 127.0.0.1:39976, 127.0.0.1:45627 for /test/testDeleteNonEmptyDirNonRecursive/childfile
2020-04-02 05:03:09,603 [DataXceiver for client DFSClient_NONMAPREDUCE_-1156947707_1326 at /127.0.0.1:58326 [Receiving block BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001 src: /127.0.0.1:58326 dest: /127.0.0.1:39320
2020-04-02 05:03:09,632 [DataXceiver for client DFSClient_NONMAPREDUCE_-1156947707_1326 at /127.0.0.1:60434 [Receiving block BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001 src: /127.0.0.1:60434 dest: /127.0.0.1:39976
2020-04-02 05:03:09,650 [DataXceiver for client DFSClient_NONMAPREDUCE_-1156947707_1326 at /127.0.0.1:45848 [Receiving block BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001 src: /127.0.0.1:45848 dest: /127.0.0.1:45627
2020-04-02 05:03:09,732 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45848, dest: /127.0.0.1:45627, bytes: 14, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1156947707_1326, offset: 0, srvID: e71f8f07-b317-454b-94fe-e7315ef3e9de, blockid: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, duration(ns): 52934027
2020-04-02 05:03:09,733 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:09,737 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45627]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60434, dest: /127.0.0.1:39976, bytes: 14, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1156947707_1326, offset: 0, srvID: 344abacc-81c9-4c09-b257-1bdb0511d8db, blockid: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, duration(ns): 62257170
2020-04-02 05:03:09,738 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45627]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45627] terminating
2020-04-02 05:03:09,743 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39976, 127.0.0.1:45627]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58326, dest: /127.0.0.1:39320, bytes: 14, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1156947707_1326, offset: 0, srvID: e9eb8ddb-a9d5-4ece-a845-c4bd22992165, blockid: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, duration(ns): 68066405
2020-04-02 05:03:09,743 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39976, 127.0.0.1:45627]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39976, 127.0.0.1:45627] terminating
2020-04-02 05:03:09,755 [IPC Server handler 8 on 33689] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test/testDeleteNonEmptyDirNonRecursive/childfile
2020-04-02 05:03:09,769 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:33689 trying to claim ACTIVE state with txid=7
2020-04-02 05:03:09,770 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:33689
2020-04-02 05:03:09,794 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:41758 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:09,794 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:41758
2020-04-02 05:03:09,821 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:41758 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:09,822 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:41758
2020-04-02 05:03:09,825 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:41758 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:09,825 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:41758
2020-04-02 05:03:09,833 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:33689 trying to claim ACTIVE state with txid=7
2020-04-02 05:03:09,834 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:33689
2020-04-02 05:03:09,834 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:33689 trying to claim ACTIVE state with txid=7
2020-04-02 05:03:09,834 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:33689
2020-04-02 05:03:09,835 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:41758 trying to claim ACTIVE state with txid=1
2020-04-02 05:03:09,835 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:41758
2020-04-02 05:03:09,855 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(576)) - Namenode Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:33689 trying to claim ACTIVE state with txid=7
2020-04-02 05:03:09,855 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BPOfferService.java:updateActorStatesFromHeartbeat(588)) - Acknowledging ACTIVE Namenode Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:33689
2020-04-02 05:03:10,167 [IPC Server handler 5 on 33689] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testDeleteNonEmptyDirNonRecursive/childfile is closed by DFSClient_NONMAPREDUCE_-1156947707_1326
2020-04-02 05:03:10,177 [IPC Server handler 9 on 33689] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 9 on 33689, call Call#157 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 127.0.0.1:34939
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/test/testDeleteNonEmptyDirNonRecursive is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2998)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:03:10,182 [IPC Server handler 1 on 37337] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 1 on 37337, call Call#156 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.delete from 172.17.0.17:60762
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: ```/test/testDeleteNonEmptyDirNonRecursive is non empty': Directory is not empty': Directory is not empty: `/test/testDeleteNonEmptyDirNonRecursive is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2998)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2998)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2998)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.fs.PathIsNotEmptyDirectoryException): `/test/testDeleteNonEmptyDirNonRecursive is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2998)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy27.delete(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.delete(ClientNamenodeProtocolTranslatorPB.java:634)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hdfs.server.federation.router.RouterRpcClient.invoke(RouterRpcClient.java:449)
	at org.apache.hadoop.hdfs.server.federation.router.RouterRpcClient.invokeMethod(RouterRpcClient.java:366)
	at org.apache.hadoop.hdfs.server.federation.router.RouterRpcClient.invokeSequential(RouterRpcClient.java:732)
	at org.apache.hadoop.hdfs.server.federation.router.RouterClientProtocol.delete(RouterClientProtocol.java:547)
	at org.apache.hadoop.hdfs.server.federation.router.RouterRpcServer.delete(RouterRpcServer.java:684)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.delete(ClientNamenodeProtocolServerSideTranslatorPB.java:692)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	... 3 more
2020-04-02 05:03:10,192 [IPC Server handler 3 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteNonEmptyDirNonRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,197 [IPC Server handler 6 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,203 [IPC Server handler 0 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonEmptyDirNonRecursive
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonEmptyDirNonRecursive
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteDeepEmptyDir
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,220 [Thread-489] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:36705 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_98083774_1338, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,248 [IPC Server handler 8 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,272 [IPC Server handler 1 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testDeleteDeepEmptyDir/d1/d2/d3/d4	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,278 [IPC Server handler 4 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteDeepEmptyDir/d1/d2/d3	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,285 [IPC Server handler 2 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testDeleteDeepEmptyDir/d1/d2/d3	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,290 [IPC Server handler 7 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test/testDeleteDeepEmptyDir/d1/d2	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,296 [IPC Server handler 5 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteDeepEmptyDir/d1/d2/d3	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,299 [IPC Server handler 9 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteDeepEmptyDir/d1/d2/d3/d4	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,301 [IPC Server handler 3 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteDeepEmptyDir/d1/d2/d3	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,303 [IPC Server handler 6 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteDeepEmptyDir/d1/d2	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,305 [IPC Server handler 0 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,307 [IPC Server handler 8 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteDeepEmptyDir
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteDeepEmptyDir
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteSingleFile
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,325 [Thread-492] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:37337 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1156947707_1326, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,330 [IPC Server handler 1 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,336 [IPC Server handler 4 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testDeleteSingleFile/d1/d2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,341 [IPC Server handler 2 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testDeleteSingleFile/d1/d2/childfile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:10,354 [IPC Server handler 7 on 33689] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:39320, 127.0.0.1:45627, 127.0.0.1:35373 for /test/testDeleteSingleFile/d1/d2/childfile
2020-04-02 05:03:10,374 [DataXceiver for client DFSClient_NONMAPREDUCE_-1156947707_1326 at /127.0.0.1:58366 [Receiving block BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002 src: /127.0.0.1:58366 dest: /127.0.0.1:39320
2020-04-02 05:03:10,378 [DataXceiver for client DFSClient_NONMAPREDUCE_-1156947707_1326 at /127.0.0.1:45888 [Receiving block BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002 src: /127.0.0.1:45888 dest: /127.0.0.1:45627
2020-04-02 05:03:10,381 [DataXceiver for client DFSClient_NONMAPREDUCE_-1156947707_1326 at /127.0.0.1:58336 [Receiving block BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002 src: /127.0.0.1:58336 dest: /127.0.0.1:35373
2020-04-02 05:03:10,432 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58336, dest: /127.0.0.1:35373, bytes: 26, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1156947707_1326, offset: 0, srvID: f64b03c7-b23c-44d1-8521-8915971f7ff5, blockid: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, duration(ns): 48353877
2020-04-02 05:03:10,433 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:10,447 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35373]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45888, dest: /127.0.0.1:45627, bytes: 26, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1156947707_1326, offset: 0, srvID: e71f8f07-b317-454b-94fe-e7315ef3e9de, blockid: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, duration(ns): 58156141
2020-04-02 05:03:10,448 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35373]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:35373] terminating
2020-04-02 05:03:10,463 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45627, 127.0.0.1:35373]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58366, dest: /127.0.0.1:39320, bytes: 26, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1156947707_1326, offset: 0, srvID: e9eb8ddb-a9d5-4ece-a845-c4bd22992165, blockid: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, duration(ns): 77573097
2020-04-02 05:03:10,463 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45627, 127.0.0.1:35373]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:45627, 127.0.0.1:35373] terminating
2020-04-02 05:03:10,467 [IPC Server handler 6 on 33689] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testDeleteSingleFile/d1/d2/childfile is closed by DFSClient_NONMAPREDUCE_-1156947707_1326
2020-04-02 05:03:10,484 [IPC Server handler 0 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteSingleFile/d1/d2/childfile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,487 [IPC Server handler 8 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteSingleFile/d1/d2/childfile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,491 [IPC Server handler 1 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testDeleteSingleFile/d1/d2/childfile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,493 [IPC Server handler 4 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test/testDeleteSingleFile/d1/d2	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,495 [IPC Server handler 2 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteSingleFile/d1/d2/childfile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,500 [IPC Server handler 7 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,504 [IPC Server handler 5 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteSingleFile
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteSingleFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonEmptyDirRecursive
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,513 [Thread-501] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:37424 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1762489881_1350, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,526 [IPC Server handler 9 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,532 [IPC Server handler 3 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testDeleteNonEmptyDirNonRecursive	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,535 [IPC Server handler 6 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/testDeleteNonEmptyDirNonRecursive/childfile	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:03:10,543 [IPC Server handler 0 on 33689] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:39320, 127.0.0.1:39976, 127.0.0.1:45627 for /test/testDeleteNonEmptyDirNonRecursive/childfile
2020-04-02 05:03:10,550 [DataXceiver for client DFSClient_NONMAPREDUCE_-1762489881_1350 at /127.0.0.1:58388 [Receiving block BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003 src: /127.0.0.1:58388 dest: /127.0.0.1:39320
2020-04-02 05:03:10,553 [DataXceiver for client DFSClient_NONMAPREDUCE_-1762489881_1350 at /127.0.0.1:60518 [Receiving block BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003 src: /127.0.0.1:60518 dest: /127.0.0.1:39976
2020-04-02 05:03:10,556 [DataXceiver for client DFSClient_NONMAPREDUCE_-1762489881_1350 at /127.0.0.1:45932 [Receiving block BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003 src: /127.0.0.1:45932 dest: /127.0.0.1:45627
2020-04-02 05:03:10,572 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45932, dest: /127.0.0.1:45627, bytes: 14, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1762489881_1350, offset: 0, srvID: e71f8f07-b317-454b-94fe-e7315ef3e9de, blockid: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, duration(ns): 13697077
2020-04-02 05:03:10,573 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:03:10,575 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45627]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60518, dest: /127.0.0.1:39976, bytes: 14, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1762489881_1350, offset: 0, srvID: 344abacc-81c9-4c09-b257-1bdb0511d8db, blockid: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, duration(ns): 15769892
2020-04-02 05:03:10,575 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45627]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:45627] terminating
2020-04-02 05:03:10,578 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39976, 127.0.0.1:45627]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58388, dest: /127.0.0.1:39320, bytes: 14, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1762489881_1350, offset: 0, srvID: e9eb8ddb-a9d5-4ece-a845-c4bd22992165, blockid: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, duration(ns): 17444000
2020-04-02 05:03:10,578 [PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39976, 127.0.0.1:45627]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1887098509-172.17.0.17-1585803781423:blk_1073741827_1003, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=2:[127.0.0.1:39976, 127.0.0.1:45627] terminating
2020-04-02 05:03:10,581 [IPC Server handler 7 on 33689] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/testDeleteNonEmptyDirNonRecursive/childfile is closed by DFSClient_NONMAPREDUCE_-1762489881_1350
2020-04-02 05:03:10,591 [IPC Server handler 5 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteNonEmptyDirNonRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,595 [IPC Server handler 9 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testDeleteNonEmptyDirNonRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,598 [IPC Server handler 3 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,600 [IPC Server handler 6 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteNonEmptyDirNonRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,603 [IPC Server handler 0 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteNonEmptyDirNonRecursive/childfile	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,606 [IPC Server handler 8 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,612 [IPC Server handler 1 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonEmptyDirRecursive
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonEmptyDirRecursive
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonexistentPathRecursive
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,622 [Thread-513] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:38944 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_29042001_1362, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,635 [IPC Server handler 4 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,642 [IPC Server handler 2 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteNonexistentPathRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,645 [IPC Server handler 7 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testDeleteNonexistentPathRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,654 [IPC Server handler 5 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,658 [IPC Server handler 9 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonexistentPathRecursive
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonexistentPathRecursive
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonexistentPathNonRecursive
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,670 [Thread-516] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:36705 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_98083774_1338, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,677 [IPC Server handler 3 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,680 [IPC Server handler 6 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteNonexistentPathNonRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,682 [IPC Server handler 0 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testDeleteNonexistentPathNonRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,684 [IPC Server handler 8 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,686 [IPC Server handler 1 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonexistentPathNonRecursive
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteNonexistentPathNonRecursive
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteEmptyDirRecursive
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,696 [Thread-517] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:36705 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_98083774_1338, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,699 [IPC Server handler 4 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,705 [IPC Server handler 2 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testDeleteEmptyDirRecursive	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,709 [IPC Server handler 7 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteEmptyDirRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,711 [IPC Server handler 5 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testDeleteEmptyDirRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,713 [IPC Server handler 9 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,715 [IPC Server handler 3 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteEmptyDirRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,717 [IPC Server handler 6 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,719 [IPC Server handler 0 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteEmptyDirRecursive
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteEmptyDirRecursive
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteEmptyDirNonRecursive
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,727 [Thread-518] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = hdfs://0.0.0.0:37424 implemented by DFS[DFSClient[clientName=DFSClient_NONMAPREDUCE_-1762489881_1350, ugi=root (auth:SIMPLE)]]
2020-04-02 05:03:10,729 [IPC Server handler 8 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,731 [IPC Server handler 1 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/testDeleteEmptyDirNonRecursive	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:03:10,733 [IPC Server handler 4 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteEmptyDirNonRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,735 [IPC Server handler 2 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test/testDeleteEmptyDirNonRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,737 [IPC Server handler 7 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,739 [IPC Server handler 5 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/testDeleteEmptyDirNonRecursive	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,741 [IPC Server handler 9 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test	dst=null	perm=null	proto=rpc
2020-04-02 05:03:10,744 [IPC Server handler 3 on 33689] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/test	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteEmptyDirNonRecursive
[msx] writeFile testName = org.apache.hadoop.fs.contract.router.TestRouterHDFSContractDelete#testDeleteEmptyDirNonRecursive
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:03:10,745 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:03:10,746 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:03:10,746 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44963 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:10,746 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:10,746 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@51768776] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:10,752 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8, DS-d4fe2c9b-6833-4755-bc87-f815c903357e) exiting.
2020-04-02 05:03:10,752 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7, DS-ae50cc0e-5ba2-4b07-823a-d0e1fb7a23f2) exiting.
2020-04-02 05:03:10,775 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@72efb5c1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:10,778 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d511b5f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:10,778 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3a0807b7{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:10,779 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d1f74b8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:10,782 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44963
2020-04-02 05:03:10,796 [IPC Server listener on 44963] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44963
2020-04-02 05:03:10,801 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:10,814 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:10,815 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:44914
2020-04-02 05:03:10,801 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:10,816 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:33689
2020-04-02 05:03:10,814 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:10,801 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:10,816 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:41758
2020-04-02 05:03:10,817 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db)
2020-04-02 05:03:10,817 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:10,816 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db) service to localhost/127.0.0.1:42246
2020-04-02 05:03:10,822 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid 344abacc-81c9-4c09-b257-1bdb0511d8db)
2020-04-02 05:03:10,829 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-244807914-172.17.0.17-1585803783954] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:10,837 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-244807914-172.17.0.17-1585803783954] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:10,839 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:10,851 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data7/current/BP-1887098509-172.17.0.17-1585803781423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:10,861 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data8/current/BP-1887098509-172.17.0.17-1585803781423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:10,872 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:10,872 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:10,873 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:10,874 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:10,884 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:10,885 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:03:10,885 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42086 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:10,885 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:10,885 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@bc57b40] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:10,886 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6, DS-531d16cc-6cf0-4602-8f54-6037bc10249b) exiting.
2020-04-02 05:03:10,886 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5, DS-a71cf5e1-0a1d-400e-952c-6cfcf8d7c8e8) exiting.
2020-04-02 05:03:10,912 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@76b74e9c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:10,912 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2d72f75e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:10,913 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21ca139c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:10,913 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@77cf3f8b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:10,917 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42086
2020-04-02 05:03:10,941 [IPC Server listener on 42086] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42086
2020-04-02 05:03:10,942 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:10,942 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:41758
2020-04-02 05:03:10,942 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:10,942 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:42246
2020-04-02 05:03:10,942 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:10,944 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:10,944 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:44914
2020-04-02 05:03:10,944 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165)
2020-04-02 05:03:10,944 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:10,942 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:10,954 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165) service to localhost/127.0.0.1:33689
2020-04-02 05:03:10,954 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e9eb8ddb-a9d5-4ece-a845-c4bd22992165)
2020-04-02 05:03:10,955 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-244807914-172.17.0.17-1585803783954] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:10,995 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-244807914-172.17.0.17-1585803783954] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:10,995 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:11,004 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data5/current/BP-1887098509-172.17.0.17-1585803781423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,013 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data6/current/BP-1887098509-172.17.0.17-1585803781423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,025 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:11,025 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:11,028 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:11,028 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:11,033 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:11,034 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:03:11,034 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38704 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:11,034 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:11,034 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@410954b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:11,035 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4, DS-1e5cc405-9ebb-49e6-a3d6-a6f7ba21a5ba) exiting.
2020-04-02 05:03:11,035 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3, DS-561d1757-0a55-48fa-93cc-e6956dec9d6b) exiting.
2020-04-02 05:03:11,050 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7689ddef{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:11,050 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@687a762c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:11,051 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@245a26e1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:11,051 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1cf2fed4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:11,052 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38704
2020-04-02 05:03:11,057 [IPC Server listener on 38704] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38704
2020-04-02 05:03:11,057 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:11,057 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:11,060 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:41758
2020-04-02 05:03:11,057 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:11,057 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:11,057 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,061 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:33689
2020-04-02 05:03:11,061 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:44914
2020-04-02 05:03:11,060 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de) service to localhost/127.0.0.1:42246
2020-04-02 05:03:11,061 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de)
2020-04-02 05:03:11,061 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid e71f8f07-b317-454b-94fe-e7315ef3e9de)
2020-04-02 05:03:11,061 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:11,069 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-244807914-172.17.0.17-1585803783954] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,075 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:11,075 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-244807914-172.17.0.17-1585803783954] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,085 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data3/current/BP-1887098509-172.17.0.17-1585803781423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,093 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data4/current/BP-1887098509-172.17.0.17-1585803781423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,105 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:11,105 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:11,107 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:11,107 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:11,110 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:11,111 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:03:11,111 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33205 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:11,112 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@62fad19] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:03:11,112 [JUnit] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:03:11,113 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1, DS-33d0d0c0-bed6-4788-a4d0-dd647793abff) exiting.
2020-04-02 05:03:11,115 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2, DS-9b0d6edd-b901-4424-93b5-cacc9c8848a5) exiting.
2020-04-02 05:03:11,143 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@44e3760b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:03:11,148 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7909b995{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:11,148 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ef0d29e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:11,148 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@28d6290{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:11,156 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33205
2020-04-02 05:03:11,165 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:11,165 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:11,165 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:11,165 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:03:11,166 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,166 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:33689] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:33689
2020-04-02 05:03:11,165 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:42246
2020-04-02 05:03:11,165 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:41758] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:41758
2020-04-02 05:03:11,166 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1887098509-172.17.0.17-1585803781423 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5)
2020-04-02 05:03:11,166 [IPC Server listener on 33205] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33205
2020-04-02 05:03:11,166 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5) service to localhost/127.0.0.1:44914
2020-04-02 05:03:11,166 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-244807914-172.17.0.17-1585803783954 (Datanode Uuid f64b03c7-b23c-44d1-8521-8915971f7ff5)
2020-04-02 05:03:11,166 [BP-1887098509-172.17.0.17-1585803781423 heartbeating to localhost/127.0.0.1:42246] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1887098509-172.17.0.17-1585803781423
2020-04-02 05:03:11,177 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-1887098509-172.17.0.17-1585803781423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,187 [BP-244807914-172.17.0.17-1585803783954 heartbeating to localhost/127.0.0.1:44914] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-244807914-172.17.0.17-1585803783954
2020-04-02 05:03:11,189 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-1887098509-172.17.0.17-1585803781423] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,211 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:03:11,212 [JUnit] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:03:11,215 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:03:11,216 [JUnit] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:03:11,218 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data1/current/BP-244807914-172.17.0.17-1585803783954] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,230 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/data/data2/current/BP-244807914-172.17.0.17-1585803783954] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:03:11,235 [JUnit] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:03:11,235 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:11,236 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33689 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:11,236 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:11,236 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1ea9f009] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:03:11,236 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 49
2020-04-02 05:03:11,237 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@721eb7df] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:03:11,237 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 50 Total time for transactions(ms): 68 Number of transactions batched in Syncs: 9 Number of syncs: 42 SyncTimes(ms): 5 3 7 
2020-04-02 05:03:11,238 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-0-through-1/current/edits_0000000000000000001-0000000000000000050
2020-04-02 05:03:11,238 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000050
2020-04-02 05:03:11,239 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000050
2020-04-02 05:03:11,239 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:03:11,239 [CacheReplicationMonitor(650842694)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:03:11,240 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33689
2020-04-02 05:03:11,246 [IPC Server listener on 33689] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33689
2020-04-02 05:03:11,252 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:11,252 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:11,252 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,289 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:11,290 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:11,291 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71e9ebae{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:11,295 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5ef5c734{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:11,295 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51c693d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:11,296 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@a82c5f1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:11,306 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:11,306 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 42246 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:11,307 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:11,307 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:11,307 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42246
2020-04-02 05:03:11,314 [IPC Server listener on 42246] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42246
2020-04-02 05:03:11,314 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,314 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:11,319 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:11,333 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:11,382 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:11,388 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1f2f9244{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:11,391 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5f0e333d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:11,392 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2cae1042{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:11,393 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b5825fa{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:11,397 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:11,398 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 41758 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:11,398 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:11,398 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 1
2020-04-02 05:03:11,398 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4c7a078] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:03:11,398 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@553f3b6e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:03:11,409 [JUnit] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 55 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 7 3 2 
2020-04-02 05:03:11,410 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/shared-edits-2-through-3/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:03:11,411 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-5/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:03:11,412 [JUnit] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/test/data/dfs/name-1-6/current/edits_0000000000000000001-0000000000000000002
2020-04-02 05:03:11,412 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:03:11,412 [CacheReplicationMonitor(603476104)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:03:11,412 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41758
2020-04-02 05:03:11,418 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,418 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:11,418 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:11,419 [IPC Server listener on 41758] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41758
2020-04-02 05:03:11,432 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:11,432 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:11,434 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@14c01636{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:11,435 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@590c73d3{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:11,436 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75c9e76b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:11,436 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@502f1f4c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:11,441 [JUnit] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:03:11,441 [JUnit] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 44914 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:03:11,441 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:11,441 [Edit log tailer] WARN  ha.EditLogTailer (EditLogTailer.java:doWork(471)) - Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:469)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$300(EditLogTailer.java:399)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:416)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:482)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:412)
2020-04-02 05:03:11,442 [JUnit] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44914
2020-04-02 05:03:11,446 [IPC Server listener on 44914] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44914
2020-04-02 05:03:11,449 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,449 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:03:11,446 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:03:11,470 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:03:11,487 [JUnit] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:03:11,491 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2bef51f2{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:03:11,494 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@650eab8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:03:11,494 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ece4966{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test-classes/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:11,494 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@388ba540{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:11,512 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:36705: State Store unavailable
2020-04-02 05:03:11,534 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:11,537 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:11,543 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:11,543 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:11,552 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:11,552 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:11,558 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:11,558 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:11,570 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:11,570 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:11,586 [Thread-521] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e27ba81{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:11,587 [Thread-521] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@54336c81{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:11,590 [Thread-521] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25243bc1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:11,592 [Thread-521] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5cad8b7d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:11,599 [Thread-521] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36183
2020-04-02 05:03:11,601 [IPC Server listener on 36183] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36183
2020-04-02 05:03:11,606 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,615 [Thread-521] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36705
2020-04-02 05:03:11,619 [IPC Server listener on 36705] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36705
2020-04-02 05:03:11,619 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:11,629 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:11,629 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:11,633 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:11,634 [Thread-521] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:12,511 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:37337: State Store unavailable
2020-04-02 05:03:12,536 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:12,536 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:12,545 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:12,545 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:12,545 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:12,560 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:12,560 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:12,565 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:12,566 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:12,577 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:12,577 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:12,587 [Thread-522] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e34c607{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:12,588 [Thread-522] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5215cd9a{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:12,591 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:12,591 [Thread-522] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@159e366{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:12,594 [Thread-522] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a1d3c1a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:12,598 [Thread-522] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43811
2020-04-02 05:03:12,608 [IPC Server listener on 43811] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43811
2020-04-02 05:03:12,614 [Thread-522] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37337
2020-04-02 05:03:12,614 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:12,617 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:12,621 [IPC Server listener on 37337] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37337
2020-04-02 05:03:12,621 [Thread-522] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping Router metrics system...
2020-04-02 05:03:12,647 [Thread-522] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - Router metrics system stopped.
2020-04-02 05:03:12,648 [Thread-522] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - Router metrics system shutdown complete.
2020-04-02 05:03:12,655 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:12,655 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:12,659 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:12,659 [Thread-522] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:12,776 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:37424: State Store unavailable
2020-04-02 05:03:12,797 [StateStoreCacheUpdateService-0] INFO  store.StateStoreService (StateStoreService.java:refreshCaches(404)) - Skipping State Store cache update, driver is not ready.
2020-04-02 05:03:12,837 [RouterHeartbeatService-0] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:38944: State Store unavailable
2020-04-02 05:03:13,507 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:37424: State Store unavailable
2020-04-02 05:03:13,508 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:13,508 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:13,509 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:13,509 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:13,510 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:13,510 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:13,511 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:13,512 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:13,512 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:13,512 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:13,514 [Thread-523] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@12365c88{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:13,515 [Thread-523] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6105f8a3{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:13,516 [Thread-523] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@25230246{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:13,517 [Thread-523] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bbbdd4b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:13,518 [Thread-523] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43074
2020-04-02 05:03:13,519 [IPC Server listener on 43074] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43074
2020-04-02 05:03:13,519 [Thread-523] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37424
2020-04-02 05:03:13,520 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:13,521 [IPC Server listener on 37424] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37424
2020-04-02 05:03:13,522 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:13,523 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:13,523 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:13,524 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:13,524 [Thread-523] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
2020-04-02 05:03:13,575 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn0:127.0.0.1:41758: End of File Exception between local host is: "1b26ddd29aee/172.17.0.17"; destination host is: "localhost":41758; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:13,575 [NamenodeHeartbeatService ns1 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn0:127.0.0.1:41758
2020-04-02 05:03:13,604 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn0:127.0.0.1:33689: End of File Exception between local host is: "1b26ddd29aee/172.17.0.17"; destination host is: "localhost":33689; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:13,604 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns0-nn1:127.0.0.1:42246: End of File Exception between local host is: "1b26ddd29aee/172.17.0.17"; destination host is: "localhost":42246; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:13,605 [NamenodeHeartbeatService ns0 nn0-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn0:127.0.0.1:33689
2020-04-02 05:03:13,605 [NamenodeHeartbeatService ns0 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns0-nn1:127.0.0.1:42246
2020-04-02 05:03:13,614 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:getNamenodeStatusReport(299)) - Cannot communicate with ns1-nn1:127.0.0.1:44914: End of File Exception between local host is: "1b26ddd29aee/172.17.0.17"; destination host is: "localhost":44914; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
2020-04-02 05:03:13,614 [NamenodeHeartbeatService ns1 nn1-0] ERROR router.NamenodeHeartbeatService (NamenodeHeartbeatService.java:updateState(208)) - Namenode is not operational: ns1-nn1:127.0.0.1:44914
2020-04-02 05:03:14,507 [Router Heartbeat Async] WARN  router.RouterHeartbeatService (RouterHeartbeatService.java:updateStateStore(106)) - Cannot heartbeat router 1b26ddd29aee:38944: State Store unavailable
2020-04-02 05:03:14,508 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - RouterHeartbeatService is shutting down
2020-04-02 05:03:14,508 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service RouterHeartbeatService
2020-04-02 05:03:14,509 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn1 is shutting down
2020-04-02 05:03:14,509 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn1
2020-04-02 05:03:14,510 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns0 nn0 is shutting down
2020-04-02 05:03:14,510 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns0 nn0
2020-04-02 05:03:14,510 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn1 is shutting down
2020-04-02 05:03:14,510 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn1
2020-04-02 05:03:14,511 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - NamenodeHeartbeatService ns1 nn0 is shutting down
2020-04-02 05:03:14,511 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service NamenodeHeartbeatService ns1 nn0
2020-04-02 05:03:14,513 [Thread-524] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@232024b9{/,null,UNAVAILABLE}{/router}
2020-04-02 05:03:14,514 [Thread-524] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ec1a32c{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2020-04-02 05:03:14,515 [Thread-524] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1162410a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:03:14,516 [Thread-524] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@51671b08{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs-rbf/target/log,UNAVAILABLE}
2020-04-02 05:03:14,517 [Thread-524] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45639
2020-04-02 05:03:14,517 [IPC Server listener on 45639] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45639
2020-04-02 05:03:14,518 [Thread-524] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38944
2020-04-02 05:03:14,518 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:14,519 [IPC Server listener on 38944] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38944
2020-04-02 05:03:14,519 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreCacheUpdateService is shutting down
2020-04-02 05:03:14,520 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:03:14,520 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreCacheUpdateService
2020-04-02 05:03:14,521 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:stopPeriodic(157)) - StateStoreConnectionMonitorService is shutting down
2020-04-02 05:03:14,521 [Thread-524] INFO  router.PeriodicService (PeriodicService.java:serviceStop(148)) - Stopping periodic service StateStoreConnectionMonitorService
[msx] all testRunFinished

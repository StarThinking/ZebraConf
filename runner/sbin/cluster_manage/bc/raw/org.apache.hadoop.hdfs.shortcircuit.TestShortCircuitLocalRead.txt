[msx] before_class
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testReadFromAnOffset
[msx] unitTestCounterInClass = 0
2020-04-02 05:07:21,453 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:22,012 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:22,028 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:22,030 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:22,031 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:22,032 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:22,032 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:22,032 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:22,033 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:22,101 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:22,107 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:07:22,108 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:22,108 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:22,115 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:22,116 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:22
2020-04-02 05:07:22,119 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:22,120 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:22,122 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:22,122 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:22,140 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:22,147 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:22,147 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:22,148 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:22,148 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:22,148 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:22,149 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:22,149 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:22,149 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:22,149 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:22,152 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:22,153 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:22,209 [Thread-1] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:07:22,232 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:22,232 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:22,233 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:22,233 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:22,239 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:22,239 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:22,239 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:22,240 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:22,245 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:22,248 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:22,253 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:22,253 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:22,254 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:22,254 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:22,275 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:22,276 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:22,276 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:22,281 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:22,281 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:22,289 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:22,290 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:22,291 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:22,291 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:22,336 [Thread-1] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:22,351 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:22,354 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:22,367 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:22,370 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:22,496 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:07:22,496 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:07:22,519 [Thread-1] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:22,523 [Thread-1] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:22,688 [Thread-1] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:07:22,737 [Thread-1] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:23,199 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:23,199 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:23,205 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:23,236 [Thread-1] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:23,279 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7e1483e8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:23,294 [Thread-1] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:23,299 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:23,316 [Thread-1] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3102ms
2020-04-02 05:07:23,428 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:23,432 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:23,433 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:23,442 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:23,445 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:23,446 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:23,446 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:23,478 [Thread-1] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:23,478 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:23,489 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36418
2020-04-02 05:07:23,491 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:23,553 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f52d4a6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:23,554 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62453dd3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:23,608 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@717f24e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:23,618 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6981a8b1{HTTP/1.1,[http/1.1]}{localhost:36418}
2020-04-02 05:07:23,618 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @3405ms
2020-04-02 05:07:23,629 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:23,630 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:23,630 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:23,630 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:23,631 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:23,631 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:23,631 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:23,632 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:23,632 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:23,633 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:23,633 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:23,634 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:23,634 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:23
2020-04-02 05:07:23,635 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:23,635 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:23,635 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:07:23,635 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:23,652 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:23,653 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:23,653 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:23,654 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:23,654 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:23,654 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:23,654 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:23,655 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:23,655 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:23,655 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:23,655 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:23,656 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:23,656 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:23,657 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:23,657 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:07:23,657 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:23,670 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:23,671 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:23,671 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:23,671 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:23,671 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:23,671 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:23,672 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:23,672 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:23,672 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:07:23,672 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:23,674 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:23,674 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:23,674 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:23,674 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:23,675 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:23,675 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:23,675 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:23,675 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:07:23,675 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:23,681 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:23,684 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:23,687 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:23,687 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:23,688 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:23,688 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:23,717 [Thread-1] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:23,722 [Thread-1] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:23,723 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:23,728 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:23,729 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:23,753 [Thread-1] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:23,753 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 77 msecs
2020-04-02 05:07:23,924 [Thread-1] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:23,935 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:23,950 [Socket Reader #1 for port 33543] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33543
2020-04-02 05:07:24,234 [Thread-1] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33543 to access this namenode/service.
2020-04-02 05:07:24,239 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:24,275 [Thread-1] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:24,294 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:24,295 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:24,295 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:24,296 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:24,300 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:24,300 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:24,300 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:24,301 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:24,301 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:24,301 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-04-02 05:07:24,349 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:24,349 [IPC Server listener on 33543] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33543: starting
2020-04-02 05:07:24,353 [Thread-1] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33543
2020-04-02 05:07:24,358 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:24,359 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:24,367 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 7 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:24,374 [CacheReplicationMonitor(706798345)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:24,382 [Thread-1] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33543 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:24,391 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:24,469 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:24,493 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:24,508 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:24,509 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:24,523 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:24,527 [Thread-1] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:24,532 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:24,533 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:24,535 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:24,540 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:24,546 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43938
2020-04-02 05:07:24,548 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:24,548 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:24,551 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:24,552 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:24,552 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.43938.sock
2020-04-02 05:07:24,561 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:24,563 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:24,564 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:24,564 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:24,567 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:24,568 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:24,568 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:24,568 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:24,572 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35339
2020-04-02 05:07:24,573 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:24,574 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d0a7d9b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:24,575 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@16d34c44{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:24,580 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@48103560{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:24,581 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4566b252{HTTP/1.1,[http/1.1]}{localhost:35339}
2020-04-02 05:07:24,602 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @4376ms
2020-04-02 05:07:24,993 [Thread-1] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37015
2020-04-02 05:07:25,002 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d78eaf5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:25,003 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:25,003 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:25,022 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:25,024 [Socket Reader #1 for port 39894] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39894
2020-04-02 05:07:25,033 [Thread-1] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39894
2020-04-02 05:07:25,072 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:25,080 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:25,450 [Thread-61] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33543 starting to offer service
2020-04-02 05:07:25,478 [IPC Server listener on 39894] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39894: starting
2020-04-02 05:07:25,499 [Thread-1] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39894 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:25,478 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:25,951 [Thread-61] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33543
2020-04-02 05:07:25,956 [Thread-61] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:25,958 [Thread-61] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:25,959 [Thread-61] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1182611324. Formatting...
2020-04-02 05:07:25,960 [Thread-61] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-eed7b9d6-c765-4861-adeb-f5324a598935 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:25,964 [Thread-61] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:25,965 [Thread-61] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1182611324. Formatting...
2020-04-02 05:07:25,965 [Thread-61] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cd926426-fda7-42ee-a671-a76660149a3f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:25,982 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:25,983 [Thread-61] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:25,984 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1783743455-172.17.0.13-1585804042321 is not formatted. Formatting ...
2020-04-02 05:07:25,984 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1783743455-172.17.0.13-1585804042321 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1783743455-172.17.0.13-1585804042321/current
2020-04-02 05:07:26,019 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:26,020 [Thread-61] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:26,020 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1783743455-172.17.0.13-1585804042321 is not formatted. Formatting ...
2020-04-02 05:07:26,020 [Thread-61] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1783743455-172.17.0.13-1585804042321 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1783743455-172.17.0.13-1585804042321/current
2020-04-02 05:07:26,022 [Thread-61] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1182611324;bpid=BP-1783743455-172.17.0.13-1585804042321;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1182611324;c=1585804042321;bpid=BP-1783743455-172.17.0.13-1585804042321;dnuuid=null
2020-04-02 05:07:26,024 [Thread-61] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 0e5426be-6eec-4286-be11-5f372305d792
2020-04-02 05:07:26,201 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eed7b9d6-c765-4861-adeb-f5324a598935
2020-04-02 05:07:26,202 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:26,217 [IPC Server handler 6 on 33543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,219 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-cd926426-fda7-42ee-a671-a76660149a3f
2020-04-02 05:07:26,219 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:26,231 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:26,234 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:26,234 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:26,236 [Thread-61] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:26,249 [Thread-61] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:26,253 [Thread-61] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:26,257 [Thread-61] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:26,258 [Thread-61] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:26,258 [Thread-79] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1783743455-172.17.0.13-1585804042321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:26,261 [Thread-80] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1783743455-172.17.0.13-1585804042321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:26,297 [Thread-80] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1783743455-172.17.0.13-1585804042321 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 31ms
2020-04-02 05:07:26,302 [Thread-79] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1783743455-172.17.0.13-1585804042321 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 41ms
2020-04-02 05:07:26,303 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1783743455-172.17.0.13-1585804042321: 45ms
2020-04-02 05:07:26,307 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1783743455-172.17.0.13-1585804042321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:26,308 [Thread-84] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1783743455-172.17.0.13-1585804042321/current/replicas doesn't exist 
2020-04-02 05:07:26,307 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1783743455-172.17.0.13-1585804042321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:26,309 [Thread-83] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1783743455-172.17.0.13-1585804042321/current/replicas doesn't exist 
2020-04-02 05:07:26,310 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1783743455-172.17.0.13-1585804042321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-04-02 05:07:26,311 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1783743455-172.17.0.13-1585804042321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-04-02 05:07:26,311 [Thread-61] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1783743455-172.17.0.13-1585804042321: 5ms
2020-04-02 05:07:26,313 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1783743455-172.17.0.13-1585804042321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:26,313 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1783743455-172.17.0.13-1585804042321 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:26,315 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-eed7b9d6-c765-4861-adeb-f5324a598935): finished scanning block pool BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:26,315 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cd926426-fda7-42ee-a671-a76660149a3f): finished scanning block pool BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:26,332 [Thread-61] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:49 AM with interval of 21600000ms
2020-04-02 05:07:26,347 [IPC Server handler 3 on 33543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,349 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:26,349 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:26,389 [BP-1783743455-172.17.0.13-1585804042321 heartbeating to localhost/127.0.0.1:33543] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1783743455-172.17.0.13-1585804042321 (Datanode Uuid 0e5426be-6eec-4286-be11-5f372305d792) service to localhost/127.0.0.1:33543 beginning handshake with NN
2020-04-02 05:07:26,407 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-eed7b9d6-c765-4861-adeb-f5324a598935): no suitable block pools found to scan.  Waiting 1814399906 ms.
2020-04-02 05:07:26,407 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cd926426-fda7-42ee-a671-a76660149a3f): no suitable block pools found to scan.  Waiting 1814399906 ms.
2020-04-02 05:07:26,410 [IPC Server handler 9 on 33543] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43938, datanodeUuid=0e5426be-6eec-4286-be11-5f372305d792, infoPort=37015, infoSecurePort=0, ipcPort=39894, storageInfo=lv=-57;cid=testClusterID;nsid=1182611324;c=1585804042321) storage 0e5426be-6eec-4286-be11-5f372305d792
2020-04-02 05:07:26,413 [IPC Server handler 9 on 33543] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:43938
2020-04-02 05:07:26,420 [IPC Server handler 9 on 33543] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0e5426be-6eec-4286-be11-5f372305d792 (127.0.0.1:43938).
2020-04-02 05:07:26,426 [BP-1783743455-172.17.0.13-1585804042321 heartbeating to localhost/127.0.0.1:33543] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1783743455-172.17.0.13-1585804042321 (Datanode Uuid 0e5426be-6eec-4286-be11-5f372305d792) service to localhost/127.0.0.1:33543 successfully registered with NN
2020-04-02 05:07:26,427 [BP-1783743455-172.17.0.13-1585804042321 heartbeating to localhost/127.0.0.1:33543] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33543 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:26,447 [IPC Server handler 8 on 33543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eed7b9d6-c765-4861-adeb-f5324a598935 for DN 127.0.0.1:43938
2020-04-02 05:07:26,448 [IPC Server handler 8 on 33543] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cd926426-fda7-42ee-a671-a76660149a3f for DN 127.0.0.1:43938
2020-04-02 05:07:26,457 [IPC Server handler 6 on 33543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,465 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:26,486 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2dd7712b99ee958d: Processing first storage report for DS-cd926426-fda7-42ee-a671-a76660149a3f from datanode 0e5426be-6eec-4286-be11-5f372305d792
2020-04-02 05:07:26,487 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2dd7712b99ee958d: from storage DS-cd926426-fda7-42ee-a671-a76660149a3f node DatanodeRegistration(127.0.0.1:43938, datanodeUuid=0e5426be-6eec-4286-be11-5f372305d792, infoPort=37015, infoSecurePort=0, ipcPort=39894, storageInfo=lv=-57;cid=testClusterID;nsid=1182611324;c=1585804042321), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:26,488 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2dd7712b99ee958d: Processing first storage report for DS-eed7b9d6-c765-4861-adeb-f5324a598935 from datanode 0e5426be-6eec-4286-be11-5f372305d792
2020-04-02 05:07:26,489 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2dd7712b99ee958d: from storage DS-eed7b9d6-c765-4861-adeb-f5324a598935 node DatanodeRegistration(127.0.0.1:43938, datanodeUuid=0e5426be-6eec-4286-be11-5f372305d792, infoPort=37015, infoSecurePort=0, ipcPort=39894, storageInfo=lv=-57;cid=testClusterID;nsid=1182611324;c=1585804042321), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:26,502 [IPC Server handler 9 on 33543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,508 [Thread-1] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:<clinit>(53)) - seed=7205351267418983539
2020-04-02 05:07:26,509 [Thread-1] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=15460
2020-04-02 05:07:26,525 [BP-1783743455-172.17.0.13-1585804042321 heartbeating to localhost/127.0.0.1:33543] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2dd7712b99ee958d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 55 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:26,526 [BP-1783743455-172.17.0.13-1585804042321 heartbeating to localhost/127.0.0.1:33543] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:26,545 [IPC Server handler 7 on 33543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:26,593 [IPC Server handler 5 on 33543] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:43938 for /user/root/filelocal.dat
2020-04-02 05:07:26,694 [DataXceiver for client DFSClient_NONMAPREDUCE_-943347418_25 at /127.0.0.1:55844 [Receiving block BP-1783743455-172.17.0.13-1585804042321:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1783743455-172.17.0.13-1585804042321:blk_1073741825_1001 src: /127.0.0.1:55844 dest: /127.0.0.1:43938
2020-04-02 05:07:26,754 [PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55844, dest: /127.0.0.1:43938, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-943347418_25, offset: 0, srvID: 0e5426be-6eec-4286-be11-5f372305d792, blockid: BP-1783743455-172.17.0.13-1585804042321:blk_1073741825_1001, duration(ns): 24312629
2020-04-02 05:07:26,755 [PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:26,767 [IPC Server handler 1 on 33543] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:43938 for /user/root/filelocal.dat
2020-04-02 05:07:26,791 [DataXceiver for client DFSClient_NONMAPREDUCE_-943347418_25 at /127.0.0.1:55854 [Receiving block BP-1783743455-172.17.0.13-1585804042321:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1783743455-172.17.0.13-1585804042321:blk_1073741826_1002 src: /127.0.0.1:55854 dest: /127.0.0.1:43938
2020-04-02 05:07:26,816 [PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55854, dest: /127.0.0.1:43938, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-943347418_25, offset: 0, srvID: 0e5426be-6eec-4286-be11-5f372305d792, blockid: BP-1783743455-172.17.0.13-1585804042321:blk_1073741826_1002, duration(ns): 22589023
2020-04-02 05:07:26,822 [PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:26,826 [IPC Server handler 8 on 33543] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:43938 for /user/root/filelocal.dat
2020-04-02 05:07:26,831 [DataXceiver for client DFSClient_NONMAPREDUCE_-943347418_25 at /127.0.0.1:55856 [Receiving block BP-1783743455-172.17.0.13-1585804042321:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1783743455-172.17.0.13-1585804042321:blk_1073741827_1003 src: /127.0.0.1:55856 dest: /127.0.0.1:43938
2020-04-02 05:07:26,837 [PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55856, dest: /127.0.0.1:43938, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-943347418_25, offset: 0, srvID: 0e5426be-6eec-4286-be11-5f372305d792, blockid: BP-1783743455-172.17.0.13-1585804042321:blk_1073741827_1003, duration(ns): 3830393
2020-04-02 05:07:26,837 [PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:26,846 [IPC Server handler 9 on 33543] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:43938 for /user/root/filelocal.dat
2020-04-02 05:07:26,861 [DataXceiver for client DFSClient_NONMAPREDUCE_-943347418_25 at /127.0.0.1:55858 [Receiving block BP-1783743455-172.17.0.13-1585804042321:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1783743455-172.17.0.13-1585804042321:blk_1073741828_1004 src: /127.0.0.1:55858 dest: /127.0.0.1:43938
2020-04-02 05:07:26,881 [PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55858, dest: /127.0.0.1:43938, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-943347418_25, offset: 0, srvID: 0e5426be-6eec-4286-be11-5f372305d792, blockid: BP-1783743455-172.17.0.13-1585804042321:blk_1073741828_1004, duration(ns): 16419241
2020-04-02 05:07:26,881 [PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1783743455-172.17.0.13-1585804042321:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:26,888 [IPC Server handler 7 on 33543] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_-943347418_25
2020-04-02 05:07:26,917 [IPC Server handler 5 on 33543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:26,968 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.43938.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_740900798_25, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: 58cc0c74daafbabdccee5142f9fde4d6, srvID: 0e5426be-6eec-4286-be11-5f372305d792, success: true
2020-04-02 05:07:26,972 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.43938.sock [Passing file descriptors for block BP-1783743455-172.17.0.13-1585804042321:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 0e5426be-6eec-4286-be11-5f372305d792, success: true
2020-04-02 05:07:26,983 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.43938.sock [Passing file descriptors for block BP-1783743455-172.17.0.13-1585804042321:blk_1073741826_1002]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741826, srvID: 0e5426be-6eec-4286-be11-5f372305d792, success: true
2020-04-02 05:07:26,985 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.43938.sock [Passing file descriptors for block BP-1783743455-172.17.0.13-1585804042321:blk_1073741827_1003]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741827, srvID: 0e5426be-6eec-4286-be11-5f372305d792, success: true
2020-04-02 05:07:26,985 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.43938.sock [Passing file descriptors for block BP-1783743455-172.17.0.13-1585804042321:blk_1073741828_1004]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741828, srvID: 0e5426be-6eec-4286-be11-5f372305d792, success: true
2020-04-02 05:07:26,989 [IPC Server handler 4 on 33543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,006 [IPC Server handler 1 on 33543] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,013 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:27,013 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:27,013 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39894 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:27,014 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@25e6bddb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:27,014 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@793d38e4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:27,030 [Thread-1] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:27,031 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cd926426-fda7-42ee-a671-a76660149a3f) exiting.
2020-04-02 05:07:27,033 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-eed7b9d6-c765-4861-adeb-f5324a598935) exiting.
2020-04-02 05:07:27,085 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@48103560{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:27,090 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4566b252{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:27,095 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@16d34c44{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:27,095 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d0a7d9b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:27,100 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39894
2020-04-02 05:07:27,116 [IPC Server listener on 39894] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39894
2020-04-02 05:07:27,116 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:27,117 [BP-1783743455-172.17.0.13-1585804042321 heartbeating to localhost/127.0.0.1:33543] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:27,117 [BP-1783743455-172.17.0.13-1585804042321 heartbeating to localhost/127.0.0.1:33543] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1783743455-172.17.0.13-1585804042321 (Datanode Uuid 0e5426be-6eec-4286-be11-5f372305d792) service to localhost/127.0.0.1:33543
2020-04-02 05:07:27,118 [BP-1783743455-172.17.0.13-1585804042321 heartbeating to localhost/127.0.0.1:33543] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1783743455-172.17.0.13-1585804042321 (Datanode Uuid 0e5426be-6eec-4286-be11-5f372305d792)
2020-04-02 05:07:27,118 [BP-1783743455-172.17.0.13-1585804042321 heartbeating to localhost/127.0.0.1:33543] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1783743455-172.17.0.13-1585804042321
2020-04-02 05:07:27,133 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1783743455-172.17.0.13-1585804042321] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:27,147 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1783743455-172.17.0.13-1585804042321] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:27,156 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:27,156 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:27,156 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:27,156 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:27,177 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:27,178 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:27,178 [Thread-1] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33543 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:27,178 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:27,181 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 17
2020-04-02 05:07:27,181 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@22ba02e0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:27,182 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@5f1c905f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:27,186 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 18 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 8 Number of syncs: 11 SyncTimes(ms): 1 2 
2020-04-02 05:07:27,187 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:27,188 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:27,188 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:27,189 [CacheReplicationMonitor(706798345)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:27,193 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33543
2020-04-02 05:07:27,200 [IPC Server listener on 33543] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33543
2020-04-02 05:07:27,203 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:27,204 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:27,203 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:27,239 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:27,239 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:27,240 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@717f24e{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:27,248 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6981a8b1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:27,248 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62453dd3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:27,249 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f52d4a6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:27,250 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:27,252 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:27,252 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:27,272 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:27,276 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:27,277 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:27,277 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:27,277 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:27,277 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:27,277 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:27,277 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:27,278 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:27,278 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:27,279 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:27,279 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:27,279 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:27,280 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:27
2020-04-02 05:07:27,280 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:27,280 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,280 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:27,281 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:27,299 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:27,300 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:27,300 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:27,301 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:27,301 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:27,301 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:27,301 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:27,301 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:27,301 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:27,301 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:27,301 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:27,302 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:27,302 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:27,302 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,303 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:27,303 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:27,309 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:27,309 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:27,310 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:27,310 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:27,310 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:27,310 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:27,310 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:27,310 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,311 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:27,311 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:27,313 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:27,313 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:27,313 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:27,314 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:27,314 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:27,314 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:27,314 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,314 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:27,314 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:27,316 [Thread-1] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:27,320 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:27,322 [Thread-1] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:27,324 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:27,324 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:27,330 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:27,332 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:27,343 [Thread-1] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:27,346 [Thread-1] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:27,352 [Thread-1] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:27,355 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:27,355 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:27,357 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:27,358 [Thread-1] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:27,369 [Thread-1] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:27,370 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:27,371 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4e278234] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:27,371 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:27,372 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:27,372 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:27,374 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:27,375 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:27,375 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:27,376 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:27,378 [Thread-1] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:27,378 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:27,379 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39842
2020-04-02 05:07:27,379 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:27,386 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a4afd5e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:27,387 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@48b0d440{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:27,394 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7715b053{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:27,396 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@28620a60{HTTP/1.1,[http/1.1]}{localhost:39842}
2020-04-02 05:07:27,396 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @7183ms
2020-04-02 05:07:27,399 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:27,400 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:27,400 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:27,400 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:27,400 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:27,400 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:27,400 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:27,401 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:27,412 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:27,412 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:27,412 [Thread-1] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:27,413 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:27,413 [Thread-1] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:27
2020-04-02 05:07:27,413 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:27,413 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,414 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:27,414 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:27,426 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:27,427 [Thread-1] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:27,427 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:27,427 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:27,428 [Thread-1] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:27,428 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:27,428 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:27,428 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:27,428 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:27,429 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:27,429 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:27,429 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:27,429 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:27,430 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,430 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:27,430 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:27,440 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:27,440 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:27,440 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:27,441 [Thread-1] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:27,441 [Thread-1] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:27,441 [Thread-1] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:27,441 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:27,441 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,442 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:27,442 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:27,444 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:27,444 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:27,444 [Thread-1] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:27,444 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:27,444 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:27,444 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:27,445 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:27,445 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:27,445 [Thread-1] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:27,448 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:27,451 [Thread-1] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:27,453 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:27,453 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:27,454 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:27,454 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:27,456 [Thread-1] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:27,457 [Thread-1] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:27,457 [Thread-1] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:27,457 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:27,458 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:27,479 [Thread-1] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:27,479 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 32 msecs
2020-04-02 05:07:27,480 [Thread-1] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:27,480 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:27,481 [Socket Reader #1 for port 41946] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41946
2020-04-02 05:07:27,485 [Thread-1] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:41946 to access this namenode/service.
2020-04-02 05:07:27,487 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:27,507 [Thread-1] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:27,509 [Thread-1] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:27,509 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:27,510 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:27,510 [Thread-1] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:27,517 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:27,518 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:27,518 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:27,518 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:27,518 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:27,518 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-04-02 05:07:27,526 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:27,526 [IPC Server listener on 41946] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41946: starting
2020-04-02 05:07:27,527 [Thread-1] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:41946
2020-04-02 05:07:27,531 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:27,532 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:27,532 [Thread-1] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:27,533 [Thread-1] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 41946 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:27,535 [CacheReplicationMonitor(765162603)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:27,540 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:27,542 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:27,543 [Thread-1] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:27,552 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:27,552 [Thread-1] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:27,552 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:27,552 [Thread-1] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:27,553 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:27,553 [Thread-1] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:27,553 [Thread-1] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:27,553 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:27,554 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38299
2020-04-02 05:07:27,554 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:27,554 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:27,554 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:27,555 [Thread-1] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:27,555 [Thread-1] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38299.sock
2020-04-02 05:07:27,556 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:27,558 [Thread-1] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:27,559 [Thread-1] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:27,559 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:27,561 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:27,562 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:27,562 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:27,562 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:27,563 [Thread-1] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42178
2020-04-02 05:07:27,563 [Thread-1] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:27,566 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@50ac2e6a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:27,567 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@602e2868{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:27,573 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@120e8fc3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:27,574 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1d6ab495{HTTP/1.1,[http/1.1]}{localhost:42178}
2020-04-02 05:07:27,575 [Thread-1] INFO  server.Server (Server.java:doStart(419)) - Started @7362ms
2020-04-02 05:07:27,664 [Thread-1] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35416
2020-04-02 05:07:27,665 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:27,665 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@20f892ca] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:27,665 [Thread-1] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:27,666 [Thread-1] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:27,666 [Socket Reader #1 for port 37001] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37001
2020-04-02 05:07:27,671 [Thread-1] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37001
2020-04-02 05:07:27,681 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:27,682 [Thread-1] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:27,683 [Thread-162] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41946 starting to offer service
2020-04-02 05:07:27,694 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:27,694 [IPC Server listener on 37001] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37001: starting
2020-04-02 05:07:27,715 [Thread-1] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37001 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:27,741 [IPC Server handler 1 on 41946] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,743 [Thread-162] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41946
2020-04-02 05:07:27,744 [Thread-162] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:27,744 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:27,744 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:27,745 [Thread-162] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:27,745 [Thread-162] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 399066089. Formatting...
2020-04-02 05:07:27,746 [Thread-162] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c646c957-f9da-40c4-a86e-303932e7e81f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:27,748 [Thread-162] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:27,748 [Thread-162] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 399066089. Formatting...
2020-04-02 05:07:27,749 [Thread-162] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-07af0390-5818-4002-9dea-8b10877c56fd for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:27,768 [Thread-162] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:27,769 [Thread-162] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:27,769 [Thread-162] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1075160331-172.17.0.13-1585804047316 is not formatted. Formatting ...
2020-04-02 05:07:27,769 [Thread-162] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1075160331-172.17.0.13-1585804047316 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1075160331-172.17.0.13-1585804047316/current
2020-04-02 05:07:27,794 [Thread-162] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:27,794 [Thread-162] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:27,794 [Thread-162] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1075160331-172.17.0.13-1585804047316 is not formatted. Formatting ...
2020-04-02 05:07:27,795 [Thread-162] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1075160331-172.17.0.13-1585804047316 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1075160331-172.17.0.13-1585804047316/current
2020-04-02 05:07:27,797 [Thread-162] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=399066089;bpid=BP-1075160331-172.17.0.13-1585804047316;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=399066089;c=1585804047316;bpid=BP-1075160331-172.17.0.13-1585804047316;dnuuid=null
2020-04-02 05:07:27,798 [Thread-162] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7210ab7e-4622-4bf9-9e1d-40fd88f49944
2020-04-02 05:07:27,801 [Thread-162] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c646c957-f9da-40c4-a86e-303932e7e81f
2020-04-02 05:07:27,804 [Thread-162] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:27,807 [Thread-162] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-07af0390-5818-4002-9dea-8b10877c56fd
2020-04-02 05:07:27,807 [Thread-162] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:27,808 [Thread-162] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:27,809 [Thread-162] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:27,824 [Thread-162] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:27,825 [Thread-162] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:27,825 [Thread-162] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:27,834 [Thread-162] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:27,834 [Thread-178] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1075160331-172.17.0.13-1585804047316 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:27,834 [Thread-179] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1075160331-172.17.0.13-1585804047316 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:27,855 [IPC Server handler 2 on 41946] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,856 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:27,857 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:27,883 [Thread-179] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1075160331-172.17.0.13-1585804047316 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 48ms
2020-04-02 05:07:27,894 [Thread-178] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1075160331-172.17.0.13-1585804047316 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 59ms
2020-04-02 05:07:27,897 [Thread-162] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1075160331-172.17.0.13-1585804047316: 64ms
2020-04-02 05:07:27,903 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1075160331-172.17.0.13-1585804047316 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:27,903 [Thread-183] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1075160331-172.17.0.13-1585804047316 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:27,904 [Thread-182] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1075160331-172.17.0.13-1585804047316/current/replicas doesn't exist 
2020-04-02 05:07:27,904 [Thread-183] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1075160331-172.17.0.13-1585804047316/current/replicas doesn't exist 
2020-04-02 05:07:27,906 [Thread-182] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1075160331-172.17.0.13-1585804047316 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-04-02 05:07:27,913 [Thread-183] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1075160331-172.17.0.13-1585804047316 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 10ms
2020-04-02 05:07:27,914 [Thread-162] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1075160331-172.17.0.13-1585804047316: 16ms
2020-04-02 05:07:27,914 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1075160331-172.17.0.13-1585804047316 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:27,915 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-07af0390-5818-4002-9dea-8b10877c56fd): finished scanning block pool BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:27,915 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1075160331-172.17.0.13-1585804047316 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:27,916 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c646c957-f9da-40c4-a86e-303932e7e81f): finished scanning block pool BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:27,921 [Thread-162] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:04 AM with interval of 21600000ms
2020-04-02 05:07:27,922 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c646c957-f9da-40c4-a86e-303932e7e81f): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:07:27,922 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-07af0390-5818-4002-9dea-8b10877c56fd): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-04-02 05:07:27,927 [BP-1075160331-172.17.0.13-1585804047316 heartbeating to localhost/127.0.0.1:41946] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1075160331-172.17.0.13-1585804047316 (Datanode Uuid 7210ab7e-4622-4bf9-9e1d-40fd88f49944) service to localhost/127.0.0.1:41946 beginning handshake with NN
2020-04-02 05:07:27,935 [IPC Server handler 4 on 41946] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38299, datanodeUuid=7210ab7e-4622-4bf9-9e1d-40fd88f49944, infoPort=35416, infoSecurePort=0, ipcPort=37001, storageInfo=lv=-57;cid=testClusterID;nsid=399066089;c=1585804047316) storage 7210ab7e-4622-4bf9-9e1d-40fd88f49944
2020-04-02 05:07:27,935 [IPC Server handler 4 on 41946] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38299
2020-04-02 05:07:27,936 [IPC Server handler 4 on 41946] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7210ab7e-4622-4bf9-9e1d-40fd88f49944 (127.0.0.1:38299).
2020-04-02 05:07:27,940 [BP-1075160331-172.17.0.13-1585804047316 heartbeating to localhost/127.0.0.1:41946] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1075160331-172.17.0.13-1585804047316 (Datanode Uuid 7210ab7e-4622-4bf9-9e1d-40fd88f49944) service to localhost/127.0.0.1:41946 successfully registered with NN
2020-04-02 05:07:27,940 [BP-1075160331-172.17.0.13-1585804047316 heartbeating to localhost/127.0.0.1:41946] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41946 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:27,951 [IPC Server handler 3 on 41946] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c646c957-f9da-40c4-a86e-303932e7e81f for DN 127.0.0.1:38299
2020-04-02 05:07:27,951 [IPC Server handler 3 on 41946] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-07af0390-5818-4002-9dea-8b10877c56fd for DN 127.0.0.1:38299
2020-04-02 05:07:27,957 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4de86f6a41002081: Processing first storage report for DS-c646c957-f9da-40c4-a86e-303932e7e81f from datanode 7210ab7e-4622-4bf9-9e1d-40fd88f49944
2020-04-02 05:07:27,965 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4de86f6a41002081: from storage DS-c646c957-f9da-40c4-a86e-303932e7e81f node DatanodeRegistration(127.0.0.1:38299, datanodeUuid=7210ab7e-4622-4bf9-9e1d-40fd88f49944, infoPort=35416, infoSecurePort=0, ipcPort=37001, storageInfo=lv=-57;cid=testClusterID;nsid=399066089;c=1585804047316), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:27,966 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4de86f6a41002081: Processing first storage report for DS-07af0390-5818-4002-9dea-8b10877c56fd from datanode 7210ab7e-4622-4bf9-9e1d-40fd88f49944
2020-04-02 05:07:27,966 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4de86f6a41002081: from storage DS-07af0390-5818-4002-9dea-8b10877c56fd node DatanodeRegistration(127.0.0.1:38299, datanodeUuid=7210ab7e-4622-4bf9-9e1d-40fd88f49944, infoPort=35416, infoSecurePort=0, ipcPort=37001, storageInfo=lv=-57;cid=testClusterID;nsid=399066089;c=1585804047316), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:27,968 [BP-1075160331-172.17.0.13-1585804047316 heartbeating to localhost/127.0.0.1:41946] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x4de86f6a41002081,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 13 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:27,968 [BP-1075160331-172.17.0.13-1585804047316 heartbeating to localhost/127.0.0.1:41946] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:27,974 [IPC Server handler 9 on 41946] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,981 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:27,990 [IPC Server handler 6 on 41946] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:27,991 [Thread-1] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=15460
2020-04-02 05:07:28,013 [IPC Server handler 7 on 41946] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:28,043 [IPC Server handler 5 on 41946] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38299 for /user/root/filelocal.dat
2020-04-02 05:07:28,053 [DataXceiver for client DFSClient_NONMAPREDUCE_-1411855656_25 at /127.0.0.1:43960 [Receiving block BP-1075160331-172.17.0.13-1585804047316:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1075160331-172.17.0.13-1585804047316:blk_1073741825_1001 src: /127.0.0.1:43960 dest: /127.0.0.1:38299
2020-04-02 05:07:28,114 [PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43960, dest: /127.0.0.1:38299, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1411855656_25, offset: 0, srvID: 7210ab7e-4622-4bf9-9e1d-40fd88f49944, blockid: BP-1075160331-172.17.0.13-1585804047316:blk_1073741825_1001, duration(ns): 43010047
2020-04-02 05:07:28,114 [PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:28,140 [IPC Server handler 1 on 41946] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:38299 for /user/root/filelocal.dat
2020-04-02 05:07:28,175 [DataXceiver for client DFSClient_NONMAPREDUCE_-1411855656_25 at /127.0.0.1:43962 [Receiving block BP-1075160331-172.17.0.13-1585804047316:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1075160331-172.17.0.13-1585804047316:blk_1073741826_1002 src: /127.0.0.1:43962 dest: /127.0.0.1:38299
2020-04-02 05:07:28,211 [PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43962, dest: /127.0.0.1:38299, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1411855656_25, offset: 0, srvID: 7210ab7e-4622-4bf9-9e1d-40fd88f49944, blockid: BP-1075160331-172.17.0.13-1585804047316:blk_1073741826_1002, duration(ns): 33021211
2020-04-02 05:07:28,211 [PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:28,238 [IPC Server handler 3 on 41946] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:38299 for /user/root/filelocal.dat
2020-04-02 05:07:28,247 [DataXceiver for client DFSClient_NONMAPREDUCE_-1411855656_25 at /127.0.0.1:43964 [Receiving block BP-1075160331-172.17.0.13-1585804047316:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1075160331-172.17.0.13-1585804047316:blk_1073741827_1003 src: /127.0.0.1:43964 dest: /127.0.0.1:38299
2020-04-02 05:07:28,281 [PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43964, dest: /127.0.0.1:38299, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1411855656_25, offset: 0, srvID: 7210ab7e-4622-4bf9-9e1d-40fd88f49944, blockid: BP-1075160331-172.17.0.13-1585804047316:blk_1073741827_1003, duration(ns): 30687352
2020-04-02 05:07:28,281 [PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:28,298 [IPC Server handler 9 on 41946] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:38299 for /user/root/filelocal.dat
2020-04-02 05:07:28,307 [DataXceiver for client DFSClient_NONMAPREDUCE_-1411855656_25 at /127.0.0.1:43968 [Receiving block BP-1075160331-172.17.0.13-1585804047316:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1075160331-172.17.0.13-1585804047316:blk_1073741828_1004 src: /127.0.0.1:43968 dest: /127.0.0.1:38299
2020-04-02 05:07:28,338 [PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43968, dest: /127.0.0.1:38299, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1411855656_25, offset: 0, srvID: 7210ab7e-4622-4bf9-9e1d-40fd88f49944, blockid: BP-1075160331-172.17.0.13-1585804047316:blk_1073741828_1004, duration(ns): 28680496
2020-04-02 05:07:28,342 [PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1075160331-172.17.0.13-1585804047316:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:28,347 [IPC Server handler 7 on 41946] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741828_1004 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/filelocal.dat
2020-04-02 05:07:28,750 [IPC Server handler 5 on 41946] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_-1411855656_25
2020-04-02 05:07:28,767 [IPC Server handler 0 on 41946] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:28,772 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38299.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-234796136_25, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: c2a2cd1528eb60037df3101d44c8031d, srvID: 7210ab7e-4622-4bf9-9e1d-40fd88f49944, success: true
2020-04-02 05:07:28,787 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38299.sock [Passing file descriptors for block BP-1075160331-172.17.0.13-1585804047316:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 7210ab7e-4622-4bf9-9e1d-40fd88f49944, success: true
2020-04-02 05:07:28,789 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38299.sock [Passing file descriptors for block BP-1075160331-172.17.0.13-1585804047316:blk_1073741826_1002]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741826, srvID: 7210ab7e-4622-4bf9-9e1d-40fd88f49944, success: true
2020-04-02 05:07:28,790 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38299.sock [Passing file descriptors for block BP-1075160331-172.17.0.13-1585804047316:blk_1073741827_1003]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741827, srvID: 7210ab7e-4622-4bf9-9e1d-40fd88f49944, success: true
2020-04-02 05:07:28,803 [IPC Server handler 2 on 41946] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:28,806 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38299.sock [Passing file descriptors for block BP-1075160331-172.17.0.13-1585804047316:blk_1073741828_1004]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741828, srvID: 7210ab7e-4622-4bf9-9e1d-40fd88f49944, success: true
2020-04-02 05:07:28,874 [IPC Server handler 1 on 41946] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:28,880 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:28,880 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:28,880 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37001 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:28,880 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5ca071d6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:28,881 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1e1c9e5e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:28,891 [Thread-1] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:28,895 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-07af0390-5818-4002-9dea-8b10877c56fd) exiting.
2020-04-02 05:07:28,895 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c646c957-f9da-40c4-a86e-303932e7e81f) exiting.
2020-04-02 05:07:29,258 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@120e8fc3{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:29,258 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1d6ab495{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:29,259 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@602e2868{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:29,259 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@50ac2e6a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:29,316 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37001
2020-04-02 05:07:29,374 [IPC Server listener on 37001] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37001
2020-04-02 05:07:29,374 [BP-1075160331-172.17.0.13-1585804047316 heartbeating to localhost/127.0.0.1:41946] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:29,375 [BP-1075160331-172.17.0.13-1585804047316 heartbeating to localhost/127.0.0.1:41946] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1075160331-172.17.0.13-1585804047316 (Datanode Uuid 7210ab7e-4622-4bf9-9e1d-40fd88f49944) service to localhost/127.0.0.1:41946
2020-04-02 05:07:29,375 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:29,375 [BP-1075160331-172.17.0.13-1585804047316 heartbeating to localhost/127.0.0.1:41946] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1075160331-172.17.0.13-1585804047316 (Datanode Uuid 7210ab7e-4622-4bf9-9e1d-40fd88f49944)
2020-04-02 05:07:29,376 [BP-1075160331-172.17.0.13-1585804047316 heartbeating to localhost/127.0.0.1:41946] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1075160331-172.17.0.13-1585804047316
2020-04-02 05:07:29,392 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1075160331-172.17.0.13-1585804047316] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:29,402 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1075160331-172.17.0.13-1585804047316] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:29,417 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:29,417 [Thread-1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:29,418 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:29,418 [Thread-1] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:29,421 [Thread-1] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:29,421 [Thread-1] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:29,421 [Thread-1] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 41946 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:29,421 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:29,422 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 17
2020-04-02 05:07:29,422 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@36949d9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:29,424 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@e811fad] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:29,427 [Thread-1] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 18 Total time for transactions(ms): 17 Number of transactions batched in Syncs: 8 Number of syncs: 11 SyncTimes(ms): 5 22 
2020-04-02 05:07:29,428 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:29,429 [Thread-1] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:29,434 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:29,438 [CacheReplicationMonitor(765162603)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:29,450 [Thread-1] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41946
2020-04-02 05:07:29,476 [IPC Server listener on 41946] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41946
2020-04-02 05:07:29,477 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:29,477 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:29,477 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:29,505 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:29,506 [Thread-1] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:29,507 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7715b053{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:29,527 [Thread-1] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@28620a60{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:29,527 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@48b0d440{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:29,528 [Thread-1] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a4afd5e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:29,551 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:29,552 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:29,553 [Thread-1] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testReadFromAnOffset
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testReadFromAnOffset
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testSkipWithVerifyChecksum
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:29,598 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:29,601 [Thread-209] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:29,601 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:29,601 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:29,601 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:29,602 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:29,602 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:29,602 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:29,602 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:29,602 [Thread-209] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:29,603 [Thread-209] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:29,603 [Thread-209] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:29,603 [Thread-209] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:29,603 [Thread-209] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:29
2020-04-02 05:07:29,603 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:29,603 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:29,604 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:29,604 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:29,608 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:29,609 [Thread-209] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:29,609 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:29,610 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:29,610 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:29,610 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:29,610 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:29,613 [Thread-209] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:29,613 [Thread-209] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:29,613 [Thread-209] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:29,613 [Thread-209] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:29,613 [Thread-209] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:29,613 [Thread-209] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:29,613 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:29,613 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:29,614 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:29,614 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:29,615 [Thread-209] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:29,615 [Thread-209] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:29,615 [Thread-209] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:29,615 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:29,615 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:29,615 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:29,615 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:29,615 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:29,616 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:29,617 [Thread-209] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:29,619 [Thread-209] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:29,622 [Thread-209] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:29,630 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:29,633 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:29,636 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:29,643 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:29,646 [Thread-209] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:29,648 [Thread-209] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:29,653 [Thread-209] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:29,665 [Thread-209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:29,666 [Thread-209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:29,668 [Thread-209] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:29,668 [Thread-209] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:29,678 [Thread-209] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:29,678 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:29,680 [Thread-209] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:29,678 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@66cff3a5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:29,681 [Thread-209] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:29,681 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:29,682 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:29,683 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:29,683 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:29,683 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:29,684 [Thread-209] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:29,684 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:29,685 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46707
2020-04-02 05:07:29,685 [Thread-209] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:29,689 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13c66d7c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:29,690 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3e88d3fb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:29,695 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2e51b744{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:29,696 [Thread-209] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3ab25aea{HTTP/1.1,[http/1.1]}{localhost:46707}
2020-04-02 05:07:29,696 [Thread-209] INFO  server.Server (Server.java:doStart(419)) - Started @9483ms
2020-04-02 05:07:29,698 [Thread-209] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:29,698 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:29,698 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:29,698 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:29,698 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:29,698 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:29,698 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:29,698 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:29,699 [Thread-209] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:29,699 [Thread-209] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:29,699 [Thread-209] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:29,699 [Thread-209] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:29,699 [Thread-209] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:29
2020-04-02 05:07:29,699 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:29,700 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:29,700 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:29,700 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:29,709 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:29,709 [Thread-209] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:29,709 [Thread-209] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:29,709 [Thread-209] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:29,709 [Thread-209] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:29,714 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:29,714 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:29,715 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:29,715 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:29,715 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:29,715 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:29,715 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:29,715 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:29,715 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:29,715 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:29,715 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:29,717 [Thread-209] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:29,717 [Thread-209] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:29,717 [Thread-209] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:29,717 [Thread-209] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:29,717 [Thread-209] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:29,717 [Thread-209] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:29,718 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:29,718 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:29,718 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:29,718 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:29,719 [Thread-209] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:29,719 [Thread-209] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:29,719 [Thread-209] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:29,719 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:29,719 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:29,719 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:29,719 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:29,719 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:29,720 [Thread-209] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:29,722 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:29,728 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:29,730 [Thread-209] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:29,730 [Thread-209] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:29,730 [Thread-209] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:29,730 [Thread-209] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:29,732 [Thread-209] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:29,733 [Thread-209] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:29,733 [Thread-209] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:29,733 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:29,736 [Thread-209] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:29,763 [Thread-209] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:29,764 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 43 msecs
2020-04-02 05:07:29,764 [Thread-209] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:29,765 [Thread-209] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:29,766 [Socket Reader #1 for port 36595] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36595
2020-04-02 05:07:29,790 [Thread-209] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36595 to access this namenode/service.
2020-04-02 05:07:29,791 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:29,820 [Thread-209] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:29,824 [Thread-209] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:29,829 [Thread-209] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:29,830 [Thread-209] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:29,830 [Thread-209] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:29,857 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:29,858 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:29,858 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:29,858 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:29,858 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:29,858 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 28 msec
2020-04-02 05:07:29,861 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:29,861 [IPC Server listener on 36595] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36595: starting
2020-04-02 05:07:29,863 [Thread-209] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36595
2020-04-02 05:07:29,870 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:29,870 [Thread-209] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:29,903 [Thread-209] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 33 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:29,904 [Thread-209] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36595 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:29,910 [CacheReplicationMonitor(494533375)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:29,910 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:29,912 [Thread-209] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:29,913 [Thread-209] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:29,921 [Thread-209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:29,922 [Thread-209] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:29,923 [Thread-209] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:29,924 [Thread-209] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:29,930 [Thread-209] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:29,930 [Thread-209] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:29,931 [Thread-209] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:29,931 [Thread-209] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:29,932 [Thread-209] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33568
2020-04-02 05:07:29,932 [Thread-209] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:29,933 [Thread-209] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:29,934 [Thread-209] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:29,936 [Thread-209] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:29,938 [Thread-209] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/testSkipWithVerifyChecksum.33568.sock
2020-04-02 05:07:29,942 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:29,944 [Thread-209] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:29,947 [Thread-209] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:29,950 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:29,955 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:29,958 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:29,961 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:29,962 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:29,966 [Thread-209] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40642
2020-04-02 05:07:29,967 [Thread-209] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:29,972 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4e027cd4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:29,973 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@75e53b94{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:29,983 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4f36cadb{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:29,985 [Thread-209] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1ec5e0a8{HTTP/1.1,[http/1.1]}{localhost:40642}
2020-04-02 05:07:29,985 [Thread-209] INFO  server.Server (Server.java:doStart(419)) - Started @9772ms
2020-04-02 05:07:30,021 [Thread-209] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43384
2020-04-02 05:07:30,036 [Thread-209] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:30,037 [Thread-209] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:30,037 [Thread-209] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:30,039 [Socket Reader #1 for port 46638] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46638
2020-04-02 05:07:30,036 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@15c3cabb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:30,045 [Thread-209] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46638
2020-04-02 05:07:30,067 [Thread-209] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:30,067 [Thread-209] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:30,072 [Thread-265] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36595 starting to offer service
2020-04-02 05:07:30,078 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:30,078 [IPC Server listener on 46638] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46638: starting
2020-04-02 05:07:30,080 [Thread-209] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46638 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:30,122 [IPC Server handler 0 on 36595] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:30,124 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:30,125 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:30,129 [Thread-265] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36595
2020-04-02 05:07:30,132 [Thread-265] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:30,138 [Thread-265] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:30,138 [Thread-265] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 812417155. Formatting...
2020-04-02 05:07:30,139 [Thread-265] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c6cdfe05-de8e-4925-b9dd-3c4d6d244c5c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:30,143 [Thread-265] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:30,144 [Thread-265] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 812417155. Formatting...
2020-04-02 05:07:30,145 [Thread-265] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5936f520-9b3d-4506-a44e-ebc9ecc2d585 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:30,172 [Thread-265] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:30,172 [Thread-265] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:30,172 [Thread-265] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1124527828-172.17.0.13-1585804049617 is not formatted. Formatting ...
2020-04-02 05:07:30,172 [Thread-265] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1124527828-172.17.0.13-1585804049617 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1124527828-172.17.0.13-1585804049617/current
2020-04-02 05:07:30,193 [Thread-265] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:30,193 [Thread-265] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:30,193 [Thread-265] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1124527828-172.17.0.13-1585804049617 is not formatted. Formatting ...
2020-04-02 05:07:30,202 [Thread-265] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1124527828-172.17.0.13-1585804049617 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1124527828-172.17.0.13-1585804049617/current
2020-04-02 05:07:30,204 [Thread-265] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=812417155;bpid=BP-1124527828-172.17.0.13-1585804049617;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=812417155;c=1585804049617;bpid=BP-1124527828-172.17.0.13-1585804049617;dnuuid=null
2020-04-02 05:07:30,209 [Thread-265] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID f1583658-8d9a-4c7e-8d3d-360e1a1a994a
2020-04-02 05:07:30,211 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c6cdfe05-de8e-4925-b9dd-3c4d6d244c5c
2020-04-02 05:07:30,211 [Thread-265] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:30,214 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5936f520-9b3d-4506-a44e-ebc9ecc2d585
2020-04-02 05:07:30,214 [Thread-265] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:30,214 [Thread-265] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:30,216 [Thread-265] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:30,216 [Thread-265] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:30,217 [Thread-265] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:30,217 [Thread-265] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:30,262 [IPC Server handler 2 on 36595] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:30,263 [Thread-265] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:30,265 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:30,265 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:30,265 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1124527828-172.17.0.13-1585804049617 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:30,265 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1124527828-172.17.0.13-1585804049617 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:30,325 [Thread-282] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1124527828-172.17.0.13-1585804049617 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 60ms
2020-04-02 05:07:30,326 [Thread-281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1124527828-172.17.0.13-1585804049617 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 61ms
2020-04-02 05:07:30,327 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1124527828-172.17.0.13-1585804049617: 63ms
2020-04-02 05:07:30,327 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1124527828-172.17.0.13-1585804049617 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:30,327 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1124527828-172.17.0.13-1585804049617 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:30,328 [Thread-286] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1124527828-172.17.0.13-1585804049617/current/replicas doesn't exist 
2020-04-02 05:07:30,328 [Thread-285] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1124527828-172.17.0.13-1585804049617/current/replicas doesn't exist 
2020-04-02 05:07:30,328 [Thread-286] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1124527828-172.17.0.13-1585804049617 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:07:30,328 [Thread-285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1124527828-172.17.0.13-1585804049617 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:07:30,334 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1124527828-172.17.0.13-1585804049617: 7ms
2020-04-02 05:07:30,335 [Thread-265] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:42 AM with interval of 21600000ms
2020-04-02 05:07:30,336 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1124527828-172.17.0.13-1585804049617 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:30,336 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5936f520-9b3d-4506-a44e-ebc9ecc2d585): finished scanning block pool BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:30,337 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5936f520-9b3d-4506-a44e-ebc9ecc2d585): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:07:30,344 [BP-1124527828-172.17.0.13-1585804049617 heartbeating to localhost/127.0.0.1:36595] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1124527828-172.17.0.13-1585804049617 (Datanode Uuid f1583658-8d9a-4c7e-8d3d-360e1a1a994a) service to localhost/127.0.0.1:36595 beginning handshake with NN
2020-04-02 05:07:30,345 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1124527828-172.17.0.13-1585804049617 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:30,345 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c6cdfe05-de8e-4925-b9dd-3c4d6d244c5c): finished scanning block pool BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:30,346 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c6cdfe05-de8e-4925-b9dd-3c4d6d244c5c): no suitable block pools found to scan.  Waiting 1814399988 ms.
2020-04-02 05:07:30,346 [IPC Server handler 3 on 36595] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33568, datanodeUuid=f1583658-8d9a-4c7e-8d3d-360e1a1a994a, infoPort=43384, infoSecurePort=0, ipcPort=46638, storageInfo=lv=-57;cid=testClusterID;nsid=812417155;c=1585804049617) storage f1583658-8d9a-4c7e-8d3d-360e1a1a994a
2020-04-02 05:07:30,347 [IPC Server handler 3 on 36595] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33568
2020-04-02 05:07:30,347 [IPC Server handler 3 on 36595] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN f1583658-8d9a-4c7e-8d3d-360e1a1a994a (127.0.0.1:33568).
2020-04-02 05:07:30,357 [BP-1124527828-172.17.0.13-1585804049617 heartbeating to localhost/127.0.0.1:36595] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1124527828-172.17.0.13-1585804049617 (Datanode Uuid f1583658-8d9a-4c7e-8d3d-360e1a1a994a) service to localhost/127.0.0.1:36595 successfully registered with NN
2020-04-02 05:07:30,357 [BP-1124527828-172.17.0.13-1585804049617 heartbeating to localhost/127.0.0.1:36595] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36595 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:30,365 [IPC Server handler 4 on 36595] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c6cdfe05-de8e-4925-b9dd-3c4d6d244c5c for DN 127.0.0.1:33568
2020-04-02 05:07:30,366 [IPC Server handler 4 on 36595] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5936f520-9b3d-4506-a44e-ebc9ecc2d585 for DN 127.0.0.1:33568
2020-04-02 05:07:30,372 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe6d86c2fbbab1e9b: Processing first storage report for DS-5936f520-9b3d-4506-a44e-ebc9ecc2d585 from datanode f1583658-8d9a-4c7e-8d3d-360e1a1a994a
2020-04-02 05:07:30,372 [IPC Server handler 4 on 36595] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:30,372 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe6d86c2fbbab1e9b: from storage DS-5936f520-9b3d-4506-a44e-ebc9ecc2d585 node DatanodeRegistration(127.0.0.1:33568, datanodeUuid=f1583658-8d9a-4c7e-8d3d-360e1a1a994a, infoPort=43384, infoSecurePort=0, ipcPort=46638, storageInfo=lv=-57;cid=testClusterID;nsid=812417155;c=1585804049617), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:30,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe6d86c2fbbab1e9b: Processing first storage report for DS-c6cdfe05-de8e-4925-b9dd-3c4d6d244c5c from datanode f1583658-8d9a-4c7e-8d3d-360e1a1a994a
2020-04-02 05:07:30,373 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe6d86c2fbbab1e9b: from storage DS-c6cdfe05-de8e-4925-b9dd-3c4d6d244c5c node DatanodeRegistration(127.0.0.1:33568, datanodeUuid=f1583658-8d9a-4c7e-8d3d-360e1a1a994a, infoPort=43384, infoSecurePort=0, ipcPort=46638, storageInfo=lv=-57;cid=testClusterID;nsid=812417155;c=1585804049617), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:30,374 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:30,376 [BP-1124527828-172.17.0.13-1585804049617 heartbeating to localhost/127.0.0.1:36595] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe6d86c2fbbab1e9b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:30,376 [BP-1124527828-172.17.0.13-1585804049617 heartbeating to localhost/127.0.0.1:36595] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:30,382 [IPC Server handler 7 on 36595] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:30,383 [Thread-209] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=15360
2020-04-02 05:07:30,394 [IPC Server handler 8 on 36595] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:30,402 [IPC Server handler 9 on 36595] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:33568 for /user/root/filelocal.dat
2020-04-02 05:07:30,414 [DataXceiver for client DFSClient_NONMAPREDUCE_2014852152_616 at /127.0.0.1:52756 [Receiving block BP-1124527828-172.17.0.13-1585804049617:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1124527828-172.17.0.13-1585804049617:blk_1073741825_1001 src: /127.0.0.1:52756 dest: /127.0.0.1:33568
2020-04-02 05:07:30,455 [PacketResponder: BP-1124527828-172.17.0.13-1585804049617:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52756, dest: /127.0.0.1:33568, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2014852152_616, offset: 0, srvID: f1583658-8d9a-4c7e-8d3d-360e1a1a994a, blockid: BP-1124527828-172.17.0.13-1585804049617:blk_1073741825_1001, duration(ns): 19070276
2020-04-02 05:07:30,455 [PacketResponder: BP-1124527828-172.17.0.13-1585804049617:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1124527828-172.17.0.13-1585804049617:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:30,476 [IPC Server handler 2 on 36595] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:33568 for /user/root/filelocal.dat
2020-04-02 05:07:30,480 [DataXceiver for client DFSClient_NONMAPREDUCE_2014852152_616 at /127.0.0.1:52764 [Receiving block BP-1124527828-172.17.0.13-1585804049617:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1124527828-172.17.0.13-1585804049617:blk_1073741826_1002 src: /127.0.0.1:52764 dest: /127.0.0.1:33568
2020-04-02 05:07:30,498 [PacketResponder: BP-1124527828-172.17.0.13-1585804049617:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52764, dest: /127.0.0.1:33568, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2014852152_616, offset: 0, srvID: f1583658-8d9a-4c7e-8d3d-360e1a1a994a, blockid: BP-1124527828-172.17.0.13-1585804049617:blk_1073741826_1002, duration(ns): 15403006
2020-04-02 05:07:30,499 [PacketResponder: BP-1124527828-172.17.0.13-1585804049617:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1124527828-172.17.0.13-1585804049617:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:30,503 [IPC Server handler 5 on 36595] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:33568 for /user/root/filelocal.dat
2020-04-02 05:07:30,509 [DataXceiver for client DFSClient_NONMAPREDUCE_2014852152_616 at /127.0.0.1:52768 [Receiving block BP-1124527828-172.17.0.13-1585804049617:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1124527828-172.17.0.13-1585804049617:blk_1073741827_1003 src: /127.0.0.1:52768 dest: /127.0.0.1:33568
2020-04-02 05:07:30,519 [PacketResponder: BP-1124527828-172.17.0.13-1585804049617:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52768, dest: /127.0.0.1:33568, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2014852152_616, offset: 0, srvID: f1583658-8d9a-4c7e-8d3d-360e1a1a994a, blockid: BP-1124527828-172.17.0.13-1585804049617:blk_1073741827_1003, duration(ns): 7758513
2020-04-02 05:07:30,519 [PacketResponder: BP-1124527828-172.17.0.13-1585804049617:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1124527828-172.17.0.13-1585804049617:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:30,523 [IPC Server handler 6 on 36595] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741827_1003 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/filelocal.dat
2020-04-02 05:07:30,925 [IPC Server handler 7 on 36595] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_2014852152_616
2020-04-02 05:07:30,928 [IPC Server handler 8 on 36595] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:30,932 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/testSkipWithVerifyChecksum.33568.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_2014852152_616, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: ab203f694f22e0d8c9b3eeabc5d69b2f, srvID: f1583658-8d9a-4c7e-8d3d-360e1a1a994a, success: true
2020-04-02 05:07:30,936 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/testSkipWithVerifyChecksum.33568.sock [Passing file descriptors for block BP-1124527828-172.17.0.13-1585804049617:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: f1583658-8d9a-4c7e-8d3d-360e1a1a994a, success: true
2020-04-02 05:07:30,938 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/testSkipWithVerifyChecksum.33568.sock [Passing file descriptors for block BP-1124527828-172.17.0.13-1585804049617:blk_1073741827_1003]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741827, srvID: f1583658-8d9a-4c7e-8d3d-360e1a1a994a, success: true
2020-04-02 05:07:30,938 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:30,939 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:30,939 [Thread-209] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46638 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:30,939 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@35545fe] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:30,939 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@34af9646] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:30,949 [Thread-209] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:30,951 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-5936f520-9b3d-4506-a44e-ebc9ecc2d585) exiting.
2020-04-02 05:07:30,951 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c6cdfe05-de8e-4925-b9dd-3c4d6d244c5c) exiting.
2020-04-02 05:07:30,994 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4f36cadb{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:30,995 [Thread-209] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1ec5e0a8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:30,996 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@75e53b94{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:30,996 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4e027cd4{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:30,998 [Thread-209] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46638
2020-04-02 05:07:31,014 [IPC Server listener on 46638] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46638
2020-04-02 05:07:31,014 [BP-1124527828-172.17.0.13-1585804049617 heartbeating to localhost/127.0.0.1:36595] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:31,015 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:31,015 [BP-1124527828-172.17.0.13-1585804049617 heartbeating to localhost/127.0.0.1:36595] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1124527828-172.17.0.13-1585804049617 (Datanode Uuid f1583658-8d9a-4c7e-8d3d-360e1a1a994a) service to localhost/127.0.0.1:36595
2020-04-02 05:07:31,016 [BP-1124527828-172.17.0.13-1585804049617 heartbeating to localhost/127.0.0.1:36595] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1124527828-172.17.0.13-1585804049617 (Datanode Uuid f1583658-8d9a-4c7e-8d3d-360e1a1a994a)
2020-04-02 05:07:31,016 [BP-1124527828-172.17.0.13-1585804049617 heartbeating to localhost/127.0.0.1:36595] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1124527828-172.17.0.13-1585804049617
2020-04-02 05:07:31,034 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1124527828-172.17.0.13-1585804049617] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:31,048 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1124527828-172.17.0.13-1585804049617] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:31,071 [Thread-209] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:31,072 [Thread-209] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:31,073 [Thread-209] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:31,074 [Thread-209] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:31,090 [Thread-209] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:31,090 [Thread-209] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:31,090 [Thread-209] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36595 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:31,090 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:31,093 [Thread-209] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 14
2020-04-02 05:07:31,093 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3217a3eb] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:31,094 [Thread-209] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 15 Total time for transactions(ms): 24 Number of transactions batched in Syncs: 6 Number of syncs: 10 SyncTimes(ms): 2 2 
2020-04-02 05:07:31,094 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@53b1a4a0] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:31,094 [Thread-209] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:07:31,095 [Thread-209] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000015
2020-04-02 05:07:31,095 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:31,100 [CacheReplicationMonitor(494533375)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:31,101 [Thread-209] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36595
2020-04-02 05:07:31,108 [IPC Server listener on 36595] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36595
2020-04-02 05:07:31,108 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:31,109 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:31,111 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:31,127 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:31,127 [Thread-209] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:31,129 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2e51b744{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:31,132 [Thread-209] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3ab25aea{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:31,132 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3e88d3fb{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:31,132 [Thread-209] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13c66d7c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:31,135 [Thread-209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:31,138 [Thread-209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:31,139 [Thread-209] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testSkipWithVerifyChecksum
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testSkipWithVerifyChecksum
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testSmallFileLocalRead
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:31,157 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:31,159 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:31,160 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:31,160 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:31,160 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:31,160 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:31,160 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:31,161 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:31,161 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:31,161 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:31,161 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:31,162 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:31,162 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:31,162 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:31
2020-04-02 05:07:31,162 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:31,162 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:31,163 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:31,163 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:31,171 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:31,171 [Thread-307] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:31,171 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:31,171 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:31,171 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:31,172 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:31,172 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:31,172 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:31,172 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:31,172 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:31,172 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:31,172 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:31,172 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:31,172 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:31,173 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:31,173 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:31,175 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:31,176 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:31,176 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:31,176 [Thread-307] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:31,176 [Thread-307] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:31,176 [Thread-307] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:31,176 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:31,176 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:31,177 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:31,177 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:31,177 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:31,178 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:31,178 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:31,178 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:31,178 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:31,178 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:31,178 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:31,178 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:31,179 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:31,180 [Thread-307] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:31,182 [Thread-307] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:31,190 [Thread-307] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:31,195 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:31,195 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:31,215 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:31,220 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:31,223 [Thread-307] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:31,224 [Thread-307] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:31,233 [Thread-307] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:31,235 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:31,235 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:31,237 [Thread-307] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:31,237 [Thread-307] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:31,255 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@28c895f6] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:31,255 [Thread-307] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:31,256 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:31,257 [Thread-307] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:31,257 [Thread-307] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:31,258 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:31,259 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:31,259 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:31,259 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:31,259 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:31,261 [Thread-307] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:31,261 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:31,261 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35100
2020-04-02 05:07:31,261 [Thread-307] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:31,263 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10fed97c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:31,264 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@26f2997f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:31,270 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@243f83a6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:31,271 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@79ed3d98{HTTP/1.1,[http/1.1]}{localhost:35100}
2020-04-02 05:07:31,272 [Thread-307] INFO  server.Server (Server.java:doStart(419)) - Started @11058ms
2020-04-02 05:07:31,275 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:31,275 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:31,275 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:31,275 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:31,275 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:31,276 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:31,276 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:31,276 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:31,276 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:31,277 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:31,277 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:31,277 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:31,277 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:31
2020-04-02 05:07:31,289 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:31,290 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:31,290 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:31,290 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:31,293 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:31,294 [Thread-307] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:31,294 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:31,294 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:31,294 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:31,294 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:31,294 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:31,294 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:31,295 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:31,295 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:31,295 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:31,295 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:31,295 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:31,295 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:31,296 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:31,296 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:31,302 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:31,303 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:31,303 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:31,303 [Thread-307] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:31,303 [Thread-307] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:31,303 [Thread-307] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:31,304 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:31,304 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:31,304 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:31,304 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:31,306 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:31,306 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:31,307 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:31,307 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:31,307 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:31,307 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:31,307 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:31,308 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:31,308 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:31,316 [Thread-307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:31,317 [Thread-307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:31,319 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:31,320 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:31,320 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:31,320 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:31,322 [Thread-307] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:31,323 [Thread-307] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:31,323 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:31,323 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:31,324 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:31,350 [Thread-307] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:31,350 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 41 msecs
2020-04-02 05:07:31,350 [Thread-307] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:31,351 [Thread-307] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:31,356 [Socket Reader #1 for port 42479] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42479
2020-04-02 05:07:31,361 [Thread-307] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:42479 to access this namenode/service.
2020-04-02 05:07:31,361 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:31,400 [Thread-307] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:31,402 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:31,402 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:31,402 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:31,402 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:31,409 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:31,409 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:31,409 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:31,409 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:31,409 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:31,409 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-04-02 05:07:31,432 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:31,433 [IPC Server listener on 42479] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42479: starting
2020-04-02 05:07:31,434 [Thread-307] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:42479
2020-04-02 05:07:31,434 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:31,434 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:31,435 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:31,438 [Thread-307] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 42479 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:31,442 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:31,444 [Thread-307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:31,466 [CacheReplicationMonitor(340934001)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:31,467 [Thread-307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:31,470 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:31,471 [Thread-307] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:31,472 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:31,472 [Thread-307] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:31,472 [Thread-307] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:31,472 [Thread-307] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:31,472 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:31,473 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:31,473 [Thread-307] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38396
2020-04-02 05:07:31,473 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:31,474 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:31,474 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:31,474 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:31,475 [Thread-307] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38396.sock
2020-04-02 05:07:31,476 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:31,478 [Thread-307] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:31,479 [Thread-307] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:31,479 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:31,481 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:31,482 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:31,482 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:31,482 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:31,483 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41559
2020-04-02 05:07:31,483 [Thread-307] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:31,484 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3f2fe035{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:31,485 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d9d4474{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:31,496 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@22a16bc4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:31,497 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@140bbedb{HTTP/1.1,[http/1.1]}{localhost:41559}
2020-04-02 05:07:31,497 [Thread-307] INFO  server.Server (Server.java:doStart(419)) - Started @11284ms
2020-04-02 05:07:31,510 [Thread-307] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43474
2020-04-02 05:07:31,510 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:31,510 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1edf49fa] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:31,510 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:31,511 [Thread-307] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:31,511 [Socket Reader #1 for port 45455] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45455
2020-04-02 05:07:31,517 [Thread-307] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45455
2020-04-02 05:07:31,523 [Thread-307] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:31,524 [Thread-307] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:31,525 [Thread-363] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42479 starting to offer service
2020-04-02 05:07:31,546 [IPC Server listener on 45455] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45455: starting
2020-04-02 05:07:31,562 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:31,564 [Thread-307] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45455 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:31,576 [IPC Server handler 1 on 42479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:31,576 [Thread-363] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42479
2020-04-02 05:07:31,577 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:31,577 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:31,578 [Thread-363] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:31,580 [Thread-363] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:31,581 [Thread-363] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 682418857. Formatting...
2020-04-02 05:07:31,581 [Thread-363] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-76db5f80-b2b1-4c5b-b60a-050552a6f70c for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:31,585 [Thread-363] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:31,585 [Thread-363] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 682418857. Formatting...
2020-04-02 05:07:31,585 [Thread-363] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9893fd9c-3dd7-4d79-93fc-63caae53d059 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:31,596 [Thread-363] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:31,597 [Thread-363] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:31,597 [Thread-363] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-775438797-172.17.0.13-1585804051180 is not formatted. Formatting ...
2020-04-02 05:07:31,597 [Thread-363] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-775438797-172.17.0.13-1585804051180 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-775438797-172.17.0.13-1585804051180/current
2020-04-02 05:07:31,610 [Thread-363] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:31,610 [Thread-363] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:31,610 [Thread-363] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-775438797-172.17.0.13-1585804051180 is not formatted. Formatting ...
2020-04-02 05:07:31,610 [Thread-363] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-775438797-172.17.0.13-1585804051180 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-775438797-172.17.0.13-1585804051180/current
2020-04-02 05:07:31,614 [Thread-363] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682418857;bpid=BP-775438797-172.17.0.13-1585804051180;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682418857;c=1585804051180;bpid=BP-775438797-172.17.0.13-1585804051180;dnuuid=null
2020-04-02 05:07:31,616 [Thread-363] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ea5deb6d-15eb-41c1-8039-8b2dddd2e063
2020-04-02 05:07:31,619 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-76db5f80-b2b1-4c5b-b60a-050552a6f70c
2020-04-02 05:07:31,619 [Thread-363] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:31,623 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9893fd9c-3dd7-4d79-93fc-63caae53d059
2020-04-02 05:07:31,623 [Thread-363] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:31,625 [Thread-363] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:31,627 [Thread-363] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:31,628 [Thread-363] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:31,629 [Thread-363] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:31,629 [Thread-363] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:31,632 [Thread-363] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:31,633 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-775438797-172.17.0.13-1585804051180 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:31,633 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-775438797-172.17.0.13-1585804051180 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:31,675 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-775438797-172.17.0.13-1585804051180 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 42ms
2020-04-02 05:07:31,678 [Thread-380] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-775438797-172.17.0.13-1585804051180 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 45ms
2020-04-02 05:07:31,679 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-775438797-172.17.0.13-1585804051180: 47ms
2020-04-02 05:07:31,679 [IPC Server handler 2 on 42479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:31,691 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:31,691 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:31,694 [Thread-383] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-775438797-172.17.0.13-1585804051180 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:31,694 [Thread-383] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-775438797-172.17.0.13-1585804051180/current/replicas doesn't exist 
2020-04-02 05:07:31,695 [Thread-383] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-775438797-172.17.0.13-1585804051180 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:07:31,697 [Thread-384] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-775438797-172.17.0.13-1585804051180 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:31,697 [Thread-384] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-775438797-172.17.0.13-1585804051180/current/replicas doesn't exist 
2020-04-02 05:07:31,698 [Thread-384] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-775438797-172.17.0.13-1585804051180 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:31,703 [Thread-363] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-775438797-172.17.0.13-1585804051180: 12ms
2020-04-02 05:07:31,704 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-775438797-172.17.0.13-1585804051180 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:31,704 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9893fd9c-3dd7-4d79-93fc-63caae53d059): finished scanning block pool BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:31,705 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9893fd9c-3dd7-4d79-93fc-63caae53d059): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:07:31,705 [Thread-363] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:04 AM with interval of 21600000ms
2020-04-02 05:07:31,708 [BP-775438797-172.17.0.13-1585804051180 heartbeating to localhost/127.0.0.1:42479] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-775438797-172.17.0.13-1585804051180 (Datanode Uuid ea5deb6d-15eb-41c1-8039-8b2dddd2e063) service to localhost/127.0.0.1:42479 beginning handshake with NN
2020-04-02 05:07:31,709 [IPC Server handler 3 on 42479] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38396, datanodeUuid=ea5deb6d-15eb-41c1-8039-8b2dddd2e063, infoPort=43474, infoSecurePort=0, ipcPort=45455, storageInfo=lv=-57;cid=testClusterID;nsid=682418857;c=1585804051180) storage ea5deb6d-15eb-41c1-8039-8b2dddd2e063
2020-04-02 05:07:31,710 [IPC Server handler 3 on 42479] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38396
2020-04-02 05:07:31,710 [IPC Server handler 3 on 42479] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ea5deb6d-15eb-41c1-8039-8b2dddd2e063 (127.0.0.1:38396).
2020-04-02 05:07:31,710 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-775438797-172.17.0.13-1585804051180 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:31,711 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-76db5f80-b2b1-4c5b-b60a-050552a6f70c): finished scanning block pool BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:31,712 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-76db5f80-b2b1-4c5b-b60a-050552a6f70c): no suitable block pools found to scan.  Waiting 1814399992 ms.
2020-04-02 05:07:31,726 [BP-775438797-172.17.0.13-1585804051180 heartbeating to localhost/127.0.0.1:42479] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-775438797-172.17.0.13-1585804051180 (Datanode Uuid ea5deb6d-15eb-41c1-8039-8b2dddd2e063) service to localhost/127.0.0.1:42479 successfully registered with NN
2020-04-02 05:07:31,726 [BP-775438797-172.17.0.13-1585804051180 heartbeating to localhost/127.0.0.1:42479] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42479 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:31,733 [IPC Server handler 4 on 42479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-76db5f80-b2b1-4c5b-b60a-050552a6f70c for DN 127.0.0.1:38396
2020-04-02 05:07:31,733 [IPC Server handler 4 on 42479] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9893fd9c-3dd7-4d79-93fc-63caae53d059 for DN 127.0.0.1:38396
2020-04-02 05:07:31,738 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xffbcd6ba85c75469: Processing first storage report for DS-76db5f80-b2b1-4c5b-b60a-050552a6f70c from datanode ea5deb6d-15eb-41c1-8039-8b2dddd2e063
2020-04-02 05:07:31,740 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xffbcd6ba85c75469: from storage DS-76db5f80-b2b1-4c5b-b60a-050552a6f70c node DatanodeRegistration(127.0.0.1:38396, datanodeUuid=ea5deb6d-15eb-41c1-8039-8b2dddd2e063, infoPort=43474, infoSecurePort=0, ipcPort=45455, storageInfo=lv=-57;cid=testClusterID;nsid=682418857;c=1585804051180), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:31,740 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xffbcd6ba85c75469: Processing first storage report for DS-9893fd9c-3dd7-4d79-93fc-63caae53d059 from datanode ea5deb6d-15eb-41c1-8039-8b2dddd2e063
2020-04-02 05:07:31,740 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xffbcd6ba85c75469: from storage DS-9893fd9c-3dd7-4d79-93fc-63caae53d059 node DatanodeRegistration(127.0.0.1:38396, datanodeUuid=ea5deb6d-15eb-41c1-8039-8b2dddd2e063, infoPort=43474, infoSecurePort=0, ipcPort=45455, storageInfo=lv=-57;cid=testClusterID;nsid=682418857;c=1585804051180), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:31,742 [BP-775438797-172.17.0.13-1585804051180 heartbeating to localhost/127.0.0.1:42479] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xffbcd6ba85c75469,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:31,743 [BP-775438797-172.17.0.13-1585804051180 heartbeating to localhost/127.0.0.1:42479] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:31,795 [IPC Server handler 6 on 42479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:31,799 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:31,803 [IPC Server handler 7 on 42479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:31,806 [Thread-307] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=13
2020-04-02 05:07:31,814 [IPC Server handler 8 on 42479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:31,829 [IPC Server handler 9 on 42479] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38396 for /user/root/filelocal.dat
2020-04-02 05:07:31,855 [DataXceiver for client DFSClient_NONMAPREDUCE_-1201935909_902 at /127.0.0.1:56094 [Receiving block BP-775438797-172.17.0.13-1585804051180:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-775438797-172.17.0.13-1585804051180:blk_1073741825_1001 src: /127.0.0.1:56094 dest: /127.0.0.1:38396
2020-04-02 05:07:31,884 [PacketResponder: BP-775438797-172.17.0.13-1585804051180:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56094, dest: /127.0.0.1:38396, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1201935909_902, offset: 0, srvID: ea5deb6d-15eb-41c1-8039-8b2dddd2e063, blockid: BP-775438797-172.17.0.13-1585804051180:blk_1073741825_1001, duration(ns): 20969905
2020-04-02 05:07:31,884 [PacketResponder: BP-775438797-172.17.0.13-1585804051180:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-775438797-172.17.0.13-1585804051180:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:31,904 [IPC Server handler 2 on 42479] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_-1201935909_902
2020-04-02 05:07:31,917 [IPC Server handler 3 on 42479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:31,925 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38396.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-615784751_902, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: f796bd30e495d92f1604bc32c5bda093, srvID: ea5deb6d-15eb-41c1-8039-8b2dddd2e063, success: true
2020-04-02 05:07:31,930 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38396.sock [Passing file descriptors for block BP-775438797-172.17.0.13-1585804051180:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: ea5deb6d-15eb-41c1-8039-8b2dddd2e063, success: true
2020-04-02 05:07:31,933 [IPC Server handler 4 on 42479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:31,943 [IPC Server handler 5 on 42479] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:31,946 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:31,946 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:31,946 [Thread-307] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45455 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:31,947 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@456ef3a6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:31,947 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6e7e2ac3] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:31,957 [Thread-307] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:31,959 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-76db5f80-b2b1-4c5b-b60a-050552a6f70c) exiting.
2020-04-02 05:07:31,962 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9893fd9c-3dd7-4d79-93fc-63caae53d059) exiting.
2020-04-02 05:07:31,980 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@22a16bc4{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:31,986 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@140bbedb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:31,998 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d9d4474{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:31,999 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3f2fe035{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:32,000 [Thread-307] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45455
2020-04-02 05:07:32,006 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:32,006 [BP-775438797-172.17.0.13-1585804051180 heartbeating to localhost/127.0.0.1:42479] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:32,006 [IPC Server listener on 45455] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45455
2020-04-02 05:07:32,006 [BP-775438797-172.17.0.13-1585804051180 heartbeating to localhost/127.0.0.1:42479] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-775438797-172.17.0.13-1585804051180 (Datanode Uuid ea5deb6d-15eb-41c1-8039-8b2dddd2e063) service to localhost/127.0.0.1:42479
2020-04-02 05:07:32,008 [BP-775438797-172.17.0.13-1585804051180 heartbeating to localhost/127.0.0.1:42479] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-775438797-172.17.0.13-1585804051180 (Datanode Uuid ea5deb6d-15eb-41c1-8039-8b2dddd2e063)
2020-04-02 05:07:32,008 [BP-775438797-172.17.0.13-1585804051180 heartbeating to localhost/127.0.0.1:42479] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-775438797-172.17.0.13-1585804051180
2020-04-02 05:07:32,016 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-775438797-172.17.0.13-1585804051180] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:32,026 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-775438797-172.17.0.13-1585804051180] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:32,045 [Thread-307] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:32,046 [Thread-307] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:32,047 [Thread-307] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:32,048 [Thread-307] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:32,062 [Thread-307] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:32,062 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:32,062 [Thread-307] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 42479 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:32,062 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:32,062 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6572b203] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:32,062 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@64bf5234] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:32,063 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:07:32,063 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 2 Number of syncs: 8 SyncTimes(ms): 2 1 
2020-04-02 05:07:32,064 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:32,065 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:32,065 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:32,065 [CacheReplicationMonitor(340934001)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:32,077 [Thread-307] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42479
2020-04-02 05:07:32,079 [IPC Server listener on 42479] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42479
2020-04-02 05:07:32,090 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:32,090 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:32,090 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:32,105 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:32,106 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:32,107 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@243f83a6{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:32,115 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@79ed3d98{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:32,122 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@26f2997f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:32,123 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10fed97c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:32,141 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:32,154 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:32,154 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:32,182 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:32,185 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:32,185 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:32,185 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:32,186 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:32,186 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:32,186 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:32,186 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:32,186 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:32,187 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:32,187 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:32,187 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:32,188 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:32,188 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:32
2020-04-02 05:07:32,188 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:32,188 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:32,189 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:32,189 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:32,193 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:32,193 [Thread-307] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:32,194 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:32,194 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:32,194 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:32,194 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:32,194 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:32,194 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:32,195 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:32,195 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:32,195 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:32,195 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:32,195 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:32,196 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:32,196 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:32,196 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:32,199 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:32,199 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:32,200 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:32,200 [Thread-307] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:32,200 [Thread-307] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:32,200 [Thread-307] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:32,200 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:32,200 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:32,201 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:32,201 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:32,203 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:32,203 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:32,203 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:32,206 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:32,206 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:32,206 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:32,207 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:32,207 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:32,207 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:32,208 [Thread-307] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:32,213 [Thread-307] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:32,218 [Thread-307] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:32,232 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:32,232 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:32,241 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 393 bytes saved in 0 seconds .
2020-04-02 05:07:32,241 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 393 bytes saved in 0 seconds .
2020-04-02 05:07:32,244 [Thread-307] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:32,245 [Thread-307] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:32,251 [Thread-307] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:32,263 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:32,263 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:32,265 [Thread-307] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:32,265 [Thread-307] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:32,273 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c88c577] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:32,274 [Thread-307] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:32,274 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:32,276 [Thread-307] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:32,302 [Thread-307] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:32,302 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:32,303 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:32,304 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:32,305 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:32,305 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:32,313 [Thread-307] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:32,313 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:32,313 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35812
2020-04-02 05:07:32,314 [Thread-307] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:32,328 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3156b9b2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:32,329 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2508bcaf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:32,338 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2a8c062{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:32,339 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@780c91d0{HTTP/1.1,[http/1.1]}{localhost:35812}
2020-04-02 05:07:32,339 [Thread-307] INFO  server.Server (Server.java:doStart(419)) - Started @12126ms
2020-04-02 05:07:32,340 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:32,341 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:32,341 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:32,342 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:32,342 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:32,342 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:32,342 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:32,342 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:32,343 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:32,343 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:32,343 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:32,344 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:32,344 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:32
2020-04-02 05:07:32,345 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:32,345 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:32,345 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:32,347 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:32,377 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:32,380 [Thread-307] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:32,380 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:32,380 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:32,380 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:32,381 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:32,382 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:32,382 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:32,382 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:32,382 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:32,382 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:32,382 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:32,383 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:32,383 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:32,383 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:32,383 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:32,389 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:32,390 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:32,390 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:32,390 [Thread-307] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:32,390 [Thread-307] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:32,390 [Thread-307] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:32,390 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:32,390 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:32,391 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:32,391 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:32,392 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:32,392 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:32,393 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:32,393 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:32,393 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:32,393 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:32,393 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:32,393 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:32,393 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:32,398 [Thread-307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:32,402 [Thread-307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:32,404 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:32,404 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:32,404 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:32,404 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:32,405 [Thread-307] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:32,406 [Thread-307] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:32,406 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:32,406 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:32,407 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:32,422 [Thread-307] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:32,422 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 27 msecs
2020-04-02 05:07:32,422 [Thread-307] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:32,423 [Thread-307] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:32,423 [Socket Reader #1 for port 37161] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37161
2020-04-02 05:07:32,431 [Thread-307] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:37161 to access this namenode/service.
2020-04-02 05:07:32,432 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:32,473 [Thread-307] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:32,483 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:32,484 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:32,484 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:32,484 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:32,489 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:32,489 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:32,489 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:32,489 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:32,490 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:32,490 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-04-02 05:07:32,509 [IPC Server listener on 37161] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37161: starting
2020-04-02 05:07:32,533 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:32,551 [Thread-307] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:37161
2020-04-02 05:07:32,552 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:32,552 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:32,554 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 2 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:32,556 [Thread-307] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 37161 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:32,559 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:32,561 [Thread-307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:32,565 [Thread-307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:32,571 [CacheReplicationMonitor(1349646196)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:32,661 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:32,663 [Thread-307] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:32,663 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:32,663 [Thread-307] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:32,664 [Thread-307] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:32,664 [Thread-307] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:32,664 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:32,665 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:32,670 [Thread-307] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44281
2020-04-02 05:07:32,670 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:32,670 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:32,671 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:32,671 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:32,671 [Thread-307] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.44281.sock
2020-04-02 05:07:32,682 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:32,692 [Thread-307] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:32,694 [Thread-307] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:32,694 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:32,696 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:32,699 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:32,700 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:32,700 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:32,701 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43916
2020-04-02 05:07:32,701 [Thread-307] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:32,704 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5f6a50e9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:32,706 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@24d6e6ca{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:32,711 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@23fcb807{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:32,712 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3159bd6e{HTTP/1.1,[http/1.1]}{localhost:43916}
2020-04-02 05:07:32,712 [Thread-307] INFO  server.Server (Server.java:doStart(419)) - Started @12499ms
2020-04-02 05:07:32,766 [Thread-307] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39646
2020-04-02 05:07:32,766 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:32,766 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:32,766 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7bd55419] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:32,767 [Thread-307] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:32,771 [Socket Reader #1 for port 38254] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38254
2020-04-02 05:07:32,780 [Thread-307] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38254
2020-04-02 05:07:32,786 [Thread-307] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:32,791 [Thread-307] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:32,792 [Thread-458] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37161 starting to offer service
2020-04-02 05:07:32,794 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:32,795 [IPC Server listener on 38254] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38254: starting
2020-04-02 05:07:32,796 [Thread-307] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38254 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:32,863 [IPC Server handler 0 on 37161] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:32,880 [Thread-458] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37161
2020-04-02 05:07:32,881 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:32,881 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:32,891 [Thread-458] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:32,895 [Thread-458] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:32,895 [Thread-458] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 236338095. Formatting...
2020-04-02 05:07:32,895 [Thread-458] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0506e585-c731-4403-8f21-14fcd4c83284 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:32,898 [Thread-458] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:32,898 [Thread-458] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 236338095. Formatting...
2020-04-02 05:07:32,899 [Thread-458] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c45acae4-6fe0-48f4-91f5-8ff495545587 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:32,918 [Thread-458] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:32,934 [Thread-458] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:32,934 [Thread-458] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-692190206-172.17.0.13-1585804052208 is not formatted. Formatting ...
2020-04-02 05:07:32,934 [Thread-458] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-692190206-172.17.0.13-1585804052208 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692190206-172.17.0.13-1585804052208/current
2020-04-02 05:07:32,946 [Thread-458] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:32,946 [Thread-458] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:32,947 [Thread-458] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-692190206-172.17.0.13-1585804052208 is not formatted. Formatting ...
2020-04-02 05:07:32,947 [Thread-458] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-692190206-172.17.0.13-1585804052208 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692190206-172.17.0.13-1585804052208/current
2020-04-02 05:07:32,949 [Thread-458] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=236338095;bpid=BP-692190206-172.17.0.13-1585804052208;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=236338095;c=1585804052208;bpid=BP-692190206-172.17.0.13-1585804052208;dnuuid=null
2020-04-02 05:07:32,951 [Thread-458] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 159c8da9-f1a1-496c-91ba-b7f5c480e800
2020-04-02 05:07:32,953 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0506e585-c731-4403-8f21-14fcd4c83284
2020-04-02 05:07:32,955 [Thread-458] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:32,959 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c45acae4-6fe0-48f4-91f5-8ff495545587
2020-04-02 05:07:32,970 [Thread-458] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:32,970 [Thread-458] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:32,972 [Thread-458] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:32,975 [Thread-458] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:32,975 [Thread-458] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:32,976 [Thread-458] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:32,980 [Thread-458] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:32,981 [Thread-474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-692190206-172.17.0.13-1585804052208 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:32,981 [Thread-475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-692190206-172.17.0.13-1585804052208 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:32,988 [IPC Server handler 5 on 37161] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:32,992 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:32,992 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:33,016 [Thread-475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-692190206-172.17.0.13-1585804052208 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 35ms
2020-04-02 05:07:33,021 [Thread-474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-692190206-172.17.0.13-1585804052208 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 40ms
2020-04-02 05:07:33,021 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-692190206-172.17.0.13-1585804052208: 41ms
2020-04-02 05:07:33,022 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-692190206-172.17.0.13-1585804052208 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:33,022 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-692190206-172.17.0.13-1585804052208 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:33,022 [Thread-478] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692190206-172.17.0.13-1585804052208/current/replicas doesn't exist 
2020-04-02 05:07:33,022 [Thread-479] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692190206-172.17.0.13-1585804052208/current/replicas doesn't exist 
2020-04-02 05:07:33,022 [Thread-478] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-692190206-172.17.0.13-1585804052208 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:07:33,023 [Thread-479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-692190206-172.17.0.13-1585804052208 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:33,029 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-692190206-172.17.0.13-1585804052208: 8ms
2020-04-02 05:07:33,029 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-692190206-172.17.0.13-1585804052208 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:33,030 [Thread-458] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:32 AM with interval of 21600000ms
2020-04-02 05:07:33,030 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c45acae4-6fe0-48f4-91f5-8ff495545587): finished scanning block pool BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:33,030 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c45acae4-6fe0-48f4-91f5-8ff495545587): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:07:33,033 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-692190206-172.17.0.13-1585804052208 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:33,035 [BP-692190206-172.17.0.13-1585804052208 heartbeating to localhost/127.0.0.1:37161] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-692190206-172.17.0.13-1585804052208 (Datanode Uuid 159c8da9-f1a1-496c-91ba-b7f5c480e800) service to localhost/127.0.0.1:37161 beginning handshake with NN
2020-04-02 05:07:33,036 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0506e585-c731-4403-8f21-14fcd4c83284): finished scanning block pool BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:33,036 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0506e585-c731-4403-8f21-14fcd4c83284): no suitable block pools found to scan.  Waiting 1814399993 ms.
2020-04-02 05:07:33,037 [IPC Server handler 7 on 37161] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44281, datanodeUuid=159c8da9-f1a1-496c-91ba-b7f5c480e800, infoPort=39646, infoSecurePort=0, ipcPort=38254, storageInfo=lv=-57;cid=testClusterID;nsid=236338095;c=1585804052208) storage 159c8da9-f1a1-496c-91ba-b7f5c480e800
2020-04-02 05:07:33,037 [IPC Server handler 7 on 37161] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44281
2020-04-02 05:07:33,037 [IPC Server handler 7 on 37161] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 159c8da9-f1a1-496c-91ba-b7f5c480e800 (127.0.0.1:44281).
2020-04-02 05:07:33,049 [BP-692190206-172.17.0.13-1585804052208 heartbeating to localhost/127.0.0.1:37161] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-692190206-172.17.0.13-1585804052208 (Datanode Uuid 159c8da9-f1a1-496c-91ba-b7f5c480e800) service to localhost/127.0.0.1:37161 successfully registered with NN
2020-04-02 05:07:33,049 [BP-692190206-172.17.0.13-1585804052208 heartbeating to localhost/127.0.0.1:37161] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37161 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:33,059 [IPC Server handler 8 on 37161] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0506e585-c731-4403-8f21-14fcd4c83284 for DN 127.0.0.1:44281
2020-04-02 05:07:33,059 [IPC Server handler 8 on 37161] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c45acae4-6fe0-48f4-91f5-8ff495545587 for DN 127.0.0.1:44281
2020-04-02 05:07:33,064 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x443720299c7506be: Processing first storage report for DS-c45acae4-6fe0-48f4-91f5-8ff495545587 from datanode 159c8da9-f1a1-496c-91ba-b7f5c480e800
2020-04-02 05:07:33,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x443720299c7506be: from storage DS-c45acae4-6fe0-48f4-91f5-8ff495545587 node DatanodeRegistration(127.0.0.1:44281, datanodeUuid=159c8da9-f1a1-496c-91ba-b7f5c480e800, infoPort=39646, infoSecurePort=0, ipcPort=38254, storageInfo=lv=-57;cid=testClusterID;nsid=236338095;c=1585804052208), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:33,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x443720299c7506be: Processing first storage report for DS-0506e585-c731-4403-8f21-14fcd4c83284 from datanode 159c8da9-f1a1-496c-91ba-b7f5c480e800
2020-04-02 05:07:33,065 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x443720299c7506be: from storage DS-0506e585-c731-4403-8f21-14fcd4c83284 node DatanodeRegistration(127.0.0.1:44281, datanodeUuid=159c8da9-f1a1-496c-91ba-b7f5c480e800, infoPort=39646, infoSecurePort=0, ipcPort=38254, storageInfo=lv=-57;cid=testClusterID;nsid=236338095;c=1585804052208), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:33,066 [BP-692190206-172.17.0.13-1585804052208 heartbeating to localhost/127.0.0.1:37161] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x443720299c7506be,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:33,066 [BP-692190206-172.17.0.13-1585804052208 heartbeating to localhost/127.0.0.1:37161] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:33,095 [IPC Server handler 3 on 37161] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:33,096 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:33,103 [IPC Server handler 2 on 37161] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:33,104 [Thread-307] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=13
2020-04-02 05:07:33,112 [IPC Server handler 1 on 37161] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:33,134 [IPC Server handler 6 on 37161] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:44281 for /user/root/filelocal.dat
2020-04-02 05:07:33,152 [DataXceiver for client DFSClient_NONMAPREDUCE_-150810646_902 at /127.0.0.1:40252 [Receiving block BP-692190206-172.17.0.13-1585804052208:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-692190206-172.17.0.13-1585804052208:blk_1073741825_1001 src: /127.0.0.1:40252 dest: /127.0.0.1:44281
2020-04-02 05:07:33,221 [PacketResponder: BP-692190206-172.17.0.13-1585804052208:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40252, dest: /127.0.0.1:44281, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-150810646_902, offset: 0, srvID: 159c8da9-f1a1-496c-91ba-b7f5c480e800, blockid: BP-692190206-172.17.0.13-1585804052208:blk_1073741825_1001, duration(ns): 63014653
2020-04-02 05:07:33,222 [PacketResponder: BP-692190206-172.17.0.13-1585804052208:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-692190206-172.17.0.13-1585804052208:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:33,225 [IPC Server handler 5 on 37161] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/filelocal.dat
2020-04-02 05:07:33,662 [IPC Server handler 7 on 37161] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_-150810646_902
2020-04-02 05:07:33,668 [IPC Server handler 8 on 37161] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:33,674 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.44281.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_2002615863_902, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: 153667b69117f6c5e9b3909203563945, srvID: 159c8da9-f1a1-496c-91ba-b7f5c480e800, success: true
2020-04-02 05:07:33,679 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.44281.sock [Passing file descriptors for block BP-692190206-172.17.0.13-1585804052208:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 159c8da9-f1a1-496c-91ba-b7f5c480e800, success: true
2020-04-02 05:07:33,685 [IPC Server handler 9 on 37161] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:33,700 [IPC Server handler 3 on 37161] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:33,707 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:33,707 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:33,707 [Thread-307] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38254 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:33,707 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@661d7efe] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:33,707 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@cea006f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:33,718 [Thread-307] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:33,723 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0506e585-c731-4403-8f21-14fcd4c83284) exiting.
2020-04-02 05:07:33,724 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-c45acae4-6fe0-48f4-91f5-8ff495545587) exiting.
2020-04-02 05:07:33,806 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@23fcb807{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:33,807 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3159bd6e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:33,807 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@24d6e6ca{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:33,808 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5f6a50e9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:33,812 [Thread-307] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38254
2020-04-02 05:07:33,815 [IPC Server listener on 38254] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38254
2020-04-02 05:07:33,815 [BP-692190206-172.17.0.13-1585804052208 heartbeating to localhost/127.0.0.1:37161] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:33,815 [BP-692190206-172.17.0.13-1585804052208 heartbeating to localhost/127.0.0.1:37161] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-692190206-172.17.0.13-1585804052208 (Datanode Uuid 159c8da9-f1a1-496c-91ba-b7f5c480e800) service to localhost/127.0.0.1:37161
2020-04-02 05:07:33,815 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:33,816 [BP-692190206-172.17.0.13-1585804052208 heartbeating to localhost/127.0.0.1:37161] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-692190206-172.17.0.13-1585804052208 (Datanode Uuid 159c8da9-f1a1-496c-91ba-b7f5c480e800)
2020-04-02 05:07:33,816 [BP-692190206-172.17.0.13-1585804052208 heartbeating to localhost/127.0.0.1:37161] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-692190206-172.17.0.13-1585804052208
2020-04-02 05:07:33,832 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692190206-172.17.0.13-1585804052208] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:33,835 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692190206-172.17.0.13-1585804052208] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:33,855 [Thread-307] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:33,855 [Thread-307] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:33,856 [Thread-307] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:33,856 [Thread-307] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:33,863 [Thread-307] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:33,863 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:33,863 [Thread-307] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 37161 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:33,863 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:33,864 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5c25aa45] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:33,865 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:07:33,868 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@769ce663] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:33,868 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 3 Number of syncs: 7 SyncTimes(ms): 4 3 
2020-04-02 05:07:33,869 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:33,870 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:33,870 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:33,874 [Thread-307] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37161
2020-04-02 05:07:33,875 [IPC Server listener on 37161] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37161
2020-04-02 05:07:33,874 [CacheReplicationMonitor(1349646196)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:33,884 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:33,885 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:33,894 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:33,914 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:33,914 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:33,915 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2a8c062{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:33,930 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@780c91d0{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:33,931 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2508bcaf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:33,931 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3156b9b2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:33,934 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:33,974 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:33,974 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:34,000 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:34,004 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:34,005 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:34,006 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:34,006 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:34,006 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:34,006 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:34,006 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:34,007 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:34,007 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:34,007 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:34,007 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:34,008 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:34,008 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:34
2020-04-02 05:07:34,008 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:34,009 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,009 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:34,009 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:34,022 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:34,023 [Thread-307] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:34,023 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:34,024 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:34,024 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,024 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:34,024 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:34,031 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:34,031 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:34,031 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:34,031 [Thread-307] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:34,032 [Thread-307] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:34,032 [Thread-307] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:34,032 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:34,032 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,032 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:34,032 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:34,041 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:34,041 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:34,041 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:34,042 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:34,042 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:34,042 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:34,042 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,042 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:34,042 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:34,044 [Thread-307] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,049 [Thread-307] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:34,051 [Thread-307] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:34,056 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:34,062 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:34,063 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:34,078 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:34,090 [Thread-307] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:34,092 [Thread-307] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:34,096 [Thread-307] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:34,098 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:34,098 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:34,100 [Thread-307] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:34,100 [Thread-307] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:34,108 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@9c54997] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:34,109 [Thread-307] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:34,109 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:34,111 [Thread-307] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:34,112 [Thread-307] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:34,112 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:34,113 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:34,114 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:34,114 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:34,115 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:34,116 [Thread-307] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:34,116 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:34,117 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36795
2020-04-02 05:07:34,118 [Thread-307] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:34,122 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7ca9dc4d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:34,123 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cd9361b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:34,129 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7cba0436{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:34,130 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6edbc035{HTTP/1.1,[http/1.1]}{localhost:36795}
2020-04-02 05:07:34,131 [Thread-307] INFO  server.Server (Server.java:doStart(419)) - Started @13917ms
2020-04-02 05:07:34,132 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:34,132 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:34,132 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:34,132 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:34,133 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:34,133 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:34,133 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:34,133 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:34,133 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:34,145 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:34,146 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:34,146 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:34,147 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:34
2020-04-02 05:07:34,147 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:34,147 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,147 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:34,147 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:34,242 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:34,249 [Thread-307] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:34,249 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:34,250 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:34,250 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:34,250 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:34,251 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:34,251 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:34,251 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:34,251 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:34,251 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:34,251 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:34,252 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:34,252 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,252 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:34,252 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:34,259 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:34,259 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:34,259 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:34,259 [Thread-307] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:34,259 [Thread-307] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:34,259 [Thread-307] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:34,260 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:34,260 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,260 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:34,260 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:34,261 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:34,261 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:34,261 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:34,261 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:34,262 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:34,262 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:34,262 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,262 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:34,262 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:34,266 [Thread-307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:34,267 [Thread-307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:34,269 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:34,269 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:34,270 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:34,270 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:34,271 [Thread-307] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:34,274 [Thread-307] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:34,274 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:34,275 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:34,275 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:34,288 [Thread-307] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:34,289 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 25 msecs
2020-04-02 05:07:34,289 [Thread-307] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:34,289 [Thread-307] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:34,290 [Socket Reader #1 for port 45110] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45110
2020-04-02 05:07:34,299 [Thread-307] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:45110 to access this namenode/service.
2020-04-02 05:07:34,300 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:34,322 [Thread-307] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:34,324 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:34,324 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:34,324 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:34,325 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:34,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:34,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:34,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:34,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:34,339 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:34,339 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2020-04-02 05:07:34,341 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:34,341 [IPC Server listener on 45110] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45110: starting
2020-04-02 05:07:34,344 [Thread-307] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:45110
2020-04-02 05:07:34,345 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:34,345 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:34,345 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:34,348 [Thread-307] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 45110 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:34,349 [CacheReplicationMonitor(1505605555)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:34,355 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:34,357 [Thread-307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:34,359 [Thread-307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:34,359 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:34,361 [Thread-307] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:34,361 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:34,361 [Thread-307] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:34,361 [Thread-307] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:34,361 [Thread-307] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:34,362 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:34,362 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:34,363 [Thread-307] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34250
2020-04-02 05:07:34,363 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:34,363 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:34,363 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:34,363 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:34,364 [Thread-307] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.34250.sock
2020-04-02 05:07:34,364 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:34,366 [Thread-307] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:34,366 [Thread-307] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:34,366 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:34,367 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:34,368 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:34,368 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:34,368 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:34,369 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46846
2020-04-02 05:07:34,369 [Thread-307] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:34,370 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d290460{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:34,371 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@45710956{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:34,376 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2432d867{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:34,377 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1412f2cf{HTTP/1.1,[http/1.1]}{localhost:46846}
2020-04-02 05:07:34,377 [Thread-307] INFO  server.Server (Server.java:doStart(419)) - Started @14164ms
2020-04-02 05:07:34,398 [Thread-307] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41049
2020-04-02 05:07:34,399 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:34,399 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:34,399 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1630a380] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:34,399 [Thread-307] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:34,400 [Socket Reader #1 for port 36836] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36836
2020-04-02 05:07:34,412 [Thread-307] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36836
2020-04-02 05:07:34,415 [Thread-307] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:34,416 [Thread-307] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:34,417 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:34,417 [IPC Server listener on 36836] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36836: starting
2020-04-02 05:07:34,417 [Thread-552] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45110 starting to offer service
2020-04-02 05:07:34,428 [Thread-307] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36836 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:34,437 [Thread-552] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45110
2020-04-02 05:07:34,438 [Thread-552] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:34,441 [IPC Server handler 1 on 45110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:34,443 [Thread-552] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:34,443 [Thread-552] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 763898151. Formatting...
2020-04-02 05:07:34,444 [Thread-552] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-af23f152-e15c-41c0-9885-f7587f65d27b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:34,444 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:34,444 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:34,447 [Thread-552] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:34,447 [Thread-552] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 763898151. Formatting...
2020-04-02 05:07:34,448 [Thread-552] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e375e716-c6cc-470a-806a-57485a696a15 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:34,460 [Thread-552] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,461 [Thread-552] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,461 [Thread-552] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-840061122-172.17.0.13-1585804054044 is not formatted. Formatting ...
2020-04-02 05:07:34,461 [Thread-552] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-840061122-172.17.0.13-1585804054044 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-840061122-172.17.0.13-1585804054044/current
2020-04-02 05:07:34,471 [Thread-552] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,471 [Thread-552] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,472 [Thread-552] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-840061122-172.17.0.13-1585804054044 is not formatted. Formatting ...
2020-04-02 05:07:34,472 [Thread-552] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-840061122-172.17.0.13-1585804054044 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-840061122-172.17.0.13-1585804054044/current
2020-04-02 05:07:34,473 [Thread-552] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=763898151;bpid=BP-840061122-172.17.0.13-1585804054044;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=763898151;c=1585804054044;bpid=BP-840061122-172.17.0.13-1585804054044;dnuuid=null
2020-04-02 05:07:34,475 [Thread-552] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 698198ac-a0f8-402e-a779-0b181a5953b5
2020-04-02 05:07:34,477 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-af23f152-e15c-41c0-9885-f7587f65d27b
2020-04-02 05:07:34,477 [Thread-552] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:34,480 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e375e716-c6cc-470a-806a-57485a696a15
2020-04-02 05:07:34,481 [Thread-552] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:34,482 [Thread-552] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:34,483 [Thread-552] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:34,484 [Thread-552] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:34,484 [Thread-552] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:34,484 [Thread-552] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:34,484 [Thread-552] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,484 [Thread-568] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-840061122-172.17.0.13-1585804054044 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:34,484 [Thread-569] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-840061122-172.17.0.13-1585804054044 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:34,506 [Thread-569] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-840061122-172.17.0.13-1585804054044 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 21ms
2020-04-02 05:07:34,514 [Thread-568] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-840061122-172.17.0.13-1585804054044 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 30ms
2020-04-02 05:07:34,514 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-840061122-172.17.0.13-1585804054044: 31ms
2020-04-02 05:07:34,515 [Thread-572] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-840061122-172.17.0.13-1585804054044 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:34,515 [Thread-573] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-840061122-172.17.0.13-1585804054044 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:34,515 [Thread-572] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-840061122-172.17.0.13-1585804054044/current/replicas doesn't exist 
2020-04-02 05:07:34,515 [Thread-573] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-840061122-172.17.0.13-1585804054044/current/replicas doesn't exist 
2020-04-02 05:07:34,516 [Thread-573] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-840061122-172.17.0.13-1585804054044 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:34,516 [Thread-572] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-840061122-172.17.0.13-1585804054044 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:07:34,521 [Thread-552] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-840061122-172.17.0.13-1585804054044: 7ms
2020-04-02 05:07:34,522 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-840061122-172.17.0.13-1585804054044 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:34,522 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-840061122-172.17.0.13-1585804054044 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:34,522 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-af23f152-e15c-41c0-9885-f7587f65d27b): finished scanning block pool BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,522 [Thread-552] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:16 AM with interval of 21600000ms
2020-04-02 05:07:34,522 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e375e716-c6cc-470a-806a-57485a696a15): finished scanning block pool BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,523 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e375e716-c6cc-470a-806a-57485a696a15): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:07:34,527 [BP-840061122-172.17.0.13-1585804054044 heartbeating to localhost/127.0.0.1:45110] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-840061122-172.17.0.13-1585804054044 (Datanode Uuid 698198ac-a0f8-402e-a779-0b181a5953b5) service to localhost/127.0.0.1:45110 beginning handshake with NN
2020-04-02 05:07:34,527 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-af23f152-e15c-41c0-9885-f7587f65d27b): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:07:34,530 [IPC Server handler 2 on 45110] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34250, datanodeUuid=698198ac-a0f8-402e-a779-0b181a5953b5, infoPort=41049, infoSecurePort=0, ipcPort=36836, storageInfo=lv=-57;cid=testClusterID;nsid=763898151;c=1585804054044) storage 698198ac-a0f8-402e-a779-0b181a5953b5
2020-04-02 05:07:34,530 [IPC Server handler 2 on 45110] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34250
2020-04-02 05:07:34,530 [IPC Server handler 2 on 45110] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 698198ac-a0f8-402e-a779-0b181a5953b5 (127.0.0.1:34250).
2020-04-02 05:07:34,533 [BP-840061122-172.17.0.13-1585804054044 heartbeating to localhost/127.0.0.1:45110] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-840061122-172.17.0.13-1585804054044 (Datanode Uuid 698198ac-a0f8-402e-a779-0b181a5953b5) service to localhost/127.0.0.1:45110 successfully registered with NN
2020-04-02 05:07:34,533 [BP-840061122-172.17.0.13-1585804054044 heartbeating to localhost/127.0.0.1:45110] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:45110 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:34,537 [IPC Server handler 3 on 45110] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-af23f152-e15c-41c0-9885-f7587f65d27b for DN 127.0.0.1:34250
2020-04-02 05:07:34,537 [IPC Server handler 3 on 45110] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e375e716-c6cc-470a-806a-57485a696a15 for DN 127.0.0.1:34250
2020-04-02 05:07:34,540 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2aa883d8a5efb04a: Processing first storage report for DS-e375e716-c6cc-470a-806a-57485a696a15 from datanode 698198ac-a0f8-402e-a779-0b181a5953b5
2020-04-02 05:07:34,540 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2aa883d8a5efb04a: from storage DS-e375e716-c6cc-470a-806a-57485a696a15 node DatanodeRegistration(127.0.0.1:34250, datanodeUuid=698198ac-a0f8-402e-a779-0b181a5953b5, infoPort=41049, infoSecurePort=0, ipcPort=36836, storageInfo=lv=-57;cid=testClusterID;nsid=763898151;c=1585804054044), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:34,540 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2aa883d8a5efb04a: Processing first storage report for DS-af23f152-e15c-41c0-9885-f7587f65d27b from datanode 698198ac-a0f8-402e-a779-0b181a5953b5
2020-04-02 05:07:34,540 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2aa883d8a5efb04a: from storage DS-af23f152-e15c-41c0-9885-f7587f65d27b node DatanodeRegistration(127.0.0.1:34250, datanodeUuid=698198ac-a0f8-402e-a779-0b181a5953b5, infoPort=41049, infoSecurePort=0, ipcPort=36836, storageInfo=lv=-57;cid=testClusterID;nsid=763898151;c=1585804054044), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:34,541 [BP-840061122-172.17.0.13-1585804054044 heartbeating to localhost/127.0.0.1:45110] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2aa883d8a5efb04a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:34,541 [BP-840061122-172.17.0.13-1585804054044 heartbeating to localhost/127.0.0.1:45110] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,548 [IPC Server handler 5 on 45110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:34,549 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:34,552 [IPC Server handler 6 on 45110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:34,556 [Thread-307] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=13
2020-04-02 05:07:34,559 [IPC Server handler 7 on 45110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:34,570 [IPC Server handler 8 on 45110] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:34250 for /user/root/filelocal.dat
2020-04-02 05:07:34,576 [DataXceiver for client DFSClient_NONMAPREDUCE_1996432663_902 at /127.0.0.1:51674 [Receiving block BP-840061122-172.17.0.13-1585804054044:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-840061122-172.17.0.13-1585804054044:blk_1073741825_1001 src: /127.0.0.1:51674 dest: /127.0.0.1:34250
2020-04-02 05:07:34,623 [PacketResponder: BP-840061122-172.17.0.13-1585804054044:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51674, dest: /127.0.0.1:34250, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1996432663_902, offset: 0, srvID: 698198ac-a0f8-402e-a779-0b181a5953b5, blockid: BP-840061122-172.17.0.13-1585804054044:blk_1073741825_1001, duration(ns): 28072080
2020-04-02 05:07:34,623 [PacketResponder: BP-840061122-172.17.0.13-1585804054044:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-840061122-172.17.0.13-1585804054044:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:34,633 [IPC Server handler 1 on 45110] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_1996432663_902
2020-04-02 05:07:34,644 [IPC Server handler 2 on 45110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:34,649 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.34250.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-103465953_902, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: 8aa54d46db6f238530e6b0dc3b8608b8, srvID: 698198ac-a0f8-402e-a779-0b181a5953b5, success: true
2020-04-02 05:07:34,651 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.34250.sock [Passing file descriptors for block BP-840061122-172.17.0.13-1585804054044:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 698198ac-a0f8-402e-a779-0b181a5953b5, success: true
2020-04-02 05:07:34,657 [IPC Server handler 3 on 45110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:34,675 [IPC Server handler 4 on 45110] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:34,676 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:34,677 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:34,677 [Thread-307] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36836 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:34,678 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1c49780a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:34,678 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7bcc0645] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:34,688 [Thread-307] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:34,695 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-af23f152-e15c-41c0-9885-f7587f65d27b) exiting.
2020-04-02 05:07:34,695 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-e375e716-c6cc-470a-806a-57485a696a15) exiting.
2020-04-02 05:07:34,734 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2432d867{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:34,749 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1412f2cf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:34,749 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@45710956{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:34,750 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d290460{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:34,753 [Thread-307] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36836
2020-04-02 05:07:34,757 [IPC Server listener on 36836] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36836
2020-04-02 05:07:34,759 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:34,759 [BP-840061122-172.17.0.13-1585804054044 heartbeating to localhost/127.0.0.1:45110] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:34,759 [BP-840061122-172.17.0.13-1585804054044 heartbeating to localhost/127.0.0.1:45110] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-840061122-172.17.0.13-1585804054044 (Datanode Uuid 698198ac-a0f8-402e-a779-0b181a5953b5) service to localhost/127.0.0.1:45110
2020-04-02 05:07:34,760 [BP-840061122-172.17.0.13-1585804054044 heartbeating to localhost/127.0.0.1:45110] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-840061122-172.17.0.13-1585804054044 (Datanode Uuid 698198ac-a0f8-402e-a779-0b181a5953b5)
2020-04-02 05:07:34,760 [BP-840061122-172.17.0.13-1585804054044 heartbeating to localhost/127.0.0.1:45110] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-840061122-172.17.0.13-1585804054044
2020-04-02 05:07:34,775 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-840061122-172.17.0.13-1585804054044] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:34,788 [Thread-307] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:34,788 [Thread-307] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:34,788 [Thread-307] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:34,789 [Thread-307] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:34,790 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-840061122-172.17.0.13-1585804054044] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:34,803 [Thread-307] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:34,804 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:34,804 [Thread-307] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 45110 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:34,804 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:34,804 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:07:34,804 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@36bdadd4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:34,804 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@9b656d1] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:34,805 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 3 Number of syncs: 7 SyncTimes(ms): 1 4 
2020-04-02 05:07:34,806 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:34,808 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:34,808 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:34,809 [CacheReplicationMonitor(1505605555)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:34,813 [Thread-307] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45110
2020-04-02 05:07:34,844 [IPC Server listener on 45110] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45110
2020-04-02 05:07:34,844 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:34,844 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:34,846 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:34,859 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:34,859 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:34,862 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7cba0436{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:34,865 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6edbc035{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:34,865 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@cd9361b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:34,866 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7ca9dc4d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:34,868 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:34,871 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:34,872 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:34,885 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:34,887 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:34,888 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:34,888 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:34,888 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:34,888 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:34,888 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:34,888 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:34,889 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:34,889 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:34,889 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:34,889 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:34,890 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:34,890 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:34
2020-04-02 05:07:34,890 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:34,890 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,890 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:34,890 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:34,895 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:34,895 [Thread-307] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:34,896 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:34,897 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:34,897 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,897 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:34,897 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:34,899 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:34,899 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:34,899 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:34,900 [Thread-307] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:34,900 [Thread-307] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:34,900 [Thread-307] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:34,900 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:34,900 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,900 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:34,900 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:34,901 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:34,901 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:34,901 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:34,902 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:34,902 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:34,902 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:34,902 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,902 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:34,902 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:34,903 [Thread-307] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:34,905 [Thread-307] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:34,909 [Thread-307] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:34,914 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:34,918 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:34,934 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:34,937 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:34,940 [Thread-307] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:34,941 [Thread-307] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:34,946 [Thread-307] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:34,947 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:34,948 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:34,949 [Thread-307] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:34,949 [Thread-307] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:34,954 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3977a943] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:34,955 [Thread-307] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:34,955 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:34,956 [Thread-307] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:34,957 [Thread-307] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:34,957 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:34,959 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:34,959 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:34,959 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:34,960 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:34,961 [Thread-307] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:34,961 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:34,962 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 32791
2020-04-02 05:07:34,962 [Thread-307] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:34,973 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62695c4e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:34,976 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2aa0a506{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:34,987 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7270f16a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:34,987 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70c3d453{HTTP/1.1,[http/1.1]}{localhost:32791}
2020-04-02 05:07:34,988 [Thread-307] INFO  server.Server (Server.java:doStart(419)) - Started @14774ms
2020-04-02 05:07:34,989 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:34,989 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:34,992 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:34,992 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:34,992 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:34,992 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:34,992 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:34,993 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:34,993 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:34,997 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:34,997 [Thread-307] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:34,998 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:34,998 [Thread-307] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:34
2020-04-02 05:07:34,998 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:34,998 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:34,998 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:34,998 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:35,003 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:35,003 [Thread-307] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:35,004 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:35,004 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:35,004 [Thread-307] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:35,004 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:35,004 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:35,004 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:35,004 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:35,004 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:35,005 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:35,005 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:35,005 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:35,005 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,005 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:35,005 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:35,007 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:35,007 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:35,007 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:35,007 [Thread-307] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:35,008 [Thread-307] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:35,008 [Thread-307] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:35,008 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:35,008 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,008 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:35,008 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:35,009 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:35,009 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:35,009 [Thread-307] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:35,009 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:35,009 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:35,010 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:35,010 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,010 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:35,010 [Thread-307] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:35,013 [Thread-307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:35,014 [Thread-307] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:35,015 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:35,015 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:35,016 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:35,016 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:35,017 [Thread-307] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:35,017 [Thread-307] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:35,018 [Thread-307] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:35,018 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:35,018 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:35,027 [Thread-307] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:35,027 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 16 msecs
2020-04-02 05:07:35,027 [Thread-307] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:35,028 [Thread-307] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:35,028 [Socket Reader #1 for port 42643] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42643
2020-04-02 05:07:35,032 [Thread-307] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:42643 to access this namenode/service.
2020-04-02 05:07:35,033 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:35,058 [Thread-307] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:35,060 [Thread-307] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:35,061 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:35,061 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:35,061 [Thread-307] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:35,065 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:35,066 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:35,066 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:35,066 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:35,066 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:35,066 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-02 05:07:35,070 [IPC Server listener on 42643] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42643: starting
2020-04-02 05:07:35,070 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:35,071 [Thread-307] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:42643
2020-04-02 05:07:35,071 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:35,071 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:35,071 [Thread-307] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:35,081 [Thread-307] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 42643 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:35,087 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:35,088 [Thread-307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:35,089 [Thread-307] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:35,089 [CacheReplicationMonitor(2020267498)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:35,097 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:35,097 [Thread-307] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:35,097 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:35,098 [Thread-307] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:35,098 [Thread-307] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:35,098 [Thread-307] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:35,098 [Thread-307] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:35,098 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:35,099 [Thread-307] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45841
2020-04-02 05:07:35,099 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:35,099 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:35,099 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:35,099 [Thread-307] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:35,099 [Thread-307] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.45841.sock
2020-04-02 05:07:35,100 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:35,101 [Thread-307] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:35,102 [Thread-307] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:35,102 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:35,103 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:35,104 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:35,104 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:35,104 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:35,105 [Thread-307] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46292
2020-04-02 05:07:35,105 [Thread-307] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:35,111 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@647d50bc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:35,114 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@653d1698{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:35,119 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@e93c9f5{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:35,120 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2305e621{HTTP/1.1,[http/1.1]}{localhost:46292}
2020-04-02 05:07:35,126 [Thread-307] INFO  server.Server (Server.java:doStart(419)) - Started @14912ms
2020-04-02 05:07:35,152 [Thread-307] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37532
2020-04-02 05:07:35,152 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:35,152 [Thread-307] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:35,153 [Thread-307] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:35,154 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@623227bc] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:35,157 [Thread-307] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43722
2020-04-02 05:07:35,170 [Socket Reader #1 for port 43722] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43722
2020-04-02 05:07:35,205 [Thread-307] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:35,206 [Thread-307] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:35,206 [Thread-642] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42643 starting to offer service
2020-04-02 05:07:35,222 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:35,227 [IPC Server listener on 43722] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43722: starting
2020-04-02 05:07:35,228 [Thread-307] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43722 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:35,252 [IPC Server handler 0 on 42643] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:35,252 [Thread-642] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:42643
2020-04-02 05:07:35,256 [Thread-642] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:35,259 [Thread-642] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:35,259 [Thread-642] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 276271803. Formatting...
2020-04-02 05:07:35,260 [Thread-642] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a174404e-32a1-49d5-a25f-748a49dd8de4 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:35,260 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:35,261 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:35,263 [Thread-642] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:35,263 [Thread-642] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 276271803. Formatting...
2020-04-02 05:07:35,263 [Thread-642] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7ea7f58d-8bf1-436d-918f-aff2bd98b07e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:35,274 [Thread-642] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:35,274 [Thread-642] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:35,274 [Thread-642] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1721828334-172.17.0.13-1585804054903 is not formatted. Formatting ...
2020-04-02 05:07:35,274 [Thread-642] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1721828334-172.17.0.13-1585804054903 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1721828334-172.17.0.13-1585804054903/current
2020-04-02 05:07:35,283 [Thread-642] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:35,284 [Thread-642] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:35,284 [Thread-642] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1721828334-172.17.0.13-1585804054903 is not formatted. Formatting ...
2020-04-02 05:07:35,284 [Thread-642] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1721828334-172.17.0.13-1585804054903 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1721828334-172.17.0.13-1585804054903/current
2020-04-02 05:07:35,285 [Thread-642] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=276271803;bpid=BP-1721828334-172.17.0.13-1585804054903;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=276271803;c=1585804054903;bpid=BP-1721828334-172.17.0.13-1585804054903;dnuuid=null
2020-04-02 05:07:35,287 [Thread-642] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 424de891-a213-4604-bf9b-44fae0912d0d
2020-04-02 05:07:35,289 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a174404e-32a1-49d5-a25f-748a49dd8de4
2020-04-02 05:07:35,290 [Thread-642] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:35,291 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7ea7f58d-8bf1-436d-918f-aff2bd98b07e
2020-04-02 05:07:35,291 [Thread-642] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:35,291 [Thread-642] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:35,292 [Thread-642] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:35,292 [Thread-642] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:35,292 [Thread-642] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:35,292 [Thread-642] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:35,292 [Thread-642] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:35,295 [Thread-659] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1721828334-172.17.0.13-1585804054903 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:35,298 [Thread-658] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1721828334-172.17.0.13-1585804054903 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:35,328 [Thread-659] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1721828334-172.17.0.13-1585804054903 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 33ms
2020-04-02 05:07:35,341 [Thread-658] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1721828334-172.17.0.13-1585804054903 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 43ms
2020-04-02 05:07:35,342 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1721828334-172.17.0.13-1585804054903: 49ms
2020-04-02 05:07:35,346 [Thread-662] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1721828334-172.17.0.13-1585804054903 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:35,346 [Thread-662] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1721828334-172.17.0.13-1585804054903/current/replicas doesn't exist 
2020-04-02 05:07:35,352 [Thread-662] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1721828334-172.17.0.13-1585804054903 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 6ms
2020-04-02 05:07:35,354 [Thread-663] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1721828334-172.17.0.13-1585804054903 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:35,354 [Thread-663] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1721828334-172.17.0.13-1585804054903/current/replicas doesn't exist 
2020-04-02 05:07:35,355 [Thread-663] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1721828334-172.17.0.13-1585804054903 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:35,355 [Thread-642] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1721828334-172.17.0.13-1585804054903: 13ms
2020-04-02 05:07:35,356 [Thread-642] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:59 AM with interval of 21600000ms
2020-04-02 05:07:35,356 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1721828334-172.17.0.13-1585804054903 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:35,356 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a174404e-32a1-49d5-a25f-748a49dd8de4): finished scanning block pool BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:35,357 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a174404e-32a1-49d5-a25f-748a49dd8de4): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:07:35,357 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1721828334-172.17.0.13-1585804054903 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:35,358 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7ea7f58d-8bf1-436d-918f-aff2bd98b07e): finished scanning block pool BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:35,359 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7ea7f58d-8bf1-436d-918f-aff2bd98b07e): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:07:35,364 [BP-1721828334-172.17.0.13-1585804054903 heartbeating to localhost/127.0.0.1:42643] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1721828334-172.17.0.13-1585804054903 (Datanode Uuid 424de891-a213-4604-bf9b-44fae0912d0d) service to localhost/127.0.0.1:42643 beginning handshake with NN
2020-04-02 05:07:35,367 [IPC Server handler 2 on 42643] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:35,368 [IPC Server handler 3 on 42643] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45841, datanodeUuid=424de891-a213-4604-bf9b-44fae0912d0d, infoPort=37532, infoSecurePort=0, ipcPort=43722, storageInfo=lv=-57;cid=testClusterID;nsid=276271803;c=1585804054903) storage 424de891-a213-4604-bf9b-44fae0912d0d
2020-04-02 05:07:35,368 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:35,368 [IPC Server handler 3 on 42643] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45841
2020-04-02 05:07:35,368 [IPC Server handler 3 on 42643] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 424de891-a213-4604-bf9b-44fae0912d0d (127.0.0.1:45841).
2020-04-02 05:07:35,368 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:35,379 [BP-1721828334-172.17.0.13-1585804054903 heartbeating to localhost/127.0.0.1:42643] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1721828334-172.17.0.13-1585804054903 (Datanode Uuid 424de891-a213-4604-bf9b-44fae0912d0d) service to localhost/127.0.0.1:42643 successfully registered with NN
2020-04-02 05:07:35,379 [BP-1721828334-172.17.0.13-1585804054903 heartbeating to localhost/127.0.0.1:42643] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:42643 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:35,397 [IPC Server handler 4 on 42643] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a174404e-32a1-49d5-a25f-748a49dd8de4 for DN 127.0.0.1:45841
2020-04-02 05:07:35,398 [IPC Server handler 4 on 42643] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ea7f58d-8bf1-436d-918f-aff2bd98b07e for DN 127.0.0.1:45841
2020-04-02 05:07:35,406 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xad6faf0b6fbfc7e7: Processing first storage report for DS-7ea7f58d-8bf1-436d-918f-aff2bd98b07e from datanode 424de891-a213-4604-bf9b-44fae0912d0d
2020-04-02 05:07:35,406 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xad6faf0b6fbfc7e7: from storage DS-7ea7f58d-8bf1-436d-918f-aff2bd98b07e node DatanodeRegistration(127.0.0.1:45841, datanodeUuid=424de891-a213-4604-bf9b-44fae0912d0d, infoPort=37532, infoSecurePort=0, ipcPort=43722, storageInfo=lv=-57;cid=testClusterID;nsid=276271803;c=1585804054903), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:35,407 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xad6faf0b6fbfc7e7: Processing first storage report for DS-a174404e-32a1-49d5-a25f-748a49dd8de4 from datanode 424de891-a213-4604-bf9b-44fae0912d0d
2020-04-02 05:07:35,407 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xad6faf0b6fbfc7e7: from storage DS-a174404e-32a1-49d5-a25f-748a49dd8de4 node DatanodeRegistration(127.0.0.1:45841, datanodeUuid=424de891-a213-4604-bf9b-44fae0912d0d, infoPort=37532, infoSecurePort=0, ipcPort=43722, storageInfo=lv=-57;cid=testClusterID;nsid=276271803;c=1585804054903), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:35,408 [BP-1721828334-172.17.0.13-1585804054903 heartbeating to localhost/127.0.0.1:42643] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xad6faf0b6fbfc7e7,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:35,408 [BP-1721828334-172.17.0.13-1585804054903 heartbeating to localhost/127.0.0.1:42643] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:35,472 [IPC Server handler 5 on 42643] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:35,473 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:35,476 [IPC Server handler 7 on 42643] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:35,477 [Thread-307] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=13
2020-04-02 05:07:35,482 [IPC Server handler 8 on 42643] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:35,507 [IPC Server handler 9 on 42643] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:45841 for /user/root/filelocal.dat
2020-04-02 05:07:35,517 [DataXceiver for client DFSClient_NONMAPREDUCE_-1710653230_902 at /127.0.0.1:54788 [Receiving block BP-1721828334-172.17.0.13-1585804054903:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1721828334-172.17.0.13-1585804054903:blk_1073741825_1001 src: /127.0.0.1:54788 dest: /127.0.0.1:45841
2020-04-02 05:07:35,532 [PacketResponder: BP-1721828334-172.17.0.13-1585804054903:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54788, dest: /127.0.0.1:45841, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1710653230_902, offset: 0, srvID: 424de891-a213-4604-bf9b-44fae0912d0d, blockid: BP-1721828334-172.17.0.13-1585804054903:blk_1073741825_1001, duration(ns): 10749489
2020-04-02 05:07:35,533 [PacketResponder: BP-1721828334-172.17.0.13-1585804054903:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1721828334-172.17.0.13-1585804054903:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:35,540 [IPC Server handler 2 on 42643] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_-1710653230_902
2020-04-02 05:07:35,552 [IPC Server handler 3 on 42643] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:35,559 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.45841.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_96020789_902, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: 74eff1dd947f722db49ba925e301a71f, srvID: 424de891-a213-4604-bf9b-44fae0912d0d, success: true
2020-04-02 05:07:35,563 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.45841.sock [Passing file descriptors for block BP-1721828334-172.17.0.13-1585804054903:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 424de891-a213-4604-bf9b-44fae0912d0d, success: true
2020-04-02 05:07:35,569 [IPC Server handler 4 on 42643] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:35,581 [IPC Server handler 6 on 42643] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:35,586 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:35,586 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:35,586 [Thread-307] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43722 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:35,587 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7eb5351e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:35,587 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@55516e4a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:35,597 [Thread-307] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:35,606 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-7ea7f58d-8bf1-436d-918f-aff2bd98b07e) exiting.
2020-04-02 05:07:35,609 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-a174404e-32a1-49d5-a25f-748a49dd8de4) exiting.
2020-04-02 05:07:35,632 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@e93c9f5{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:35,633 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2305e621{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:35,633 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@653d1698{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:35,633 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@647d50bc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:35,639 [Thread-307] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43722
2020-04-02 05:07:35,644 [BP-1721828334-172.17.0.13-1585804054903 heartbeating to localhost/127.0.0.1:42643] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:35,644 [BP-1721828334-172.17.0.13-1585804054903 heartbeating to localhost/127.0.0.1:42643] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1721828334-172.17.0.13-1585804054903 (Datanode Uuid 424de891-a213-4604-bf9b-44fae0912d0d) service to localhost/127.0.0.1:42643
2020-04-02 05:07:35,644 [BP-1721828334-172.17.0.13-1585804054903 heartbeating to localhost/127.0.0.1:42643] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1721828334-172.17.0.13-1585804054903 (Datanode Uuid 424de891-a213-4604-bf9b-44fae0912d0d)
2020-04-02 05:07:35,644 [BP-1721828334-172.17.0.13-1585804054903 heartbeating to localhost/127.0.0.1:42643] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1721828334-172.17.0.13-1585804054903
2020-04-02 05:07:35,649 [IPC Server listener on 43722] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43722
2020-04-02 05:07:35,650 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:35,668 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1721828334-172.17.0.13-1585804054903] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:35,678 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1721828334-172.17.0.13-1585804054903] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:35,687 [Thread-307] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:35,687 [Thread-307] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:35,689 [Thread-307] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:35,689 [Thread-307] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:35,709 [Thread-307] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:35,712 [Thread-307] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:35,712 [Thread-307] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 42643 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:35,713 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:35,713 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:07:35,713 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@603fb6de] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:35,713 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@f45e0f7] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:35,714 [Thread-307] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 9 Number of transactions batched in Syncs: 4 Number of syncs: 6 SyncTimes(ms): 1 3 
2020-04-02 05:07:35,715 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:35,715 [Thread-307] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:35,715 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:35,716 [CacheReplicationMonitor(2020267498)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:35,729 [Thread-307] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42643
2020-04-02 05:07:35,730 [IPC Server listener on 42643] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42643
2020-04-02 05:07:35,741 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:35,744 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:35,745 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:35,763 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:35,763 [Thread-307] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:35,765 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7270f16a{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:35,773 [Thread-307] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70c3d453{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:35,773 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2aa0a506{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:35,774 [Thread-307] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62695c4e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:35,775 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:35,776 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:35,778 [Thread-307] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testSmallFileLocalRead
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testSmallFileLocalRead
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testLongFile
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:35,824 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:35,827 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:35,828 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:35,828 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:35,828 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:35,828 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:35,828 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:35,828 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:35,829 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:35,829 [Thread-678] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:35,829 [Thread-678] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:35,829 [Thread-678] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:35,830 [Thread-678] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:35,830 [Thread-678] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:35
2020-04-02 05:07:35,830 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:35,830 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,830 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:35,830 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:35,839 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:35,839 [Thread-678] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:35,840 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:35,841 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:35,841 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,841 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:35,841 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:35,847 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:35,847 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:35,847 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:35,847 [Thread-678] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:35,848 [Thread-678] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:35,848 [Thread-678] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:35,848 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:35,848 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,848 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:35,848 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:35,849 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:35,849 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:35,849 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:35,849 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:35,849 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:35,850 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:35,850 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,850 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:35,850 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:35,851 [Thread-678] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:35,854 [Thread-678] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:35,856 [Thread-678] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:35,857 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:35,857 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:35,862 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:35,865 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:35,867 [Thread-678] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:35,868 [Thread-678] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:35,874 [Thread-678] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:35,892 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:35,892 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:35,893 [Thread-678] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:35,894 [Thread-678] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:35,901 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3be06de8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:35,901 [Thread-678] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:35,902 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:35,903 [Thread-678] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:35,904 [Thread-678] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:35,905 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:35,915 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:35,915 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:35,915 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:35,915 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:35,917 [Thread-678] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:35,917 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:35,917 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39016
2020-04-02 05:07:35,917 [Thread-678] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:35,923 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5f0fc8ed{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:35,924 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5a743d41{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:35,927 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@63b5af51{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:35,928 [Thread-678] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@bf73501{HTTP/1.1,[http/1.1]}{localhost:39016}
2020-04-02 05:07:35,931 [Thread-678] INFO  server.Server (Server.java:doStart(419)) - Started @15718ms
2020-04-02 05:07:35,934 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:35,935 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:35,935 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:35,935 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:35,935 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:35,935 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:35,935 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:35,935 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:35,936 [Thread-678] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:35,937 [Thread-678] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:35,937 [Thread-678] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:35,937 [Thread-678] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:35,938 [Thread-678] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:35
2020-04-02 05:07:35,938 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:35,938 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,938 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:35,938 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:35,948 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:35,948 [Thread-678] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:35,948 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:35,948 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:35,948 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:35,948 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:35,948 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:35,949 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:35,949 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:35,949 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:35,949 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:35,949 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:35,949 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:35,949 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,950 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:35,950 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:35,955 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:35,956 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:35,956 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:35,956 [Thread-678] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:35,956 [Thread-678] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:35,956 [Thread-678] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:35,956 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:35,956 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,956 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:35,956 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:35,957 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:35,957 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:35,957 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:35,958 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:35,958 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:35,958 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:35,958 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:35,958 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:35,958 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:35,960 [Thread-678] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:35,966 [Thread-678] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:35,967 [Thread-678] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:35,968 [Thread-678] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:35,968 [Thread-678] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:35,968 [Thread-678] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:35,995 [Thread-678] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:36,002 [Thread-678] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:36,003 [Thread-678] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:36,003 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:36,023 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:36,052 [Thread-678] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:36,052 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 93 msecs
2020-04-02 05:07:36,053 [Thread-678] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:36,053 [Thread-678] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:36,054 [Socket Reader #1 for port 36012] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36012
2020-04-02 05:07:36,058 [Thread-678] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36012 to access this namenode/service.
2020-04-02 05:07:36,059 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:36,085 [Thread-678] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:36,087 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:36,087 [Thread-678] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:36,087 [Thread-678] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:36,087 [Thread-678] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:36,093 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:36,093 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:36,093 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:36,093 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:36,093 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:36,093 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-04-02 05:07:36,095 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:36,095 [IPC Server listener on 36012] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36012: starting
2020-04-02 05:07:36,107 [Thread-678] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36012
2020-04-02 05:07:36,107 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:36,108 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:36,108 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:36,111 [Thread-678] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36012 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:36,116 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:36,117 [Thread-678] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:36,120 [Thread-678] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:36,121 [CacheReplicationMonitor(171549228)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:36,134 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:36,135 [Thread-678] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:36,135 [Thread-678] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:36,135 [Thread-678] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:36,135 [Thread-678] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:36,135 [Thread-678] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:36,135 [Thread-678] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:36,136 [Thread-678] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:36,136 [Thread-678] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40388
2020-04-02 05:07:36,136 [Thread-678] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:36,136 [Thread-678] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:36,136 [Thread-678] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:36,136 [Thread-678] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:36,137 [Thread-678] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock
2020-04-02 05:07:36,137 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:36,141 [Thread-678] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:36,142 [Thread-678] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:36,142 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:36,143 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:36,144 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:36,145 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:36,145 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:36,145 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41299
2020-04-02 05:07:36,146 [Thread-678] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:36,148 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@98dfac1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:36,148 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fa55be6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:36,156 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@881d853{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:36,164 [Thread-678] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@72a94252{HTTP/1.1,[http/1.1]}{localhost:41299}
2020-04-02 05:07:36,164 [Thread-678] INFO  server.Server (Server.java:doStart(419)) - Started @15951ms
2020-04-02 05:07:36,180 [Thread-678] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38991
2020-04-02 05:07:36,180 [Thread-678] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:36,180 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1a4d2538] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:36,180 [Thread-678] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:36,181 [Thread-678] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:36,182 [Socket Reader #1 for port 40628] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40628
2020-04-02 05:07:36,188 [Thread-678] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40628
2020-04-02 05:07:36,192 [Thread-678] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:36,193 [Thread-678] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:36,193 [Thread-734] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012 starting to offer service
2020-04-02 05:07:36,196 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:36,196 [IPC Server listener on 40628] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40628: starting
2020-04-02 05:07:36,203 [Thread-678] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40628 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:36,204 [Thread-734] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36012
2020-04-02 05:07:36,210 [Thread-734] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:36,213 [Thread-734] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:36,213 [Thread-734] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1465315908. Formatting...
2020-04-02 05:07:36,217 [Thread-734] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-491628b5-f0a2-4a9f-af35-911f78b26a53 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:36,217 [IPC Server handler 1 on 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:36,218 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:36,218 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:36,220 [Thread-734] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:36,220 [Thread-734] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1465315908. Formatting...
2020-04-02 05:07:36,221 [Thread-734] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-205a2527-5644-4462-a3bc-b0456ef18c5d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:36,231 [Thread-734] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:36,231 [Thread-734] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:36,231 [Thread-734] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-659160656-172.17.0.13-1585804055851 is not formatted. Formatting ...
2020-04-02 05:07:36,231 [Thread-734] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-659160656-172.17.0.13-1585804055851 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-659160656-172.17.0.13-1585804055851/current
2020-04-02 05:07:36,242 [Thread-734] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:36,242 [Thread-734] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:36,242 [Thread-734] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-659160656-172.17.0.13-1585804055851 is not formatted. Formatting ...
2020-04-02 05:07:36,242 [Thread-734] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-659160656-172.17.0.13-1585804055851 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-659160656-172.17.0.13-1585804055851/current
2020-04-02 05:07:36,244 [Thread-734] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1465315908;bpid=BP-659160656-172.17.0.13-1585804055851;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1465315908;c=1585804055851;bpid=BP-659160656-172.17.0.13-1585804055851;dnuuid=null
2020-04-02 05:07:36,245 [Thread-734] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID e53f5a27-8b5c-485d-9986-224b83ef60f2
2020-04-02 05:07:36,247 [Thread-734] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-491628b5-f0a2-4a9f-af35-911f78b26a53
2020-04-02 05:07:36,247 [Thread-734] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:36,249 [Thread-734] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-205a2527-5644-4462-a3bc-b0456ef18c5d
2020-04-02 05:07:36,249 [Thread-734] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:36,265 [Thread-734] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:36,266 [Thread-734] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:36,270 [Thread-734] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:36,270 [Thread-734] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:36,270 [Thread-734] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:36,271 [Thread-734] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:36,285 [Thread-750] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-659160656-172.17.0.13-1585804055851 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:36,286 [Thread-751] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-659160656-172.17.0.13-1585804055851 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:36,328 [Thread-750] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-659160656-172.17.0.13-1585804055851 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 43ms
2020-04-02 05:07:36,331 [IPC Server handler 2 on 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:36,332 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:36,332 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:36,333 [Thread-751] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-659160656-172.17.0.13-1585804055851 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 47ms
2020-04-02 05:07:36,333 [Thread-734] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-659160656-172.17.0.13-1585804055851: 62ms
2020-04-02 05:07:36,333 [Thread-754] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-659160656-172.17.0.13-1585804055851 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:36,333 [Thread-755] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-659160656-172.17.0.13-1585804055851 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:36,334 [Thread-754] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-659160656-172.17.0.13-1585804055851/current/replicas doesn't exist 
2020-04-02 05:07:36,334 [Thread-755] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-659160656-172.17.0.13-1585804055851/current/replicas doesn't exist 
2020-04-02 05:07:36,334 [Thread-755] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-659160656-172.17.0.13-1585804055851 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:07:36,336 [Thread-754] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-659160656-172.17.0.13-1585804055851 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:07:36,337 [Thread-734] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-659160656-172.17.0.13-1585804055851: 4ms
2020-04-02 05:07:36,337 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-659160656-172.17.0.13-1585804055851 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:36,337 [Thread-734] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:44 AM with interval of 21600000ms
2020-04-02 05:07:36,337 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-491628b5-f0a2-4a9f-af35-911f78b26a53): finished scanning block pool BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:36,349 [BP-659160656-172.17.0.13-1585804055851 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-659160656-172.17.0.13-1585804055851 (Datanode Uuid e53f5a27-8b5c-485d-9986-224b83ef60f2) service to localhost/127.0.0.1:36012 beginning handshake with NN
2020-04-02 05:07:36,349 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-491628b5-f0a2-4a9f-af35-911f78b26a53): no suitable block pools found to scan.  Waiting 1814399988 ms.
2020-04-02 05:07:36,349 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-659160656-172.17.0.13-1585804055851 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:36,350 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-205a2527-5644-4462-a3bc-b0456ef18c5d): finished scanning block pool BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:36,350 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-205a2527-5644-4462-a3bc-b0456ef18c5d): no suitable block pools found to scan.  Waiting 1814399987 ms.
2020-04-02 05:07:36,350 [IPC Server handler 3 on 36012] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40388, datanodeUuid=e53f5a27-8b5c-485d-9986-224b83ef60f2, infoPort=38991, infoSecurePort=0, ipcPort=40628, storageInfo=lv=-57;cid=testClusterID;nsid=1465315908;c=1585804055851) storage e53f5a27-8b5c-485d-9986-224b83ef60f2
2020-04-02 05:07:36,351 [IPC Server handler 3 on 36012] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40388
2020-04-02 05:07:36,351 [IPC Server handler 3 on 36012] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e53f5a27-8b5c-485d-9986-224b83ef60f2 (127.0.0.1:40388).
2020-04-02 05:07:36,357 [BP-659160656-172.17.0.13-1585804055851 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-659160656-172.17.0.13-1585804055851 (Datanode Uuid e53f5a27-8b5c-485d-9986-224b83ef60f2) service to localhost/127.0.0.1:36012 successfully registered with NN
2020-04-02 05:07:36,357 [BP-659160656-172.17.0.13-1585804055851 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36012 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:36,364 [IPC Server handler 8 on 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-491628b5-f0a2-4a9f-af35-911f78b26a53 for DN 127.0.0.1:40388
2020-04-02 05:07:36,364 [IPC Server handler 8 on 36012] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-205a2527-5644-4462-a3bc-b0456ef18c5d for DN 127.0.0.1:40388
2020-04-02 05:07:36,369 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x64728ba3b7b14533: Processing first storage report for DS-491628b5-f0a2-4a9f-af35-911f78b26a53 from datanode e53f5a27-8b5c-485d-9986-224b83ef60f2
2020-04-02 05:07:36,370 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x64728ba3b7b14533: from storage DS-491628b5-f0a2-4a9f-af35-911f78b26a53 node DatanodeRegistration(127.0.0.1:40388, datanodeUuid=e53f5a27-8b5c-485d-9986-224b83ef60f2, infoPort=38991, infoSecurePort=0, ipcPort=40628, storageInfo=lv=-57;cid=testClusterID;nsid=1465315908;c=1585804055851), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:36,370 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x64728ba3b7b14533: Processing first storage report for DS-205a2527-5644-4462-a3bc-b0456ef18c5d from datanode e53f5a27-8b5c-485d-9986-224b83ef60f2
2020-04-02 05:07:36,370 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x64728ba3b7b14533: from storage DS-205a2527-5644-4462-a3bc-b0456ef18c5d node DatanodeRegistration(127.0.0.1:40388, datanodeUuid=e53f5a27-8b5c-485d-9986-224b83ef60f2, infoPort=38991, infoSecurePort=0, ipcPort=40628, storageInfo=lv=-57;cid=testClusterID;nsid=1465315908;c=1585804055851), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:36,371 [BP-659160656-172.17.0.13-1585804055851 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x64728ba3b7b14533,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:36,371 [BP-659160656-172.17.0.13-1585804055851 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:36,434 [IPC Server handler 6 on 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:36,435 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:36,439 [IPC Server handler 5 on 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:36,441 [Thread-678] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=51300
2020-04-02 05:07:36,451 [IPC Server handler 4 on 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:36,472 [IPC Server handler 7 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,482 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46406 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741825_1001 src: /127.0.0.1:46406 dest: /127.0.0.1:40388
2020-04-02 05:07:36,511 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46406, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741825_1001, duration(ns): 24442872
2020-04-02 05:07:36,512 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,532 [IPC Server handler 2 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,538 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46416 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741826_1002 src: /127.0.0.1:46416 dest: /127.0.0.1:40388
2020-04-02 05:07:36,549 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46416, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741826_1002, duration(ns): 7452491
2020-04-02 05:07:36,550 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,552 [IPC Server handler 8 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,554 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46418 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741827_1003 src: /127.0.0.1:46418 dest: /127.0.0.1:40388
2020-04-02 05:07:36,563 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46418, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741827_1003, duration(ns): 4808947
2020-04-02 05:07:36,563 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,566 [IPC Server handler 6 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,569 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46420 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741828_1004 src: /127.0.0.1:46420 dest: /127.0.0.1:40388
2020-04-02 05:07:36,579 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46420, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741828_1004, duration(ns): 5690254
2020-04-02 05:07:36,579 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,582 [IPC Server handler 4 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,584 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46422 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741829_1005 src: /127.0.0.1:46422 dest: /127.0.0.1:40388
2020-04-02 05:07:36,633 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46422, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741829_1005, duration(ns): 40880776
2020-04-02 05:07:36,633 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,639 [IPC Server handler 0 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,647 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46426 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741830_1006 src: /127.0.0.1:46426 dest: /127.0.0.1:40388
2020-04-02 05:07:36,669 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46426, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741830_1006, duration(ns): 18330490
2020-04-02 05:07:36,669 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,674 [IPC Server handler 2 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,680 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46428 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741831_1007 src: /127.0.0.1:46428 dest: /127.0.0.1:40388
2020-04-02 05:07:36,699 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46428, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741831_1007, duration(ns): 13617057
2020-04-02 05:07:36,699 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,703 [IPC Server handler 3 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,705 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46430 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741832_1008 src: /127.0.0.1:46430 dest: /127.0.0.1:40388
2020-04-02 05:07:36,720 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46430, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741832_1008, duration(ns): 11407739
2020-04-02 05:07:36,721 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,727 [IPC Server handler 9 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,729 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46434 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741833_1009 src: /127.0.0.1:46434 dest: /127.0.0.1:40388
2020-04-02 05:07:36,756 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46434, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741833_1009, duration(ns): 23530254
2020-04-02 05:07:36,756 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,762 [IPC Server handler 4 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,765 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46436 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741834_1010 src: /127.0.0.1:46436 dest: /127.0.0.1:40388
2020-04-02 05:07:36,778 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46436, dest: /127.0.0.1:40388, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741834_1010, duration(ns): 10089320
2020-04-02 05:07:36,778 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,783 [IPC Server handler 7 on 36012] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:40388 for /user/root/filelocal.dat
2020-04-02 05:07:36,788 [DataXceiver for client DFSClient_NONMAPREDUCE_-491266691_2020 at /127.0.0.1:46438 [Receiving block BP-659160656-172.17.0.13-1585804055851:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-659160656-172.17.0.13-1585804055851:blk_1073741835_1011 src: /127.0.0.1:46438 dest: /127.0.0.1:40388
2020-04-02 05:07:36,803 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46438, dest: /127.0.0.1:40388, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-491266691_2020, offset: 0, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, blockid: BP-659160656-172.17.0.13-1585804055851:blk_1073741835_1011, duration(ns): 5274785
2020-04-02 05:07:36,803 [PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-659160656-172.17.0.13-1585804055851:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:36,806 [IPC Server handler 1 on 36012] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741835_1011 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/filelocal.dat
2020-04-02 05:07:37,208 [IPC Server handler 8 on 36012] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_-491266691_2020
2020-04-02 05:07:37,214 [IPC Server handler 3 on 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:37,223 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-2106845854_2020, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: 412d2f202a36b130311dafa0c228c8e8, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,225 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,227 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741826_1002]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741826, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,228 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741827_1003]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741827, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,228 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741828_1004]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741828, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,229 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741829_1005]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741829, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,230 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741830_1006]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741830, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,231 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741831_1007]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741831, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,232 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741832_1008]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741832, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,233 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741833_1009]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741833, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,233 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741834_1010]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741834, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,238 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40388.sock [Passing file descriptors for block BP-659160656-172.17.0.13-1585804055851:blk_1073741835_1011]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741835, srvID: e53f5a27-8b5c-485d-9986-224b83ef60f2, success: true
2020-04-02 05:07:37,244 [IPC Server handler 9 on 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:37,259 [IPC Server handler 6 on 36012] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:37,266 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:37,266 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:37,266 [Thread-678] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40628 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:37,268 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5ce6d14e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:37,270 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@22a67d59] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:37,277 [Thread-678] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:37,280 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-205a2527-5644-4462-a3bc-b0456ef18c5d) exiting.
2020-04-02 05:07:37,281 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-491628b5-f0a2-4a9f-af35-911f78b26a53) exiting.
2020-04-02 05:07:37,321 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@881d853{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:37,326 [Thread-678] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@72a94252{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:37,327 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fa55be6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:37,327 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@98dfac1{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:37,331 [Thread-678] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40628
2020-04-02 05:07:37,338 [IPC Server listener on 40628] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40628
2020-04-02 05:07:37,338 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:37,339 [BP-659160656-172.17.0.13-1585804055851 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:37,339 [BP-659160656-172.17.0.13-1585804055851 heartbeating to localhost/127.0.0.1:36012] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-659160656-172.17.0.13-1585804055851 (Datanode Uuid e53f5a27-8b5c-485d-9986-224b83ef60f2) service to localhost/127.0.0.1:36012
2020-04-02 05:07:37,339 [BP-659160656-172.17.0.13-1585804055851 heartbeating to localhost/127.0.0.1:36012] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-659160656-172.17.0.13-1585804055851 (Datanode Uuid e53f5a27-8b5c-485d-9986-224b83ef60f2)
2020-04-02 05:07:37,339 [BP-659160656-172.17.0.13-1585804055851 heartbeating to localhost/127.0.0.1:36012] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-659160656-172.17.0.13-1585804055851
2020-04-02 05:07:37,356 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-659160656-172.17.0.13-1585804055851] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:37,365 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-659160656-172.17.0.13-1585804055851] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:37,371 [Thread-678] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:37,372 [Thread-678] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:37,372 [Thread-678] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:37,373 [Thread-678] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:37,376 [Thread-678] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:37,377 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:37,377 [Thread-678] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36012 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:37,377 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:37,378 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 38
2020-04-02 05:07:37,378 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1837b521] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:37,378 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@630ea64f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:37,378 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 39 Total time for transactions(ms): 6 Number of transactions batched in Syncs: 11 Number of syncs: 29 SyncTimes(ms): 11 2 
2020-04-02 05:07:37,379 [Thread-678] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000039
2020-04-02 05:07:37,380 [Thread-678] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000039
2020-04-02 05:07:37,380 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:37,380 [CacheReplicationMonitor(171549228)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:37,391 [Thread-678] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36012
2020-04-02 05:07:37,392 [IPC Server listener on 36012] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36012
2020-04-02 05:07:37,393 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:37,393 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:37,393 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:37,402 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:37,402 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:37,404 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@63b5af51{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:37,405 [Thread-678] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@bf73501{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:37,405 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5a743d41{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:37,406 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5f0fc8ed{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:37,406 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:37,415 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:37,415 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:37,427 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:37,429 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:37,429 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:37,429 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:37,430 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:37,430 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:37,430 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:37,430 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:37,430 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:37,430 [Thread-678] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:37,430 [Thread-678] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:37,430 [Thread-678] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:37,430 [Thread-678] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:37,434 [Thread-678] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:37
2020-04-02 05:07:37,434 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:37,434 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:37,434 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:37,434 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:37,437 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:37,438 [Thread-678] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:37,438 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:37,438 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:37,438 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:37,439 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:37,439 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:37,440 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:37,440 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:37,440 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:37,440 [Thread-678] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:37,440 [Thread-678] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:37,440 [Thread-678] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:37,440 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:37,440 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:37,441 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:37,441 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:37,441 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:37,442 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:37,442 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:37,442 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:37,442 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:37,442 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:37,443 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:37,443 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:37,443 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:37,444 [Thread-678] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:37,446 [Thread-678] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:37,448 [Thread-678] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:37,449 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:37,449 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:37,460 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:37,467 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:37,469 [Thread-678] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:37,470 [Thread-678] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:37,473 [Thread-678] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:37,475 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:37,475 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:37,476 [Thread-678] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:37,476 [Thread-678] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:37,481 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5084849b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:37,481 [Thread-678] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:37,481 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:37,483 [Thread-678] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:37,483 [Thread-678] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:37,483 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:37,484 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:37,484 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:37,484 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:37,485 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:37,486 [Thread-678] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:37,486 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:37,486 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33468
2020-04-02 05:07:37,486 [Thread-678] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:37,488 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1654cebc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:37,488 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@45b37d49{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:37,499 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@45dc92b9{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:37,502 [Thread-678] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@63dc4feb{HTTP/1.1,[http/1.1]}{localhost:33468}
2020-04-02 05:07:37,504 [Thread-678] INFO  server.Server (Server.java:doStart(419)) - Started @17290ms
2020-04-02 05:07:37,505 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:37,505 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:37,505 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:37,505 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:37,505 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:37,506 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:37,506 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:37,506 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:37,506 [Thread-678] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:37,507 [Thread-678] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:37,507 [Thread-678] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:37,507 [Thread-678] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:37,507 [Thread-678] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:37
2020-04-02 05:07:37,508 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:37,508 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:37,508 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:37,508 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:37,512 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:37,513 [Thread-678] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:37,513 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:37,513 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:37,513 [Thread-678] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:37,513 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:37,513 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:37,514 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:37,514 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:37,514 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:37,514 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:37,514 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:37,514 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:37,515 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:37,515 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:37,515 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:37,519 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:37,519 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:37,519 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:37,519 [Thread-678] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:37,520 [Thread-678] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:37,520 [Thread-678] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:37,520 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:37,520 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:37,520 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:37,520 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:37,522 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:37,522 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:37,522 [Thread-678] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:37,523 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:37,523 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:37,523 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:37,523 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:37,523 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:37,523 [Thread-678] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:37,529 [Thread-678] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:37,533 [Thread-678] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:37,535 [Thread-678] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:37,535 [Thread-678] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:37,535 [Thread-678] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:37,535 [Thread-678] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:37,536 [Thread-678] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:37,536 [Thread-678] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:37,537 [Thread-678] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:37,537 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:37,537 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:37,547 [Thread-678] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:37,547 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 23 msecs
2020-04-02 05:07:37,548 [Thread-678] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:37,548 [Thread-678] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:37,548 [Socket Reader #1 for port 43529] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43529
2020-04-02 05:07:37,552 [Thread-678] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:43529 to access this namenode/service.
2020-04-02 05:07:37,552 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:37,573 [Thread-678] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:37,576 [Thread-678] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:37,576 [Thread-678] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:37,576 [Thread-678] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:37,576 [Thread-678] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:37,581 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:37,581 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:37,581 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:37,581 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:37,581 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:37,581 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-02 05:07:37,583 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:37,583 [IPC Server listener on 43529] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43529: starting
2020-04-02 05:07:37,588 [Thread-678] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43529
2020-04-02 05:07:37,589 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:37,589 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:37,594 [Thread-678] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:37,596 [Thread-678] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43529 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:37,598 [CacheReplicationMonitor(745217102)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:37,610 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:37,610 [Thread-678] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:37,611 [Thread-678] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:37,611 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:37,613 [Thread-678] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:37,613 [Thread-678] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:37,613 [Thread-678] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:37,613 [Thread-678] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:37,613 [Thread-678] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:37,613 [Thread-678] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:37,614 [Thread-678] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:37,614 [Thread-678] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41582
2020-04-02 05:07:37,614 [Thread-678] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:37,615 [Thread-678] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:37,615 [Thread-678] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:37,615 [Thread-678] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:37,615 [Thread-678] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock
2020-04-02 05:07:37,616 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:37,618 [Thread-678] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:37,619 [Thread-678] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:37,619 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:37,620 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:37,620 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:37,621 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:37,621 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:37,621 [Thread-678] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45406
2020-04-02 05:07:37,622 [Thread-678] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:37,624 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@48c54db7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:37,624 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6639c1ef{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:37,629 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6798ee7d{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:37,630 [Thread-678] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@e9ba8d8{HTTP/1.1,[http/1.1]}{localhost:45406}
2020-04-02 05:07:37,631 [Thread-678] INFO  server.Server (Server.java:doStart(419)) - Started @17418ms
2020-04-02 05:07:37,644 [Thread-678] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33386
2020-04-02 05:07:37,645 [Thread-678] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:37,645 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2091cf74] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:37,645 [Thread-678] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:37,646 [Thread-678] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:37,647 [Socket Reader #1 for port 44707] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44707
2020-04-02 05:07:37,651 [Thread-678] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44707
2020-04-02 05:07:37,657 [Thread-678] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:37,657 [Thread-678] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:37,658 [Thread-855] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43529 starting to offer service
2020-04-02 05:07:37,661 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:37,661 [IPC Server listener on 44707] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44707: starting
2020-04-02 05:07:37,668 [Thread-678] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44707 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:37,669 [Thread-855] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43529
2020-04-02 05:07:37,678 [Thread-855] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:37,679 [IPC Server handler 1 on 43529] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:37,680 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:37,680 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:37,681 [Thread-855] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:37,681 [Thread-855] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 997603512. Formatting...
2020-04-02 05:07:37,681 [Thread-855] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7731d3db-a0dd-4d80-bd93-a3a417397f2f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:37,684 [Thread-855] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:37,684 [Thread-855] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 997603512. Formatting...
2020-04-02 05:07:37,684 [Thread-855] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ddd57538-eff7-4346-9ba0-b99c70d94d28 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:37,694 [Thread-855] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:37,694 [Thread-855] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:37,695 [Thread-855] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1406449837-172.17.0.13-1585804057444 is not formatted. Formatting ...
2020-04-02 05:07:37,695 [Thread-855] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1406449837-172.17.0.13-1585804057444 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1406449837-172.17.0.13-1585804057444/current
2020-04-02 05:07:37,704 [Thread-855] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:37,704 [Thread-855] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:37,705 [Thread-855] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1406449837-172.17.0.13-1585804057444 is not formatted. Formatting ...
2020-04-02 05:07:37,705 [Thread-855] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1406449837-172.17.0.13-1585804057444 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1406449837-172.17.0.13-1585804057444/current
2020-04-02 05:07:37,706 [Thread-855] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=997603512;bpid=BP-1406449837-172.17.0.13-1585804057444;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=997603512;c=1585804057444;bpid=BP-1406449837-172.17.0.13-1585804057444;dnuuid=null
2020-04-02 05:07:37,708 [Thread-855] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID bdd9c0a3-d530-4334-b590-71d34f03a195
2020-04-02 05:07:37,713 [Thread-855] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7731d3db-a0dd-4d80-bd93-a3a417397f2f
2020-04-02 05:07:37,713 [Thread-855] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:37,719 [Thread-855] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ddd57538-eff7-4346-9ba0-b99c70d94d28
2020-04-02 05:07:37,719 [Thread-855] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:37,720 [Thread-855] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:37,721 [Thread-855] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:37,723 [Thread-855] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:37,723 [Thread-855] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:37,723 [Thread-855] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:37,725 [Thread-855] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:37,725 [Thread-871] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1406449837-172.17.0.13-1585804057444 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:37,725 [Thread-872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1406449837-172.17.0.13-1585804057444 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:37,752 [Thread-871] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1406449837-172.17.0.13-1585804057444 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 26ms
2020-04-02 05:07:37,756 [Thread-872] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1406449837-172.17.0.13-1585804057444 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 29ms
2020-04-02 05:07:37,756 [Thread-855] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1406449837-172.17.0.13-1585804057444: 31ms
2020-04-02 05:07:37,757 [Thread-875] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1406449837-172.17.0.13-1585804057444 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:37,757 [Thread-876] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1406449837-172.17.0.13-1585804057444 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:37,757 [Thread-875] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1406449837-172.17.0.13-1585804057444/current/replicas doesn't exist 
2020-04-02 05:07:37,757 [Thread-876] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1406449837-172.17.0.13-1585804057444/current/replicas doesn't exist 
2020-04-02 05:07:37,764 [Thread-876] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1406449837-172.17.0.13-1585804057444 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 7ms
2020-04-02 05:07:37,768 [Thread-875] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1406449837-172.17.0.13-1585804057444 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 11ms
2020-04-02 05:07:37,769 [Thread-855] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1406449837-172.17.0.13-1585804057444: 13ms
2020-04-02 05:07:37,770 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1406449837-172.17.0.13-1585804057444 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:37,770 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1406449837-172.17.0.13-1585804057444 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:37,770 [Thread-855] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:38 AM with interval of 21600000ms
2020-04-02 05:07:37,770 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-7731d3db-a0dd-4d80-bd93-a3a417397f2f): finished scanning block pool BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:37,770 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ddd57538-eff7-4346-9ba0-b99c70d94d28): finished scanning block pool BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:37,771 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-7731d3db-a0dd-4d80-bd93-a3a417397f2f): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:07:37,775 [BP-1406449837-172.17.0.13-1585804057444 heartbeating to localhost/127.0.0.1:43529] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1406449837-172.17.0.13-1585804057444 (Datanode Uuid bdd9c0a3-d530-4334-b590-71d34f03a195) service to localhost/127.0.0.1:43529 beginning handshake with NN
2020-04-02 05:07:37,776 [IPC Server handler 2 on 43529] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41582, datanodeUuid=bdd9c0a3-d530-4334-b590-71d34f03a195, infoPort=33386, infoSecurePort=0, ipcPort=44707, storageInfo=lv=-57;cid=testClusterID;nsid=997603512;c=1585804057444) storage bdd9c0a3-d530-4334-b590-71d34f03a195
2020-04-02 05:07:37,777 [IPC Server handler 2 on 43529] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41582
2020-04-02 05:07:37,777 [IPC Server handler 2 on 43529] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bdd9c0a3-d530-4334-b590-71d34f03a195 (127.0.0.1:41582).
2020-04-02 05:07:37,771 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ddd57538-eff7-4346-9ba0-b99c70d94d28): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:07:37,782 [BP-1406449837-172.17.0.13-1585804057444 heartbeating to localhost/127.0.0.1:43529] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1406449837-172.17.0.13-1585804057444 (Datanode Uuid bdd9c0a3-d530-4334-b590-71d34f03a195) service to localhost/127.0.0.1:43529 successfully registered with NN
2020-04-02 05:07:37,785 [IPC Server handler 3 on 43529] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:37,785 [BP-1406449837-172.17.0.13-1585804057444 heartbeating to localhost/127.0.0.1:43529] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43529 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:37,787 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:41582
2020-04-02 05:07:37,787 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:37,787 [IPC Server handler 5 on 43529] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7731d3db-a0dd-4d80-bd93-a3a417397f2f for DN 127.0.0.1:41582
2020-04-02 05:07:37,788 [IPC Server handler 5 on 43529] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ddd57538-eff7-4346-9ba0-b99c70d94d28 for DN 127.0.0.1:41582
2020-04-02 05:07:37,791 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x13309193e82459dd: Processing first storage report for DS-7731d3db-a0dd-4d80-bd93-a3a417397f2f from datanode bdd9c0a3-d530-4334-b590-71d34f03a195
2020-04-02 05:07:37,792 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x13309193e82459dd: from storage DS-7731d3db-a0dd-4d80-bd93-a3a417397f2f node DatanodeRegistration(127.0.0.1:41582, datanodeUuid=bdd9c0a3-d530-4334-b590-71d34f03a195, infoPort=33386, infoSecurePort=0, ipcPort=44707, storageInfo=lv=-57;cid=testClusterID;nsid=997603512;c=1585804057444), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:37,792 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x13309193e82459dd: Processing first storage report for DS-ddd57538-eff7-4346-9ba0-b99c70d94d28 from datanode bdd9c0a3-d530-4334-b590-71d34f03a195
2020-04-02 05:07:37,792 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x13309193e82459dd: from storage DS-ddd57538-eff7-4346-9ba0-b99c70d94d28 node DatanodeRegistration(127.0.0.1:41582, datanodeUuid=bdd9c0a3-d530-4334-b590-71d34f03a195, infoPort=33386, infoSecurePort=0, ipcPort=44707, storageInfo=lv=-57;cid=testClusterID;nsid=997603512;c=1585804057444), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:37,793 [BP-1406449837-172.17.0.13-1585804057444 heartbeating to localhost/127.0.0.1:43529] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x13309193e82459dd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:37,793 [BP-1406449837-172.17.0.13-1585804057444 heartbeating to localhost/127.0.0.1:43529] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:37,889 [IPC Server handler 6 on 43529] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:37,890 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:37,893 [IPC Server handler 7 on 43529] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:37,894 [Thread-678] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=51300
2020-04-02 05:07:37,897 [IPC Server handler 8 on 43529] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:37,915 [IPC Server handler 9 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:37,919 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37506 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741825_1001 src: /127.0.0.1:37506 dest: /127.0.0.1:41582
2020-04-02 05:07:37,928 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37506, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741825_1001, duration(ns): 2571158
2020-04-02 05:07:37,928 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:37,931 [IPC Server handler 1 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:37,937 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37512 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741826_1002 src: /127.0.0.1:37512 dest: /127.0.0.1:41582
2020-04-02 05:07:37,955 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37512, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741826_1002, duration(ns): 12189880
2020-04-02 05:07:37,955 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:37,958 [IPC Server handler 5 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:37,964 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37518 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741827_1003 src: /127.0.0.1:37518 dest: /127.0.0.1:41582
2020-04-02 05:07:37,970 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37518, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741827_1003, duration(ns): 2888353
2020-04-02 05:07:37,970 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:37,974 [IPC Server handler 4 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:37,977 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37524 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741828_1004 src: /127.0.0.1:37524 dest: /127.0.0.1:41582
2020-04-02 05:07:38,001 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37524, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741828_1004, duration(ns): 20367631
2020-04-02 05:07:38,002 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,005 [IPC Server handler 7 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:38,010 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37544 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741829_1005 src: /127.0.0.1:37544 dest: /127.0.0.1:41582
2020-04-02 05:07:38,021 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37544, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741829_1005, duration(ns): 8270602
2020-04-02 05:07:38,021 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,026 [IPC Server handler 0 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:38,032 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37554 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741830_1006 src: /127.0.0.1:37554 dest: /127.0.0.1:41582
2020-04-02 05:07:38,037 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37554, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741830_1006, duration(ns): 2927068
2020-04-02 05:07:38,037 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,042 [IPC Server handler 2 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:38,045 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37560 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741831_1007 src: /127.0.0.1:37560 dest: /127.0.0.1:41582
2020-04-02 05:07:38,057 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37560, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741831_1007, duration(ns): 5970317
2020-04-02 05:07:38,057 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,062 [IPC Server handler 5 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:38,074 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37572 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741832_1008 src: /127.0.0.1:37572 dest: /127.0.0.1:41582
2020-04-02 05:07:38,079 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37572, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741832_1008, duration(ns): 2369606
2020-04-02 05:07:38,080 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,082 [IPC Server handler 6 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:38,090 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37578 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741833_1009 src: /127.0.0.1:37578 dest: /127.0.0.1:41582
2020-04-02 05:07:38,095 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37578, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741833_1009, duration(ns): 2827462
2020-04-02 05:07:38,096 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,099 [IPC Server handler 8 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:38,102 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37580 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741834_1010 src: /127.0.0.1:37580 dest: /127.0.0.1:41582
2020-04-02 05:07:38,119 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37580, dest: /127.0.0.1:41582, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741834_1010, duration(ns): 10983011
2020-04-02 05:07:38,119 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,127 [IPC Server handler 9 on 43529] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:41582 for /user/root/filelocal.dat
2020-04-02 05:07:38,132 [DataXceiver for client DFSClient_NONMAPREDUCE_-2180065_2020 at /127.0.0.1:37588 [Receiving block BP-1406449837-172.17.0.13-1585804057444:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1406449837-172.17.0.13-1585804057444:blk_1073741835_1011 src: /127.0.0.1:37588 dest: /127.0.0.1:41582
2020-04-02 05:07:38,137 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:37588, dest: /127.0.0.1:41582, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2180065_2020, offset: 0, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, blockid: BP-1406449837-172.17.0.13-1585804057444:blk_1073741835_1011, duration(ns): 3172245
2020-04-02 05:07:38,138 [PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1406449837-172.17.0.13-1585804057444:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,140 [IPC Server handler 2 on 43529] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_-2180065_2020
2020-04-02 05:07:38,147 [IPC Server handler 3 on 43529] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:38,165 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-1900682600_2020, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: ba6b9f8ecfe3c7de1616a4eb27feda88, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,167 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,169 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741826_1002]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741826, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,170 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741827_1003]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741827, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,171 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741828_1004]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741828, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,171 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741829_1005]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741829, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,172 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741830_1006]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741830, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,173 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741831_1007]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741831, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,174 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741832_1008]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741832, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,174 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741833_1009]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741833, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,177 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741834_1010]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741834, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,179 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.41582.sock [Passing file descriptors for block BP-1406449837-172.17.0.13-1585804057444:blk_1073741835_1011]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741835, srvID: bdd9c0a3-d530-4334-b590-71d34f03a195, success: true
2020-04-02 05:07:38,188 [IPC Server handler 5 on 43529] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:38,199 [IPC Server handler 4 on 43529] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:38,205 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:38,205 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:38,205 [Thread-678] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44707 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:38,206 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3e3dbd0b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:38,206 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7b4d73be] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:38,216 [Thread-678] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:38,218 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-7731d3db-a0dd-4d80-bd93-a3a417397f2f) exiting.
2020-04-02 05:07:38,221 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ddd57538-eff7-4346-9ba0-b99c70d94d28) exiting.
2020-04-02 05:07:38,240 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6798ee7d{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:38,241 [Thread-678] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@e9ba8d8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:38,241 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6639c1ef{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:38,241 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@48c54db7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:38,242 [Thread-678] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44707
2020-04-02 05:07:38,246 [IPC Server listener on 44707] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44707
2020-04-02 05:07:38,246 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:38,246 [BP-1406449837-172.17.0.13-1585804057444 heartbeating to localhost/127.0.0.1:43529] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:38,248 [BP-1406449837-172.17.0.13-1585804057444 heartbeating to localhost/127.0.0.1:43529] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1406449837-172.17.0.13-1585804057444 (Datanode Uuid bdd9c0a3-d530-4334-b590-71d34f03a195) service to localhost/127.0.0.1:43529
2020-04-02 05:07:38,248 [BP-1406449837-172.17.0.13-1585804057444 heartbeating to localhost/127.0.0.1:43529] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1406449837-172.17.0.13-1585804057444 (Datanode Uuid bdd9c0a3-d530-4334-b590-71d34f03a195)
2020-04-02 05:07:38,248 [BP-1406449837-172.17.0.13-1585804057444 heartbeating to localhost/127.0.0.1:43529] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1406449837-172.17.0.13-1585804057444
2020-04-02 05:07:38,256 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1406449837-172.17.0.13-1585804057444] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:38,264 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1406449837-172.17.0.13-1585804057444] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:38,286 [Thread-678] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:38,287 [Thread-678] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:38,287 [Thread-678] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:38,287 [Thread-678] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:38,290 [Thread-678] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:38,292 [Thread-678] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:38,292 [Thread-678] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43529 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:38,292 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:38,293 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@721845f5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:38,293 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1d3f6637] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:38,293 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 38
2020-04-02 05:07:38,293 [Thread-678] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 39 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 17 Number of syncs: 23 SyncTimes(ms): 3 4 
2020-04-02 05:07:38,294 [Thread-678] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000039
2020-04-02 05:07:38,295 [Thread-678] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000039
2020-04-02 05:07:38,295 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:38,295 [CacheReplicationMonitor(745217102)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:38,303 [Thread-678] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43529
2020-04-02 05:07:38,306 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:38,307 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:38,307 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:38,307 [IPC Server listener on 43529] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43529
2020-04-02 05:07:38,318 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:38,318 [Thread-678] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:38,320 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@45dc92b9{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:38,324 [Thread-678] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@63dc4feb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:38,325 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@45b37d49{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:38,325 [Thread-678] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1654cebc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:38,326 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:38,331 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:38,331 [Thread-678] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testLongFile
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testLongFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testReadWithRemoteBlockReader2
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:38,369 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:38,380 [Thread-924] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:38,380 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:38,380 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:38,380 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:38,381 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:38,381 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:38,381 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:38,381 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:38,381 [Thread-924] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:38,382 [Thread-924] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:38,382 [Thread-924] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:38,382 [Thread-924] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:38,383 [Thread-924] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:38
2020-04-02 05:07:38,383 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:38,383 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:38,383 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:38,383 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:38,388 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:38,389 [Thread-924] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:38,389 [Thread-924] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:38,389 [Thread-924] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:38,389 [Thread-924] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:38,389 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:38,389 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:38,389 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:38,389 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:38,390 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:38,390 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:38,390 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:38,390 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:38,390 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:38,391 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:38,391 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:38,393 [Thread-924] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:38,393 [Thread-924] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:38,394 [Thread-924] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:38,394 [Thread-924] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:38,394 [Thread-924] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:38,394 [Thread-924] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:38,394 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:38,394 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:38,395 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:38,395 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:38,396 [Thread-924] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:38,396 [Thread-924] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:38,396 [Thread-924] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:38,396 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:38,396 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:38,396 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:38,396 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:38,397 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:38,397 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:38,398 [Thread-924] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:38,408 [Thread-924] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:38,410 [Thread-924] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:38,410 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:38,410 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:38,414 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:38,417 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:38,419 [Thread-924] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:38,420 [Thread-924] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:38,424 [Thread-924] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:38,426 [Thread-924] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:38,426 [Thread-924] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:38,429 [Thread-924] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:38,429 [Thread-924] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:38,434 [Thread-924] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:38,434 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:38,435 [Thread-924] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:38,436 [Thread-924] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:38,436 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:38,437 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:38,438 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@31c9d6fb] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:38,438 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:38,438 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:38,438 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:38,440 [Thread-924] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:38,440 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:38,440 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36080
2020-04-02 05:07:38,440 [Thread-924] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:38,443 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@bcba42c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:38,444 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f2a0ebd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:38,449 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@767b2039{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:38,454 [Thread-924] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5a0dadfd{HTTP/1.1,[http/1.1]}{localhost:36080}
2020-04-02 05:07:38,454 [Thread-924] INFO  server.Server (Server.java:doStart(419)) - Started @18241ms
2020-04-02 05:07:38,455 [Thread-924] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:38,455 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:38,456 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:38,456 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:38,456 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:38,456 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:38,456 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:38,456 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:38,456 [Thread-924] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:38,457 [Thread-924] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:38,457 [Thread-924] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:38,457 [Thread-924] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:38,457 [Thread-924] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:38
2020-04-02 05:07:38,457 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:38,458 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:38,458 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:38,458 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:38,462 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:38,463 [Thread-924] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:38,463 [Thread-924] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:38,463 [Thread-924] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:38,463 [Thread-924] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:38,463 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:38,463 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:38,463 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:38,463 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:38,463 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:38,463 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:38,464 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:38,464 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:38,464 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:38,464 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:38,464 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:38,488 [Thread-924] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:38,488 [Thread-924] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:38,488 [Thread-924] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:38,488 [Thread-924] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:38,488 [Thread-924] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:38,488 [Thread-924] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:38,489 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:38,489 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:38,489 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:38,489 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:38,491 [Thread-924] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:38,491 [Thread-924] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:38,491 [Thread-924] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:38,491 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:38,491 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:38,491 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:38,491 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:38,492 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:38,492 [Thread-924] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:38,503 [Thread-924] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:38,505 [Thread-924] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:38,506 [Thread-924] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:38,506 [Thread-924] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:38,506 [Thread-924] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:38,506 [Thread-924] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:38,507 [Thread-924] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:38,508 [Thread-924] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:38,508 [Thread-924] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:38,508 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:38,508 [Thread-924] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:38,524 [Thread-924] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:38,525 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 32 msecs
2020-04-02 05:07:38,525 [Thread-924] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:38,525 [Thread-924] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:38,527 [Socket Reader #1 for port 36750] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36750
2020-04-02 05:07:38,535 [Thread-924] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36750 to access this namenode/service.
2020-04-02 05:07:38,535 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:38,559 [Thread-924] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:38,561 [Thread-924] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:38,562 [Thread-924] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:38,562 [Thread-924] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:38,562 [Thread-924] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:38,566 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:38,566 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:38,566 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:38,566 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:38,566 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:38,567 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-02 05:07:38,569 [IPC Server listener on 36750] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36750: starting
2020-04-02 05:07:38,569 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:38,577 [Thread-924] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36750
2020-04-02 05:07:38,579 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:38,579 [Thread-924] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:38,582 [Thread-924] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:38,583 [Thread-924] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36750 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:38,587 [CacheReplicationMonitor(1244159292)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:38,591 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:38,591 [Thread-924] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:38,592 [Thread-924] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:38,593 [Thread-924] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:38,601 [Thread-924] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:38,602 [Thread-924] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:38,602 [Thread-924] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:38,602 [Thread-924] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:38,602 [Thread-924] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:38,602 [Thread-924] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:38,602 [Thread-924] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:38,607 [Thread-924] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41570
2020-04-02 05:07:38,607 [Thread-924] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:38,607 [Thread-924] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:38,608 [Thread-924] WARN  datanode.DataNode (DataNode.java:getDomainPeerServer(1193)) - Although short-circuit local reads are configured, they are disabled because you didn't configure dfs.domain.socket.path
2020-04-02 05:07:38,608 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:38,610 [Thread-924] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:38,610 [Thread-924] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:38,610 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:38,611 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:38,611 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:38,612 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:38,612 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:38,612 [Thread-924] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43323
2020-04-02 05:07:38,612 [Thread-924] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:38,613 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@343d1a95{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:38,614 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4b0a4f0e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:38,617 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5d7aae31{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:38,618 [Thread-924] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@357a498e{HTTP/1.1,[http/1.1]}{localhost:43323}
2020-04-02 05:07:38,618 [Thread-924] INFO  server.Server (Server.java:doStart(419)) - Started @18405ms
2020-04-02 05:07:38,630 [Thread-924] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41569
2020-04-02 05:07:38,630 [Thread-924] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:38,630 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@77cb8ad3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:38,631 [Thread-924] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:38,631 [Thread-924] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:38,632 [Socket Reader #1 for port 41264] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41264
2020-04-02 05:07:38,635 [Thread-924] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41264
2020-04-02 05:07:38,639 [Thread-924] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:38,640 [Thread-924] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:38,641 [Thread-979] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36750 starting to offer service
2020-04-02 05:07:38,641 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:38,641 [IPC Server listener on 41264] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41264: starting
2020-04-02 05:07:38,644 [Thread-924] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41264 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:38,650 [Thread-979] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36750
2020-04-02 05:07:38,654 [IPC Server handler 0 on 36750] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:38,654 [Thread-979] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:38,655 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:38,655 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:38,657 [Thread-979] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:38,657 [Thread-979] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1108908080. Formatting...
2020-04-02 05:07:38,657 [Thread-979] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c1ee1969-df29-4126-8d0b-cab97cb18f4b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:38,659 [Thread-979] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:38,660 [Thread-979] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1108908080. Formatting...
2020-04-02 05:07:38,660 [Thread-979] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a4579a02-64c0-401e-9191-7aa1281ee734 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:38,669 [Thread-979] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:38,669 [Thread-979] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:38,670 [Thread-979] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1571220501-172.17.0.13-1585804058398 is not formatted. Formatting ...
2020-04-02 05:07:38,670 [Thread-979] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1571220501-172.17.0.13-1585804058398 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1571220501-172.17.0.13-1585804058398/current
2020-04-02 05:07:38,695 [Thread-979] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:38,695 [Thread-979] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:38,696 [Thread-979] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1571220501-172.17.0.13-1585804058398 is not formatted. Formatting ...
2020-04-02 05:07:38,696 [Thread-979] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1571220501-172.17.0.13-1585804058398 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1571220501-172.17.0.13-1585804058398/current
2020-04-02 05:07:38,702 [Thread-979] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1108908080;bpid=BP-1571220501-172.17.0.13-1585804058398;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1108908080;c=1585804058398;bpid=BP-1571220501-172.17.0.13-1585804058398;dnuuid=null
2020-04-02 05:07:38,703 [Thread-979] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69
2020-04-02 05:07:38,705 [Thread-979] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c1ee1969-df29-4126-8d0b-cab97cb18f4b
2020-04-02 05:07:38,707 [Thread-979] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:38,708 [Thread-979] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a4579a02-64c0-401e-9191-7aa1281ee734
2020-04-02 05:07:38,708 [Thread-979] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:38,714 [Thread-979] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:38,715 [Thread-979] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:38,716 [Thread-979] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:38,716 [Thread-979] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:38,716 [Thread-979] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:38,718 [Thread-979] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:38,718 [Thread-994] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1571220501-172.17.0.13-1585804058398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:38,718 [Thread-995] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1571220501-172.17.0.13-1585804058398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:38,743 [Thread-995] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1571220501-172.17.0.13-1585804058398 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 25ms
2020-04-02 05:07:38,751 [Thread-994] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1571220501-172.17.0.13-1585804058398 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 34ms
2020-04-02 05:07:38,752 [Thread-979] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1571220501-172.17.0.13-1585804058398: 34ms
2020-04-02 05:07:38,752 [Thread-998] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1571220501-172.17.0.13-1585804058398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:38,752 [Thread-999] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1571220501-172.17.0.13-1585804058398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:38,752 [Thread-998] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1571220501-172.17.0.13-1585804058398/current/replicas doesn't exist 
2020-04-02 05:07:38,752 [Thread-999] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1571220501-172.17.0.13-1585804058398/current/replicas doesn't exist 
2020-04-02 05:07:38,753 [Thread-998] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1571220501-172.17.0.13-1585804058398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:07:38,753 [Thread-999] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1571220501-172.17.0.13-1585804058398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:38,761 [IPC Server handler 3 on 36750] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:38,761 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:38,761 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:38,761 [Thread-979] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1571220501-172.17.0.13-1585804058398: 10ms
2020-04-02 05:07:38,762 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1571220501-172.17.0.13-1585804058398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:38,762 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a4579a02-64c0-401e-9191-7aa1281ee734): finished scanning block pool BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:38,762 [Thread-979] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:06 AM with interval of 21600000ms
2020-04-02 05:07:38,764 [BP-1571220501-172.17.0.13-1585804058398 heartbeating to localhost/127.0.0.1:36750] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1571220501-172.17.0.13-1585804058398 (Datanode Uuid 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69) service to localhost/127.0.0.1:36750 beginning handshake with NN
2020-04-02 05:07:38,764 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1571220501-172.17.0.13-1585804058398 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:38,764 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c1ee1969-df29-4126-8d0b-cab97cb18f4b): finished scanning block pool BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:38,765 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c1ee1969-df29-4126-8d0b-cab97cb18f4b): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:07:38,765 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a4579a02-64c0-401e-9191-7aa1281ee734): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:07:38,765 [IPC Server handler 4 on 36750] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41570, datanodeUuid=206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69, infoPort=41569, infoSecurePort=0, ipcPort=41264, storageInfo=lv=-57;cid=testClusterID;nsid=1108908080;c=1585804058398) storage 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69
2020-04-02 05:07:38,765 [IPC Server handler 4 on 36750] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41570
2020-04-02 05:07:38,766 [IPC Server handler 4 on 36750] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69 (127.0.0.1:41570).
2020-04-02 05:07:38,784 [BP-1571220501-172.17.0.13-1585804058398 heartbeating to localhost/127.0.0.1:36750] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1571220501-172.17.0.13-1585804058398 (Datanode Uuid 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69) service to localhost/127.0.0.1:36750 successfully registered with NN
2020-04-02 05:07:38,784 [BP-1571220501-172.17.0.13-1585804058398 heartbeating to localhost/127.0.0.1:36750] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36750 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:38,804 [IPC Server handler 2 on 36750] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c1ee1969-df29-4126-8d0b-cab97cb18f4b for DN 127.0.0.1:41570
2020-04-02 05:07:38,804 [IPC Server handler 2 on 36750] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a4579a02-64c0-401e-9191-7aa1281ee734 for DN 127.0.0.1:41570
2020-04-02 05:07:38,814 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaf5863caa0c3834: Processing first storage report for DS-c1ee1969-df29-4126-8d0b-cab97cb18f4b from datanode 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69
2020-04-02 05:07:38,814 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaf5863caa0c3834: from storage DS-c1ee1969-df29-4126-8d0b-cab97cb18f4b node DatanodeRegistration(127.0.0.1:41570, datanodeUuid=206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69, infoPort=41569, infoSecurePort=0, ipcPort=41264, storageInfo=lv=-57;cid=testClusterID;nsid=1108908080;c=1585804058398), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:38,814 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaf5863caa0c3834: Processing first storage report for DS-a4579a02-64c0-401e-9191-7aa1281ee734 from datanode 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69
2020-04-02 05:07:38,815 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaf5863caa0c3834: from storage DS-a4579a02-64c0-401e-9191-7aa1281ee734 node DatanodeRegistration(127.0.0.1:41570, datanodeUuid=206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69, infoPort=41569, infoSecurePort=0, ipcPort=41264, storageInfo=lv=-57;cid=testClusterID;nsid=1108908080;c=1585804058398), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:38,815 [BP-1571220501-172.17.0.13-1585804058398 heartbeating to localhost/127.0.0.1:36750] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xaf5863caa0c3834,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:38,815 [BP-1571220501-172.17.0.13-1585804058398 heartbeating to localhost/127.0.0.1:36750] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:38,866 [IPC Server handler 7 on 36750] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:38,867 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:38,871 [IPC Server handler 8 on 36750] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:38,872 [Thread-924] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=15460
2020-04-02 05:07:38,876 [IPC Server handler 9 on 36750] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:38,905 [IPC Server handler 6 on 36750] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:41570 for /user/root/filelocal.dat
2020-04-02 05:07:38,917 [DataXceiver for client DFSClient_NONMAPREDUCE_1753700366_2642 at /127.0.0.1:41836 [Receiving block BP-1571220501-172.17.0.13-1585804058398:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1571220501-172.17.0.13-1585804058398:blk_1073741825_1001 src: /127.0.0.1:41836 dest: /127.0.0.1:41570
2020-04-02 05:07:38,927 [PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41836, dest: /127.0.0.1:41570, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753700366_2642, offset: 0, srvID: 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69, blockid: BP-1571220501-172.17.0.13-1585804058398:blk_1073741825_1001, duration(ns): 2019868
2020-04-02 05:07:38,927 [PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,947 [IPC Server handler 3 on 36750] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:41570 for /user/root/filelocal.dat
2020-04-02 05:07:38,952 [DataXceiver for client DFSClient_NONMAPREDUCE_1753700366_2642 at /127.0.0.1:41838 [Receiving block BP-1571220501-172.17.0.13-1585804058398:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1571220501-172.17.0.13-1585804058398:blk_1073741826_1002 src: /127.0.0.1:41838 dest: /127.0.0.1:41570
2020-04-02 05:07:38,968 [PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41838, dest: /127.0.0.1:41570, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753700366_2642, offset: 0, srvID: 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69, blockid: BP-1571220501-172.17.0.13-1585804058398:blk_1073741826_1002, duration(ns): 1514897
2020-04-02 05:07:38,971 [PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:38,979 [IPC Server handler 2 on 36750] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:41570 for /user/root/filelocal.dat
2020-04-02 05:07:38,983 [DataXceiver for client DFSClient_NONMAPREDUCE_1753700366_2642 at /127.0.0.1:41840 [Receiving block BP-1571220501-172.17.0.13-1585804058398:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1571220501-172.17.0.13-1585804058398:blk_1073741827_1003 src: /127.0.0.1:41840 dest: /127.0.0.1:41570
2020-04-02 05:07:39,014 [PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41840, dest: /127.0.0.1:41570, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753700366_2642, offset: 0, srvID: 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69, blockid: BP-1571220501-172.17.0.13-1585804058398:blk_1073741827_1003, duration(ns): 23191028
2020-04-02 05:07:39,014 [PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:39,018 [IPC Server handler 7 on 36750] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:41570 for /user/root/filelocal.dat
2020-04-02 05:07:39,024 [DataXceiver for client DFSClient_NONMAPREDUCE_1753700366_2642 at /127.0.0.1:41846 [Receiving block BP-1571220501-172.17.0.13-1585804058398:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1571220501-172.17.0.13-1585804058398:blk_1073741828_1004 src: /127.0.0.1:41846 dest: /127.0.0.1:41570
2020-04-02 05:07:39,042 [PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41846, dest: /127.0.0.1:41570, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1753700366_2642, offset: 0, srvID: 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69, blockid: BP-1571220501-172.17.0.13-1585804058398:blk_1073741828_1004, duration(ns): 12991660
2020-04-02 05:07:39,043 [PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1571220501-172.17.0.13-1585804058398:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:39,052 [IPC Server handler 9 on 36750] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_1753700366_2642
2020-04-02 05:07:39,059 [IPC Server handler 6 on 36750] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:39,098 [IPC Server handler 0 on 36750] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:39,113 [IPC Server handler 3 on 36750] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:39,115 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:39,116 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:39,116 [Thread-924] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41264 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:39,116 [Thread-924] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:39,122 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@600a5e37] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:39,124 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a4579a02-64c0-401e-9191-7aa1281ee734) exiting.
2020-04-02 05:07:39,125 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c1ee1969-df29-4126-8d0b-cab97cb18f4b) exiting.
2020-04-02 05:07:39,157 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5d7aae31{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:39,158 [Thread-924] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@357a498e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:39,158 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4b0a4f0e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:39,159 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@343d1a95{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:39,160 [Thread-924] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41264
2020-04-02 05:07:39,167 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:39,167 [IPC Server listener on 41264] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41264
2020-04-02 05:07:39,169 [BP-1571220501-172.17.0.13-1585804058398 heartbeating to localhost/127.0.0.1:36750] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:39,169 [BP-1571220501-172.17.0.13-1585804058398 heartbeating to localhost/127.0.0.1:36750] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1571220501-172.17.0.13-1585804058398 (Datanode Uuid 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69) service to localhost/127.0.0.1:36750
2020-04-02 05:07:39,169 [BP-1571220501-172.17.0.13-1585804058398 heartbeating to localhost/127.0.0.1:36750] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1571220501-172.17.0.13-1585804058398 (Datanode Uuid 206f4fcd-9f4d-4dfc-b4df-c2dc88d32f69)
2020-04-02 05:07:39,170 [BP-1571220501-172.17.0.13-1585804058398 heartbeating to localhost/127.0.0.1:36750] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1571220501-172.17.0.13-1585804058398
2020-04-02 05:07:39,180 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1571220501-172.17.0.13-1585804058398] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:39,201 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1571220501-172.17.0.13-1585804058398] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:39,214 [Thread-924] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:39,215 [Thread-924] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:39,217 [Thread-924] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:39,217 [Thread-924] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:39,220 [Thread-924] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:39,220 [Thread-924] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:39,220 [Thread-924] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36750 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:39,220 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:39,220 [Thread-924] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 17
2020-04-02 05:07:39,220 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@40d26cad] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:39,220 [Thread-924] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 18 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 9 Number of syncs: 10 SyncTimes(ms): 3 1 
2020-04-02 05:07:39,221 [Thread-924] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:39,222 [Thread-924] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:39,222 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:39,222 [CacheReplicationMonitor(1244159292)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:39,226 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@7bf20d01] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:39,245 [Thread-924] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36750
2020-04-02 05:07:39,258 [IPC Server listener on 36750] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36750
2020-04-02 05:07:39,270 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:39,272 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:39,272 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:39,278 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:39,278 [Thread-924] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:39,279 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@767b2039{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:39,281 [Thread-924] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5a0dadfd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:39,281 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f2a0ebd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:39,281 [Thread-924] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@bcba42c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:39,282 [Thread-924] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:39,290 [Thread-924] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:39,290 [Thread-924] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testReadWithRemoteBlockReader2
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testReadWithRemoteBlockReader2
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testFileLocalReadNoChecksum
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:39,310 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:39,312 [Thread-1019] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:39,313 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:39,313 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:39,313 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:39,313 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:39,313 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:39,313 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:39,313 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:39,314 [Thread-1019] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:39,314 [Thread-1019] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:39,314 [Thread-1019] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:39,314 [Thread-1019] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:39,314 [Thread-1019] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:39
2020-04-02 05:07:39,314 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:39,314 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:39,315 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:39,315 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:39,450 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:39,476 [Thread-1019] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:39,503 [Thread-1019] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:39,503 [Thread-1019] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:39,503 [Thread-1019] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:39,503 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:39,503 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:39,503 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:39,503 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:39,503 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:39,504 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:39,504 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:39,504 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:39,504 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:39,504 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:39,504 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:39,515 [Thread-1019] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:39,515 [Thread-1019] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:39,515 [Thread-1019] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:39,515 [Thread-1019] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:39,515 [Thread-1019] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:39,515 [Thread-1019] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:39,516 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:39,516 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:39,516 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:39,516 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:39,517 [Thread-1019] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:39,517 [Thread-1019] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:39,517 [Thread-1019] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:39,517 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:39,517 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:39,519 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:39,519 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:39,519 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:39,519 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:39,522 [Thread-1019] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:39,554 [Thread-1019] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:39,559 [Thread-1019] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:39,563 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:39,563 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:39,568 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:39,613 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:39,626 [Thread-1019] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:39,628 [Thread-1019] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:39,646 [Thread-1019] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:39,650 [Thread-1019] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:39,650 [Thread-1019] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:39,651 [Thread-1019] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:39,651 [Thread-1019] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:39,656 [Thread-1019] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:39,657 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:39,657 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@134a44c2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:39,668 [Thread-1019] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:39,670 [Thread-1019] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:39,671 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:39,672 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:39,672 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:39,672 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:39,673 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:39,674 [Thread-1019] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:39,674 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:39,675 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42587
2020-04-02 05:07:39,675 [Thread-1019] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:39,686 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61fb052f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:39,687 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4939c4c9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:39,692 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1d4b1b99{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:39,693 [Thread-1019] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@cb6dbc7{HTTP/1.1,[http/1.1]}{localhost:42587}
2020-04-02 05:07:39,693 [Thread-1019] INFO  server.Server (Server.java:doStart(419)) - Started @19480ms
2020-04-02 05:07:39,694 [Thread-1019] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:39,695 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:39,695 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:39,695 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:39,695 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:39,695 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:39,695 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:39,695 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:39,702 [Thread-1019] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:39,704 [Thread-1019] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:39,704 [Thread-1019] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:39,705 [Thread-1019] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:39,705 [Thread-1019] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:39
2020-04-02 05:07:39,705 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:39,705 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:39,705 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.9 MB
2020-04-02 05:07:39,705 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:39,710 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:39,710 [Thread-1019] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:39,710 [Thread-1019] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:39,710 [Thread-1019] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:39,710 [Thread-1019] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:39,711 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:39,711 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:39,711 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:39,711 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:39,711 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:39,711 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:39,711 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:39,711 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:39,711 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:39,711 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:39,711 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:39,716 [Thread-1019] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:39,716 [Thread-1019] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:39,716 [Thread-1019] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:39,716 [Thread-1019] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:39,716 [Thread-1019] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:39,717 [Thread-1019] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:39,717 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:39,717 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:39,717 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:39,717 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:39,718 [Thread-1019] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:39,718 [Thread-1019] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:39,718 [Thread-1019] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:39,718 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:39,719 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:39,719 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:39,719 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:39,719 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:39,719 [Thread-1019] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:39,722 [Thread-1019] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:39,724 [Thread-1019] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:39,726 [Thread-1019] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:39,726 [Thread-1019] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:39,727 [Thread-1019] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:39,727 [Thread-1019] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:39,728 [Thread-1019] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:39,729 [Thread-1019] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:39,730 [Thread-1019] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:39,731 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:39,732 [Thread-1019] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:39,750 [Thread-1019] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:39,750 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 30 msecs
2020-04-02 05:07:39,751 [Thread-1019] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:39,751 [Thread-1019] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:39,752 [Socket Reader #1 for port 36776] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36776
2020-04-02 05:07:39,758 [Thread-1019] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36776 to access this namenode/service.
2020-04-02 05:07:39,759 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:39,790 [Thread-1019] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:39,791 [Thread-1019] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:39,793 [Thread-1019] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:39,794 [Thread-1019] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:39,794 [Thread-1019] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:39,800 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:39,800 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:39,800 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:39,800 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:39,800 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:39,800 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-04-02 05:07:39,807 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:39,818 [IPC Server listener on 36776] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36776: starting
2020-04-02 05:07:39,838 [Thread-1019] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36776
2020-04-02 05:07:39,838 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:39,839 [Thread-1019] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:39,839 [Thread-1019] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:39,844 [Thread-1019] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36776 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:39,852 [CacheReplicationMonitor(495898435)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:39,861 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:39,863 [Thread-1019] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:39,863 [Thread-1019] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:39,868 [Thread-1019] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:39,868 [Thread-1019] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:39,868 [Thread-1019] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:39,868 [Thread-1019] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:39,869 [Thread-1019] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:39,869 [Thread-1019] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:39,869 [Thread-1019] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:39,869 [Thread-1019] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:39,870 [Thread-1019] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35385
2020-04-02 05:07:39,870 [Thread-1019] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:39,870 [Thread-1019] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:39,870 [Thread-1019] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:39,871 [Thread-1019] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:39,871 [Thread-1019] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.35385.sock
2020-04-02 05:07:39,871 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:39,873 [Thread-1019] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:39,875 [Thread-1019] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:39,875 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:39,877 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:39,878 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:39,878 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:39,878 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:39,879 [Thread-1019] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45442
2020-04-02 05:07:39,879 [Thread-1019] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:39,888 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@537e62c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:39,895 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f451c8a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:39,900 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9e2910c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:39,900 [Thread-1019] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6cc2a784{HTTP/1.1,[http/1.1]}{localhost:45442}
2020-04-02 05:07:39,904 [Thread-1019] INFO  server.Server (Server.java:doStart(419)) - Started @19690ms
2020-04-02 05:07:39,929 [Thread-1019] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42451
2020-04-02 05:07:39,946 [Thread-1019] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:39,946 [Thread-1019] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:39,946 [Thread-1019] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:39,946 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1e903811] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:39,955 [Socket Reader #1 for port 42885] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42885
2020-04-02 05:07:39,964 [Thread-1019] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42885
2020-04-02 05:07:39,969 [Thread-1019] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:39,969 [Thread-1019] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:39,973 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:39,974 [IPC Server listener on 42885] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42885: starting
2020-04-02 05:07:39,975 [Thread-1019] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42885 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:39,977 [Thread-1075] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36776 starting to offer service
2020-04-02 05:07:40,000 [IPC Server handler 1 on 36776] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:40,002 [Thread-1075] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36776
2020-04-02 05:07:40,008 [Thread-1075] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:40,009 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:40,009 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:40,010 [Thread-1075] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:40,010 [Thread-1075] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1772310896. Formatting...
2020-04-02 05:07:40,011 [Thread-1075] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9f14860d-09bc-4dcb-b2ae-140ea164d281 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:40,013 [Thread-1075] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:40,013 [Thread-1075] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1772310896. Formatting...
2020-04-02 05:07:40,013 [Thread-1075] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a423151e-2976-469c-88e5-f5fc70430c15 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:40,022 [Thread-1075] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:40,023 [Thread-1075] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:40,023 [Thread-1075] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1413411040-172.17.0.13-1585804059522 is not formatted. Formatting ...
2020-04-02 05:07:40,023 [Thread-1075] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1413411040-172.17.0.13-1585804059522 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1413411040-172.17.0.13-1585804059522/current
2020-04-02 05:07:40,033 [Thread-1075] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:40,033 [Thread-1075] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:40,033 [Thread-1075] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1413411040-172.17.0.13-1585804059522 is not formatted. Formatting ...
2020-04-02 05:07:40,034 [Thread-1075] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1413411040-172.17.0.13-1585804059522 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1413411040-172.17.0.13-1585804059522/current
2020-04-02 05:07:40,035 [Thread-1075] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1772310896;bpid=BP-1413411040-172.17.0.13-1585804059522;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1772310896;c=1585804059522;bpid=BP-1413411040-172.17.0.13-1585804059522;dnuuid=null
2020-04-02 05:07:40,036 [Thread-1075] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID bb31a02e-1610-4013-af28-49cb349ee106
2020-04-02 05:07:40,038 [Thread-1075] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9f14860d-09bc-4dcb-b2ae-140ea164d281
2020-04-02 05:07:40,040 [Thread-1075] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:40,041 [Thread-1075] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a423151e-2976-469c-88e5-f5fc70430c15
2020-04-02 05:07:40,043 [Thread-1075] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:40,044 [Thread-1075] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:40,045 [Thread-1075] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:40,046 [Thread-1075] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:40,046 [Thread-1075] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:40,046 [Thread-1075] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:40,046 [Thread-1075] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:40,046 [Thread-1091] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1413411040-172.17.0.13-1585804059522 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:40,047 [Thread-1092] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1413411040-172.17.0.13-1585804059522 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:40,077 [Thread-1092] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1413411040-172.17.0.13-1585804059522 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 30ms
2020-04-02 05:07:40,091 [Thread-1091] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1413411040-172.17.0.13-1585804059522 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 44ms
2020-04-02 05:07:40,092 [Thread-1075] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1413411040-172.17.0.13-1585804059522: 46ms
2020-04-02 05:07:40,093 [Thread-1095] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1413411040-172.17.0.13-1585804059522 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:40,093 [Thread-1096] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1413411040-172.17.0.13-1585804059522 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:40,093 [Thread-1095] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1413411040-172.17.0.13-1585804059522/current/replicas doesn't exist 
2020-04-02 05:07:40,093 [Thread-1096] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1413411040-172.17.0.13-1585804059522/current/replicas doesn't exist 
2020-04-02 05:07:40,093 [Thread-1095] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1413411040-172.17.0.13-1585804059522 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 0ms
2020-04-02 05:07:40,095 [Thread-1096] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1413411040-172.17.0.13-1585804059522 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:07:40,095 [Thread-1075] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1413411040-172.17.0.13-1585804059522: 2ms
2020-04-02 05:07:40,095 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1413411040-172.17.0.13-1585804059522 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:40,095 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1413411040-172.17.0.13-1585804059522 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:40,096 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9f14860d-09bc-4dcb-b2ae-140ea164d281): finished scanning block pool BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:40,096 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a423151e-2976-469c-88e5-f5fc70430c15): finished scanning block pool BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:40,096 [Thread-1075] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:34 AM with interval of 21600000ms
2020-04-02 05:07:40,096 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a423151e-2976-469c-88e5-f5fc70430c15): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:07:40,096 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9f14860d-09bc-4dcb-b2ae-140ea164d281): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:07:40,102 [BP-1413411040-172.17.0.13-1585804059522 heartbeating to localhost/127.0.0.1:36776] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1413411040-172.17.0.13-1585804059522 (Datanode Uuid bb31a02e-1610-4013-af28-49cb349ee106) service to localhost/127.0.0.1:36776 beginning handshake with NN
2020-04-02 05:07:40,104 [IPC Server handler 3 on 36776] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35385, datanodeUuid=bb31a02e-1610-4013-af28-49cb349ee106, infoPort=42451, infoSecurePort=0, ipcPort=42885, storageInfo=lv=-57;cid=testClusterID;nsid=1772310896;c=1585804059522) storage bb31a02e-1610-4013-af28-49cb349ee106
2020-04-02 05:07:40,104 [IPC Server handler 3 on 36776] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35385
2020-04-02 05:07:40,104 [IPC Server handler 3 on 36776] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN bb31a02e-1610-4013-af28-49cb349ee106 (127.0.0.1:35385).
2020-04-02 05:07:40,110 [BP-1413411040-172.17.0.13-1585804059522 heartbeating to localhost/127.0.0.1:36776] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1413411040-172.17.0.13-1585804059522 (Datanode Uuid bb31a02e-1610-4013-af28-49cb349ee106) service to localhost/127.0.0.1:36776 successfully registered with NN
2020-04-02 05:07:40,112 [BP-1413411040-172.17.0.13-1585804059522 heartbeating to localhost/127.0.0.1:36776] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36776 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:40,116 [IPC Server handler 4 on 36776] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:40,119 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:35385
2020-04-02 05:07:40,120 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:40,122 [IPC Server handler 5 on 36776] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9f14860d-09bc-4dcb-b2ae-140ea164d281 for DN 127.0.0.1:35385
2020-04-02 05:07:40,122 [IPC Server handler 5 on 36776] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a423151e-2976-469c-88e5-f5fc70430c15 for DN 127.0.0.1:35385
2020-04-02 05:07:40,126 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xed010de580fa038a: Processing first storage report for DS-9f14860d-09bc-4dcb-b2ae-140ea164d281 from datanode bb31a02e-1610-4013-af28-49cb349ee106
2020-04-02 05:07:40,126 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xed010de580fa038a: from storage DS-9f14860d-09bc-4dcb-b2ae-140ea164d281 node DatanodeRegistration(127.0.0.1:35385, datanodeUuid=bb31a02e-1610-4013-af28-49cb349ee106, infoPort=42451, infoSecurePort=0, ipcPort=42885, storageInfo=lv=-57;cid=testClusterID;nsid=1772310896;c=1585804059522), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:40,127 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xed010de580fa038a: Processing first storage report for DS-a423151e-2976-469c-88e5-f5fc70430c15 from datanode bb31a02e-1610-4013-af28-49cb349ee106
2020-04-02 05:07:40,128 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xed010de580fa038a: from storage DS-a423151e-2976-469c-88e5-f5fc70430c15 node DatanodeRegistration(127.0.0.1:35385, datanodeUuid=bb31a02e-1610-4013-af28-49cb349ee106, infoPort=42451, infoSecurePort=0, ipcPort=42885, storageInfo=lv=-57;cid=testClusterID;nsid=1772310896;c=1585804059522), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:40,130 [BP-1413411040-172.17.0.13-1585804059522 heartbeating to localhost/127.0.0.1:36776] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xed010de580fa038a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:40,130 [BP-1413411040-172.17.0.13-1585804059522 heartbeating to localhost/127.0.0.1:36776] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:40,222 [IPC Server handler 6 on 36776] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:40,223 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:40,226 [IPC Server handler 8 on 36776] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:40,227 [Thread-1019] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=15460
2020-04-02 05:07:40,234 [IPC Server handler 9 on 36776] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:40,240 [IPC Server handler 2 on 36776] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:35385 for /user/root/filelocal.dat
2020-04-02 05:07:40,242 [DataXceiver for client DFSClient_NONMAPREDUCE_-1316384708_2922 at /127.0.0.1:48362 [Receiving block BP-1413411040-172.17.0.13-1585804059522:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1413411040-172.17.0.13-1585804059522:blk_1073741825_1001 src: /127.0.0.1:48362 dest: /127.0.0.1:35385
2020-04-02 05:07:40,249 [PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48362, dest: /127.0.0.1:35385, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1316384708_2922, offset: 0, srvID: bb31a02e-1610-4013-af28-49cb349ee106, blockid: BP-1413411040-172.17.0.13-1585804059522:blk_1073741825_1001, duration(ns): 2408224
2020-04-02 05:07:40,249 [PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:40,252 [IPC Server handler 1 on 36776] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:35385 for /user/root/filelocal.dat
2020-04-02 05:07:40,270 [DataXceiver for client DFSClient_NONMAPREDUCE_-1316384708_2922 at /127.0.0.1:48386 [Receiving block BP-1413411040-172.17.0.13-1585804059522:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1413411040-172.17.0.13-1585804059522:blk_1073741826_1002 src: /127.0.0.1:48386 dest: /127.0.0.1:35385
2020-04-02 05:07:40,279 [PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48386, dest: /127.0.0.1:35385, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1316384708_2922, offset: 0, srvID: bb31a02e-1610-4013-af28-49cb349ee106, blockid: BP-1413411040-172.17.0.13-1585804059522:blk_1073741826_1002, duration(ns): 3096097
2020-04-02 05:07:40,279 [PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:40,283 [IPC Server handler 5 on 36776] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:35385 for /user/root/filelocal.dat
2020-04-02 05:07:40,285 [DataXceiver for client DFSClient_NONMAPREDUCE_-1316384708_2922 at /127.0.0.1:48390 [Receiving block BP-1413411040-172.17.0.13-1585804059522:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1413411040-172.17.0.13-1585804059522:blk_1073741827_1003 src: /127.0.0.1:48390 dest: /127.0.0.1:35385
2020-04-02 05:07:40,302 [PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48390, dest: /127.0.0.1:35385, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1316384708_2922, offset: 0, srvID: bb31a02e-1610-4013-af28-49cb349ee106, blockid: BP-1413411040-172.17.0.13-1585804059522:blk_1073741827_1003, duration(ns): 9102487
2020-04-02 05:07:40,302 [PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:40,315 [IPC Server handler 7 on 36776] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:35385 for /user/root/filelocal.dat
2020-04-02 05:07:40,317 [DataXceiver for client DFSClient_NONMAPREDUCE_-1316384708_2922 at /127.0.0.1:48396 [Receiving block BP-1413411040-172.17.0.13-1585804059522:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1413411040-172.17.0.13-1585804059522:blk_1073741828_1004 src: /127.0.0.1:48396 dest: /127.0.0.1:35385
2020-04-02 05:07:40,331 [PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:48396, dest: /127.0.0.1:35385, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1316384708_2922, offset: 0, srvID: bb31a02e-1610-4013-af28-49cb349ee106, blockid: BP-1413411040-172.17.0.13-1585804059522:blk_1073741828_1004, duration(ns): 6578486
2020-04-02 05:07:40,332 [PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1413411040-172.17.0.13-1585804059522:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:40,333 [IPC Server handler 9 on 36776] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_-1316384708_2922
2020-04-02 05:07:40,348 [IPC Server handler 2 on 36776] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:40,361 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.35385.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-794732681_2922, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: aa2e08fa55c441c1b13f45a1702b147d, srvID: bb31a02e-1610-4013-af28-49cb349ee106, success: true
2020-04-02 05:07:40,364 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.35385.sock [Passing file descriptors for block BP-1413411040-172.17.0.13-1585804059522:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: bb31a02e-1610-4013-af28-49cb349ee106, success: true
2020-04-02 05:07:40,367 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.35385.sock [Passing file descriptors for block BP-1413411040-172.17.0.13-1585804059522:blk_1073741826_1002]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741826, srvID: bb31a02e-1610-4013-af28-49cb349ee106, success: true
2020-04-02 05:07:40,368 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.35385.sock [Passing file descriptors for block BP-1413411040-172.17.0.13-1585804059522:blk_1073741827_1003]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741827, srvID: bb31a02e-1610-4013-af28-49cb349ee106, success: true
2020-04-02 05:07:40,370 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.35385.sock [Passing file descriptors for block BP-1413411040-172.17.0.13-1585804059522:blk_1073741828_1004]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741828, srvID: bb31a02e-1610-4013-af28-49cb349ee106, success: true
2020-04-02 05:07:40,378 [IPC Server handler 0 on 36776] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:40,388 [IPC Server handler 1 on 36776] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:40,391 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:40,391 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:40,391 [Thread-1019] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42885 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:40,392 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4517acb7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:40,394 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@171f50e7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:40,402 [Thread-1019] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:40,404 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-9f14860d-09bc-4dcb-b2ae-140ea164d281) exiting.
2020-04-02 05:07:40,404 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-a423151e-2976-469c-88e5-f5fc70430c15) exiting.
2020-04-02 05:07:40,421 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9e2910c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:40,424 [Thread-1019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6cc2a784{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:40,425 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f451c8a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:40,425 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@537e62c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:40,436 [Thread-1019] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42885
2020-04-02 05:07:40,438 [IPC Server listener on 42885] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42885
2020-04-02 05:07:40,438 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:40,438 [BP-1413411040-172.17.0.13-1585804059522 heartbeating to localhost/127.0.0.1:36776] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:40,438 [BP-1413411040-172.17.0.13-1585804059522 heartbeating to localhost/127.0.0.1:36776] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1413411040-172.17.0.13-1585804059522 (Datanode Uuid bb31a02e-1610-4013-af28-49cb349ee106) service to localhost/127.0.0.1:36776
2020-04-02 05:07:40,439 [BP-1413411040-172.17.0.13-1585804059522 heartbeating to localhost/127.0.0.1:36776] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1413411040-172.17.0.13-1585804059522 (Datanode Uuid bb31a02e-1610-4013-af28-49cb349ee106)
2020-04-02 05:07:40,439 [BP-1413411040-172.17.0.13-1585804059522 heartbeating to localhost/127.0.0.1:36776] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1413411040-172.17.0.13-1585804059522
2020-04-02 05:07:40,451 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1413411040-172.17.0.13-1585804059522] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:40,460 [Thread-1019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:40,461 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1413411040-172.17.0.13-1585804059522] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:40,461 [Thread-1019] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:40,463 [Thread-1019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:40,464 [Thread-1019] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:40,475 [Thread-1019] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:40,476 [Thread-1019] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:40,476 [Thread-1019] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36776 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:40,476 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:40,476 [Thread-1019] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 17
2020-04-02 05:07:40,477 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@27d60c1e] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:40,476 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@57ffe235] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:40,477 [Thread-1019] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 18 Total time for transactions(ms): 15 Number of transactions batched in Syncs: 7 Number of syncs: 12 SyncTimes(ms): 6 1 
2020-04-02 05:07:40,477 [Thread-1019] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:40,478 [Thread-1019] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:40,478 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:40,479 [CacheReplicationMonitor(495898435)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:40,485 [Thread-1019] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36776
2020-04-02 05:07:40,490 [IPC Server listener on 36776] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36776
2020-04-02 05:07:40,490 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:40,490 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:40,490 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:40,499 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:40,499 [Thread-1019] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:40,500 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1d4b1b99{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:40,501 [Thread-1019] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@cb6dbc7{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:40,507 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4939c4c9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:40,508 [Thread-1019] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61fb052f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:40,509 [Thread-1019] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:40,511 [Thread-1019] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:40,511 [Thread-1019] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testFileLocalReadNoChecksum
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testFileLocalReadNoChecksum
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testLocalReadLegacy
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:40,530 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:40,532 [Thread-1119] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:40,533 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:40,533 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:40,533 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:40,533 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:40,533 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:40,533 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:40,533 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:40,533 [Thread-1119] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:40,533 [Thread-1119] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:40,533 [Thread-1119] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:40,534 [Thread-1119] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:40,534 [Thread-1119] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:40
2020-04-02 05:07:40,534 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:40,534 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:40,534 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.9 MB
2020-04-02 05:07:40,534 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:40,538 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:40,539 [Thread-1119] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:40,539 [Thread-1119] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:40,539 [Thread-1119] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:40,539 [Thread-1119] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:40,539 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:40,539 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:40,539 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:40,539 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:40,539 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:40,539 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:40,540 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:40,540 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:40,540 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:40,540 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:40,540 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:40,542 [Thread-1119] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:40,542 [Thread-1119] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:40,542 [Thread-1119] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:40,542 [Thread-1119] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:40,542 [Thread-1119] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:40,542 [Thread-1119] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:40,542 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:40,542 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:40,543 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:40,543 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:40,544 [Thread-1119] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:40,544 [Thread-1119] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:40,544 [Thread-1119] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:40,544 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:40,544 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:40,544 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:40,544 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:40,544 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:40,544 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:40,545 [Thread-1119] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:40,549 [Thread-1119] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:40,558 [Thread-1119] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:40,594 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:40,597 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:40,601 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:40,609 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:40,611 [Thread-1119] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:40,612 [Thread-1119] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:40,615 [Thread-1119] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:40,616 [Thread-1119] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:40,616 [Thread-1119] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:40,617 [Thread-1119] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:40,617 [Thread-1119] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:40,621 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@52214cf4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:40,621 [Thread-1119] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:40,621 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:40,622 [Thread-1119] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:40,623 [Thread-1119] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:40,623 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:40,624 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:40,624 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:40,624 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:40,624 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:40,628 [Thread-1119] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:40,629 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:40,629 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39296
2020-04-02 05:07:40,629 [Thread-1119] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:40,631 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@566139d6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:40,631 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b8df730{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:40,648 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3e799332{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:40,649 [Thread-1119] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@39fc9fb1{HTTP/1.1,[http/1.1]}{localhost:39296}
2020-04-02 05:07:40,649 [Thread-1119] INFO  server.Server (Server.java:doStart(419)) - Started @20436ms
2020-04-02 05:07:40,650 [Thread-1119] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:40,657 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:40,658 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:40,658 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:40,658 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:40,658 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:40,658 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:40,659 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:40,659 [Thread-1119] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:40,659 [Thread-1119] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:40,667 [Thread-1119] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:40,667 [Thread-1119] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:40,667 [Thread-1119] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:40
2020-04-02 05:07:40,668 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:40,668 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:40,668 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.9 MB
2020-04-02 05:07:40,668 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:40,672 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:40,673 [Thread-1119] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:40,673 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:40,674 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:40,675 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:40,675 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:40,675 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:40,676 [Thread-1119] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:40,677 [Thread-1119] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:40,677 [Thread-1119] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:40,677 [Thread-1119] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:40,677 [Thread-1119] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:40,677 [Thread-1119] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:40,677 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:40,677 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:40,677 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:40,677 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:40,680 [Thread-1119] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:40,680 [Thread-1119] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:40,681 [Thread-1119] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:40,681 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:40,681 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:40,682 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:40,682 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:40,682 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:40,683 [Thread-1119] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:40,687 [Thread-1119] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:40,689 [Thread-1119] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:40,690 [Thread-1119] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:40,690 [Thread-1119] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:40,698 [Thread-1119] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:40,698 [Thread-1119] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:40,699 [Thread-1119] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:40,700 [Thread-1119] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:40,701 [Thread-1119] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:40,702 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:40,707 [Thread-1119] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:40,724 [Thread-1119] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:40,724 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 40 msecs
2020-04-02 05:07:40,724 [Thread-1119] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:40,725 [Thread-1119] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:40,726 [Socket Reader #1 for port 44333] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44333
2020-04-02 05:07:40,734 [Thread-1119] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:44333 to access this namenode/service.
2020-04-02 05:07:40,734 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:40,755 [Thread-1119] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:40,758 [Thread-1119] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:40,759 [Thread-1119] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:40,759 [Thread-1119] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:40,759 [Thread-1119] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:40,766 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:40,766 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:40,766 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:40,766 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:40,767 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:40,767 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-04-02 05:07:40,771 [IPC Server listener on 44333] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44333: starting
2020-04-02 05:07:40,772 [Thread-1119] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:44333
2020-04-02 05:07:40,772 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:40,772 [Thread-1119] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:40,787 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:40,796 [Thread-1119] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 24 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:40,798 [Thread-1119] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 44333 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:40,805 [CacheReplicationMonitor(856421951)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:40,805 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:40,807 [Thread-1119] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:40,807 [Thread-1119] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:40,814 [Thread-1119] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:40,814 [Thread-1119] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:40,815 [Thread-1119] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:40,815 [Thread-1119] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:40,820 [Thread-1119] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:40,820 [Thread-1119] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:40,820 [Thread-1119] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:40,821 [Thread-1119] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:40,821 [Thread-1119] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44795
2020-04-02 05:07:40,821 [Thread-1119] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:40,822 [Thread-1119] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:40,822 [Thread-1119] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:40,822 [Thread-1119] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:40,822 [Thread-1119] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.44795.sock
2020-04-02 05:07:40,823 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:40,825 [Thread-1119] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:40,826 [Thread-1119] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:40,826 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:40,831 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:40,836 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:40,836 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:40,836 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:40,837 [Thread-1119] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38070
2020-04-02 05:07:40,837 [Thread-1119] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:40,854 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61397dda{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:40,856 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@141a9748{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:40,866 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44f05b05{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:40,867 [Thread-1119] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@32178d4{HTTP/1.1,[http/1.1]}{localhost:38070}
2020-04-02 05:07:40,867 [Thread-1119] INFO  server.Server (Server.java:doStart(419)) - Started @20654ms
2020-04-02 05:07:40,920 [Thread-1119] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45933
2020-04-02 05:07:40,921 [Thread-1119] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:40,921 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1bf834b8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:40,921 [Thread-1119] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:40,921 [Thread-1119] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:40,922 [Socket Reader #1 for port 37738] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37738
2020-04-02 05:07:40,923 [Thread-1119] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37738
2020-04-02 05:07:40,928 [Thread-1119] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:40,929 [Thread-1119] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:40,929 [Thread-1175] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44333 starting to offer service
2020-04-02 05:07:40,931 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:40,931 [IPC Server listener on 37738] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37738: starting
2020-04-02 05:07:40,953 [Thread-1175] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44333
2020-04-02 05:07:40,953 [Thread-1119] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37738 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:40,954 [Thread-1175] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:40,956 [Thread-1175] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:40,957 [Thread-1175] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1002969445. Formatting...
2020-04-02 05:07:40,959 [IPC Server handler 9 on 44333] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:40,959 [Thread-1175] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c8b879dd-10f3-4397-8abc-014292152f36 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:40,959 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:40,959 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:40,962 [Thread-1175] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:40,963 [Thread-1175] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1002969445. Formatting...
2020-04-02 05:07:40,963 [Thread-1175] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9cca39c0-9a1f-493b-a9a3-cce2413c43ee for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:40,973 [Thread-1175] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:40,974 [Thread-1175] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:40,975 [Thread-1175] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1326777985-172.17.0.13-1585804060545 is not formatted. Formatting ...
2020-04-02 05:07:40,975 [Thread-1175] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1326777985-172.17.0.13-1585804060545 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1326777985-172.17.0.13-1585804060545/current
2020-04-02 05:07:40,986 [Thread-1175] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:40,987 [Thread-1175] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:40,987 [Thread-1175] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1326777985-172.17.0.13-1585804060545 is not formatted. Formatting ...
2020-04-02 05:07:40,987 [Thread-1175] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1326777985-172.17.0.13-1585804060545 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1326777985-172.17.0.13-1585804060545/current
2020-04-02 05:07:40,988 [Thread-1175] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1002969445;bpid=BP-1326777985-172.17.0.13-1585804060545;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1002969445;c=1585804060545;bpid=BP-1326777985-172.17.0.13-1585804060545;dnuuid=null
2020-04-02 05:07:40,993 [Thread-1175] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ac87d5c4-909f-434e-85f8-2ad1e4e2f156
2020-04-02 05:07:40,998 [Thread-1175] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c8b879dd-10f3-4397-8abc-014292152f36
2020-04-02 05:07:40,998 [Thread-1175] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:41,001 [Thread-1175] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9cca39c0-9a1f-493b-a9a3-cce2413c43ee
2020-04-02 05:07:41,003 [Thread-1175] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:41,004 [Thread-1175] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:41,004 [Thread-1175] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:41,008 [Thread-1175] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:41,008 [Thread-1175] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:41,008 [Thread-1175] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:41,019 [Thread-1175] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:41,020 [Thread-1191] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1326777985-172.17.0.13-1585804060545 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:41,020 [Thread-1192] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1326777985-172.17.0.13-1585804060545 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:41,038 [Thread-1192] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1326777985-172.17.0.13-1585804060545 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 18ms
2020-04-02 05:07:41,050 [Thread-1191] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1326777985-172.17.0.13-1585804060545 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 30ms
2020-04-02 05:07:41,070 [Thread-1175] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1326777985-172.17.0.13-1585804060545: 51ms
2020-04-02 05:07:41,070 [Thread-1195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1326777985-172.17.0.13-1585804060545 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:41,070 [Thread-1196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1326777985-172.17.0.13-1585804060545 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:41,071 [Thread-1195] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1326777985-172.17.0.13-1585804060545/current/replicas doesn't exist 
2020-04-02 05:07:41,071 [Thread-1196] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1326777985-172.17.0.13-1585804060545/current/replicas doesn't exist 
2020-04-02 05:07:41,071 [Thread-1196] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1326777985-172.17.0.13-1585804060545 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:07:41,074 [IPC Server handler 3 on 44333] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:41,075 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:41,075 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:41,077 [Thread-1195] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1326777985-172.17.0.13-1585804060545 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 6ms
2020-04-02 05:07:41,077 [Thread-1175] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1326777985-172.17.0.13-1585804060545: 7ms
2020-04-02 05:07:41,077 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1326777985-172.17.0.13-1585804060545 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:41,077 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1326777985-172.17.0.13-1585804060545 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:41,077 [Thread-1175] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:40 AM with interval of 21600000ms
2020-04-02 05:07:41,077 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c8b879dd-10f3-4397-8abc-014292152f36): finished scanning block pool BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:41,079 [BP-1326777985-172.17.0.13-1585804060545 heartbeating to localhost/127.0.0.1:44333] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1326777985-172.17.0.13-1585804060545 (Datanode Uuid ac87d5c4-909f-434e-85f8-2ad1e4e2f156) service to localhost/127.0.0.1:44333 beginning handshake with NN
2020-04-02 05:07:41,079 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9cca39c0-9a1f-493b-a9a3-cce2413c43ee): finished scanning block pool BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:41,080 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c8b879dd-10f3-4397-8abc-014292152f36): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:07:41,080 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9cca39c0-9a1f-493b-a9a3-cce2413c43ee): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:07:41,080 [IPC Server handler 8 on 44333] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44795, datanodeUuid=ac87d5c4-909f-434e-85f8-2ad1e4e2f156, infoPort=45933, infoSecurePort=0, ipcPort=37738, storageInfo=lv=-57;cid=testClusterID;nsid=1002969445;c=1585804060545) storage ac87d5c4-909f-434e-85f8-2ad1e4e2f156
2020-04-02 05:07:41,080 [IPC Server handler 8 on 44333] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44795
2020-04-02 05:07:41,081 [IPC Server handler 8 on 44333] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ac87d5c4-909f-434e-85f8-2ad1e4e2f156 (127.0.0.1:44795).
2020-04-02 05:07:41,088 [BP-1326777985-172.17.0.13-1585804060545 heartbeating to localhost/127.0.0.1:44333] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1326777985-172.17.0.13-1585804060545 (Datanode Uuid ac87d5c4-909f-434e-85f8-2ad1e4e2f156) service to localhost/127.0.0.1:44333 successfully registered with NN
2020-04-02 05:07:41,088 [BP-1326777985-172.17.0.13-1585804060545 heartbeating to localhost/127.0.0.1:44333] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44333 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:41,092 [IPC Server handler 7 on 44333] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c8b879dd-10f3-4397-8abc-014292152f36 for DN 127.0.0.1:44795
2020-04-02 05:07:41,093 [IPC Server handler 7 on 44333] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9cca39c0-9a1f-493b-a9a3-cce2413c43ee for DN 127.0.0.1:44795
2020-04-02 05:07:41,099 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x992cd20ac944f8c5: Processing first storage report for DS-c8b879dd-10f3-4397-8abc-014292152f36 from datanode ac87d5c4-909f-434e-85f8-2ad1e4e2f156
2020-04-02 05:07:41,100 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x992cd20ac944f8c5: from storage DS-c8b879dd-10f3-4397-8abc-014292152f36 node DatanodeRegistration(127.0.0.1:44795, datanodeUuid=ac87d5c4-909f-434e-85f8-2ad1e4e2f156, infoPort=45933, infoSecurePort=0, ipcPort=37738, storageInfo=lv=-57;cid=testClusterID;nsid=1002969445;c=1585804060545), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:41,100 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x992cd20ac944f8c5: Processing first storage report for DS-9cca39c0-9a1f-493b-a9a3-cce2413c43ee from datanode ac87d5c4-909f-434e-85f8-2ad1e4e2f156
2020-04-02 05:07:41,100 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x992cd20ac944f8c5: from storage DS-9cca39c0-9a1f-493b-a9a3-cce2413c43ee node DatanodeRegistration(127.0.0.1:44795, datanodeUuid=ac87d5c4-909f-434e-85f8-2ad1e4e2f156, infoPort=45933, infoSecurePort=0, ipcPort=37738, storageInfo=lv=-57;cid=testClusterID;nsid=1002969445;c=1585804060545), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:41,100 [BP-1326777985-172.17.0.13-1585804060545 heartbeating to localhost/127.0.0.1:44333] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x992cd20ac944f8c5,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:41,100 [BP-1326777985-172.17.0.13-1585804060545 heartbeating to localhost/127.0.0.1:44333] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:41,176 [IPC Server handler 5 on 44333] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:41,177 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:41,180 [IPC Server handler 4 on 44333] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:41,182 [Thread-1119] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=13
2020-04-02 05:07:41,183 [IPC Server handler 2 on 44333] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:41,201 [IPC Server handler 1 on 44333] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:44795 for /user/root/filelocal.dat
2020-04-02 05:07:41,210 [DataXceiver for client DFSClient_NONMAPREDUCE_2014741564_3210 at /127.0.0.1:33364 [Receiving block BP-1326777985-172.17.0.13-1585804060545:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1326777985-172.17.0.13-1585804060545:blk_1073741825_1001 src: /127.0.0.1:33364 dest: /127.0.0.1:44795
2020-04-02 05:07:41,223 [PacketResponder: BP-1326777985-172.17.0.13-1585804060545:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33364, dest: /127.0.0.1:44795, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2014741564_3210, offset: 0, srvID: ac87d5c4-909f-434e-85f8-2ad1e4e2f156, blockid: BP-1326777985-172.17.0.13-1585804060545:blk_1073741825_1001, duration(ns): 9407041
2020-04-02 05:07:41,223 [PacketResponder: BP-1326777985-172.17.0.13-1585804060545:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1326777985-172.17.0.13-1585804060545:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:41,237 [IPC Server handler 3 on 44333] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_2014741564_3210
2020-04-02 05:07:41,248 [IPC Server handler 8 on 44333] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:41,357 [IPC Server handler 7 on 44333] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:41,383 [IPC Server handler 6 on 44333] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:41,398 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:41,398 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:41,399 [Thread-1119] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37738 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:41,399 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3fae3874] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:41,399 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3e19d866] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:41,409 [Thread-1119] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:41,415 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-c8b879dd-10f3-4397-8abc-014292152f36) exiting.
2020-04-02 05:07:41,417 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9cca39c0-9a1f-493b-a9a3-cce2413c43ee) exiting.
2020-04-02 05:07:41,466 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@44f05b05{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:41,467 [Thread-1119] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@32178d4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:41,467 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@141a9748{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:41,467 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61397dda{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:41,473 [Thread-1119] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37738
2020-04-02 05:07:41,478 [IPC Server listener on 37738] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37738
2020-04-02 05:07:41,486 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:41,486 [BP-1326777985-172.17.0.13-1585804060545 heartbeating to localhost/127.0.0.1:44333] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:41,486 [BP-1326777985-172.17.0.13-1585804060545 heartbeating to localhost/127.0.0.1:44333] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1326777985-172.17.0.13-1585804060545 (Datanode Uuid ac87d5c4-909f-434e-85f8-2ad1e4e2f156) service to localhost/127.0.0.1:44333
2020-04-02 05:07:41,486 [BP-1326777985-172.17.0.13-1585804060545 heartbeating to localhost/127.0.0.1:44333] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1326777985-172.17.0.13-1585804060545 (Datanode Uuid ac87d5c4-909f-434e-85f8-2ad1e4e2f156)
2020-04-02 05:07:41,486 [BP-1326777985-172.17.0.13-1585804060545 heartbeating to localhost/127.0.0.1:44333] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1326777985-172.17.0.13-1585804060545
2020-04-02 05:07:41,504 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1326777985-172.17.0.13-1585804060545] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:41,520 [Thread-1119] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:41,520 [Thread-1119] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:41,522 [Thread-1119] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:41,522 [Thread-1119] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:41,538 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1326777985-172.17.0.13-1585804060545] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:41,538 [Thread-1119] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:41,538 [Thread-1119] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:41,538 [Thread-1119] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 44333 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:41,538 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:41,539 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@699f1596] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:41,539 [Thread-1119] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:07:41,541 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@142a36f9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:41,541 [Thread-1119] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 3 Number of syncs: 7 SyncTimes(ms): 1 9 
2020-04-02 05:07:41,542 [Thread-1119] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:41,542 [Thread-1119] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:41,543 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:41,543 [CacheReplicationMonitor(856421951)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:41,557 [Thread-1119] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44333
2020-04-02 05:07:41,562 [IPC Server listener on 44333] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44333
2020-04-02 05:07:41,563 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:41,587 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:41,587 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:41,609 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:41,612 [Thread-1119] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:41,614 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3e799332{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:41,625 [Thread-1119] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@39fc9fb1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:41,626 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b8df730{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:41,626 [Thread-1119] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@566139d6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:41,637 [Thread-1119] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:41,639 [Thread-1119] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:41,639 [Thread-1119] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testLocalReadLegacy
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testLocalReadLegacy
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testLocalReadFallback
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:41,663 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:41,666 [Thread-1208] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:41,666 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:41,666 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:41,666 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:41,666 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:41,667 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:41,667 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:41,667 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:41,667 [Thread-1208] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:41,667 [Thread-1208] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:41,667 [Thread-1208] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:41,668 [Thread-1208] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:41,668 [Thread-1208] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:41
2020-04-02 05:07:41,668 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:41,668 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:41,668 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.9 MB
2020-04-02 05:07:41,668 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:41,674 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:41,674 [Thread-1208] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:41,674 [Thread-1208] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:41,674 [Thread-1208] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:41,674 [Thread-1208] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:41,675 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:41,675 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:41,675 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:41,675 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:41,675 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:41,675 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:41,675 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:41,675 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:41,675 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:41,676 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:41,676 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:41,678 [Thread-1208] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:41,678 [Thread-1208] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:41,678 [Thread-1208] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:41,678 [Thread-1208] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:41,678 [Thread-1208] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:41,678 [Thread-1208] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:41,678 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:41,679 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:41,679 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:41,679 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:41,679 [Thread-1208] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:41,680 [Thread-1208] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:41,680 [Thread-1208] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:41,680 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:41,680 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:41,680 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:41,680 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:41,680 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:41,680 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:41,681 [Thread-1208] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:41,684 [Thread-1208] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:41,686 [Thread-1208] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:41,687 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:41,687 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:41,703 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:41,706 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:41,714 [Thread-1208] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:41,716 [Thread-1208] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:41,721 [Thread-1208] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:41,730 [Thread-1208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:41,730 [Thread-1208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:41,731 [Thread-1208] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:41,732 [Thread-1208] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:41,736 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@275d3439] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:41,737 [Thread-1208] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:41,737 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:41,738 [Thread-1208] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:41,741 [Thread-1208] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:41,741 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:41,743 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:41,743 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:41,743 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:41,743 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:41,744 [Thread-1208] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:41,745 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:41,745 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41910
2020-04-02 05:07:41,745 [Thread-1208] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:41,749 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@86db38d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:41,750 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@564d2664{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:41,754 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@37134857{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:41,755 [Thread-1208] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@d3310cb{HTTP/1.1,[http/1.1]}{localhost:41910}
2020-04-02 05:07:41,755 [Thread-1208] INFO  server.Server (Server.java:doStart(419)) - Started @21542ms
2020-04-02 05:07:41,756 [Thread-1208] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:41,756 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:41,756 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:41,756 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:41,757 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:41,757 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:41,757 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:41,757 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:41,757 [Thread-1208] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:41,757 [Thread-1208] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:41,757 [Thread-1208] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:41,757 [Thread-1208] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:41,758 [Thread-1208] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:41
2020-04-02 05:07:41,758 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:41,758 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:41,758 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.9 MB
2020-04-02 05:07:41,758 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:41,762 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:41,763 [Thread-1208] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:41,763 [Thread-1208] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:41,763 [Thread-1208] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:41,763 [Thread-1208] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:41,763 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:41,763 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:41,763 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:41,763 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:41,763 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:41,764 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:41,764 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:41,764 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:41,764 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:41,764 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:41,764 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:41,766 [Thread-1208] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:41,766 [Thread-1208] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:41,766 [Thread-1208] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:41,766 [Thread-1208] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:41,766 [Thread-1208] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:41,766 [Thread-1208] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:41,767 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:41,767 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:41,767 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:41,767 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:41,767 [Thread-1208] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:41,768 [Thread-1208] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:41,768 [Thread-1208] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:41,768 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:41,768 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:41,768 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:41,768 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:41,768 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:41,768 [Thread-1208] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:41,771 [Thread-1208] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:41,772 [Thread-1208] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:41,774 [Thread-1208] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:41,774 [Thread-1208] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:41,774 [Thread-1208] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:41,774 [Thread-1208] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:41,775 [Thread-1208] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:41,776 [Thread-1208] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:41,776 [Thread-1208] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:41,776 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:41,776 [Thread-1208] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:41,782 [Thread-1208] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:41,782 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 12 msecs
2020-04-02 05:07:41,783 [Thread-1208] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:41,783 [Thread-1208] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:41,784 [Socket Reader #1 for port 43293] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43293
2020-04-02 05:07:41,803 [Thread-1208] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:43293 to access this namenode/service.
2020-04-02 05:07:41,803 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:41,830 [Thread-1208] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:41,831 [Thread-1208] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:41,832 [Thread-1208] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:41,832 [Thread-1208] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:41,832 [Thread-1208] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:41,842 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:41,842 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:41,842 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:41,842 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:41,842 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:41,842 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-04-02 05:07:41,850 [IPC Server listener on 43293] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43293: starting
2020-04-02 05:07:41,851 [Thread-1208] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43293
2020-04-02 05:07:41,852 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:41,852 [Thread-1208] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:41,852 [Thread-1208] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:41,853 [Thread-1208] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43293 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:41,869 [CacheReplicationMonitor(817203566)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:41,870 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:41,874 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:41,875 [Thread-1208] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:41,876 [Thread-1208] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:41,892 [Thread-1208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:41,893 [Thread-1208] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:41,893 [Thread-1208] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:41,893 [Thread-1208] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:41,893 [Thread-1208] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:41,893 [Thread-1208] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:41,893 [Thread-1208] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:41,894 [Thread-1208] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:41,894 [Thread-1208] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40851
2020-04-02 05:07:41,894 [Thread-1208] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:41,894 [Thread-1208] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:41,894 [Thread-1208] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:41,894 [Thread-1208] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:41,894 [Thread-1208] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.40851.sock
2020-04-02 05:07:41,898 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:41,899 [Thread-1208] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:41,900 [Thread-1208] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:41,900 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:41,901 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:41,901 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:41,901 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:41,905 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:41,905 [Thread-1208] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39570
2020-04-02 05:07:41,905 [Thread-1208] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:41,952 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@10518943{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:41,953 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@61c6ee86{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:41,957 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7a69ddfe{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:41,957 [Thread-1208] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@221a417e{HTTP/1.1,[http/1.1]}{localhost:39570}
2020-04-02 05:07:41,957 [Thread-1208] INFO  server.Server (Server.java:doStart(419)) - Started @21744ms
2020-04-02 05:07:41,974 [Thread-1208] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38484
2020-04-02 05:07:41,974 [Thread-1208] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:41,974 [Thread-1208] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:41,975 [Thread-1208] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:41,976 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@16f91699] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:41,976 [Socket Reader #1 for port 33572] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33572
2020-04-02 05:07:41,981 [Thread-1208] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33572
2020-04-02 05:07:41,987 [Thread-1208] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:41,987 [Thread-1208] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:41,988 [Thread-1264] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43293 starting to offer service
2020-04-02 05:07:41,994 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:41,994 [IPC Server listener on 33572] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33572: starting
2020-04-02 05:07:41,996 [Thread-1208] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33572 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:42,017 [IPC Server handler 2 on 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:42,017 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:42,018 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:42,018 [Thread-1264] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43293
2020-04-02 05:07:42,027 [Thread-1264] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:42,029 [Thread-1264] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:42,029 [Thread-1264] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1142418265. Formatting...
2020-04-02 05:07:42,029 [Thread-1264] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-20b840ba-9650-43c2-b613-c242f8c40677 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:42,036 [Thread-1264] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:42,036 [Thread-1264] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1142418265. Formatting...
2020-04-02 05:07:42,036 [Thread-1264] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f86c21fa-b248-4b53-abe3-a2aea2a4a316 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:42,049 [Thread-1264] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:42,049 [Thread-1264] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:42,049 [Thread-1264] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-223911935-172.17.0.13-1585804061681 is not formatted. Formatting ...
2020-04-02 05:07:42,049 [Thread-1264] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-223911935-172.17.0.13-1585804061681 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-223911935-172.17.0.13-1585804061681/current
2020-04-02 05:07:42,060 [Thread-1264] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:42,061 [Thread-1264] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:42,061 [Thread-1264] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-223911935-172.17.0.13-1585804061681 is not formatted. Formatting ...
2020-04-02 05:07:42,061 [Thread-1264] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-223911935-172.17.0.13-1585804061681 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-223911935-172.17.0.13-1585804061681/current
2020-04-02 05:07:42,070 [Thread-1264] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1142418265;bpid=BP-223911935-172.17.0.13-1585804061681;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1142418265;c=1585804061681;bpid=BP-223911935-172.17.0.13-1585804061681;dnuuid=null
2020-04-02 05:07:42,079 [Thread-1264] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 8961c6bd-5e00-46d3-8054-ded912aa4503
2020-04-02 05:07:42,086 [Thread-1264] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-20b840ba-9650-43c2-b613-c242f8c40677
2020-04-02 05:07:42,086 [Thread-1264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:42,092 [Thread-1264] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f86c21fa-b248-4b53-abe3-a2aea2a4a316
2020-04-02 05:07:42,092 [Thread-1264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:42,094 [Thread-1264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:42,095 [Thread-1264] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:42,096 [Thread-1264] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:42,096 [Thread-1264] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:42,096 [Thread-1264] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:42,099 [Thread-1264] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:42,100 [Thread-1280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-223911935-172.17.0.13-1585804061681 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:42,100 [Thread-1281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-223911935-172.17.0.13-1585804061681 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:42,121 [IPC Server handler 1 on 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:42,122 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:42,122 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:42,122 [Thread-1281] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-223911935-172.17.0.13-1585804061681 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 22ms
2020-04-02 05:07:42,124 [Thread-1280] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-223911935-172.17.0.13-1585804061681 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 24ms
2020-04-02 05:07:42,125 [Thread-1264] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-223911935-172.17.0.13-1585804061681: 26ms
2020-04-02 05:07:42,126 [Thread-1284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-223911935-172.17.0.13-1585804061681 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:42,126 [Thread-1284] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-223911935-172.17.0.13-1585804061681/current/replicas doesn't exist 
2020-04-02 05:07:42,127 [Thread-1284] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-223911935-172.17.0.13-1585804061681 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:07:42,131 [Thread-1285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-223911935-172.17.0.13-1585804061681 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:42,131 [Thread-1285] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-223911935-172.17.0.13-1585804061681/current/replicas doesn't exist 
2020-04-02 05:07:42,132 [Thread-1285] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-223911935-172.17.0.13-1585804061681 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:42,133 [Thread-1264] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-223911935-172.17.0.13-1585804061681: 8ms
2020-04-02 05:07:42,134 [Thread-1264] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:11 AM with interval of 21600000ms
2020-04-02 05:07:42,136 [BP-223911935-172.17.0.13-1585804061681 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-223911935-172.17.0.13-1585804061681 (Datanode Uuid 8961c6bd-5e00-46d3-8054-ded912aa4503) service to localhost/127.0.0.1:43293 beginning handshake with NN
2020-04-02 05:07:42,137 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-223911935-172.17.0.13-1585804061681 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:42,138 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-20b840ba-9650-43c2-b613-c242f8c40677): finished scanning block pool BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:42,138 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-20b840ba-9650-43c2-b613-c242f8c40677): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:07:42,139 [IPC Server handler 3 on 43293] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40851, datanodeUuid=8961c6bd-5e00-46d3-8054-ded912aa4503, infoPort=38484, infoSecurePort=0, ipcPort=33572, storageInfo=lv=-57;cid=testClusterID;nsid=1142418265;c=1585804061681) storage 8961c6bd-5e00-46d3-8054-ded912aa4503
2020-04-02 05:07:42,139 [IPC Server handler 3 on 43293] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40851
2020-04-02 05:07:42,139 [IPC Server handler 3 on 43293] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 8961c6bd-5e00-46d3-8054-ded912aa4503 (127.0.0.1:40851).
2020-04-02 05:07:42,143 [BP-223911935-172.17.0.13-1585804061681 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-223911935-172.17.0.13-1585804061681 (Datanode Uuid 8961c6bd-5e00-46d3-8054-ded912aa4503) service to localhost/127.0.0.1:43293 successfully registered with NN
2020-04-02 05:07:42,144 [BP-223911935-172.17.0.13-1585804061681 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43293 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:42,144 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-223911935-172.17.0.13-1585804061681 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:42,145 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f86c21fa-b248-4b53-abe3-a2aea2a4a316): finished scanning block pool BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:42,145 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f86c21fa-b248-4b53-abe3-a2aea2a4a316): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-04-02 05:07:42,163 [IPC Server handler 4 on 43293] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-20b840ba-9650-43c2-b613-c242f8c40677 for DN 127.0.0.1:40851
2020-04-02 05:07:42,163 [IPC Server handler 4 on 43293] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f86c21fa-b248-4b53-abe3-a2aea2a4a316 for DN 127.0.0.1:40851
2020-04-02 05:07:42,175 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1038f8351ab5d6ea: Processing first storage report for DS-20b840ba-9650-43c2-b613-c242f8c40677 from datanode 8961c6bd-5e00-46d3-8054-ded912aa4503
2020-04-02 05:07:42,176 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1038f8351ab5d6ea: from storage DS-20b840ba-9650-43c2-b613-c242f8c40677 node DatanodeRegistration(127.0.0.1:40851, datanodeUuid=8961c6bd-5e00-46d3-8054-ded912aa4503, infoPort=38484, infoSecurePort=0, ipcPort=33572, storageInfo=lv=-57;cid=testClusterID;nsid=1142418265;c=1585804061681), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:42,179 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1038f8351ab5d6ea: Processing first storage report for DS-f86c21fa-b248-4b53-abe3-a2aea2a4a316 from datanode 8961c6bd-5e00-46d3-8054-ded912aa4503
2020-04-02 05:07:42,179 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1038f8351ab5d6ea: from storage DS-f86c21fa-b248-4b53-abe3-a2aea2a4a316 node DatanodeRegistration(127.0.0.1:40851, datanodeUuid=8961c6bd-5e00-46d3-8054-ded912aa4503, infoPort=38484, infoSecurePort=0, ipcPort=33572, storageInfo=lv=-57;cid=testClusterID;nsid=1142418265;c=1585804061681), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:42,180 [BP-223911935-172.17.0.13-1585804061681 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1038f8351ab5d6ea,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:42,180 [BP-223911935-172.17.0.13-1585804061681 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:42,228 [IPC Server handler 7 on 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:42,232 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:42,238 [IPC Server handler 5 on 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:42,239 [Thread-1208] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=13
2020-04-02 05:07:42,241 [IPC Server handler 8 on 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:42,254 [IPC Server handler 9 on 43293] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40851 for /user/root/filelocal.dat
2020-04-02 05:07:42,258 [DataXceiver for client DFSClient_NONMAPREDUCE_1258842142_3485 at /127.0.0.1:40864 [Receiving block BP-223911935-172.17.0.13-1585804061681:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-223911935-172.17.0.13-1585804061681:blk_1073741825_1001 src: /127.0.0.1:40864 dest: /127.0.0.1:40851
2020-04-02 05:07:42,281 [PacketResponder: BP-223911935-172.17.0.13-1585804061681:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40864, dest: /127.0.0.1:40851, bytes: 13, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1258842142_3485, offset: 0, srvID: 8961c6bd-5e00-46d3-8054-ded912aa4503, blockid: BP-223911935-172.17.0.13-1585804061681:blk_1073741825_1001, duration(ns): 21051878
2020-04-02 05:07:42,281 [PacketResponder: BP-223911935-172.17.0.13-1585804061681:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-223911935-172.17.0.13-1585804061681:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:42,286 [IPC Server handler 2 on 43293] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/filelocal.dat
2020-04-02 05:07:42,697 [IPC Server handler 3 on 43293] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_1258842142_3485
2020-04-02 05:07:42,705 [IPC Server handler 4 on 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=notallowed (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:42,724 [IPC Server handler 0 on 33572] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 0 on 33572, call Call#278 Retry#0 org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.getBlockLocalPathInfo from 127.0.0.1:58514
org.apache.hadoop.security.AccessControlException: Can't continue with getBlockLocalPathInfo() authorization. The user notallowed is not configured in dfs.block.local-path-access.user
	at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1891)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1906)
	at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:14646)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:42,731 [Thread-1208] WARN  impl.BlockReaderFactory (BlockReaderFactory.java:getLegacyBlockReaderLocal(459)) - BlockReaderFactory(fileName=/user/root/filelocal.dat, block=BP-223911935-172.17.0.13-1585804061681:blk_1073741825_1001): error creating legacy BlockReaderLocal.  Disabling legacy local reads.
org.apache.hadoop.security.AccessControlException: Can't continue with getBlockLocalPathInfo() authorization. The user notallowed is not configured in dfs.block.local-path-access.user
	at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1891)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1906)
	at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:14646)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:88)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getLegacyBlockReaderLocal(BlockReaderFactory.java:445)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.build(BlockReaderFactory.java:352)
	at org.apache.hadoop.hdfs.DFSInputStream.getBlockReader(DFSInputStream.java:643)
	at org.apache.hadoop.hdfs.DFSInputStream.actualGetFromOneDataNode(DFSInputStream.java:1045)
	at org.apache.hadoop.hdfs.DFSInputStream.fetchBlockByteRange(DFSInputStream.java:997)
	at org.apache.hadoop.hdfs.DFSInputStream.pread(DFSInputStream.java:1353)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:1317)
	at org.apache.hadoop.fs.FSInputStream.readFully(FSInputStream.java:121)
	at org.apache.hadoop.fs.FSDataInputStream.readFully(FSDataInputStream.java:120)
	at org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead.checkFileContent(TestShortCircuitLocalRead.java:146)
	at org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead.doTestShortCircuitReadImpl(TestShortCircuitLocalRead.java:289)
	at org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead.doTestShortCircuitReadLegacy(TestShortCircuitLocalRead.java:238)
	at org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead.testLocalReadFallback(TestShortCircuitLocalRead.java:330)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
Caused by: org.apache.hadoop.ipc.RemoteException(org.apache.hadoop.security.AccessControlException): Can't continue with getBlockLocalPathInfo() authorization. The user notallowed is not configured in dfs.block.local-path-access.user
	at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1891)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1906)
	at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:14646)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)

	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1511)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy30.getBlockLocalPathInfo(Unknown Source)
	at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolTranslatorPB.java:236)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy.getBlockPathInfo(BlockReaderLocalLegacy.java:284)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderLocalLegacy.newBlockReader(BlockReaderLocalLegacy.java:204)
	at org.apache.hadoop.hdfs.client.impl.BlockReaderFactory.getLegacyBlockReaderLocal(BlockReaderFactory.java:441)
	... 21 more
2020-04-02 05:07:42,741 [IPC Server handler 7 on 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=notallowed (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:42,755 [IPC Server handler 5 on 43293] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=notallowed (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:42,759 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:42,759 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:42,759 [Thread-1208] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33572 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:42,759 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5620f1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:42,759 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@10eb9e39] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:42,769 [Thread-1208] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:42,771 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-20b840ba-9650-43c2-b613-c242f8c40677) exiting.
2020-04-02 05:07:42,771 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-f86c21fa-b248-4b53-abe3-a2aea2a4a316) exiting.
2020-04-02 05:07:42,799 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7a69ddfe{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:42,799 [Thread-1208] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@221a417e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:42,800 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@61c6ee86{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:42,801 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@10518943{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:42,810 [Thread-1208] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33572
2020-04-02 05:07:42,811 [IPC Server listener on 33572] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33572
2020-04-02 05:07:42,816 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:42,816 [BP-223911935-172.17.0.13-1585804061681 heartbeating to localhost/127.0.0.1:43293] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:42,816 [BP-223911935-172.17.0.13-1585804061681 heartbeating to localhost/127.0.0.1:43293] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-223911935-172.17.0.13-1585804061681 (Datanode Uuid 8961c6bd-5e00-46d3-8054-ded912aa4503) service to localhost/127.0.0.1:43293
2020-04-02 05:07:42,816 [BP-223911935-172.17.0.13-1585804061681 heartbeating to localhost/127.0.0.1:43293] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-223911935-172.17.0.13-1585804061681 (Datanode Uuid 8961c6bd-5e00-46d3-8054-ded912aa4503)
2020-04-02 05:07:42,816 [BP-223911935-172.17.0.13-1585804061681 heartbeating to localhost/127.0.0.1:43293] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-223911935-172.17.0.13-1585804061681
2020-04-02 05:07:42,828 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-223911935-172.17.0.13-1585804061681] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:42,845 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-223911935-172.17.0.13-1585804061681] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:42,847 [Thread-1208] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:42,848 [Thread-1208] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:42,849 [Thread-1208] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:42,849 [Thread-1208] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:42,851 [Thread-1208] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:42,852 [Thread-1208] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:42,852 [Thread-1208] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43293 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:42,852 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:42,854 [Thread-1208] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:07:42,854 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3bb4c21d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:42,854 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@37218ec9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:42,854 [Thread-1208] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 3 Number of syncs: 7 SyncTimes(ms): 1 1 
2020-04-02 05:07:42,855 [Thread-1208] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:42,855 [Thread-1208] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:07:42,856 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:42,856 [CacheReplicationMonitor(817203566)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:42,861 [Thread-1208] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43293
2020-04-02 05:07:42,866 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:42,866 [IPC Server listener on 43293] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43293
2020-04-02 05:07:42,866 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:42,866 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:42,882 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:42,882 [Thread-1208] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:42,884 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@37134857{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:42,894 [Thread-1208] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@d3310cb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:42,894 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@564d2664{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:42,896 [Thread-1208] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@86db38d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:42,922 [Thread-1208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:42,927 [Thread-1208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:42,928 [Thread-1208] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testLocalReadFallback
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testLocalReadFallback
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testFileLocalReadChecksum
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:42,943 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:42,946 [Thread-1301] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:42,947 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:42,947 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:42,947 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:42,947 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:42,947 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:42,947 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:42,947 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:42,948 [Thread-1301] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:42,948 [Thread-1301] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:42,948 [Thread-1301] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:42,948 [Thread-1301] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:42,948 [Thread-1301] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:42
2020-04-02 05:07:42,948 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:42,949 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:42,949 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.9 MB
2020-04-02 05:07:42,949 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:42,953 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:42,954 [Thread-1301] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:42,954 [Thread-1301] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:42,954 [Thread-1301] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:42,954 [Thread-1301] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:42,954 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:42,954 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:42,954 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:42,954 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:42,955 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:42,955 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:42,955 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:42,955 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:42,955 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:42,955 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:42,955 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:42,957 [Thread-1301] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:42,957 [Thread-1301] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:42,957 [Thread-1301] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:42,957 [Thread-1301] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:42,957 [Thread-1301] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:42,957 [Thread-1301] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:42,958 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:42,958 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:42,958 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:42,958 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:42,959 [Thread-1301] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:42,959 [Thread-1301] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:42,959 [Thread-1301] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:42,959 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:42,959 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:42,959 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:42,959 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:42,960 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:42,960 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:42,961 [Thread-1301] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:42,966 [Thread-1301] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:42,974 [Thread-1301] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:42,975 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:42,975 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:42,980 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 393 bytes saved in 0 seconds .
2020-04-02 05:07:42,983 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 393 bytes saved in 0 seconds .
2020-04-02 05:07:42,985 [Thread-1301] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:42,987 [Thread-1301] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:42,991 [Thread-1301] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:42,992 [Thread-1301] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:42,992 [Thread-1301] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:42,993 [Thread-1301] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:42,994 [Thread-1301] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:42,999 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d852c4f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:42,999 [Thread-1301] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:42,999 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:43,001 [Thread-1301] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:43,010 [Thread-1301] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:43,010 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:43,011 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:43,012 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:43,012 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:43,012 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:43,013 [Thread-1301] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:43,014 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:43,014 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35272
2020-04-02 05:07:43,014 [Thread-1301] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:43,025 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2b285199{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:43,026 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3252f9ae{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:43,030 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1d8456eb{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:43,031 [Thread-1301] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4f9da1c6{HTTP/1.1,[http/1.1]}{localhost:35272}
2020-04-02 05:07:43,031 [Thread-1301] INFO  server.Server (Server.java:doStart(419)) - Started @22818ms
2020-04-02 05:07:43,032 [Thread-1301] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:43,032 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:43,032 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:43,033 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:43,033 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:43,033 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:43,033 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:43,033 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:43,034 [Thread-1301] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:43,034 [Thread-1301] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:43,034 [Thread-1301] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:43,034 [Thread-1301] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:43,034 [Thread-1301] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:43
2020-04-02 05:07:43,035 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:43,035 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:43,035 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.9 MB
2020-04-02 05:07:43,035 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:43,040 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:43,041 [Thread-1301] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:43,041 [Thread-1301] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:43,041 [Thread-1301] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:43,041 [Thread-1301] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:43,041 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:43,041 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:43,041 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:43,042 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:43,048 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:43,048 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:43,048 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:43,048 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:43,048 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:43,048 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:43,049 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:43,057 [Thread-1301] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:43,057 [Thread-1301] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:43,057 [Thread-1301] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:43,057 [Thread-1301] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:43,057 [Thread-1301] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:43,057 [Thread-1301] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:43,057 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:43,058 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:43,058 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:43,058 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:43,058 [Thread-1301] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:43,059 [Thread-1301] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:43,059 [Thread-1301] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:43,059 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:43,059 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:43,059 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:43,059 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:43,059 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:43,059 [Thread-1301] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:43,065 [Thread-1301] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:43,067 [Thread-1301] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:43,068 [Thread-1301] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:43,068 [Thread-1301] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:43,069 [Thread-1301] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:43,069 [Thread-1301] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:43,072 [Thread-1301] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:43,072 [Thread-1301] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:43,072 [Thread-1301] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:43,073 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:43,078 [Thread-1301] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:43,088 [Thread-1301] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:43,088 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 28 msecs
2020-04-02 05:07:43,089 [Thread-1301] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:43,089 [Thread-1301] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:43,091 [Socket Reader #1 for port 34623] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34623
2020-04-02 05:07:43,095 [Thread-1301] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:34623 to access this namenode/service.
2020-04-02 05:07:43,096 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:43,124 [Thread-1301] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:43,125 [Thread-1301] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:43,126 [Thread-1301] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:43,126 [Thread-1301] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:43,126 [Thread-1301] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:43,131 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:43,131 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:43,131 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:43,131 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:43,131 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:43,131 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-04-02 05:07:43,133 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:43,133 [IPC Server listener on 34623] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34623: starting
2020-04-02 05:07:43,135 [Thread-1301] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:34623
2020-04-02 05:07:43,135 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:43,136 [Thread-1301] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:43,136 [Thread-1301] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:43,137 [Thread-1301] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 34623 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:43,140 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:43,141 [Thread-1301] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:43,141 [Thread-1301] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:43,142 [Thread-1301] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:43,142 [Thread-1301] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:43,143 [Thread-1301] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:43,143 [Thread-1301] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:43,143 [Thread-1301] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:43,143 [Thread-1301] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:43,143 [Thread-1301] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:43,144 [Thread-1301] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:43,144 [Thread-1301] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38619
2020-04-02 05:07:43,144 [Thread-1301] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:43,144 [Thread-1301] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:43,145 [Thread-1301] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:43,145 [Thread-1301] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:43,145 [Thread-1301] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38619.sock
2020-04-02 05:07:43,155 [CacheReplicationMonitor(2046938596)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:43,167 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:43,169 [Thread-1301] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:43,172 [Thread-1301] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:43,172 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:43,173 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:43,174 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:43,174 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:43,174 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:43,176 [Thread-1301] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36283
2020-04-02 05:07:43,176 [Thread-1301] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:43,178 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@63d8b9f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:43,178 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3830904f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:43,181 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70f8dca5{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:43,182 [Thread-1301] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@60b43e6e{HTTP/1.1,[http/1.1]}{localhost:36283}
2020-04-02 05:07:43,182 [Thread-1301] INFO  server.Server (Server.java:doStart(419)) - Started @22969ms
2020-04-02 05:07:43,195 [Thread-1301] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36096
2020-04-02 05:07:43,196 [Thread-1301] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:43,196 [Thread-1301] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:43,196 [Thread-1301] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:43,197 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5bf9901d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:43,197 [Socket Reader #1 for port 34117] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34117
2020-04-02 05:07:43,243 [Thread-1301] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34117
2020-04-02 05:07:43,248 [Thread-1301] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:43,248 [Thread-1301] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:43,249 [Thread-1357] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34623 starting to offer service
2020-04-02 05:07:43,258 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:43,258 [IPC Server listener on 34117] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34117: starting
2020-04-02 05:07:43,306 [Thread-1301] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34117 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:43,309 [Thread-1357] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34623
2020-04-02 05:07:43,311 [Thread-1357] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:43,329 [IPC Server handler 0 on 34623] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:43,330 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:43,330 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:43,330 [Thread-1357] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:43,330 [Thread-1357] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 27332263. Formatting...
2020-04-02 05:07:43,331 [Thread-1357] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-70998178-c488-4aff-81fe-17568219546b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:43,334 [Thread-1357] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:43,335 [Thread-1357] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 27332263. Formatting...
2020-04-02 05:07:43,335 [Thread-1357] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9bf178cd-8bee-4166-a3ed-7d6b3d0243b8 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:43,346 [Thread-1357] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:43,346 [Thread-1357] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:43,346 [Thread-1357] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-528199344-172.17.0.13-1585804062961 is not formatted. Formatting ...
2020-04-02 05:07:43,346 [Thread-1357] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-528199344-172.17.0.13-1585804062961 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-528199344-172.17.0.13-1585804062961/current
2020-04-02 05:07:43,361 [Thread-1357] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:43,362 [Thread-1357] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:43,362 [Thread-1357] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-528199344-172.17.0.13-1585804062961 is not formatted. Formatting ...
2020-04-02 05:07:43,362 [Thread-1357] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-528199344-172.17.0.13-1585804062961 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-528199344-172.17.0.13-1585804062961/current
2020-04-02 05:07:43,364 [Thread-1357] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=27332263;bpid=BP-528199344-172.17.0.13-1585804062961;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=27332263;c=1585804062961;bpid=BP-528199344-172.17.0.13-1585804062961;dnuuid=null
2020-04-02 05:07:43,365 [Thread-1357] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 859508f5-340f-4ced-83a4-503c9093c756
2020-04-02 05:07:43,367 [Thread-1357] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-70998178-c488-4aff-81fe-17568219546b
2020-04-02 05:07:43,367 [Thread-1357] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:43,377 [Thread-1357] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9bf178cd-8bee-4166-a3ed-7d6b3d0243b8
2020-04-02 05:07:43,396 [Thread-1357] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:43,397 [Thread-1357] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:43,398 [Thread-1357] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:43,398 [Thread-1357] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:43,398 [Thread-1357] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:43,400 [Thread-1357] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:43,400 [Thread-1357] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:43,401 [Thread-1373] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-528199344-172.17.0.13-1585804062961 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:43,401 [Thread-1374] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-528199344-172.17.0.13-1585804062961 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:43,421 [Thread-1374] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-528199344-172.17.0.13-1585804062961 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 20ms
2020-04-02 05:07:43,426 [Thread-1373] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-528199344-172.17.0.13-1585804062961 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 25ms
2020-04-02 05:07:43,427 [Thread-1357] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-528199344-172.17.0.13-1585804062961: 26ms
2020-04-02 05:07:43,427 [Thread-1378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-528199344-172.17.0.13-1585804062961 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:43,427 [Thread-1377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-528199344-172.17.0.13-1585804062961 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:43,427 [Thread-1378] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-528199344-172.17.0.13-1585804062961/current/replicas doesn't exist 
2020-04-02 05:07:43,427 [Thread-1377] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-528199344-172.17.0.13-1585804062961/current/replicas doesn't exist 
2020-04-02 05:07:43,427 [Thread-1378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-528199344-172.17.0.13-1585804062961 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:43,427 [Thread-1377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-528199344-172.17.0.13-1585804062961 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:07:43,430 [Thread-1357] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-528199344-172.17.0.13-1585804062961: 3ms
2020-04-02 05:07:43,430 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-528199344-172.17.0.13-1585804062961 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:43,431 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9bf178cd-8bee-4166-a3ed-7d6b3d0243b8): finished scanning block pool BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:43,431 [Thread-1357] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:01 AM with interval of 21600000ms
2020-04-02 05:07:43,431 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9bf178cd-8bee-4166-a3ed-7d6b3d0243b8): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:07:43,433 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-528199344-172.17.0.13-1585804062961 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:43,433 [BP-528199344-172.17.0.13-1585804062961 heartbeating to localhost/127.0.0.1:34623] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-528199344-172.17.0.13-1585804062961 (Datanode Uuid 859508f5-340f-4ced-83a4-503c9093c756) service to localhost/127.0.0.1:34623 beginning handshake with NN
2020-04-02 05:07:43,433 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-70998178-c488-4aff-81fe-17568219546b): finished scanning block pool BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:43,437 [IPC Server handler 2 on 34623] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:43,437 [IPC Server handler 4 on 34623] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38619, datanodeUuid=859508f5-340f-4ced-83a4-503c9093c756, infoPort=36096, infoSecurePort=0, ipcPort=34117, storageInfo=lv=-57;cid=testClusterID;nsid=27332263;c=1585804062961) storage 859508f5-340f-4ced-83a4-503c9093c756
2020-04-02 05:07:43,437 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:43,437 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:43,437 [IPC Server handler 4 on 34623] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38619
2020-04-02 05:07:43,438 [IPC Server handler 4 on 34623] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 859508f5-340f-4ced-83a4-503c9093c756 (127.0.0.1:38619).
2020-04-02 05:07:43,441 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-70998178-c488-4aff-81fe-17568219546b): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-04-02 05:07:43,442 [BP-528199344-172.17.0.13-1585804062961 heartbeating to localhost/127.0.0.1:34623] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-528199344-172.17.0.13-1585804062961 (Datanode Uuid 859508f5-340f-4ced-83a4-503c9093c756) service to localhost/127.0.0.1:34623 successfully registered with NN
2020-04-02 05:07:43,443 [BP-528199344-172.17.0.13-1585804062961 heartbeating to localhost/127.0.0.1:34623] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34623 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:43,448 [IPC Server handler 5 on 34623] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-70998178-c488-4aff-81fe-17568219546b for DN 127.0.0.1:38619
2020-04-02 05:07:43,449 [IPC Server handler 5 on 34623] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9bf178cd-8bee-4166-a3ed-7d6b3d0243b8 for DN 127.0.0.1:38619
2020-04-02 05:07:43,453 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1ef047582800f50a: Processing first storage report for DS-70998178-c488-4aff-81fe-17568219546b from datanode 859508f5-340f-4ced-83a4-503c9093c756
2020-04-02 05:07:43,453 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1ef047582800f50a: from storage DS-70998178-c488-4aff-81fe-17568219546b node DatanodeRegistration(127.0.0.1:38619, datanodeUuid=859508f5-340f-4ced-83a4-503c9093c756, infoPort=36096, infoSecurePort=0, ipcPort=34117, storageInfo=lv=-57;cid=testClusterID;nsid=27332263;c=1585804062961), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:43,454 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1ef047582800f50a: Processing first storage report for DS-9bf178cd-8bee-4166-a3ed-7d6b3d0243b8 from datanode 859508f5-340f-4ced-83a4-503c9093c756
2020-04-02 05:07:43,454 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1ef047582800f50a: from storage DS-9bf178cd-8bee-4166-a3ed-7d6b3d0243b8 node DatanodeRegistration(127.0.0.1:38619, datanodeUuid=859508f5-340f-4ced-83a4-503c9093c756, infoPort=36096, infoSecurePort=0, ipcPort=34117, storageInfo=lv=-57;cid=testClusterID;nsid=27332263;c=1585804062961), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:43,454 [BP-528199344-172.17.0.13-1585804062961 heartbeating to localhost/127.0.0.1:34623] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1ef047582800f50a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:43,454 [BP-528199344-172.17.0.13-1585804062961 heartbeating to localhost/127.0.0.1:34623] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:43,542 [IPC Server handler 7 on 34623] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:43,544 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:43,549 [IPC Server handler 8 on 34623] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/	dst=null	perm=null	proto=rpc
2020-04-02 05:07:43,554 [Thread-1301] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:randomBytes(79)) - seed=3735928559, size=15460
2020-04-02 05:07:43,563 [IPC Server handler 9 on 34623] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/user/root/filelocal.dat	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:43,574 [IPC Server handler 3 on 34623] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:38619 for /user/root/filelocal.dat
2020-04-02 05:07:43,586 [DataXceiver for client DFSClient_NONMAPREDUCE_754338288_3764 at /127.0.0.1:56314 [Receiving block BP-528199344-172.17.0.13-1585804062961:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-528199344-172.17.0.13-1585804062961:blk_1073741825_1001 src: /127.0.0.1:56314 dest: /127.0.0.1:38619
2020-04-02 05:07:43,600 [PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56314, dest: /127.0.0.1:38619, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_754338288_3764, offset: 0, srvID: 859508f5-340f-4ced-83a4-503c9093c756, blockid: BP-528199344-172.17.0.13-1585804062961:blk_1073741825_1001, duration(ns): 12335083
2020-04-02 05:07:43,600 [PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:43,611 [IPC Server handler 2 on 34623] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:38619 for /user/root/filelocal.dat
2020-04-02 05:07:43,616 [DataXceiver for client DFSClient_NONMAPREDUCE_754338288_3764 at /127.0.0.1:56328 [Receiving block BP-528199344-172.17.0.13-1585804062961:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-528199344-172.17.0.13-1585804062961:blk_1073741826_1002 src: /127.0.0.1:56328 dest: /127.0.0.1:38619
2020-04-02 05:07:43,621 [PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56328, dest: /127.0.0.1:38619, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_754338288_3764, offset: 0, srvID: 859508f5-340f-4ced-83a4-503c9093c756, blockid: BP-528199344-172.17.0.13-1585804062961:blk_1073741826_1002, duration(ns): 3657231
2020-04-02 05:07:43,621 [PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:43,623 [IPC Server handler 5 on 34623] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:38619 for /user/root/filelocal.dat
2020-04-02 05:07:43,626 [DataXceiver for client DFSClient_NONMAPREDUCE_754338288_3764 at /127.0.0.1:56330 [Receiving block BP-528199344-172.17.0.13-1585804062961:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-528199344-172.17.0.13-1585804062961:blk_1073741827_1003 src: /127.0.0.1:56330 dest: /127.0.0.1:38619
2020-04-02 05:07:43,630 [PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56330, dest: /127.0.0.1:38619, bytes: 5120, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_754338288_3764, offset: 0, srvID: 859508f5-340f-4ced-83a4-503c9093c756, blockid: BP-528199344-172.17.0.13-1585804062961:blk_1073741827_1003, duration(ns): 1717363
2020-04-02 05:07:43,630 [PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:43,632 [IPC Server handler 7 on 34623] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:38619 for /user/root/filelocal.dat
2020-04-02 05:07:43,634 [DataXceiver for client DFSClient_NONMAPREDUCE_754338288_3764 at /127.0.0.1:56346 [Receiving block BP-528199344-172.17.0.13-1585804062961:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-528199344-172.17.0.13-1585804062961:blk_1073741828_1004 src: /127.0.0.1:56346 dest: /127.0.0.1:38619
2020-04-02 05:07:43,638 [PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56346, dest: /127.0.0.1:38619, bytes: 100, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_754338288_3764, offset: 0, srvID: 859508f5-340f-4ced-83a4-503c9093c756, blockid: BP-528199344-172.17.0.13-1585804062961:blk_1073741828_1004, duration(ns): 1990280
2020-04-02 05:07:43,638 [PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-528199344-172.17.0.13-1585804062961:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:43,639 [IPC Server handler 8 on 34623] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741828_1004 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /user/root/filelocal.dat
2020-04-02 05:07:44,041 [IPC Server handler 3 on 34623] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /user/root/filelocal.dat is closed by DFSClient_NONMAPREDUCE_754338288_3764
2020-04-02 05:07:44,045 [IPC Server handler 1 on 34623] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:44,048 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38619.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-1615194571_3764, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: e41f7a327154ac4ab7e861383d174b90, srvID: 859508f5-340f-4ced-83a4-503c9093c756, success: true
2020-04-02 05:07:44,049 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38619.sock [Passing file descriptors for block BP-528199344-172.17.0.13-1585804062961:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 859508f5-340f-4ced-83a4-503c9093c756, success: true
2020-04-02 05:07:44,051 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38619.sock [Passing file descriptors for block BP-528199344-172.17.0.13-1585804062961:blk_1073741826_1002]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741826, srvID: 859508f5-340f-4ced-83a4-503c9093c756, success: true
2020-04-02 05:07:44,053 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38619.sock [Passing file descriptors for block BP-528199344-172.17.0.13-1585804062961:blk_1073741827_1003]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741827, srvID: 859508f5-340f-4ced-83a4-503c9093c756, success: true
2020-04-02 05:07:44,055 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/TestShortCircuitLocalRead.38619.sock [Passing file descriptors for block BP-528199344-172.17.0.13-1585804062961:blk_1073741828_1004]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741828, srvID: 859508f5-340f-4ced-83a4-503c9093c756, success: true
2020-04-02 05:07:44,058 [IPC Server handler 0 on 34623] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:44,064 [IPC Server handler 2 on 34623] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/user/root/filelocal.dat	dst=null	perm=null	proto=rpc
2020-04-02 05:07:44,068 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:44,068 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:44,068 [Thread-1301] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34117 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:44,068 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@51f1b4a8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:44,070 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@bed2dfe] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:44,079 [Thread-1301] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:44,080 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-9bf178cd-8bee-4166-a3ed-7d6b3d0243b8) exiting.
2020-04-02 05:07:44,080 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-70998178-c488-4aff-81fe-17568219546b) exiting.
2020-04-02 05:07:44,111 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70f8dca5{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:44,112 [Thread-1301] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@60b43e6e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:44,112 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3830904f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:44,113 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@63d8b9f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:44,114 [Thread-1301] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34117
2020-04-02 05:07:44,127 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:44,127 [IPC Server listener on 34117] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34117
2020-04-02 05:07:44,129 [BP-528199344-172.17.0.13-1585804062961 heartbeating to localhost/127.0.0.1:34623] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:44,130 [BP-528199344-172.17.0.13-1585804062961 heartbeating to localhost/127.0.0.1:34623] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-528199344-172.17.0.13-1585804062961 (Datanode Uuid 859508f5-340f-4ced-83a4-503c9093c756) service to localhost/127.0.0.1:34623
2020-04-02 05:07:44,130 [BP-528199344-172.17.0.13-1585804062961 heartbeating to localhost/127.0.0.1:34623] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-528199344-172.17.0.13-1585804062961 (Datanode Uuid 859508f5-340f-4ced-83a4-503c9093c756)
2020-04-02 05:07:44,130 [BP-528199344-172.17.0.13-1585804062961 heartbeating to localhost/127.0.0.1:34623] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-528199344-172.17.0.13-1585804062961
2020-04-02 05:07:44,141 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-528199344-172.17.0.13-1585804062961] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:44,149 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-528199344-172.17.0.13-1585804062961] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:44,152 [Thread-1301] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:44,152 [Thread-1301] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:44,154 [Thread-1301] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:44,154 [Thread-1301] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:44,163 [Thread-1301] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:44,163 [Thread-1301] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:44,163 [Thread-1301] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 34623 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:44,163 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:44,164 [Thread-1301] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 17
2020-04-02 05:07:44,164 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@18b0259b] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:44,164 [Thread-1301] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 18 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 8 Number of syncs: 11 SyncTimes(ms): 1 1 
2020-04-02 05:07:44,165 [Thread-1301] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:44,165 [Thread-1301] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000018
2020-04-02 05:07:44,165 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:44,166 [CacheReplicationMonitor(2046938596)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:44,167 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5494084a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:44,176 [Thread-1301] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34623
2020-04-02 05:07:44,191 [IPC Server listener on 34623] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34623
2020-04-02 05:07:44,210 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:44,211 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:44,211 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:44,220 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:44,221 [Thread-1301] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:44,222 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1d8456eb{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:44,231 [Thread-1301] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4f9da1c6{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:44,231 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3252f9ae{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:44,231 [Thread-1301] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2b285199{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:44,232 [Thread-1301] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:44,235 [Thread-1301] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:44,235 [Thread-1301] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testFileLocalReadChecksum
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testFileLocalReadChecksum
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testHandleTruncatedBlockFile
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:44,256 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:44,263 [Thread-1404] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:44,264 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:44,264 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:44,264 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:44,264 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:44,265 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:44,265 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:44,265 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:44,265 [Thread-1404] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:44,265 [Thread-1404] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:44,265 [Thread-1404] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:44,270 [Thread-1404] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:44,270 [Thread-1404] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:44
2020-04-02 05:07:44,270 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:44,270 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:44,271 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.9 MB
2020-04-02 05:07:44,271 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:44,275 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:44,276 [Thread-1404] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:44,276 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:44,277 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:44,277 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:44,277 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:44,277 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:44,281 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:44,281 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:44,281 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:44,281 [Thread-1404] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:44,281 [Thread-1404] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:44,282 [Thread-1404] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:44,282 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:44,282 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:44,282 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:44,282 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:44,283 [Thread-1404] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:44,283 [Thread-1404] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:44,283 [Thread-1404] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:44,284 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:44,284 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:44,284 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:44,284 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:44,284 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:44,284 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:44,285 [Thread-1404] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:44,293 [Thread-1404] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:44,295 [Thread-1404] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:44,296 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:44,297 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:44,302 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:44,307 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:44,310 [Thread-1404] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:44,314 [Thread-1404] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:44,318 [Thread-1404] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:44,320 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:44,320 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:44,321 [Thread-1404] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:44,324 [Thread-1404] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:44,338 [Thread-1404] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:44,338 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:44,340 [Thread-1404] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:44,338 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6a817af8] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:44,350 [Thread-1404] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:44,350 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:44,352 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:44,352 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:44,352 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:44,353 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:44,359 [Thread-1404] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:44,359 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:44,360 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33281
2020-04-02 05:07:44,360 [Thread-1404] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:44,379 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4b68df1a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:44,382 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1570258c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:44,390 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@23639d7e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:44,391 [Thread-1404] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3f15563d{HTTP/1.1,[http/1.1]}{localhost:33281}
2020-04-02 05:07:44,391 [Thread-1404] INFO  server.Server (Server.java:doStart(419)) - Started @24178ms
2020-04-02 05:07:44,392 [Thread-1404] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:44,392 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:44,392 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:44,393 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:44,393 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:44,393 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:44,393 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:44,393 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:44,394 [Thread-1404] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:44,395 [Thread-1404] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:44,395 [Thread-1404] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:44,395 [Thread-1404] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:44,395 [Thread-1404] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:44
2020-04-02 05:07:44,396 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:44,396 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:44,396 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.9 MB
2020-04-02 05:07:44,396 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:44,401 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:44,402 [Thread-1404] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:44,402 [Thread-1404] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:44,402 [Thread-1404] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:44,402 [Thread-1404] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:44,402 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:44,402 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:44,402 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:44,402 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:44,403 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:44,403 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:44,403 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:44,403 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:44,403 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:44,403 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.5 MB
2020-04-02 05:07:44,404 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:44,405 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:44,405 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:44,405 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:44,406 [Thread-1404] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:44,406 [Thread-1404] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:44,406 [Thread-1404] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:44,406 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:44,406 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:44,406 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:44,406 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:44,407 [Thread-1404] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:44,407 [Thread-1404] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:44,407 [Thread-1404] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:44,407 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:44,407 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:44,407 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:44,408 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:44,408 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 597.7 KB
2020-04-02 05:07:44,408 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:44,411 [Thread-1404] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:44,412 [Thread-1404] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:44,413 [Thread-1404] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:44,414 [Thread-1404] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:44,414 [Thread-1404] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:44,414 [Thread-1404] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:44,415 [Thread-1404] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:44,415 [Thread-1404] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:44,415 [Thread-1404] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:44,416 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:44,416 [Thread-1404] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:44,426 [Thread-1404] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:44,426 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 17 msecs
2020-04-02 05:07:44,426 [Thread-1404] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:44,427 [Thread-1404] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:44,428 [Socket Reader #1 for port 35885] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35885
2020-04-02 05:07:44,436 [Thread-1404] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:35885 to access this namenode/service.
2020-04-02 05:07:44,437 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:44,463 [Thread-1404] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:44,464 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:44,465 [Thread-1404] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:44,481 [Thread-1404] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:44,481 [Thread-1404] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:44,494 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:44,494 [IPC Server listener on 35885] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35885: starting
2020-04-02 05:07:44,495 [Thread-1404] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:35885
2020-04-02 05:07:44,495 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:44,495 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:44,496 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:44,500 [Thread-1404] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 35885 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:44,518 [CacheReplicationMonitor(519538466)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:44,520 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:44,520 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:44,520 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:44,520 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:44,520 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:44,520 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 11 msec
2020-04-02 05:07:44,521 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:44,522 [Thread-1404] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:44,523 [Thread-1404] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:44,523 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:44,523 [Thread-1404] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:44,523 [Thread-1404] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:44,523 [Thread-1404] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:44,524 [Thread-1404] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:44,524 [Thread-1404] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:44,524 [Thread-1404] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:44,524 [Thread-1404] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:44,524 [Thread-1404] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44776
2020-04-02 05:07:44,524 [Thread-1404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:44,524 [Thread-1404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:44,525 [Thread-1404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:44,525 [Thread-1404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:44,525 [Thread-1404] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.44776.sock
2020-04-02 05:07:44,527 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:44,528 [Thread-1404] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:44,529 [Thread-1404] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:44,529 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:44,530 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:44,532 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:44,532 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:44,532 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:44,533 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34611
2020-04-02 05:07:44,533 [Thread-1404] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:44,534 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6e8a3f0b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:44,534 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2598a17d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:44,538 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5503005b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:44,538 [Thread-1404] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@14ef4107{HTTP/1.1,[http/1.1]}{localhost:34611}
2020-04-02 05:07:44,539 [Thread-1404] INFO  server.Server (Server.java:doStart(419)) - Started @24325ms
2020-04-02 05:07:44,550 [Thread-1404] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33163
2020-04-02 05:07:44,550 [Thread-1404] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:44,551 [Thread-1404] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:44,550 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@52f41f88] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:44,551 [Thread-1404] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:44,552 [Socket Reader #1 for port 38203] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38203
2020-04-02 05:07:44,553 [Thread-1404] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38203
2020-04-02 05:07:44,560 [Thread-1404] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:44,561 [Thread-1404] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:44,564 [Thread-1460] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35885 starting to offer service
2020-04-02 05:07:44,580 [IPC Server listener on 38203] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38203: starting
2020-04-02 05:07:44,580 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:44,581 [Thread-1404] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38203 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:44,593 [IPC Server handler 0 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:44,594 [Thread-1460] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35885
2020-04-02 05:07:44,596 [Thread-1460] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:44,596 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:44,596 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:44,597 [Thread-1460] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:44,597 [Thread-1460] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 925488864. Formatting...
2020-04-02 05:07:44,598 [Thread-1460] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:44,602 [Thread-1460] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:44,602 [Thread-1460] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 925488864. Formatting...
2020-04-02 05:07:44,603 [Thread-1460] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-36a17b1b-30d4-4534-89e6-9850e36decc6 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:44,615 [Thread-1460] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:44,618 [Thread-1460] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:44,618 [Thread-1460] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-692916669-172.17.0.13-1585804064285 is not formatted. Formatting ...
2020-04-02 05:07:44,618 [Thread-1460] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-692916669-172.17.0.13-1585804064285 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692916669-172.17.0.13-1585804064285/current
2020-04-02 05:07:44,628 [Thread-1460] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:44,629 [Thread-1460] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:44,629 [Thread-1460] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-692916669-172.17.0.13-1585804064285 is not formatted. Formatting ...
2020-04-02 05:07:44,629 [Thread-1460] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-692916669-172.17.0.13-1585804064285 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692916669-172.17.0.13-1585804064285/current
2020-04-02 05:07:44,635 [Thread-1460] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=925488864;bpid=BP-692916669-172.17.0.13-1585804064285;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=925488864;c=1585804064285;bpid=BP-692916669-172.17.0.13-1585804064285;dnuuid=null
2020-04-02 05:07:44,636 [Thread-1460] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 9d54c3bc-a514-4586-9131-3637b7343cc1
2020-04-02 05:07:44,638 [Thread-1460] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7
2020-04-02 05:07:44,640 [Thread-1460] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:44,641 [Thread-1460] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-36a17b1b-30d4-4534-89e6-9850e36decc6
2020-04-02 05:07:44,643 [Thread-1460] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:44,644 [Thread-1460] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:44,645 [Thread-1460] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:44,645 [Thread-1460] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:44,645 [Thread-1460] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:44,645 [Thread-1460] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:44,648 [Thread-1460] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:44,649 [Thread-1475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:44,649 [Thread-1476] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:44,692 [Thread-1475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-692916669-172.17.0.13-1585804064285 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 44ms
2020-04-02 05:07:44,699 [IPC Server handler 2 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:44,703 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:44,703 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:44,704 [Thread-1476] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-692916669-172.17.0.13-1585804064285 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 55ms
2020-04-02 05:07:44,704 [Thread-1460] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-692916669-172.17.0.13-1585804064285: 55ms
2020-04-02 05:07:44,704 [Thread-1479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:44,704 [Thread-1480] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:44,704 [Thread-1479] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692916669-172.17.0.13-1585804064285/current/replicas doesn't exist 
2020-04-02 05:07:44,704 [Thread-1480] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692916669-172.17.0.13-1585804064285/current/replicas doesn't exist 
2020-04-02 05:07:44,705 [Thread-1479] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:07:44,705 [Thread-1480] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:44,705 [Thread-1460] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-692916669-172.17.0.13-1585804064285: 1ms
2020-04-02 05:07:44,705 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:44,706 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:44,706 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-36a17b1b-30d4-4534-89e6-9850e36decc6): finished scanning block pool BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:44,706 [Thread-1460] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:46 AM with interval of 21600000ms
2020-04-02 05:07:44,706 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7): finished scanning block pool BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:44,709 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-36a17b1b-30d4-4534-89e6-9850e36decc6): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:07:44,709 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:35885] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-692916669-172.17.0.13-1585804064285 (Datanode Uuid 9d54c3bc-a514-4586-9131-3637b7343cc1) service to localhost/127.0.0.1:35885 beginning handshake with NN
2020-04-02 05:07:44,709 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:07:44,716 [IPC Server handler 3 on 35885] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44776, datanodeUuid=9d54c3bc-a514-4586-9131-3637b7343cc1, infoPort=33163, infoSecurePort=0, ipcPort=38203, storageInfo=lv=-57;cid=testClusterID;nsid=925488864;c=1585804064285) storage 9d54c3bc-a514-4586-9131-3637b7343cc1
2020-04-02 05:07:44,716 [IPC Server handler 3 on 35885] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:44776
2020-04-02 05:07:44,717 [IPC Server handler 3 on 35885] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9d54c3bc-a514-4586-9131-3637b7343cc1 (127.0.0.1:44776).
2020-04-02 05:07:44,720 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:35885] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-692916669-172.17.0.13-1585804064285 (Datanode Uuid 9d54c3bc-a514-4586-9131-3637b7343cc1) service to localhost/127.0.0.1:35885 successfully registered with NN
2020-04-02 05:07:44,720 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:35885] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35885 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:44,725 [IPC Server handler 4 on 35885] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7 for DN 127.0.0.1:44776
2020-04-02 05:07:44,725 [IPC Server handler 4 on 35885] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-36a17b1b-30d4-4534-89e6-9850e36decc6 for DN 127.0.0.1:44776
2020-04-02 05:07:44,731 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x212f8c579c6c120d: Processing first storage report for DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7 from datanode 9d54c3bc-a514-4586-9131-3637b7343cc1
2020-04-02 05:07:44,731 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x212f8c579c6c120d: from storage DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7 node DatanodeRegistration(127.0.0.1:44776, datanodeUuid=9d54c3bc-a514-4586-9131-3637b7343cc1, infoPort=33163, infoSecurePort=0, ipcPort=38203, storageInfo=lv=-57;cid=testClusterID;nsid=925488864;c=1585804064285), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:44,731 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x212f8c579c6c120d: Processing first storage report for DS-36a17b1b-30d4-4534-89e6-9850e36decc6 from datanode 9d54c3bc-a514-4586-9131-3637b7343cc1
2020-04-02 05:07:44,731 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x212f8c579c6c120d: from storage DS-36a17b1b-30d4-4534-89e6-9850e36decc6 node DatanodeRegistration(127.0.0.1:44776, datanodeUuid=9d54c3bc-a514-4586-9131-3637b7343cc1, infoPort=33163, infoSecurePort=0, ipcPort=38203, storageInfo=lv=-57;cid=testClusterID;nsid=925488864;c=1585804064285), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:44,732 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:35885] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x212f8c579c6c120d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:44,732 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:35885] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:44,804 [IPC Server handler 6 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:44,805 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:44,808 [IPC Server handler 7 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:44,809 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:44,813 [IPC Server handler 8 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:44,818 [IPC Server handler 9 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/a	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:44,823 [IPC Server handler 1 on 35885] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:44776 for /a
2020-04-02 05:07:44,826 [DataXceiver for client DFSClient_NONMAPREDUCE_-545450699_4054 at /127.0.0.1:36238 [Receiving block BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001 src: /127.0.0.1:36238 dest: /127.0.0.1:44776
2020-04-02 05:07:44,831 [PacketResponder: BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36238, dest: /127.0.0.1:44776, bytes: 3456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-545450699_4054, offset: 0, srvID: 9d54c3bc-a514-4586-9131-3637b7343cc1, blockid: BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001, duration(ns): 769786
2020-04-02 05:07:44,831 [PacketResponder: BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:44,834 [IPC Server handler 3 on 35885] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /a
2020-04-02 05:07:45,244 [IPC Server handler 4 on 35885] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /a is closed by DFSClient_NONMAPREDUCE_-545450699_4054
2020-04-02 05:07:45,246 [IPC Server handler 5 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:45,249 [IPC Server handler 6 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/b	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:45,254 [IPC Server handler 7 on 35885] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:44776 for /b
2020-04-02 05:07:45,256 [DataXceiver for client DFSClient_NONMAPREDUCE_-545450699_4054 at /127.0.0.1:36432 [Receiving block BP-692916669-172.17.0.13-1585804064285:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-692916669-172.17.0.13-1585804064285:blk_1073741826_1002 src: /127.0.0.1:36432 dest: /127.0.0.1:44776
2020-04-02 05:07:45,265 [PacketResponder: BP-692916669-172.17.0.13-1585804064285:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36432, dest: /127.0.0.1:44776, bytes: 3456, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-545450699_4054, offset: 0, srvID: 9d54c3bc-a514-4586-9131-3637b7343cc1, blockid: BP-692916669-172.17.0.13-1585804064285:blk_1073741826_1002, duration(ns): 2891369
2020-04-02 05:07:45,265 [PacketResponder: BP-692916669-172.17.0.13-1585804064285:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-692916669-172.17.0.13-1585804064285:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:45,271 [IPC Server handler 9 on 35885] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /b is closed by DFSClient_NONMAPREDUCE_-545450699_4054
2020-04-02 05:07:45,273 [IPC Server handler 1 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/b	dst=null	perm=null	proto=rpc
2020-04-02 05:07:45,275 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.44776.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_-545450699_4054, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: aaff1002b196aaad4ce02a0c2af5015b, srvID: 9d54c3bc-a514-4586-9131-3637b7343cc1, success: true
2020-04-02 05:07:45,276 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.44776.sock [Passing file descriptors for block BP-692916669-172.17.0.13-1585804064285:blk_1073741826_1002]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741826, srvID: 9d54c3bc-a514-4586-9131-3637b7343cc1, success: true
2020-04-02 05:07:45,277 [IPC Server handler 0 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/a	dst=null	perm=null	proto=rpc
2020-04-02 05:07:45,280 [IPC Server handler 2 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/a	dst=null	perm=null	proto=rpc
All blocks of file /a verified to have replication factor 1
2020-04-02 05:07:45,283 [IPC Server handler 3 on 35885] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/a	dst=null	perm=null	proto=rpc
2020-04-02 05:07:45,287 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.44776.sock [Passing file descriptors for block BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 9d54c3bc-a514-4586-9131-3637b7343cc1, success: true
2020-04-02 05:07:45,288 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:45,288 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:45,288 [Thread-1404] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38203 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:45,288 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@795291aa] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:45,288 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4efc5637] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:45,298 [Thread-1404] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:45,305 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7) exiting.
2020-04-02 05:07:45,309 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-36a17b1b-30d4-4534-89e6-9850e36decc6) exiting.
2020-04-02 05:07:45,501 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5503005b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:45,503 [Thread-1404] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@14ef4107{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:45,503 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2598a17d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:45,503 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6e8a3f0b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:45,504 [Thread-1404] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38203
2020-04-02 05:07:45,505 [IPC Server listener on 38203] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38203
2020-04-02 05:07:45,506 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:45,508 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:35885] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:45,508 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:35885] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-692916669-172.17.0.13-1585804064285 (Datanode Uuid 9d54c3bc-a514-4586-9131-3637b7343cc1) service to localhost/127.0.0.1:35885
2020-04-02 05:07:45,508 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:35885] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-692916669-172.17.0.13-1585804064285 (Datanode Uuid 9d54c3bc-a514-4586-9131-3637b7343cc1)
2020-04-02 05:07:45,508 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:35885] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:45,520 [Thread-1404] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:45,520 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692916669-172.17.0.13-1585804064285] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:45,520 [Thread-1404] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:45,525 [Thread-1404] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:45,525 [Thread-1404] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:45,533 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692916669-172.17.0.13-1585804064285] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:45,539 [Thread-1404] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:45,539 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:45,539 [Thread-1404] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 35885 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:45,539 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:45,553 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@159feda4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:45,554 [Thread-1404] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 11
2020-04-02 05:07:45,554 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@11b12740] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:45,556 [Thread-1404] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 12 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 2 Number of syncs: 11 SyncTimes(ms): 1 1 
2020-04-02 05:07:45,556 [Thread-1404] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000012
2020-04-02 05:07:45,558 [Thread-1404] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000012
2020-04-02 05:07:45,559 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:45,561 [Thread-1404] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35885
2020-04-02 05:07:45,563 [CacheReplicationMonitor(519538466)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:45,563 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:45,563 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:45,564 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:45,565 [IPC Server listener on 35885] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35885
2020-04-02 05:07:45,601 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:45,610 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:45,612 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@23639d7e{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:45,615 [Thread-1404] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3f15563d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:45,615 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1570258c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:45,615 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4b68df1a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:45,626 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:45,626 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:45,626 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:45,631 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:45,632 [Thread-1404] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:45,635 [Thread-1404] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:45,638 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:45,638 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:45,638 [Thread-1404] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:45,639 [Thread-1404] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:45,644 [Thread-1404] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:45,644 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@c033da] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:45,644 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:45,646 [Thread-1404] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:45,647 [Thread-1404] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:45,647 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:45,647 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:45,648 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:45,648 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:45,648 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:45,649 [Thread-1404] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:45,649 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:45,649 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41594
2020-04-02 05:07:45,649 [Thread-1404] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:45,651 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5fbc9cdc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:45,651 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23a48b5c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:45,656 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@269a3b25{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:45,658 [Thread-1404] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@310c8258{HTTP/1.1,[http/1.1]}{localhost:41594}
2020-04-02 05:07:45,659 [Thread-1404] INFO  server.Server (Server.java:doStart(419)) - Started @25445ms
2020-04-02 05:07:45,660 [Thread-1404] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:45,660 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:45,660 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:45,660 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:45,660 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:45,660 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:45,660 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:45,661 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:45,661 [Thread-1404] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:45,661 [Thread-1404] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:45,665 [Thread-1404] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:45,666 [Thread-1404] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:45,666 [Thread-1404] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:45
2020-04-02 05:07:45,666 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:45,666 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:45,666 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.3 MB
2020-04-02 05:07:45,666 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:45,672 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:45,673 [Thread-1404] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:45,673 [Thread-1404] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:45,674 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:45,674 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:45,674 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.2 MB
2020-04-02 05:07:45,674 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:45,676 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:45,676 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:45,677 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:45,677 [Thread-1404] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:45,677 [Thread-1404] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:45,677 [Thread-1404] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:45,677 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:45,677 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:45,677 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.8 MB
2020-04-02 05:07:45,677 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:45,678 [Thread-1404] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:45,678 [Thread-1404] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:45,678 [Thread-1404] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:45,678 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:45,679 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:45,679 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:45,679 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:45,679 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 589.1 KB
2020-04-02 05:07:45,679 [Thread-1404] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:45,682 [Thread-1404] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:45,683 [Thread-1404] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:45,685 [Thread-1404] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:45,686 [Thread-1404] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:45,692 [Thread-1404] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:45,693 [Thread-1404] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:45,693 [Thread-1404] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:45,693 [Thread-1404] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:45,693 [Thread-1404] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@70454de9 expecting start txid #1
2020-04-02 05:07:45,694 [Thread-1404] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000012, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000012 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:45,694 [Thread-1404] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000012' to transaction ID 1
2020-04-02 05:07:45,708 [Thread-1404] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000012, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000012 of size 740 edits # 12 loaded in 0 seconds
2020-04-02 05:07:45,708 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:45,709 [Thread-1404] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 13
2020-04-02 05:07:45,714 [Thread-1404] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:45,714 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 35 msecs
2020-04-02 05:07:45,715 [Thread-1404] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:45,715 [Thread-1404] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:45,715 [Socket Reader #1 for port 43301] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43301
2020-04-02 05:07:45,723 [Thread-1404] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:43301 to access this namenode/service.
2020-04-02 05:07:45,723 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:45,747 [Thread-1404] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:45,751 [Thread-1404] INFO  hdfs.StateChange (BlockManagerSafeMode.java:reportStatus(607)) - STATE* Safe mode ON. 
The reported blocks 0 needs additional 1 blocks to reach the threshold 0.9990 of total blocks 2.
The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.
2020-04-02 05:07:45,781 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:45,781 [IPC Server listener on 43301] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43301: starting
2020-04-02 05:07:45,785 [Thread-1404] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:43301
2020-04-02 05:07:45,785 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:45,785 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:45,787 [Thread-1404] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=3
storage space=6912
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:45,788 [Thread-1404] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 43301 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:45,790 [CacheReplicationMonitor(1298370820)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:45,791 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:45,792 [Thread-1404] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:45,792 [Thread-1404] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:45,793 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:45,794 [Thread-1404] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:45,794 [Thread-1404] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:45,794 [Thread-1404] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:45,795 [Thread-1404] INFO  datanode.DataNode (DataNode.java:<init>(497)) - File descriptor passing is enabled.
2020-04-02 05:07:45,795 [Thread-1404] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:45,795 [Thread-1404] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:45,795 [Thread-1404] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:45,796 [Thread-1404] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33047
2020-04-02 05:07:45,796 [Thread-1404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:45,796 [Thread-1404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:45,796 [Thread-1404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:45,796 [Thread-1404] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:45,796 [Thread-1404] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1176)) - Listening on UNIX domain socket: /tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.33047.sock
2020-04-02 05:07:45,797 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:45,798 [Thread-1404] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:45,799 [Thread-1404] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:45,799 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:45,800 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:45,800 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:45,800 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:45,800 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:45,801 [Thread-1404] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 32798
2020-04-02 05:07:45,801 [Thread-1404] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:45,802 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53f030a7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:45,802 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69a5f88{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:45,805 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@44121263{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:45,805 [Thread-1404] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@552076a8{HTTP/1.1,[http/1.1]}{localhost:32798}
2020-04-02 05:07:45,805 [Thread-1404] INFO  server.Server (Server.java:doStart(419)) - Started @25592ms
2020-04-02 05:07:45,815 [Thread-1404] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33189
2020-04-02 05:07:45,816 [Thread-1404] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:45,816 [Thread-1404] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:45,816 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@78358687] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:45,816 [Thread-1404] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:45,817 [Socket Reader #1 for port 38429] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38429
2020-04-02 05:07:45,820 [Thread-1404] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38429
2020-04-02 05:07:45,826 [Thread-1404] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:45,827 [Thread-1404] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:45,831 [Thread-1546] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43301 starting to offer service
2020-04-02 05:07:45,834 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:45,834 [IPC Server listener on 38429] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38429: starting
2020-04-02 05:07:45,835 [Thread-1404] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38429 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:45,842 [IPC Server handler 0 on 43301] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:45,843 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:45,843 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:45,847 [Thread-1546] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:43301
2020-04-02 05:07:45,849 [Thread-1546] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:45,851 [Thread-1546] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:45,853 [Thread-1546] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:45,860 [Thread-1546] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:45,860 [Thread-1546] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:45,868 [Thread-1546] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:45,869 [Thread-1546] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:45,870 [Thread-1546] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=925488864;bpid=BP-692916669-172.17.0.13-1585804064285;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=925488864;c=1585804064285;bpid=BP-692916669-172.17.0.13-1585804064285;dnuuid=9d54c3bc-a514-4586-9131-3637b7343cc1
2020-04-02 05:07:45,872 [Thread-1546] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7
2020-04-02 05:07:45,879 [Thread-1546] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:45,881 [Thread-1546] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-36a17b1b-30d4-4534-89e6-9850e36decc6
2020-04-02 05:07:45,882 [Thread-1546] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:45,883 [Thread-1546] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:45,885 [Thread-1546] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:45,886 [Thread-1546] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:45,886 [Thread-1546] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:45,886 [Thread-1546] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:45,886 [Thread-1546] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:45,886 [Thread-1561] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:45,886 [Thread-1562] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:45,888 [Thread-1561] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692916669-172.17.0.13-1585804064285/current: 28067
2020-04-02 05:07:45,891 [Thread-1562] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692916669-172.17.0.13-1585804064285/current: 28067
2020-04-02 05:07:45,897 [Thread-1561] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-692916669-172.17.0.13-1585804064285 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 11ms
2020-04-02 05:07:45,898 [Thread-1562] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-692916669-172.17.0.13-1585804064285 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 12ms
2020-04-02 05:07:45,898 [Thread-1546] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-692916669-172.17.0.13-1585804064285: 12ms
2020-04-02 05:07:45,899 [Thread-1563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:45,899 [Thread-1564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:45,901 [Thread-1563] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692916669-172.17.0.13-1585804064285/current/replicas
2020-04-02 05:07:45,902 [Thread-1564] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692916669-172.17.0.13-1585804064285/current/replicas
2020-04-02 05:07:45,902 [Thread-1563] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:07:45,902 [Thread-1564] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-692916669-172.17.0.13-1585804064285 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 3ms
2020-04-02 05:07:45,904 [Thread-1546] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-692916669-172.17.0.13-1585804064285: 5ms
2020-04-02 05:07:45,918 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-36a17b1b-30d4-4534-89e6-9850e36decc6): no suitable block pools found to scan.  Waiting 1814398787 ms.
2020-04-02 05:07:45,918 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7): no suitable block pools found to scan.  Waiting 1814398788 ms.
2020-04-02 05:07:45,918 [Thread-1546] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 11:02 AM with interval of 21600000ms
2020-04-02 05:07:45,921 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:43301] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-692916669-172.17.0.13-1585804064285 (Datanode Uuid 9d54c3bc-a514-4586-9131-3637b7343cc1) service to localhost/127.0.0.1:43301 beginning handshake with NN
2020-04-02 05:07:45,922 [IPC Server handler 2 on 43301] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33047, datanodeUuid=9d54c3bc-a514-4586-9131-3637b7343cc1, infoPort=33189, infoSecurePort=0, ipcPort=38429, storageInfo=lv=-57;cid=testClusterID;nsid=925488864;c=1585804064285) storage 9d54c3bc-a514-4586-9131-3637b7343cc1
2020-04-02 05:07:45,922 [IPC Server handler 2 on 43301] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33047
2020-04-02 05:07:45,925 [IPC Server handler 2 on 43301] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9d54c3bc-a514-4586-9131-3637b7343cc1 (127.0.0.1:33047).
2020-04-02 05:07:45,930 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:43301] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-692916669-172.17.0.13-1585804064285 (Datanode Uuid 9d54c3bc-a514-4586-9131-3637b7343cc1) service to localhost/127.0.0.1:43301 successfully registered with NN
2020-04-02 05:07:45,930 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:43301] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:43301 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:45,935 [IPC Server handler 3 on 43301] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7 for DN 127.0.0.1:33047
2020-04-02 05:07:45,935 [IPC Server handler 3 on 43301] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-36a17b1b-30d4-4534-89e6-9850e36decc6 for DN 127.0.0.1:33047
2020-04-02 05:07:45,942 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5820af7a58a95eaa: Processing first storage report for DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7 from datanode 9d54c3bc-a514-4586-9131-3637b7343cc1
2020-04-02 05:07:45,942 [Block report processor] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:45,945 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(391)) - STATE* Safe mode is OFF
2020-04-02 05:07:45,945 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:45,945 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 1 racks and 1 datanodes
2020-04-02 05:07:45,945 [Block report processor] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:45,950 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5820af7a58a95eaa: from storage DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7 node DatanodeRegistration(127.0.0.1:33047, datanodeUuid=9d54c3bc-a514-4586-9131-3637b7343cc1, infoPort=33189, infoSecurePort=0, ipcPort=38429, storageInfo=lv=-57;cid=testClusterID;nsid=925488864;c=1585804064285), blocks: 1, hasStaleStorage: true, processing time: 8 msecs, invalidatedBlocks: 0
2020-04-02 05:07:45,956 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 2
2020-04-02 05:07:45,956 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:45,956 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:45,956 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:45,956 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:45,956 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 12 msec
2020-04-02 05:07:45,957 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x5820af7a58a95eaa: Processing first storage report for DS-36a17b1b-30d4-4534-89e6-9850e36decc6 from datanode 9d54c3bc-a514-4586-9131-3637b7343cc1
2020-04-02 05:07:45,960 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x5820af7a58a95eaa: from storage DS-36a17b1b-30d4-4534-89e6-9850e36decc6 node DatanodeRegistration(127.0.0.1:33047, datanodeUuid=9d54c3bc-a514-4586-9131-3637b7343cc1, infoPort=33189, infoSecurePort=0, ipcPort=38429, storageInfo=lv=-57;cid=testClusterID;nsid=925488864;c=1585804064285), blocks: 1, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-04-02 05:07:45,963 [IPC Server handler 5 on 43301] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:45,963 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:45,967 [IPC Server handler 6 on 43301] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:45,968 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:45,970 [IPC Server handler 7 on 43301] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/a	dst=null	perm=null	proto=rpc
2020-04-02 05:07:45,971 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:43301] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x5820af7a58a95eaa,  containing 2 storage report(s), of which we sent 2. The reports had 2 total blocks and used 1 RPC(s). This took 0 msec to generate and 33 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:45,975 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:43301] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:45,976 [Thread-1404] INFO  shortcircuit.ShortCircuitCache (ShortCircuitCache.java:fetch(754)) - ShortCircuitCache(0x3c132fac): got stale replica ShortCircuitReplica{key=1073741825_BP-692916669-172.17.0.13-1585804064285, metaHeader.version=1, metaHeader.checksum=DataChecksum(type=CRC32C, chunkSize=512), ident=0x2179cfe2, creationTimeMs=689234665}.  Removing this replica from the replicaInfoMap and retrying.
2020-04-02 05:07:45,978 [ShortCircuitCache_SlotReleaser] ERROR shortcircuit.ShortCircuitCache (ShortCircuitCache.java:run(210)) - ShortCircuitCache(0x3c132fac): failed to release short-circuit shared memory slot Slot(slotIdx=1, shm=DfsClientShm(aaff1002b196aaad4ce02a0c2af5015b)) by sending ReleaseShortCircuitAccessRequestProto to /tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.44776.sock.  Closing shared memory segment.
java.net.ConnectException: connect(2) error: Connection refused when trying to connect to '/tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.44776.sock'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:256)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser.run(ShortCircuitCache.java:195)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:07:45,980 [ShortCircuitCache_SlotReleaser] WARN  shortcircuit.DfsClientShmManager (DfsClientShmManager.java:shutdown(365)) - EndpointShmManager(DatanodeInfoWithStorage[127.0.0.1:44776,DS-36a17b1b-30d4-4534-89e6-9850e36decc6,DISK], parent=ShortCircuitShmManager(08535950)): error shutting down shm: got IOException calling shutdown(SHUT_RDWR)
java.nio.channels.ClosedChannelException
	at org.apache.hadoop.util.CloseableReferenceCount.reference(CloseableReferenceCount.java:57)
	at org.apache.hadoop.net.unix.DomainSocket.shutdown(DomainSocket.java:393)
	at org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.shutdown(DfsClientShmManager.java:363)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser.run(ShortCircuitCache.java:218)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:07:45,990 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.33047.sock [Waiting for operation #1]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitShm(524)) - cliID: DFSClient_NONMAPREDUCE_2103742980_4054, src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_SHM, shmId: 284e95622049e4088cd3f2b8c6e4790a, srvID: 9d54c3bc-a514-4586-9131-3637b7343cc1, success: true
2020-04-02 05:07:45,991 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.33047.sock [Passing file descriptors for block BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741825, srvID: 9d54c3bc-a514-4586-9131-3637b7343cc1, success: true
2020-04-02 05:07:45,992 [Thread-1404] WARN  hdfs.DFSClient (DFSInputStream.java:reportLostBlock(959)) - No live nodes contain block BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001 after checking nodes = [DatanodeInfoWithStorage[127.0.0.1:33047,DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7,DISK]], ignoredNodes = null
2020-04-02 05:07:45,992 [Thread-1404] INFO  hdfs.DFSClient (DFSInputStream.java:refetchLocations(882)) - Could not obtain BP-692916669-172.17.0.13-1585804064285:blk_1073741825_1001 from any node:  No live nodes contain current block Block locations: DatanodeInfoWithStorage[127.0.0.1:33047,DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7,DISK] Dead nodes:  DatanodeInfoWithStorage[127.0.0.1:33047,DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7,DISK]. Will get new block locations from namenode and retry...
2020-04-02 05:07:45,992 [Thread-1404] WARN  hdfs.DFSClient (DFSInputStream.java:refetchLocations(901)) - DFS chooseDataNode: got # 1 IOException, will wait for 1451.0949314658353 msec.
2020-04-02 05:07:47,449 [IPC Server handler 8 on 43301] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/a	dst=null	perm=null	proto=rpc
2020-04-02 05:07:47,452 [Thread-1404] WARN  hdfs.DFSClient (DFSInputStream.java:readWithStrategy(782)) - DFS Read
java.io.IOException: Unexpected EOS from the reader
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:771)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead.testHandleTruncatedBlockFile(TestShortCircuitLocalRead.java:492)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:07:47,452 [Thread-1404] ERROR hdfs.DFSClient (TestShortCircuitLocalRead.java:testHandleTruncatedBlockFile(496)) - caught exception 
java.io.IOException: Unexpected EOS from the reader
	at org.apache.hadoop.hdfs.DFSInputStream.readWithStrategy(DFSInputStream.java:771)
	at org.apache.hadoop.hdfs.DFSInputStream.read(DFSInputStream.java:825)
	at java.io.DataInputStream.readFully(DataInputStream.java:195)
	at org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead.testHandleTruncatedBlockFile(TestShortCircuitLocalRead.java:492)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
2020-04-02 05:07:47,454 [IPC Server handler 9 on 43301] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/b	dst=null	perm=null	proto=rpc
2020-04-02 05:07:47,455 [Thread-1404] INFO  shortcircuit.ShortCircuitCache (ShortCircuitCache.java:fetch(754)) - ShortCircuitCache(0x3c132fac): got stale replica ShortCircuitReplica{key=1073741826_BP-692916669-172.17.0.13-1585804064285, metaHeader.version=1, metaHeader.checksum=DataChecksum(type=CRC32C, chunkSize=512), ident=0x3ded9518, creationTimeMs=689234654}.  Removing this replica from the replicaInfoMap and retrying.
2020-04-02 05:07:47,455 [ShortCircuitCache_SlotReleaser] ERROR shortcircuit.ShortCircuitCache (ShortCircuitCache.java:run(210)) - ShortCircuitCache(0x3c132fac): failed to release short-circuit shared memory slot Slot(slotIdx=0, shm=DfsClientShm(aaff1002b196aaad4ce02a0c2af5015b)) by sending ReleaseShortCircuitAccessRequestProto to /tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.44776.sock.  Closing shared memory segment.
java.net.ConnectException: connect(2) error: Connection refused when trying to connect to '/tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.44776.sock'
	at org.apache.hadoop.net.unix.DomainSocket.connect0(Native Method)
	at org.apache.hadoop.net.unix.DomainSocket.connect(DomainSocket.java:256)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser.run(ShortCircuitCache.java:195)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:07:47,456 [ShortCircuitCache_SlotReleaser] WARN  shortcircuit.DfsClientShmManager (DfsClientShmManager.java:shutdown(365)) - EndpointShmManager(DatanodeInfoWithStorage[127.0.0.1:44776,DS-36a17b1b-30d4-4534-89e6-9850e36decc6,DISK], parent=ShortCircuitShmManager(08535950)): error shutting down shm: got IOException calling shutdown(SHUT_RDWR)
java.nio.channels.ClosedChannelException
	at org.apache.hadoop.util.CloseableReferenceCount.reference(CloseableReferenceCount.java:57)
	at org.apache.hadoop.net.unix.DomainSocket.shutdown(DomainSocket.java:393)
	at org.apache.hadoop.hdfs.shortcircuit.DfsClientShmManager$EndpointShmManager.shutdown(DfsClientShmManager.java:363)
	at org.apache.hadoop.hdfs.shortcircuit.ShortCircuitCache$SlotReleaser.run(ShortCircuitCache.java:218)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)
	at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:07:47,457 [DataXceiver for client unix:/tmp/socks.1585804040900.-279246518/testHandleTruncatedBlockFile.33047.sock [Passing file descriptors for block BP-692916669-172.17.0.13-1585804064285:blk_1073741826_1002]] INFO  DataNode.clienttrace (DataXceiver.java:requestShortCircuitFds(425)) - src: 127.0.0.1, dest: 127.0.0.1, op: REQUEST_SHORT_CIRCUIT_FDS, blockid: 1073741826, srvID: 9d54c3bc-a514-4586-9131-3637b7343cc1, success: true
2020-04-02 05:07:47,460 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:47,460 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:47,461 [Thread-1404] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38429 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:47,461 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1abe346e] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:47,461 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@466663f0] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:47,471 [Thread-1404] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:47,473 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-e5b256bb-e61e-4cec-ab25-afe84f7bd7a7) exiting.
2020-04-02 05:07:47,473 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-36a17b1b-30d4-4534-89e6-9850e36decc6) exiting.
2020-04-02 05:07:47,517 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@44121263{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:47,522 [Thread-1404] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@552076a8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:47,522 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69a5f88{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:47,522 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53f030a7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:47,524 [Thread-1404] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38429
2020-04-02 05:07:47,527 [IPC Server listener on 38429] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38429
2020-04-02 05:07:47,528 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:47,528 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:43301] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:47,528 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:43301] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-692916669-172.17.0.13-1585804064285 (Datanode Uuid 9d54c3bc-a514-4586-9131-3637b7343cc1) service to localhost/127.0.0.1:43301
2020-04-02 05:07:47,528 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:43301] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-692916669-172.17.0.13-1585804064285 (Datanode Uuid 9d54c3bc-a514-4586-9131-3637b7343cc1)
2020-04-02 05:07:47,528 [BP-692916669-172.17.0.13-1585804064285 heartbeating to localhost/127.0.0.1:43301] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-692916669-172.17.0.13-1585804064285
2020-04-02 05:07:47,536 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-692916669-172.17.0.13-1585804064285] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:47,552 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-692916669-172.17.0.13-1585804064285] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:47,554 [Thread-1404] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:47,555 [Thread-1404] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:47,556 [Thread-1404] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:47,556 [Thread-1404] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:47,559 [Thread-1404] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:47,561 [Thread-1404] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:47,561 [Thread-1404] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 43301 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:47,561 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:47,561 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@1e5f7e5f] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:47,561 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@10486dc6] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:47,562 [Thread-1404] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 13, 13
2020-04-02 05:07:47,562 [Thread-1404] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 12 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-04-02 05:07:47,562 [Thread-1404] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000013 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000013-0000000000000000014
2020-04-02 05:07:47,563 [Thread-1404] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000013 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000013-0000000000000000014
2020-04-02 05:07:47,563 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:47,564 [CacheReplicationMonitor(1298370820)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:47,564 [Thread-1404] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43301
2020-04-02 05:07:47,566 [IPC Server listener on 43301] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43301
2020-04-02 05:07:47,566 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:47,567 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:47,567 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:47,573 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:47,574 [Thread-1404] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:47,578 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@269a3b25{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:47,583 [Thread-1404] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@310c8258{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:47,583 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@23a48b5c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:47,584 [Thread-1404] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5fbc9cdc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:47,587 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:47,587 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:47,588 [Thread-1404] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testHandleTruncatedBlockFile
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testHandleTruncatedBlockFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testDeprecatedGetBlockLocalPathInfoRpc
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:47,611 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:07:47,619 [Thread-1571] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:47,620 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:47,620 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:47,620 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:47,620 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:47,620 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:47,620 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:47,620 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:47,620 [Thread-1571] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:47,620 [Thread-1571] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:47,620 [Thread-1571] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:47,621 [Thread-1571] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:47,621 [Thread-1571] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:47
2020-04-02 05:07:47,621 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:47,621 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:47,621 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.3 MB
2020-04-02 05:07:47,621 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:47,668 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:47,670 [Thread-1571] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:47,671 [Thread-1571] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:47,672 [Thread-1571] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:47,675 [Thread-1571] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:47,676 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:47,676 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:47,676 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:47,676 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:47,676 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:47,677 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:47,677 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:47,678 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:47,678 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:47,678 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.2 MB
2020-04-02 05:07:47,679 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:47,681 [Thread-1571] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:47,681 [Thread-1571] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:47,681 [Thread-1571] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:47,682 [Thread-1571] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:47,682 [Thread-1571] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:47,683 [Thread-1571] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:47,683 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:47,683 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:47,694 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.8 MB
2020-04-02 05:07:47,694 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:47,695 [Thread-1571] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:47,695 [Thread-1571] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:47,695 [Thread-1571] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:47,695 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:47,695 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:47,695 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:47,695 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:47,696 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 589.1 KB
2020-04-02 05:07:47,696 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:47,696 [Thread-1571] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:47,699 [Thread-1571] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:07:47,701 [Thread-1571] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:07:47,724 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:47,725 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:07:47,730 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:47,735 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 396 bytes saved in 0 seconds .
2020-04-02 05:07:47,739 [Thread-1571] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:07:47,740 [Thread-1571] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:47,743 [Thread-1571] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:47,745 [Thread-1571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:47,745 [Thread-1571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:47,746 [Thread-1571] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:47,746 [Thread-1571] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:47,749 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@401e7797] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:47,749 [Thread-1571] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:47,749 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:47,751 [Thread-1571] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:47,751 [Thread-1571] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:47,751 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:47,752 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:47,752 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:47,753 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:47,753 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:47,754 [Thread-1571] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:47,754 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:47,754 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 32996
2020-04-02 05:07:47,754 [Thread-1571] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:47,757 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@144205af{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:47,759 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2c7b4f3e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:47,764 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@318ea695{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:47,764 [Thread-1571] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4eb02b35{HTTP/1.1,[http/1.1]}{localhost:32996}
2020-04-02 05:07:47,765 [Thread-1571] INFO  server.Server (Server.java:doStart(419)) - Started @27551ms
2020-04-02 05:07:47,766 [Thread-1571] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:47,767 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:47,767 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:47,767 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:47,767 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:47,767 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:47,767 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:47,767 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:47,768 [Thread-1571] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:47,768 [Thread-1571] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:47,768 [Thread-1571] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:47,768 [Thread-1571] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:47,768 [Thread-1571] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:47
2020-04-02 05:07:47,769 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:47,769 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:47,769 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 38.3 MB
2020-04-02 05:07:47,769 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:47,785 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:47,785 [Thread-1571] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:47,785 [Thread-1571] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:47,786 [Thread-1571] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:47,786 [Thread-1571] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:47,786 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:47,786 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:47,786 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:47,787 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:47,787 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:47,787 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:47,787 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:47,787 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:47,787 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:47,787 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.2 MB
2020-04-02 05:07:47,787 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:47,789 [Thread-1571] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:07:47,789 [Thread-1571] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:47,789 [Thread-1571] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:47,789 [Thread-1571] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:47,789 [Thread-1571] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:47,789 [Thread-1571] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:47,789 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:47,789 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:47,789 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.8 MB
2020-04-02 05:07:47,789 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:47,794 [Thread-1571] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:47,794 [Thread-1571] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:47,794 [Thread-1571] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:47,794 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:47,794 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:47,794 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:47,794 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:47,805 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 589.1 KB
2020-04-02 05:07:47,805 [Thread-1571] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:47,807 [Thread-1571] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:47,818 [Thread-1571] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:47,819 [Thread-1571] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:47,819 [Thread-1571] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:47,820 [Thread-1571] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:47,820 [Thread-1571] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:47,821 [Thread-1571] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:47,821 [Thread-1571] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:47,821 [Thread-1571] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:47,821 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:47,822 [Thread-1571] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:47,827 [Thread-1571] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:47,827 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 21 msecs
2020-04-02 05:07:47,827 [Thread-1571] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:47,827 [Thread-1571] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:47,828 [Socket Reader #1 for port 41713] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41713
2020-04-02 05:07:47,829 [Thread-1571] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:41713 to access this namenode/service.
2020-04-02 05:07:47,830 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:47,851 [Thread-1571] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:47,862 [Thread-1571] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:47,862 [Thread-1571] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:47,862 [Thread-1571] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:47,863 [Thread-1571] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:47,866 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:47,866 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:47,866 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:47,866 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:47,866 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:47,866 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2020-04-02 05:07:47,868 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:47,869 [IPC Server listener on 41713] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41713: starting
2020-04-02 05:07:47,872 [Thread-1571] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:41713
2020-04-02 05:07:47,872 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:47,872 [Thread-1571] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:47,873 [Thread-1571] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:47,874 [Thread-1571] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 41713 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:47,879 [CacheReplicationMonitor(413768441)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:47,884 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:47,887 [Thread-1571] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:47,888 [Thread-1571] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:47,889 [Thread-1571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:47,891 [Thread-1571] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:47,891 [Thread-1571] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:47,891 [Thread-1571] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:47,891 [Thread-1571] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:47,891 [Thread-1571] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:47,892 [Thread-1571] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:47,892 [Thread-1571] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45254
2020-04-02 05:07:47,892 [Thread-1571] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:47,892 [Thread-1571] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:47,893 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:47,894 [Thread-1571] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:47,895 [Thread-1571] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:47,895 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:47,896 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:47,896 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:47,896 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:47,896 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:47,897 [Thread-1571] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43552
2020-04-02 05:07:47,897 [Thread-1571] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:47,898 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1651080c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:47,899 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@13964dcf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:47,903 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@154e9ce7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:47,903 [Thread-1571] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7b9cf7c5{HTTP/1.1,[http/1.1]}{localhost:43552}
2020-04-02 05:07:47,903 [Thread-1571] INFO  server.Server (Server.java:doStart(419)) - Started @27690ms
2020-04-02 05:07:47,915 [Thread-1571] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33521
2020-04-02 05:07:47,915 [Thread-1571] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:47,915 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3c22844b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:47,915 [Thread-1571] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:47,916 [Thread-1571] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:47,916 [Socket Reader #1 for port 46112] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46112
2020-04-02 05:07:47,920 [Thread-1571] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46112
2020-04-02 05:07:47,922 [Thread-1571] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:47,923 [Thread-1571] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:47,923 [Thread-1626] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41713 starting to offer service
2020-04-02 05:07:47,925 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:47,925 [IPC Server listener on 46112] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46112: starting
2020-04-02 05:07:47,927 [Thread-1571] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46112 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:47,927 [Thread-1571] WARN  hdfs.ClientContext (ClientContext.java:printConfWarningIfNeeded(199)) - Existing client context 'default' does not match requested configuration.  Existing: shortCircuitStreamsCacheSize = 256, shortCircuitStreamsCacheExpiryMs = 300000, shortCircuitMmapCacheSize = 256, shortCircuitMmapCacheExpiryMs = 3600000, shortCircuitMmapCacheRetryTimeout = 300000, shortCircuitCacheStaleThresholdMs = 1800000, socketCacheCapacity = 16, socketCacheExpiry = 3000, shortCircuitLocalReads = true, useLegacyBlockReaderLocal = false, domainSocketDataTraffic = false, shortCircuitSharedMemoryWatcherInterruptCheckMs = 60000, keyProviderCacheExpiryMs = 864000000, domainSocketDisableIntervalSeconds = 600, Requested: shortCircuitStreamsCacheSize = 256, shortCircuitStreamsCacheExpiryMs = 300000, shortCircuitMmapCacheSize = 256, shortCircuitMmapCacheExpiryMs = 3600000, shortCircuitMmapCacheRetryTimeout = 300000, shortCircuitCacheStaleThresholdMs = 1800000, socketCacheCapacity = 16, socketCacheExpiry = 3000, shortCircuitLocalReads = false, useLegacyBlockReaderLocal = false, domainSocketDataTraffic = false, shortCircuitSharedMemoryWatcherInterruptCheckMs = 60000, keyProviderCacheExpiryMs = 864000000, domainSocketDisableIntervalSeconds = 600
2020-04-02 05:07:47,936 [Thread-1626] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:41713
2020-04-02 05:07:47,938 [Thread-1626] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:47,939 [IPC Server handler 0 on 41713] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:47,942 [Thread-1626] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:47,942 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:47,945 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:47,945 [Thread-1626] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 417582521. Formatting...
2020-04-02 05:07:47,945 [Thread-1626] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-80a5ced9-07a0-4215-ab38-0a732ec891c8 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:47,948 [Thread-1626] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 15965@5909b7672181
2020-04-02 05:07:47,948 [Thread-1626] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 417582521. Formatting...
2020-04-02 05:07:47,949 [Thread-1626] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-aa0238fd-6677-412c-b155-cd493e551899 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:47,959 [Thread-1626] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:47,959 [Thread-1626] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:47,959 [Thread-1626] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1105082618-172.17.0.13-1585804067696 is not formatted. Formatting ...
2020-04-02 05:07:47,959 [Thread-1626] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1105082618-172.17.0.13-1585804067696 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1105082618-172.17.0.13-1585804067696/current
2020-04-02 05:07:47,972 [Thread-1626] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:47,972 [Thread-1626] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:47,972 [Thread-1626] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1105082618-172.17.0.13-1585804067696 is not formatted. Formatting ...
2020-04-02 05:07:47,973 [Thread-1626] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1105082618-172.17.0.13-1585804067696 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1105082618-172.17.0.13-1585804067696/current
2020-04-02 05:07:47,975 [Thread-1626] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=417582521;bpid=BP-1105082618-172.17.0.13-1585804067696;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=417582521;c=1585804067696;bpid=BP-1105082618-172.17.0.13-1585804067696;dnuuid=null
2020-04-02 05:07:47,977 [Thread-1626] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 22bb2d74-6ed0-471d-aaf8-fed840068f1d
2020-04-02 05:07:47,979 [Thread-1626] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-80a5ced9-07a0-4215-ab38-0a732ec891c8
2020-04-02 05:07:47,979 [Thread-1626] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:47,993 [Thread-1626] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-aa0238fd-6677-412c-b155-cd493e551899
2020-04-02 05:07:47,993 [Thread-1626] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:47,993 [Thread-1626] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:47,999 [Thread-1626] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:48,002 [Thread-1626] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:48,002 [Thread-1626] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:48,002 [Thread-1626] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:48,011 [Thread-1626] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:48,011 [Thread-1641] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1105082618-172.17.0.13-1585804067696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:48,012 [Thread-1642] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1105082618-172.17.0.13-1585804067696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:48,041 [Thread-1642] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1105082618-172.17.0.13-1585804067696 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 29ms
2020-04-02 05:07:48,045 [Thread-1641] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1105082618-172.17.0.13-1585804067696 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 33ms
2020-04-02 05:07:48,045 [Thread-1626] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1105082618-172.17.0.13-1585804067696: 34ms
2020-04-02 05:07:48,045 [Thread-1645] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1105082618-172.17.0.13-1585804067696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:48,045 [Thread-1646] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1105082618-172.17.0.13-1585804067696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:48,045 [Thread-1645] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1105082618-172.17.0.13-1585804067696/current/replicas doesn't exist 
2020-04-02 05:07:48,045 [Thread-1646] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1105082618-172.17.0.13-1585804067696/current/replicas doesn't exist 
2020-04-02 05:07:48,049 [Thread-1646] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1105082618-172.17.0.13-1585804067696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-04-02 05:07:48,049 [Thread-1645] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1105082618-172.17.0.13-1585804067696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 4ms
2020-04-02 05:07:48,051 [Thread-1626] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1105082618-172.17.0.13-1585804067696: 6ms
2020-04-02 05:07:48,051 [Thread-1626] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:49 AM with interval of 21600000ms
2020-04-02 05:07:48,052 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1105082618-172.17.0.13-1585804067696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:48,053 [IPC Server handler 2 on 41713] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:48,053 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:48,053 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-80a5ced9-07a0-4215-ab38-0a732ec891c8): finished scanning block pool BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:48,055 [BP-1105082618-172.17.0.13-1585804067696 heartbeating to localhost/127.0.0.1:41713] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1105082618-172.17.0.13-1585804067696 (Datanode Uuid 22bb2d74-6ed0-471d-aaf8-fed840068f1d) service to localhost/127.0.0.1:41713 beginning handshake with NN
2020-04-02 05:07:48,055 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1105082618-172.17.0.13-1585804067696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:48,055 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-aa0238fd-6677-412c-b155-cd493e551899): finished scanning block pool BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:48,055 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-80a5ced9-07a0-4215-ab38-0a732ec891c8): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:07:48,055 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-aa0238fd-6677-412c-b155-cd493e551899): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:07:48,056 [IPC Server handler 3 on 41713] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45254, datanodeUuid=22bb2d74-6ed0-471d-aaf8-fed840068f1d, infoPort=33521, infoSecurePort=0, ipcPort=46112, storageInfo=lv=-57;cid=testClusterID;nsid=417582521;c=1585804067696) storage 22bb2d74-6ed0-471d-aaf8-fed840068f1d
2020-04-02 05:07:48,057 [IPC Server handler 3 on 41713] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:45254
2020-04-02 05:07:48,054 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:48,061 [IPC Server handler 3 on 41713] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 22bb2d74-6ed0-471d-aaf8-fed840068f1d (127.0.0.1:45254).
2020-04-02 05:07:48,064 [BP-1105082618-172.17.0.13-1585804067696 heartbeating to localhost/127.0.0.1:41713] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1105082618-172.17.0.13-1585804067696 (Datanode Uuid 22bb2d74-6ed0-471d-aaf8-fed840068f1d) service to localhost/127.0.0.1:41713 successfully registered with NN
2020-04-02 05:07:48,064 [BP-1105082618-172.17.0.13-1585804067696 heartbeating to localhost/127.0.0.1:41713] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:41713 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:48,070 [IPC Server handler 4 on 41713] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-80a5ced9-07a0-4215-ab38-0a732ec891c8 for DN 127.0.0.1:45254
2020-04-02 05:07:48,070 [IPC Server handler 4 on 41713] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-aa0238fd-6677-412c-b155-cd493e551899 for DN 127.0.0.1:45254
2020-04-02 05:07:48,073 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4e27226c738f6b9: Processing first storage report for DS-80a5ced9-07a0-4215-ab38-0a732ec891c8 from datanode 22bb2d74-6ed0-471d-aaf8-fed840068f1d
2020-04-02 05:07:48,074 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4e27226c738f6b9: from storage DS-80a5ced9-07a0-4215-ab38-0a732ec891c8 node DatanodeRegistration(127.0.0.1:45254, datanodeUuid=22bb2d74-6ed0-471d-aaf8-fed840068f1d, infoPort=33521, infoSecurePort=0, ipcPort=46112, storageInfo=lv=-57;cid=testClusterID;nsid=417582521;c=1585804067696), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:48,074 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4e27226c738f6b9: Processing first storage report for DS-aa0238fd-6677-412c-b155-cd493e551899 from datanode 22bb2d74-6ed0-471d-aaf8-fed840068f1d
2020-04-02 05:07:48,074 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4e27226c738f6b9: from storage DS-aa0238fd-6677-412c-b155-cd493e551899 node DatanodeRegistration(127.0.0.1:45254, datanodeUuid=22bb2d74-6ed0-471d-aaf8-fed840068f1d, infoPort=33521, infoSecurePort=0, ipcPort=46112, storageInfo=lv=-57;cid=testClusterID;nsid=417582521;c=1585804067696), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:48,075 [BP-1105082618-172.17.0.13-1585804067696 heartbeating to localhost/127.0.0.1:41713] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x4e27226c738f6b9,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:48,075 [BP-1105082618-172.17.0.13-1585804067696 heartbeating to localhost/127.0.0.1:41713] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:48,162 [IPC Server handler 6 on 41713] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:48,163 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:48,169 [IPC Server handler 7 on 41713] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:48,170 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:48,172 [IPC Server handler 8 on 41713] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:48,175 [IPC Server handler 9 on 41713] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/x	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:48,185 [IPC Server handler 1 on 41713] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:45254 for /tmp/x
2020-04-02 05:07:48,191 [DataXceiver for client DFSClient_NONMAPREDUCE_1401452064_4592 at /127.0.0.1:50214 [Receiving block BP-1105082618-172.17.0.13-1585804067696:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1105082618-172.17.0.13-1585804067696:blk_1073741825_1001 src: /127.0.0.1:50214 dest: /127.0.0.1:45254
2020-04-02 05:07:48,202 [PacketResponder: BP-1105082618-172.17.0.13-1585804067696:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50214, dest: /127.0.0.1:45254, bytes: 16, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1401452064_4592, offset: 0, srvID: 22bb2d74-6ed0-471d-aaf8-fed840068f1d, blockid: BP-1105082618-172.17.0.13-1585804067696:blk_1073741825_1001, duration(ns): 3056536
2020-04-02 05:07:48,202 [PacketResponder: BP-1105082618-172.17.0.13-1585804067696:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1105082618-172.17.0.13-1585804067696:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:48,211 [IPC Server handler 3 on 41713] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/x is closed by DFSClient_NONMAPREDUCE_1401452064_4592
2020-04-02 05:07:48,217 [IPC Server handler 2 on 46112] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 2 on 46112, call Call#353 Retry#0 org.apache.hadoop.hdfs.protocol.ClientDatanodeProtocol.getBlockLocalPathInfo from 127.0.0.1:32854
org.apache.hadoop.security.AccessControlException: Can't continue with getBlockLocalPathInfo() authorization. The user root is not configured in dfs.block.local-path-access.user
	at org.apache.hadoop.hdfs.server.datanode.DataNode.checkBlockLocalPathAccess(DataNode.java:1891)
	at org.apache.hadoop.hdfs.server.datanode.DataNode.getBlockLocalPathInfo(DataNode.java:1906)
	at org.apache.hadoop.hdfs.protocolPB.ClientDatanodeProtocolServerSideTranslatorPB.getBlockLocalPathInfo(ClientDatanodeProtocolServerSideTranslatorPB.java:139)
	at org.apache.hadoop.hdfs.protocol.proto.ClientDatanodeProtocolProtos$ClientDatanodeProtocolService$2.callBlockingMethod(ClientDatanodeProtocolProtos.java:14646)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:48,228 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:48,228 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:48,228 [Thread-1571] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46112 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:48,228 [Thread-1571] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:48,228 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2aceec7] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:48,230 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-80a5ced9-07a0-4215-ab38-0a732ec891c8) exiting.
2020-04-02 05:07:48,230 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-aa0238fd-6677-412c-b155-cd493e551899) exiting.
2020-04-02 05:07:48,246 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@154e9ce7{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:48,246 [Thread-1571] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7b9cf7c5{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:48,247 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@13964dcf{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:48,247 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1651080c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:48,248 [Thread-1571] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46112
2020-04-02 05:07:48,251 [IPC Server listener on 46112] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46112
2020-04-02 05:07:48,251 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:48,251 [BP-1105082618-172.17.0.13-1585804067696 heartbeating to localhost/127.0.0.1:41713] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:48,251 [BP-1105082618-172.17.0.13-1585804067696 heartbeating to localhost/127.0.0.1:41713] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1105082618-172.17.0.13-1585804067696 (Datanode Uuid 22bb2d74-6ed0-471d-aaf8-fed840068f1d) service to localhost/127.0.0.1:41713
2020-04-02 05:07:48,252 [BP-1105082618-172.17.0.13-1585804067696 heartbeating to localhost/127.0.0.1:41713] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1105082618-172.17.0.13-1585804067696 (Datanode Uuid 22bb2d74-6ed0-471d-aaf8-fed840068f1d)
2020-04-02 05:07:48,252 [BP-1105082618-172.17.0.13-1585804067696 heartbeating to localhost/127.0.0.1:41713] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1105082618-172.17.0.13-1585804067696
2020-04-02 05:07:48,255 [Thread-1571] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:48,256 [Thread-1571] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:48,257 [Thread-1571] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:48,257 [Thread-1571] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:48,261 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1105082618-172.17.0.13-1585804067696] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:48,267 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1105082618-172.17.0.13-1585804067696] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:48,274 [Thread-1571] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:48,274 [Thread-1571] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:48,274 [Thread-1571] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 41713 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:48,274 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:48,277 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@777c56e4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:48,277 [Thread-1571] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:07:48,278 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@39f1f827] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:48,278 [Thread-1571] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 1 Number of syncs: 8 SyncTimes(ms): 2 0 
2020-04-02 05:07:48,279 [Thread-1571] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:07:48,279 [Thread-1571] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:07:48,280 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:48,281 [CacheReplicationMonitor(413768441)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:48,285 [Thread-1571] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41713
2020-04-02 05:07:48,298 [IPC Server listener on 41713] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41713
2020-04-02 05:07:48,298 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:48,298 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:48,299 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:48,325 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:48,326 [Thread-1571] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:48,327 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@318ea695{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:48,330 [Thread-1571] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4eb02b35{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:48,332 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2c7b4f3e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:48,332 [Thread-1571] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@144205af{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:48,333 [Thread-1571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:48,334 [Thread-1571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:48,334 [Thread-1571] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testDeprecatedGetBlockLocalPathInfoRpc
[msx] writeFile testName = org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead#testDeprecatedGetBlockLocalPathInfoRpc
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] all testRunFinished

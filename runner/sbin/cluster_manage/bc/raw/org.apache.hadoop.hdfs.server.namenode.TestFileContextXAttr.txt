[msx] before_class
2020-04-02 05:06:58,206 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:06:58,777 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:58,791 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:58,793 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:58,795 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:58,816 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:58,816 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:58,816 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:58,817 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:58,895 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:58,902 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:06:58,902 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:06:58,902 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:58,909 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:58,910 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:58
2020-04-02 05:06:58,913 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:58,915 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:58,918 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:58,919 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:58,940 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:58,946 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:58,946 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:58,946 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:58,947 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:58,947 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:06:58,947 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:58,947 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:58,947 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:58,948 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:06:58,948 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:58,948 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:58,975 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:06:58,996 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:58,997 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:58,997 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:58,998 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:59,004 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:06:59,005 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:59,005 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:59,005 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:59,012 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:59,017 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:59,021 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:59,022 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:59,022 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:59,022 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:59,031 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:59,031 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:59,031 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:59,035 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:59,035 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:59,038 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:59,038 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:59,039 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:59,039 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:59,073 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:06:59,093 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:59,095 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:59,107 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:59,107 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:59,226 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:06:59,226 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:06:59,253 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:59,257 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:59,416 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:06:59,470 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:59,875 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:59,875 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:59,886 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:59,916 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:59,966 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@59505b48] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:59,982 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:59,988 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:00,003 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3261ms
2020-04-02 05:07:00,127 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:00,131 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:00,131 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:00,139 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:00,141 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:00,142 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:00,142 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:00,173 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:00,173 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:00,183 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41352
2020-04-02 05:07:00,185 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:00,228 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f67a4d3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:00,229 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2fb0623e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:00,274 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@48c76607{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:00,283 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@52e7a6b2{HTTP/1.1,[http/1.1]}{localhost:41352}
2020-04-02 05:07:00,284 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3541ms
2020-04-02 05:07:00,295 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:00,295 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:00,296 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:00,296 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:00,296 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:00,296 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:00,296 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:00,297 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:00,297 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:00,298 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:00,298 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:00,299 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:00,300 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:00
2020-04-02 05:07:00,300 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:00,300 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:00,300 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:07:00,301 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:00,321 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:00,321 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:00,322 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:00,322 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:00,322 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:00,322 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:00,323 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:00,323 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:00,323 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:00,323 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:00,324 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:00,324 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:00,324 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:00,325 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:00,325 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:07:00,326 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:00,333 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:00,333 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:00,334 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:00,334 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:00,334 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:00,335 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:00,335 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:00,335 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:00,335 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:07:00,335 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:00,336 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:00,336 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:00,336 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:00,337 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:00,337 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:00,337 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:00,337 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:00,337 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:07:00,338 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:00,344 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:00,347 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:00,350 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:00,350 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:00,351 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:07:00,355 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:00,383 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:00,390 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:00,390 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:00,396 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:00,397 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:07:00,426 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:00,426 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 86 msecs
2020-04-02 05:07:00,641 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:00,652 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:00,672 [Socket Reader #1 for port 45951] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45951
2020-04-02 05:07:01,032 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:45951 to access this namenode/service.
2020-04-02 05:07:01,040 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:01,071 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:01,085 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:01,085 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:01,086 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:01,086 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:01,092 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:07:01,092 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:01,092 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:07:01,092 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:01,092 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:01,092 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 7 msec
2020-04-02 05:07:01,164 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:01,164 [IPC Server listener on 45951] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45951: starting
2020-04-02 05:07:01,168 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:45951
2020-04-02 05:07:01,174 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:01,175 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:01,179 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:01,209 [CacheReplicationMonitor(1558424064)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:01,210 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 45951 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:01,219 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:01,289 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:01,314 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:01,334 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:01,335 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:01,345 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:01,348 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:01,352 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:01,353 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:01,358 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:01,366 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42310
2020-04-02 05:07:01,368 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:01,368 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:01,386 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:01,389 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:01,390 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:01,390 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:01,392 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:01,393 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:01,394 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:01,394 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:01,398 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42770
2020-04-02 05:07:01,398 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:01,400 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fa2213{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:01,401 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f0b0a5e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:01,408 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4da602fc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:01,409 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a8d39c4{HTTP/1.1,[http/1.1]}{localhost:42770}
2020-04-02 05:07:01,409 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4667ms
2020-04-02 05:07:01,850 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38136
2020-04-02 05:07:01,852 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@625e134e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:01,853 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:01,854 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:01,884 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:01,885 [Socket Reader #1 for port 33299] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33299
2020-04-02 05:07:01,893 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33299
2020-04-02 05:07:01,910 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:01,914 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:02,264 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45951 starting to offer service
2020-04-02 05:07:02,303 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:02,304 [IPC Server listener on 33299] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33299: starting
2020-04-02 05:07:02,308 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33299 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:02,822 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:45951
2020-04-02 05:07:02,831 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:02,840 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:02,840 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1074675762. Formatting...
2020-04-02 05:07:02,842 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:07:02,847 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:02,847 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1074675762. Formatting...
2020-04-02 05:07:02,847 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-afe7793b-8839-4536-91e9-98e46497afea for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:07:02,863 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:02,864 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:02,864 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1627096859-172.17.0.17-1585804019062 is not formatted. Formatting ...
2020-04-02 05:07:02,864 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1627096859-172.17.0.17-1585804019062 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current
2020-04-02 05:07:02,878 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:02,878 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:02,878 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1627096859-172.17.0.17-1585804019062 is not formatted. Formatting ...
2020-04-02 05:07:02,879 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1627096859-172.17.0.17-1585804019062 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current
2020-04-02 05:07:02,881 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=null
2020-04-02 05:07:02,882 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:03,006 [IPC Server handler 6 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:03,015 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:03,016 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:03,023 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:03,026 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:03,028 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:03,033 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:03,039 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:03,044 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:03,051 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:03,052 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:03,053 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:03,070 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:03,077 [Thread-78] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:03,076 [Thread-77] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:03,128 [IPC Server handler 4 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:03,128 [Thread-77] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 51ms
2020-04-02 05:07:03,130 [Thread-78] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 53ms
2020-04-02 05:07:03,131 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 61ms
2020-04-02 05:07:03,131 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:03,131 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:03,136 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:03,136 [Thread-81] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:03,136 [Thread-82] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas doesn't exist 
2020-04-02 05:07:03,137 [Thread-81] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas doesn't exist 
2020-04-02 05:07:03,138 [Thread-82] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:07:03,141 [Thread-81] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 4ms
2020-04-02 05:07:03,145 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 10ms
2020-04-02 05:07:03,148 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:03,159 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): finished scanning block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:03,148 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:03,162 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): finished scanning block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:03,173 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:33 AM with interval of 21600000ms
2020-04-02 05:07:03,182 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:45951] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:45951 beginning handshake with NN
2020-04-02 05:07:03,205 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814399942 ms.
2020-04-02 05:07:03,205 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814399943 ms.
2020-04-02 05:07:03,214 [IPC Server handler 9 on 45951] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42310, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=38136, infoSecurePort=0, ipcPort=33299, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:03,221 [IPC Server handler 9 on 45951] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42310
2020-04-02 05:07:03,222 [IPC Server handler 9 on 45951] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:42310).
2020-04-02 05:07:03,240 [IPC Server handler 7 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:03,241 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:45951] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:45951 successfully registered with NN
2020-04-02 05:07:03,242 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:45951] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:45951 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:03,249 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:42310
2020-04-02 05:07:03,249 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:03,267 [IPC Server handler 8 on 45951] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:42310
2020-04-02 05:07:03,268 [IPC Server handler 8 on 45951] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:42310
2020-04-02 05:07:03,310 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe043fc1a76273614: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:03,312 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe043fc1a76273614: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:42310, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=38136, infoSecurePort=0, ipcPort=33299, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:07:03,313 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe043fc1a76273614: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:03,313 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe043fc1a76273614: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:42310, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=38136, infoSecurePort=0, ipcPort=33299, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:03,338 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:45951] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe043fc1a76273614,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 5 msec to generate and 45 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:03,339 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:45951] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:03,354 [IPC Server handler 4 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:03,357 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:03,368 [IPC Server handler 9 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:03,369 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testUnreadableBySuperuserXAttr
[msx] unitTestCounterInClass = 0
2020-04-02 05:07:03,444 [IPC Server handler 7 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:03,498 [IPC Server handler 1 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p1	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:07:03,507 [IPC Server handler 5 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p1	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:07:03,557 [IPC Server handler 0 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/p1/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:03,631 [IPC Server handler 2 on 45951] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:42310 for /p1/file
2020-04-02 05:07:03,731 [DataXceiver for client DFSClient_NONMAPREDUCE_-1426486526_1 at /127.0.0.1:58724 [Receiving block BP-1627096859-172.17.0.17-1585804019062:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1627096859-172.17.0.17-1585804019062:blk_1073741825_1001 src: /127.0.0.1:58724 dest: /127.0.0.1:42310
2020-04-02 05:07:03,787 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58724, dest: /127.0.0.1:42310, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1426486526_1, offset: 0, srvID: 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, blockid: BP-1627096859-172.17.0.17-1585804019062:blk_1073741825_1001, duration(ns): 18526151
2020-04-02 05:07:03,788 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:03,815 [IPC Server handler 8 on 45951] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /p1/file
2020-04-02 05:07:04,221 [IPC Server handler 4 on 45951] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /p1/file is closed by DFSClient_NONMAPREDUCE_-1426486526_1
2020-04-02 05:07:04,237 [IPC Server handler 9 on 45951] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 9 on 45951, call Call#18 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:38908
java.io.IOException: Can only set 'security.hdfs.unreadable.by.superuser' on a file.
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:298)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:04,249 [IPC Server handler 7 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p1/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:04,260 [IPC Server handler 1 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,268 [IPC Server handler 5 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,280 [IPC Server handler 0 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p1/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:04,291 [IPC Server handler 2 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,303 [IPC Server handler 3 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,314 [IPC Server handler 6 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,315 [IPC Server handler 6 on 45951] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 45951, call Call#25 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:38908: org.apache.hadoop.security.AccessControlException: The xattr 'security.hdfs.unreadable.by.superuser' can not be deleted.
2020-04-02 05:07:04,333 [IPC Server handler 8 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,338 [IPC Server handler 4 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,344 [IPC Server handler 9 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,344 [IPC Server handler 9 on 45951] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 45951, call Call#28 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:38908: org.apache.hadoop.security.AccessControlException: Attempt to set a value for 'security.hdfs.unreadable.by.superuser'. Values are not allowed for this xattr.
2020-04-02 05:07:04,360 [IPC Server handler 7 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,371 [IPC Server handler 1 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,371 [IPC Server handler 1 on 45951] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 45951, call Call#30 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getBlockLocations from 127.0.0.1:38908: org.apache.hadoop.security.AccessControlException: Access is denied for root since the superuser is not allowed to perform this operation.
2020-04-02 05:07:04,384 [IPC Server handler 5 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p1/file	dst=/p1/filex	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:04,394 [IPC Server handler 0 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p1/filex	dst=/p1/file	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:04,408 [IPC Server handler 2 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,418 [IPC Server handler 3 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p1	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,427 [IPC Server handler 6 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p1	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:04,442 [IPC Server handler 8 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p1	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:07:04,454 [IPC Server handler 4 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p1	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
2020-04-02 05:07:04,458 [IPC Server handler 9 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/p1/file	dst=null	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:04,471 [IPC Server handler 7 on 45951] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:42310 for /p1/file
2020-04-02 05:07:04,492 [DataXceiver for client DFSClient_NONMAPREDUCE_1537163100_301 at /127.0.0.1:58806 [Receiving block BP-1627096859-172.17.0.17-1585804019062:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1627096859-172.17.0.17-1585804019062:blk_1073741826_1002 src: /127.0.0.1:58806 dest: /127.0.0.1:42310
2020-04-02 05:07:04,539 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58806, dest: /127.0.0.1:42310, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1537163100_301, offset: 0, srvID: 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, blockid: BP-1627096859-172.17.0.17-1585804019062:blk_1073741826_1002, duration(ns): 34005421
2020-04-02 05:07:04,540 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:04,542 [IPC Server handler 5 on 45951] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741826_1002 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /p1/file
2020-04-02 05:07:04,946 [IPC Server handler 2 on 45951] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /p1/file is closed by DFSClient_NONMAPREDUCE_1537163100_301
2020-04-02 05:07:04,949 [IPC Server handler 3 on 45951] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 3 on 45951, call Call#44 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:39028
java.io.IOException: Can only set 'security.hdfs.unreadable.by.superuser' on a file.
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:298)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:04,967 [IPC Server handler 6 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p1/file	dst=null	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:04,969 [IPC Server handler 8 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,972 [IPC Server handler 4 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,973 [IPC Server handler 9 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p1/file	dst=null	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:04,975 [IPC Server handler 7 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,977 [IPC Server handler 1 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,979 [IPC Server handler 5 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,979 [IPC Server handler 5 on 45951] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 45951, call Call#51 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:39028: org.apache.hadoop.security.AccessControlException: The xattr 'security.hdfs.unreadable.by.superuser' can not be deleted.
2020-04-02 05:07:04,984 [IPC Server handler 0 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,986 [IPC Server handler 2 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,987 [IPC Server handler 3 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:04,988 [IPC Server handler 3 on 45951] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 45951, call Call#54 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:39028: org.apache.hadoop.security.AccessControlException: Attempt to set a value for 'security.hdfs.unreadable.by.superuser'. Values are not allowed for this xattr.
2020-04-02 05:07:04,995 [IPC Server handler 6 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:05,000 [IPC Server handler 8 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:05,066 [IPC Server handler 4 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p1/file	dst=/p1/filex	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,070 [IPC Server handler 9 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p1/filex	dst=/p1/file	perm=user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,076 [IPC Server handler 7 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p1/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:05,078 [IPC Server handler 1 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p1	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testUnreadableBySuperuserXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testUnreadableBySuperuserXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testCreateXAttr
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:05,093 [IPC Server handler 5 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:05,096 [IPC Server handler 0 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,110 [IPC Server handler 2 on 45951] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:42310 for /p2/file
2020-04-02 05:07:05,128 [DataXceiver for client DFSClient_NONMAPREDUCE_1445502776_1 at /127.0.0.1:58828 [Receiving block BP-1627096859-172.17.0.17-1585804019062:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1627096859-172.17.0.17-1585804019062:blk_1073741827_1003 src: /127.0.0.1:58828 dest: /127.0.0.1:42310
2020-04-02 05:07:05,153 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58828, dest: /127.0.0.1:42310, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1445502776_1, offset: 0, srvID: 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, blockid: BP-1627096859-172.17.0.17-1585804019062:blk_1073741827_1003, duration(ns): 20615234
2020-04-02 05:07:05,153 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:05,165 [IPC Server handler 8 on 45951] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /p2/file is closed by DFSClient_NONMAPREDUCE_1445502776_1
2020-04-02 05:07:05,169 [IPC Server handler 4 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,174 [IPC Server handler 9 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:05,181 [IPC Server handler 7 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,190 [IPC Server handler 1 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:05,196 [IPC Server handler 5 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,202 [IPC Server handler 0 on 45951] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 0 on 45951, call Call#72 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:38908
java.io.IOException: XAttr: a1 already exists. The REPLACE flag must be specified.
	at org.apache.hadoop.fs.XAttrSetFlag.validate(XAttrSetFlag.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:342)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:272)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:05,223 [IPC Server handler 2 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,226 [IPC Server handler 3 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,228 [IPC Server handler 6 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,229 [IPC Server handler 8 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:05,232 [IPC Server handler 4 on 45951] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:05,233 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:05,237 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:05,238 [Thread-99] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33299 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:05,239 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3543df7d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:05,238 [Thread-99] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:05,253 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:05,253 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:05,335 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4da602fc{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:05,358 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a8d39c4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:05,359 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f0b0a5e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:05,361 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fa2213{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:05,390 [Thread-99] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33299
2020-04-02 05:07:05,406 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:05,410 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:45951] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:05,410 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:45951] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:45951
2020-04-02 05:07:05,410 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:45951] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:05,410 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:45951] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:05,412 [IPC Server listener on 33299] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33299
2020-04-02 05:07:05,429 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:05,452 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:05,462 [Thread-99] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:05,462 [Thread-99] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:05,463 [Thread-99] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:05,463 [Thread-99] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:05,471 [Thread-99] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:05,471 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:05,471 [Thread-99] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 45951 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:05,471 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:05,473 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 40
2020-04-02 05:07:05,475 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@73173f63] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:05,478 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@55562aa9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:05,484 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 41 Total time for transactions(ms): 49 Number of transactions batched in Syncs: 3 Number of syncs: 39 SyncTimes(ms): 2 4 
2020-04-02 05:07:05,485 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000041
2020-04-02 05:07:05,486 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000041
2020-04-02 05:07:05,487 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:05,494 [CacheReplicationMonitor(1558424064)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:05,497 [Thread-99] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45951
2020-04-02 05:07:05,509 [IPC Server listener on 45951] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45951
2020-04-02 05:07:05,510 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:05,537 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:05,537 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:05,624 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:05,625 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:05,627 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@48c76607{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:05,649 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@52e7a6b2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:05,649 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2fb0623e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:05,650 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f67a4d3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:05,652 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:05,656 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:05,656 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:05,662 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:05,665 [Thread-99] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:05,680 [Thread-99] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:05,689 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:05,689 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:05,690 [Thread-99] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:05,690 [Thread-99] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:05,699 [Thread-99] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:05,699 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:05,700 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4dcae723] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:05,701 [Thread-99] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:05,701 [Thread-99] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:05,702 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:05,726 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:05,727 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:05,727 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:05,727 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:05,729 [Thread-99] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:05,729 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:05,737 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33373
2020-04-02 05:07:05,737 [Thread-99] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:05,769 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7b81b275{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:05,770 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@29038d5f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:05,783 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@9b99196{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:05,784 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4fa857ee{HTTP/1.1,[http/1.1]}{localhost:33373}
2020-04-02 05:07:05,784 [Thread-99] INFO  server.Server (Server.java:doStart(419)) - Started @9042ms
2020-04-02 05:07:05,789 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:05,790 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:05,790 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:05,790 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:05,790 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:05,790 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:05,790 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:05,791 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:05,791 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:05,792 [Thread-99] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:05,792 [Thread-99] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:05,792 [Thread-99] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:05,793 [Thread-99] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:05
2020-04-02 05:07:05,793 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:05,793 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:05,801 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:05,802 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:05,817 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:05,817 [Thread-99] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:05,822 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:05,823 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:05,823 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:05,823 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:05,823 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:05,823 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:05,823 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:05,823 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:05,823 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:05,823 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:05,824 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:05,826 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:05,827 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:05,831 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:05,840 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:05,840 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:05,841 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:05,841 [Thread-99] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:05,841 [Thread-99] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:05,841 [Thread-99] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:05,844 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:05,844 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:05,845 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:05,845 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:05,847 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:05,847 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:05,848 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:05,849 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:05,849 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:05,849 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:05,849 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:05,850 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:05,850 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:05,853 [Thread-99] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:05,856 [Thread-99] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:05,864 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:05,865 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:05,872 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:05,874 [Thread-99] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:07:05,876 [Thread-99] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:05,878 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:07:05,878 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@45faa735 expecting start txid #1
2020-04-02 05:07:05,878 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000041, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000041 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:05,879 [Thread-99] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000041' to transaction ID 1
2020-04-02 05:07:05,908 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000041, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000041 of size 2665 edits # 41 loaded in 0 seconds
2020-04-02 05:07:05,908 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:05,909 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 42
2020-04-02 05:07:05,933 [Thread-99] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:05,933 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 82 msecs
2020-04-02 05:07:05,934 [Thread-99] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:05,934 [Thread-99] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:05,935 [Socket Reader #1 for port 44240] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44240
2020-04-02 05:07:05,942 [Thread-99] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:44240 to access this namenode/service.
2020-04-02 05:07:05,942 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:05,982 [Thread-99] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:05,984 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:05,985 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:05,985 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:05,985 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:05,991 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:05,991 [IPC Server listener on 44240] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44240: starting
2020-04-02 05:07:05,995 [Thread-99] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:44240
2020-04-02 05:07:05,996 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:06,000 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:06,000 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:06,000 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:06,000 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:06,000 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 15 msec
2020-04-02 05:07:06,000 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:06,000 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:06,001 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=8192
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:06,007 [Thread-99] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 44240 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:06,010 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:06,011 [Thread-99] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:06,038 [Thread-99] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:06,045 [CacheReplicationMonitor(717984858)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:06,063 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:06,063 [Thread-99] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:06,064 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:06,064 [Thread-99] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:06,076 [Thread-99] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:06,076 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:06,076 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:06,077 [Thread-99] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37101
2020-04-02 05:07:06,077 [Thread-99] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:06,078 [Thread-99] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:06,079 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:06,083 [Thread-99] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:06,088 [Thread-99] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:06,088 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:06,090 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:06,091 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:06,091 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:06,091 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:06,108 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34377
2020-04-02 05:07:06,108 [Thread-99] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:06,110 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5d4d7636{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:06,111 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4c5f21e3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:06,117 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@67821f4e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:06,118 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1ae93856{HTTP/1.1,[http/1.1]}{localhost:34377}
2020-04-02 05:07:06,118 [Thread-99] INFO  server.Server (Server.java:doStart(419)) - Started @9376ms
2020-04-02 05:07:06,279 [Thread-99] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39448
2020-04-02 05:07:06,285 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:06,286 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:06,286 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@8da39f4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:06,286 [Thread-99] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:06,287 [Socket Reader #1 for port 33739] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33739
2020-04-02 05:07:06,315 [Thread-99] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33739
2020-04-02 05:07:06,320 [Thread-99] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:06,321 [Thread-99] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:06,336 [Thread-154] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44240 starting to offer service
2020-04-02 05:07:06,338 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:06,338 [IPC Server listener on 33739] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33739: starting
2020-04-02 05:07:06,340 [Thread-99] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33739 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:06,399 [IPC Server handler 0 on 44240] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:06,404 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:06,404 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:06,406 [Thread-154] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:44240
2020-04-02 05:07:06,410 [Thread-154] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:06,415 [Thread-154] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:06,422 [Thread-154] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:06,460 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:06,463 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:06,483 [Thread-154] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:06,484 [Thread-154] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:06,487 [Thread-154] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:06,493 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:06,493 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:06,496 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:06,496 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:06,497 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:06,499 [Thread-154] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:06,504 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:06,505 [Thread-154] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:06,506 [Thread-154] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:06,520 [Thread-154] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:06,520 [Thread-169] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:06,524 [Thread-169] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 41102
2020-04-02 05:07:06,524 [Thread-170] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:06,526 [Thread-170] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:06,538 [Thread-169] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 17ms
2020-04-02 05:07:06,543 [IPC Server handler 3 on 44240] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:06,545 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:06,545 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:06,552 [Thread-170] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 29ms
2020-04-02 05:07:06,554 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 34ms
2020-04-02 05:07:06,555 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:06,555 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:06,562 [Thread-171] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:06,563 [Thread-171] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 8ms
2020-04-02 05:07:06,568 [Thread-172] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:06,569 [Thread-172] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 14ms
2020-04-02 05:07:06,577 [Thread-154] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 24ms
2020-04-02 05:07:06,616 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814396531 ms.
2020-04-02 05:07:06,616 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814396532 ms.
2020-04-02 05:07:06,619 [Thread-154] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:00 AM with interval of 21600000ms
2020-04-02 05:07:06,628 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:44240] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:44240 beginning handshake with NN
2020-04-02 05:07:06,630 [IPC Server handler 4 on 44240] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37101, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=39448, infoSecurePort=0, ipcPort=33739, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:06,630 [IPC Server handler 4 on 44240] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37101
2020-04-02 05:07:06,630 [IPC Server handler 4 on 44240] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:37101).
2020-04-02 05:07:06,641 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:44240] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:44240 successfully registered with NN
2020-04-02 05:07:06,641 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:44240] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:44240 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:06,658 [IPC Server handler 5 on 44240] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:06,660 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:37101
2020-04-02 05:07:06,660 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:06,662 [IPC Server handler 6 on 44240] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:37101
2020-04-02 05:07:06,663 [IPC Server handler 6 on 44240] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:37101
2020-04-02 05:07:06,685 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfbd7f7ff5f1e6bc1: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:06,687 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfbd7f7ff5f1e6bc1: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:37101, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=39448, infoSecurePort=0, ipcPort=33739, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:06,687 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfbd7f7ff5f1e6bc1: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:06,689 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfbd7f7ff5f1e6bc1: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:37101, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=39448, infoSecurePort=0, ipcPort=33739, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 2, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:07:06,692 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:44240] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfbd7f7ff5f1e6bc1,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 0 msec to generate and 19 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:06,692 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:44240] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:06,762 [IPC Server handler 8 on 44240] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:06,763 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:06,766 [IPC Server handler 1 on 44240] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:06,767 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:06,773 [IPC Server handler 9 on 44240] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:06,774 [Thread-99] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:06,774 [Thread-99] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:06,774 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 42, 42
2020-04-02 05:07:06,779 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 13 Number of transactions batched in Syncs: 41 Number of syncs: 3 SyncTimes(ms): 3 3 
2020-04-02 05:07:06,780 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000042 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000042-0000000000000000043
2020-04-02 05:07:06,781 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000042 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000042-0000000000000000043
2020-04-02 05:07:06,786 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000043 using no compression
2020-04-02 05:07:06,786 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000043 using no compression
2020-04-02 05:07:06,804 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000043 of size 623 bytes saved in 0 seconds .
2020-04-02 05:07:06,805 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000043 of size 623 bytes saved in 0 seconds .
2020-04-02 05:07:06,811 [Thread-99] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 0
2020-04-02 05:07:06,818 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 44
2020-04-02 05:07:06,828 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:06,828 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:06,829 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:06,829 [Thread-99] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33739 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:06,829 [Thread-99] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:06,836 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@14924c30] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:06,838 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:06,844 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:06,974 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@67821f4e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:07,149 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1ae93856{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:07,149 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4c5f21e3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:07,150 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5d4d7636{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:07,167 [Thread-99] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33739
2020-04-02 05:07:07,200 [IPC Server listener on 33739] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33739
2020-04-02 05:07:07,206 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:07,206 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:44240] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:07,214 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:44240] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:44240
2020-04-02 05:07:07,214 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:44240] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:07,214 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:44240] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:07,257 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:07,262 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:07,275 [Thread-99] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:07,275 [Thread-99] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:07,276 [Thread-99] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:07,276 [Thread-99] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:07,286 [Thread-99] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:07,286 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:07,286 [Thread-99] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 44240 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:07,286 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:07,302 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 44, 44
2020-04-02 05:07:07,302 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1b61177d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:07,302 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@6f2548ef] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:07,304 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 3 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 1 
2020-04-02 05:07:07,305 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000044 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000044-0000000000000000045
2020-04-02 05:07:07,305 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000044 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000044-0000000000000000045
2020-04-02 05:07:07,306 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:07,306 [CacheReplicationMonitor(717984858)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:07,309 [Thread-99] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44240
2020-04-02 05:07:07,320 [IPC Server listener on 44240] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44240
2020-04-02 05:07:07,320 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:07,320 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:07,336 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:07,356 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:07,357 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:07,358 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@9b99196{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:07,365 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4fa857ee{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:07,365 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@29038d5f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:07,365 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7b81b275{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:07,386 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:07,393 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:07,394 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:07,401 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:07,402 [Thread-99] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:07,407 [Thread-99] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:07,409 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:07,410 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:07,410 [Thread-99] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:07,411 [Thread-99] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:07,418 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@373e3122] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:07,418 [Thread-99] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:07,419 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:07,420 [Thread-99] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:07,421 [Thread-99] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:07,421 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:07,423 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:07,423 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:07,424 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:07,424 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:07,425 [Thread-99] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:07,425 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:07,426 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37045
2020-04-02 05:07:07,426 [Thread-99] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:07,428 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b8eb57d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:07,429 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21a3bbec{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:07,435 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4cbf1e8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:07,438 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1e78054f{HTTP/1.1,[http/1.1]}{localhost:37045}
2020-04-02 05:07:07,438 [Thread-99] INFO  server.Server (Server.java:doStart(419)) - Started @10696ms
2020-04-02 05:07:07,440 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:07,440 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:07,440 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:07,441 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:07,441 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:07,441 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:07,441 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:07,441 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:07,441 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:07,477 [Thread-99] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:07,478 [Thread-99] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:07,478 [Thread-99] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:07,479 [Thread-99] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:07
2020-04-02 05:07:07,479 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:07,479 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:07,523 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:07,525 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:07,539 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:07,539 [Thread-99] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:07,539 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:07,540 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:07,540 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:07,540 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:07,540 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:07,540 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:07,540 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:07,540 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:07,540 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:07,576 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:07,577 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:07,577 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:07,577 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:07,577 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:07,594 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:07,594 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:07,594 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:07,594 [Thread-99] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:07,595 [Thread-99] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:07,595 [Thread-99] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:07,595 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:07,595 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:07,596 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:07,596 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:07,597 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:07,597 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:07,597 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:07,598 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:07,599 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:07,602 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:07,602 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:07,603 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:07,603 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:07,605 [Thread-99] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:07,610 [Thread-99] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:07,611 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:07,612 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:07,612 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2020-04-02 05:07:07,614 [Thread-99] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 3 INodes.
2020-04-02 05:07:07,616 [Thread-99] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:07,616 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 43 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000043
2020-04-02 05:07:07,616 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@75d31300 expecting start txid #44
2020-04-02 05:07:07,616 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000044-0000000000000000045, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000044-0000000000000000045 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:07,616 [Thread-99] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000044-0000000000000000045' to transaction ID 44
2020-04-02 05:07:07,616 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000044-0000000000000000045, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000044-0000000000000000045 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:07,617 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:07,617 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 46
2020-04-02 05:07:07,626 [Thread-99] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:07,626 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 22 msecs
2020-04-02 05:07:07,627 [Thread-99] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:07,627 [Thread-99] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:07,631 [Socket Reader #1 for port 38353] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38353
2020-04-02 05:07:07,637 [Thread-99] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38353 to access this namenode/service.
2020-04-02 05:07:07,661 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:07,695 [Thread-99] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:07,696 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:07,697 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:07,697 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:07,697 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:07,712 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:07,713 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:07,713 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:07,713 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:07,713 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:07,713 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2020-04-02 05:07:07,716 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:07,716 [IPC Server listener on 38353] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38353: starting
2020-04-02 05:07:07,718 [Thread-99] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38353
2020-04-02 05:07:07,719 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:07,719 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:07,741 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 22 milliseconds
name space=3
storage space=8192
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:07,758 [Thread-99] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38353 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:07,759 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:07,767 [Thread-99] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:07,767 [Thread-99] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:07,773 [CacheReplicationMonitor(1222117389)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:07,794 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:07,795 [Thread-99] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:07,795 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:07,795 [Thread-99] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:07,796 [Thread-99] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:07,796 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:07,796 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:07,797 [Thread-99] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41333
2020-04-02 05:07:07,797 [Thread-99] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:07,797 [Thread-99] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:07,801 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:07,803 [Thread-99] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:07,803 [Thread-99] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:07,803 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:07,805 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:07,805 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:07,809 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:07,809 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:07,809 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41748
2020-04-02 05:07:07,810 [Thread-99] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:07,813 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@19c7fa89{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:07,816 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30238ca8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:07,826 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71516da1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:07,827 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@76f3522e{HTTP/1.1,[http/1.1]}{localhost:41748}
2020-04-02 05:07:07,827 [Thread-99] INFO  server.Server (Server.java:doStart(419)) - Started @11085ms
2020-04-02 05:07:07,853 [Thread-99] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36873
2020-04-02 05:07:07,853 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:07,853 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4087faf] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:07,854 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:07,854 [Thread-99] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:07,855 [Socket Reader #1 for port 38325] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38325
2020-04-02 05:07:07,872 [Thread-99] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38325
2020-04-02 05:07:07,875 [Thread-99] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:07,875 [Thread-99] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:07,876 [Thread-226] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38353 starting to offer service
2020-04-02 05:07:07,878 [IPC Server listener on 38325] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38325: starting
2020-04-02 05:07:07,878 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:07,882 [Thread-99] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38325 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:07,904 [Thread-226] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38353
2020-04-02 05:07:07,914 [Thread-226] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:07,915 [IPC Server handler 2 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:07,916 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:07,916 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:07,916 [Thread-226] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:07,927 [Thread-226] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:07,938 [Thread-226] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:07,938 [Thread-226] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:07,962 [Thread-226] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:07,963 [Thread-226] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:07,964 [Thread-226] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:07,969 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:07,970 [Thread-226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:07,972 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:07,972 [Thread-226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:07,972 [Thread-226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:07,994 [Thread-226] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:08,015 [Thread-226] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:08,015 [Thread-226] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:08,015 [Thread-226] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:08,023 [Thread-226] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:08,024 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:08,024 [Thread-242] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:08,020 [IPC Server handler 4 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:08,026 [Thread-242] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:08,026 [Thread-241] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 41102
2020-04-02 05:07:08,030 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:08,030 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:08,055 [Thread-241] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 31ms
2020-04-02 05:07:08,064 [Thread-242] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 40ms
2020-04-02 05:07:08,065 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 42ms
2020-04-02 05:07:08,065 [Thread-243] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:08,065 [Thread-244] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:08,070 [Thread-243] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:08,071 [Thread-243] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 6ms
2020-04-02 05:07:08,077 [Thread-244] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:08,078 [Thread-244] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 13ms
2020-04-02 05:07:08,083 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 18ms
2020-04-02 05:07:08,084 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814395063 ms.
2020-04-02 05:07:08,084 [Thread-226] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:23 AM with interval of 21600000ms
2020-04-02 05:07:08,086 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814395063 ms.
2020-04-02 05:07:08,090 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38353] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:38353 beginning handshake with NN
2020-04-02 05:07:08,094 [IPC Server handler 5 on 38353] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41333, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=36873, infoSecurePort=0, ipcPort=38325, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:08,095 [IPC Server handler 5 on 38353] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41333
2020-04-02 05:07:08,095 [IPC Server handler 5 on 38353] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:41333).
2020-04-02 05:07:08,105 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38353] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:38353 successfully registered with NN
2020-04-02 05:07:08,105 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38353] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38353 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:08,118 [IPC Server handler 3 on 38353] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:41333
2020-04-02 05:07:08,119 [IPC Server handler 3 on 38353] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:41333
2020-04-02 05:07:08,133 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd59ee462c5d9d18e: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:08,133 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd59ee462c5d9d18e: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:41333, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=36873, infoSecurePort=0, ipcPort=38325, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:08,138 [IPC Server handler 7 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:08,139 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:08,139 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd59ee462c5d9d18e: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:08,144 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd59ee462c5d9d18e: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:41333, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=36873, infoSecurePort=0, ipcPort=38325, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 2, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2020-04-02 05:07:08,145 [IPC Server handler 8 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:08,146 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38353] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd59ee462c5d9d18e,  containing 2 storage report(s), of which we sent 2. The reports had 3 total blocks and used 1 RPC(s). This took 1 msec to generate and 17 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:08,147 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38353] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:08,151 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:08,156 [IPC Server handler 9 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:08,167 [IPC Server handler 1 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:08,169 [IPC Server handler 0 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/.reserved/raw/p2	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:08,172 [IPC Server handler 2 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/.reserved/raw/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:08,183 [IPC Server handler 4 on 38353] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:41333 for /p2/file
2020-04-02 05:07:08,190 [DataXceiver for client DFSClient_NONMAPREDUCE_-1039229464_315 at /127.0.0.1:59038 [Receiving block BP-1627096859-172.17.0.17-1585804019062:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1627096859-172.17.0.17-1585804019062:blk_1073741828_1004 src: /127.0.0.1:59038 dest: /127.0.0.1:41333
2020-04-02 05:07:08,248 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59038, dest: /127.0.0.1:41333, bytes: 8192, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1039229464_315, offset: 0, srvID: 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, blockid: BP-1627096859-172.17.0.17-1585804019062:blk_1073741828_1004, duration(ns): 53119789
2020-04-02 05:07:08,249 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:08,259 [IPC Server handler 7 on 38353] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /.reserved/raw/p2/file is closed by DFSClient_NONMAPREDUCE_-1039229464_315
2020-04-02 05:07:08,262 [IPC Server handler 6 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:08,274 [IPC Server handler 8 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:08,277 [IPC Server handler 9 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:08,278 [IPC Server handler 1 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:08,281 [IPC Server handler 0 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:08,286 [IPC Server handler 2 on 38353] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 2 on 38353, call Call#109 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:42440
java.io.IOException: XAttr: a1 already exists. The REPLACE flag must be specified.
	at org.apache.hadoop.fs.XAttrSetFlag.validate(XAttrSetFlag.java:61)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:342)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:272)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:08,294 [IPC Server handler 4 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:08,297 [IPC Server handler 5 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:08,304 [IPC Server handler 3 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:08,309 [IPC Server handler 7 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:08,315 [IPC Server handler 6 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p2/file	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:07:08,317 [IPC Server handler 8 on 38353] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:08,318 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:08,318 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:08,318 [Thread-99] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38325 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:08,318 [Thread-99] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:08,320 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@46666d52] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:08,323 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:08,325 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:08,393 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71516da1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:08,400 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@76f3522e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:08,400 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30238ca8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:08,401 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@19c7fa89{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:08,414 [Thread-99] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38325
2020-04-02 05:07:08,423 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:08,424 [IPC Server listener on 38325] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38325
2020-04-02 05:07:08,423 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38353] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:08,425 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38353] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:38353
2020-04-02 05:07:08,425 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38353] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:08,426 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38353] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:08,449 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:08,455 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:08,501 [Thread-99] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:08,508 [Thread-99] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:08,513 [Thread-99] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:08,513 [Thread-99] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:08,518 [Thread-99] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:08,518 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:08,519 [Thread-99] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38353 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:08,519 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:08,522 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 46, 60
2020-04-02 05:07:08,524 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@44554d69] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:08,529 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5bc04ffc] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:08,529 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 16 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 47 Number of syncs: 15 SyncTimes(ms): 3 1 
2020-04-02 05:07:08,532 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000046 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000046-0000000000000000061
2020-04-02 05:07:08,533 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000046 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000046-0000000000000000061
2020-04-02 05:07:08,533 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:08,541 [CacheReplicationMonitor(1222117389)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:08,550 [Thread-99] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38353
2020-04-02 05:07:08,563 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:08,565 [IPC Server listener on 38353] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38353
2020-04-02 05:07:08,575 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:08,565 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:08,597 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:08,602 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:08,614 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4cbf1e8{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:08,642 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1e78054f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:08,643 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21a3bbec{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:08,643 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b8eb57d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:08,650 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:08,655 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:08,655 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:08,661 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:08,672 [Thread-99] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:08,690 [Thread-99] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:08,692 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:08,692 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:08,693 [Thread-99] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:08,693 [Thread-99] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:08,699 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6f523583] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:08,700 [Thread-99] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:08,700 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:08,701 [Thread-99] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:08,702 [Thread-99] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:08,702 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:08,703 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:08,704 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:08,704 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:08,704 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:08,706 [Thread-99] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:08,706 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:08,707 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33988
2020-04-02 05:07:08,707 [Thread-99] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:08,714 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6bca3d2f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:08,715 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@135c734c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:08,721 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@331ac3d7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:08,722 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@68b1fa40{HTTP/1.1,[http/1.1]}{localhost:33988}
2020-04-02 05:07:08,722 [Thread-99] INFO  server.Server (Server.java:doStart(419)) - Started @11980ms
2020-04-02 05:07:08,724 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:08,725 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:08,725 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:08,725 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:08,725 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:08,725 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:08,726 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:08,726 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:08,726 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:08,727 [Thread-99] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:08,727 [Thread-99] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:08,727 [Thread-99] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:08,728 [Thread-99] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:08
2020-04-02 05:07:08,728 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:08,728 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:08,728 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:08,728 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:08,744 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:08,744 [Thread-99] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:08,745 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:08,745 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:08,745 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:08,746 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:08,746 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:08,747 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:08,747 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:08,747 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:08,747 [Thread-99] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:08,747 [Thread-99] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:08,747 [Thread-99] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:08,748 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:08,748 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:08,748 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:08,748 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:08,749 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:08,749 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:08,749 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:08,750 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:08,750 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:08,750 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:08,750 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:08,750 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:08,750 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:08,763 [Thread-99] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:08,764 [Thread-99] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:08,768 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:08,768 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:08,770 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2020-04-02 05:07:08,772 [Thread-99] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 3 INodes.
2020-04-02 05:07:08,779 [Thread-99] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:08,779 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 43 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000043
2020-04-02 05:07:08,779 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@741ec930 expecting start txid #44
2020-04-02 05:07:08,779 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000044-0000000000000000045, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000044-0000000000000000045 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:08,779 [Thread-99] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000044-0000000000000000045' to transaction ID 44
2020-04-02 05:07:08,780 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000044-0000000000000000045, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000044-0000000000000000045 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:08,782 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a764922 expecting start txid #46
2020-04-02 05:07:08,782 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000046-0000000000000000061, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000046-0000000000000000061 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:08,782 [Thread-99] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000046-0000000000000000061' to transaction ID 44
2020-04-02 05:07:08,802 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000046-0000000000000000061, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000046-0000000000000000061 of size 976 edits # 16 loaded in 0 seconds
2020-04-02 05:07:08,803 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:08,803 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 62
2020-04-02 05:07:08,844 [Thread-99] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:08,844 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 82 msecs
2020-04-02 05:07:08,844 [Thread-99] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:08,845 [Thread-99] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:08,850 [Socket Reader #1 for port 39403] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39403
2020-04-02 05:07:08,857 [Thread-99] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:39403 to access this namenode/service.
2020-04-02 05:07:08,858 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:08,947 [Thread-99] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:08,953 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:08,958 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:08,958 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:08,958 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:08,966 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:08,966 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:08,966 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:08,966 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:08,966 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:08,966 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-04-02 05:07:08,977 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:08,977 [IPC Server listener on 39403] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39403: starting
2020-04-02 05:07:08,978 [Thread-99] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:39403
2020-04-02 05:07:08,979 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:08,979 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:08,979 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=8192
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:08,980 [Thread-99] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 39403 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:08,986 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:08,988 [Thread-99] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:08,989 [Thread-99] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:09,008 [CacheReplicationMonitor(1660437874)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:09,023 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:09,023 [Thread-99] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:09,023 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:09,024 [Thread-99] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:09,024 [Thread-99] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:09,024 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:09,024 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:09,025 [Thread-99] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38564
2020-04-02 05:07:09,025 [Thread-99] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:09,025 [Thread-99] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:09,030 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:09,032 [Thread-99] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:09,033 [Thread-99] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:09,033 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:09,038 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:09,039 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:09,039 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:09,039 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:09,040 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41026
2020-04-02 05:07:09,040 [Thread-99] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:09,043 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fbf812d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:09,043 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2a5a45d4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:09,111 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@54db7217{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:09,112 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d5161b1{HTTP/1.1,[http/1.1]}{localhost:41026}
2020-04-02 05:07:09,112 [Thread-99] INFO  server.Server (Server.java:doStart(419)) - Started @12370ms
2020-04-02 05:07:09,146 [Thread-99] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40810
2020-04-02 05:07:09,157 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@472f1d1a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:09,157 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:09,158 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:09,159 [Thread-99] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:09,164 [Socket Reader #1 for port 40796] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40796
2020-04-02 05:07:09,190 [Thread-99] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40796
2020-04-02 05:07:09,197 [Thread-99] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:09,198 [Thread-99] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:09,198 [Thread-304] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39403 starting to offer service
2020-04-02 05:07:09,199 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:09,199 [IPC Server listener on 40796] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40796: starting
2020-04-02 05:07:09,220 [Thread-99] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40796 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:09,242 [Thread-304] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:39403
2020-04-02 05:07:09,247 [Thread-304] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:09,249 [Thread-304] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:09,269 [IPC Server handler 1 on 39403] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:09,272 [Thread-304] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:09,274 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:09,274 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:09,283 [Thread-304] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:09,283 [Thread-304] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:09,297 [Thread-304] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:09,297 [Thread-304] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:09,298 [Thread-304] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:09,301 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:09,302 [Thread-304] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:09,306 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:09,306 [Thread-304] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:09,307 [Thread-304] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:09,319 [Thread-304] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:09,322 [Thread-304] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:09,322 [Thread-304] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:09,322 [Thread-304] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:09,325 [Thread-304] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:09,326 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:09,326 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:09,328 [Thread-320] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:09,328 [Thread-319] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 49365
2020-04-02 05:07:09,338 [Thread-319] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 12ms
2020-04-02 05:07:09,338 [Thread-320] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 12ms
2020-04-02 05:07:09,338 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 13ms
2020-04-02 05:07:09,339 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:09,339 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:09,340 [Thread-322] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:09,340 [Thread-321] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:09,341 [Thread-322] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:07:09,341 [Thread-321] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 2ms
2020-04-02 05:07:09,351 [Thread-304] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 12ms
2020-04-02 05:07:09,352 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814393796 ms.
2020-04-02 05:07:09,352 [Thread-304] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:27 AM with interval of 21600000ms
2020-04-02 05:07:09,352 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814393795 ms.
2020-04-02 05:07:09,354 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:39403] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:39403 beginning handshake with NN
2020-04-02 05:07:09,359 [IPC Server handler 2 on 39403] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38564, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=40810, infoSecurePort=0, ipcPort=40796, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:09,359 [IPC Server handler 2 on 39403] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:38564
2020-04-02 05:07:09,359 [IPC Server handler 2 on 39403] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:38564).
2020-04-02 05:07:09,407 [IPC Server handler 3 on 39403] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:09,409 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2709)) - !dn.datanode.isDatanodeFullyStarted()
2020-04-02 05:07:09,409 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:09,410 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:39403] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:39403 successfully registered with NN
2020-04-02 05:07:09,410 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:39403] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:39403 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:09,422 [IPC Server handler 4 on 39403] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:38564
2020-04-02 05:07:09,422 [IPC Server handler 4 on 39403] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:38564
2020-04-02 05:07:09,434 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x97aa9b8dfb6b0771: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:09,442 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x97aa9b8dfb6b0771: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:38564, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=40810, infoSecurePort=0, ipcPort=40796, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:09,442 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x97aa9b8dfb6b0771: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:09,443 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x97aa9b8dfb6b0771: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:38564, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=40810, infoSecurePort=0, ipcPort=40796, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 3, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:09,449 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:39403] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x97aa9b8dfb6b0771,  containing 2 storage report(s), of which we sent 2. The reports had 4 total blocks and used 1 RPC(s). This took 1 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:09,450 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:39403] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:09,518 [IPC Server handler 6 on 39403] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:09,521 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:09,526 [IPC Server handler 7 on 39403] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:09,531 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:09,557 [IPC Server handler 8 on 39403] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:09,561 [Thread-99] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:09,562 [Thread-99] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:09,562 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 62, 62
2020-04-02 05:07:09,567 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 14 Number of transactions batched in Syncs: 61 Number of syncs: 3 SyncTimes(ms): 5 6 
2020-04-02 05:07:09,568 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000062-0000000000000000063
2020-04-02 05:07:09,568 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000062 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000062-0000000000000000063
2020-04-02 05:07:09,576 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000063 using no compression
2020-04-02 05:07:09,576 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000063 using no compression
2020-04-02 05:07:09,585 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000063 of size 635 bytes saved in 0 seconds .
2020-04-02 05:07:09,585 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000063 of size 635 bytes saved in 0 seconds .
2020-04-02 05:07:09,589 [Thread-99] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 43
2020-04-02 05:07:09,589 [Thread-99] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:09,590 [Thread-99] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:07:09,593 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 64
2020-04-02 05:07:09,604 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:09,604 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:09,604 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:09,604 [Thread-99] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40796 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:09,604 [Thread-99] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:09,605 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@28d06d13] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:09,615 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:09,615 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:09,639 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@54db7217{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:09,640 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d5161b1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:09,641 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2a5a45d4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:09,641 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fbf812d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:09,655 [Thread-99] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40796
2020-04-02 05:07:09,656 [IPC Server listener on 40796] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40796
2020-04-02 05:07:09,657 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:09,657 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:39403] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:09,657 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:39403] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:39403
2020-04-02 05:07:09,657 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:39403] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:09,657 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:39403] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:09,671 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:09,696 [Thread-99] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:09,696 [Thread-99] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:09,698 [Thread-99] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:09,698 [Thread-99] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:09,707 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:09,709 [Thread-99] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:09,710 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:09,710 [Thread-99] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 39403 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:09,710 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:09,710 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@15c4b009] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:09,710 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@5df72ad5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:09,710 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 64, 64
2020-04-02 05:07:09,717 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 8 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 2 
2020-04-02 05:07:09,718 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000064 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000064-0000000000000000065
2020-04-02 05:07:09,723 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000064 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000064-0000000000000000065
2020-04-02 05:07:09,723 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:09,724 [CacheReplicationMonitor(1660437874)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:09,730 [Thread-99] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39403
2020-04-02 05:07:09,731 [IPC Server listener on 39403] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39403
2020-04-02 05:07:09,734 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:09,734 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:09,735 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:09,744 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:09,745 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:09,746 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@331ac3d7{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:09,751 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@68b1fa40{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:09,751 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@135c734c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:09,752 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6bca3d2f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:09,754 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:09,759 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:09,759 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:09,768 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:09,769 [Thread-99] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:09,775 [Thread-99] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:09,813 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:09,814 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:09,814 [Thread-99] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:09,815 [Thread-99] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:09,820 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3dd3389a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:09,821 [Thread-99] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:09,821 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:09,823 [Thread-99] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:09,823 [Thread-99] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:09,823 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:09,825 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:09,825 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:09,826 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:09,826 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:09,827 [Thread-99] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:09,827 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:09,827 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35135
2020-04-02 05:07:09,828 [Thread-99] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:09,829 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@59235d17{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:09,834 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62345f32{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:09,840 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@40fcb654{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:09,841 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4b79f317{HTTP/1.1,[http/1.1]}{localhost:35135}
2020-04-02 05:07:09,841 [Thread-99] INFO  server.Server (Server.java:doStart(419)) - Started @13099ms
2020-04-02 05:07:09,843 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:09,844 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:09,844 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:09,844 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:09,844 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:09,844 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:09,844 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:09,845 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:09,845 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:09,845 [Thread-99] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:09,845 [Thread-99] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:09,846 [Thread-99] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:09,851 [Thread-99] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:09
2020-04-02 05:07:09,851 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:09,851 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:09,851 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:09,851 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:09,855 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:09,855 [Thread-99] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:09,856 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:09,857 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:09,857 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:09,857 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:09,857 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:09,860 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:09,860 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:09,860 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:09,860 [Thread-99] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:09,860 [Thread-99] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:09,860 [Thread-99] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:09,860 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:09,860 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:09,860 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:09,860 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:09,862 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:09,862 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:09,862 [Thread-99] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:09,863 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:09,863 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:09,863 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:09,863 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:09,863 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:09,863 [Thread-99] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:09,866 [Thread-99] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:09,867 [Thread-99] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:09,869 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:09,870 [Thread-99] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:09,870 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000063, cpktTxId=0000000000000000063)
2020-04-02 05:07:09,872 [Thread-99] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 3 INodes.
2020-04-02 05:07:09,873 [Thread-99] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:09,873 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 63 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000063
2020-04-02 05:07:09,873 [Thread-99] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@46e1730 expecting start txid #64
2020-04-02 05:07:09,873 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000064-0000000000000000065, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000064-0000000000000000065 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:09,874 [Thread-99] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000064-0000000000000000065' to transaction ID 64
2020-04-02 05:07:09,874 [Thread-99] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000064-0000000000000000065, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000064-0000000000000000065 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:09,874 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:09,875 [Thread-99] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 66
2020-04-02 05:07:09,898 [Thread-99] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:09,899 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 34 msecs
2020-04-02 05:07:09,899 [Thread-99] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:09,899 [Thread-99] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:09,900 [Socket Reader #1 for port 34247] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34247
2020-04-02 05:07:09,914 [Thread-99] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:34247 to access this namenode/service.
2020-04-02 05:07:09,914 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:09,959 [Thread-99] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:09,962 [Thread-99] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:09,962 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:09,968 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:09,968 [Thread-99] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:09,976 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:09,979 [IPC Server listener on 34247] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34247: starting
2020-04-02 05:07:10,022 [Thread-99] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:34247
2020-04-02 05:07:10,025 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:10,026 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:10,026 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:10,026 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:10,026 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:10,026 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 60 msec
2020-04-02 05:07:10,026 [Thread-99] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:10,026 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:10,027 [Thread-99] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 1 milliseconds
name space=3
storage space=8192
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:10,038 [Thread-99] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 34247 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:10,055 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:10,056 [Thread-99] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:10,057 [Thread-99] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:10,060 [CacheReplicationMonitor(962772694)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:10,094 [Thread-99] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:10,095 [Thread-99] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:10,095 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:10,095 [Thread-99] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:10,096 [Thread-99] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:10,096 [Thread-99] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:10,096 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:10,097 [Thread-99] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36298
2020-04-02 05:07:10,097 [Thread-99] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:10,097 [Thread-99] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:10,098 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:10,099 [Thread-99] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:10,101 [Thread-99] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:10,101 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:10,102 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:10,103 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:10,103 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:10,103 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:10,105 [Thread-99] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46252
2020-04-02 05:07:10,105 [Thread-99] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:10,106 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@148d1e19{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:10,107 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22c8fb06{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:10,114 [Thread-99] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@771f8bb6{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:10,116 [Thread-99] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5787100c{HTTP/1.1,[http/1.1]}{localhost:46252}
2020-04-02 05:07:10,116 [Thread-99] INFO  server.Server (Server.java:doStart(419)) - Started @13374ms
2020-04-02 05:07:10,137 [Thread-99] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:44152
2020-04-02 05:07:10,138 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:10,138 [Thread-99] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:10,139 [Thread-99] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:10,140 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@35fd63ea] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:10,140 [Socket Reader #1 for port 36086] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36086
2020-04-02 05:07:10,149 [Thread-99] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:36086
2020-04-02 05:07:10,157 [Thread-99] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:10,157 [Thread-99] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:10,158 [Thread-376] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34247 starting to offer service
2020-04-02 05:07:10,170 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:10,171 [IPC Server listener on 36086] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36086: starting
2020-04-02 05:07:10,172 [Thread-99] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 36086 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:10,191 [IPC Server handler 1 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,191 [Thread-376] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34247
2020-04-02 05:07:10,193 [Thread-376] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:10,195 [Thread-376] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:10,197 [Thread-376] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:10,198 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:10,198 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:10,207 [Thread-376] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:10,208 [Thread-376] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:10,217 [Thread-376] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:10,218 [Thread-376] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:10,219 [Thread-376] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:10,221 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:10,221 [Thread-376] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:10,224 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:10,225 [Thread-376] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:10,225 [Thread-376] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:10,226 [Thread-376] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:10,227 [Thread-376] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:10,227 [Thread-376] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:10,227 [Thread-376] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:10,253 [Thread-376] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:10,254 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:10,255 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:10,255 [Thread-391] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 49365
2020-04-02 05:07:10,256 [Thread-392] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:10,278 [Thread-392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 23ms
2020-04-02 05:07:10,283 [Thread-391] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 29ms
2020-04-02 05:07:10,283 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 29ms
2020-04-02 05:07:10,283 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:10,283 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:10,285 [Thread-394] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:10,285 [Thread-393] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:10,285 [Thread-394] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:10,288 [Thread-393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 5ms
2020-04-02 05:07:10,290 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 7ms
2020-04-02 05:07:10,291 [Thread-376] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:35 AM with interval of 21600000ms
2020-04-02 05:07:10,294 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814392853 ms.
2020-04-02 05:07:10,294 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814392854 ms.
2020-04-02 05:07:10,294 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34247] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:34247 beginning handshake with NN
2020-04-02 05:07:10,312 [IPC Server handler 5 on 34247] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36298, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=44152, infoSecurePort=0, ipcPort=36086, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:10,312 [IPC Server handler 5 on 34247] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36298
2020-04-02 05:07:10,312 [IPC Server handler 5 on 34247] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:36298).
2020-04-02 05:07:10,315 [IPC Server handler 6 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,325 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:10,326 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:10,325 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34247] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:34247 successfully registered with NN
2020-04-02 05:07:10,329 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34247] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34247 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:10,341 [IPC Server handler 8 on 34247] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:36298
2020-04-02 05:07:10,342 [IPC Server handler 8 on 34247] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:36298
2020-04-02 05:07:10,354 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x180f12f12effe725: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:10,354 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x180f12f12effe725: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:36298, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=44152, infoSecurePort=0, ipcPort=36086, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:10,354 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x180f12f12effe725: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:10,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x180f12f12effe725: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:36298, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=44152, infoSecurePort=0, ipcPort=36086, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 3, hasStaleStorage: false, processing time: 6 msecs, invalidatedBlocks: 0
2020-04-02 05:07:10,361 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34247] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x180f12f12effe725,  containing 2 storage report(s), of which we sent 2. The reports had 4 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:10,361 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34247] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:10,427 [IPC Server handler 4 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,428 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:10,431 [IPC Server handler 3 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,432 [Thread-99] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:10,442 [IPC Server handler 2 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p2/file	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,458 [IPC Server handler 7 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/.reserved/raw/p2/file	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testCreateXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testCreateXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRawXAttrs
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:10,465 [IPC Server handler 0 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p3	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:10,470 [IPC Server handler 1 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,475 [IPC Server handler 6 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,477 [IPC Server handler 5 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,481 [IPC Server handler 8 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,483 [IPC Server handler 9 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,485 [IPC Server handler 4 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,498 [IPC Server handler 3 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,500 [IPC Server handler 2 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,501 [IPC Server handler 7 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,504 [IPC Server handler 0 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,506 [IPC Server handler 1 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,519 [IPC Server handler 6 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/.reserved/raw/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,525 [IPC Server handler 5 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,534 [IPC Server handler 8 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,540 [IPC Server handler 9 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,541 [IPC Server handler 4 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,556 [IPC Server handler 3 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,567 [IPC Server handler 2 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,569 [IPC Server handler 7 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,607 [IPC Server handler 0 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,608 [IPC Server handler 0 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 34247, call Call#155 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: raw.a1
2020-04-02 05:07:10,622 [IPC Server handler 1 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,622 [IPC Server handler 1 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 34247, call Call#156 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: Access denied for user user. Superuser privilege is required
2020-04-02 05:07:10,629 [IPC Server handler 6 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,630 [IPC Server handler 6 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 34247, call Call#157 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p3":root:supergroup:drwxr-x---
2020-04-02 05:07:10,637 [IPC Server handler 5 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,638 [IPC Server handler 5 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 34247, call Call#158 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p3":root:supergroup:drwxr-x---
2020-04-02 05:07:10,641 [IPC Server handler 8 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,641 [IPC Server handler 8 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 34247, call Call#159 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p3":root:supergroup:drwxr-x---
2020-04-02 05:07:10,654 [IPC Server handler 9 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,654 [IPC Server handler 9 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 9 on 34247, call Call#160 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: raw.a1
2020-04-02 05:07:10,658 [IPC Server handler 4 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,662 [IPC Server handler 3 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,662 [IPC Server handler 3 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 34247, call Call#162 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p3":root:supergroup:drwxr-x---
2020-04-02 05:07:10,665 [IPC Server handler 2 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,665 [IPC Server handler 2 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34247, call Call#163 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: raw.a1
2020-04-02 05:07:10,674 [IPC Server handler 7 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,675 [IPC Server handler 7 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 34247, call Call#164 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p3":root:supergroup:drwxr-x---
2020-04-02 05:07:10,682 [IPC Server handler 0 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/.reserved/raw/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,683 [IPC Server handler 0 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 34247, call Call#165 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:38442: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p3":root:supergroup:drwxr-x---
2020-04-02 05:07:10,689 [IPC Server handler 1 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p3	dst=null	perm=root:supergroup:rwxr-x--x	proto=rpc
2020-04-02 05:07:10,698 [IPC Server handler 6 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p3/child3	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:10,700 [IPC Server handler 5 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p3/child3	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:10,705 [IPC Server handler 8 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/p3/child3	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:10,708 [IPC Server handler 9 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/.reserved/raw/p3/child3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,710 [IPC Server handler 4 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/.reserved/raw/p3	dst=null	perm=root:supergroup:rwxr-x--x	proto=rpc
2020-04-02 05:07:10,712 [IPC Server handler 3 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/foo	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:10,720 [IPC Server handler 2 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setOwner	src=/foo	dst=null	perm=user:mygroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:10,722 [IPC Server handler 7 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/foo	dst=null	perm=user:mygroup:rwx-----x	proto=rpc
2020-04-02 05:07:10,725 [IPC Server handler 0 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/foo	dst=null	perm=user:mygroup:rwx-----x	proto=rpc
2020-04-02 05:07:10,731 [IPC Server handler 1 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo/bar	dst=null	perm=user:mygroup:rw-r--r--	proto=rpc
2020-04-02 05:07:10,754 [IPC Server handler 6 on 34247] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:36298 for /foo/bar
2020-04-02 05:07:10,771 [DataXceiver for client DFSClient_NONMAPREDUCE_-393855798_1352 at /127.0.0.1:56806 [Receiving block BP-1627096859-172.17.0.17-1585804019062:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1627096859-172.17.0.17-1585804019062:blk_1073741829_1005 src: /127.0.0.1:56806 dest: /127.0.0.1:36298
2020-04-02 05:07:10,814 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56806, dest: /127.0.0.1:36298, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-393855798_1352, offset: 0, srvID: 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, blockid: BP-1627096859-172.17.0.17-1585804019062:blk_1073741829_1005, duration(ns): 39483775
2020-04-02 05:07:10,814 [PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1627096859-172.17.0.17-1585804019062:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:07:10,822 [IPC Server handler 9 on 34247] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /foo/bar is closed by DFSClient_NONMAPREDUCE_-393855798_1352
2020-04-02 05:07:10,827 [IPC Server handler 4 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/foo/bar	dst=null	perm=user:mygroup:rwxr-----	proto=rpc
2020-04-02 05:07:10,836 [IPC Server handler 3 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/.reserved/raw/foo/bar	dst=null	perm=user:mygroup:rwxr-----	proto=rpc
2020-04-02 05:07:10,839 [IPC Server handler 2 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/.reserved/raw/foo/bar	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,850 [IPC Server handler 7 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=fakeUser (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p3	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,850 [IPC Server handler 7 on 34247] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 34247, call Call#184 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:38458: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: raw.a1
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRawXAttrs
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRawXAttrs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRemoveXAttr
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:10,861 [IPC Server handler 0 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p4	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:10,863 [IPC Server handler 1 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,866 [IPC Server handler 6 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,886 [IPC Server handler 5 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,889 [IPC Server handler 8 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,894 [IPC Server handler 9 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,895 [IPC Server handler 4 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:10,900 [IPC Server handler 3 on 34247] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:10,904 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:10,905 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:10,905 [Thread-406] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 36086 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:10,905 [Thread-406] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:10,905 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@11bc4282] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:10,917 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:10,919 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:10,942 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@771f8bb6{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:10,946 [Thread-406] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5787100c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:10,960 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22c8fb06{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:10,978 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@148d1e19{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:10,982 [Thread-406] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36086
2020-04-02 05:07:10,985 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:10,985 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34247] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:10,985 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34247] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:34247
2020-04-02 05:07:10,985 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34247] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:10,985 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34247] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:10,985 [IPC Server listener on 36086] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36086
2020-04-02 05:07:11,007 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:11,041 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:11,055 [Thread-406] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:11,056 [Thread-406] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:11,059 [Thread-406] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:11,060 [Thread-406] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:11,066 [Thread-406] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:11,066 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:11,066 [Thread-406] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 34247 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:11,066 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:11,066 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 66, 105
2020-04-02 05:07:11,066 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@6149faa2] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:11,067 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4e6eef2a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:11,067 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 41 Total time for transactions(ms): 16 Number of transactions batched in Syncs: 67 Number of syncs: 40 SyncTimes(ms): 5 5 
2020-04-02 05:07:11,068 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000066 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000066-0000000000000000106
2020-04-02 05:07:11,075 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000066 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000066-0000000000000000106
2020-04-02 05:07:11,075 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:11,077 [CacheReplicationMonitor(962772694)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:11,080 [Thread-406] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34247
2020-04-02 05:07:11,083 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:11,086 [IPC Server listener on 34247] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34247
2020-04-02 05:07:11,083 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:11,083 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:11,096 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:11,096 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:11,119 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@40fcb654{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:11,123 [Thread-406] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4b79f317{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:11,125 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62345f32{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:11,134 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@59235d17{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:11,137 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:11,138 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:11,138 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:11,155 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:11,158 [Thread-406] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:11,171 [Thread-406] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:11,178 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:11,179 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:11,179 [Thread-406] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:11,180 [Thread-406] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:11,186 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@405620b2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:11,186 [Thread-406] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:11,186 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:11,188 [Thread-406] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:11,189 [Thread-406] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:11,189 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:11,190 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:11,191 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:11,191 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:11,191 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:11,193 [Thread-406] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:11,193 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:11,194 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45187
2020-04-02 05:07:11,194 [Thread-406] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:11,204 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@57f778b9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:11,206 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@31871b60{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:11,231 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1e3b821{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:11,232 [Thread-406] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@45aee076{HTTP/1.1,[http/1.1]}{localhost:45187}
2020-04-02 05:07:11,235 [Thread-406] INFO  server.Server (Server.java:doStart(419)) - Started @14493ms
2020-04-02 05:07:11,237 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:11,238 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:11,238 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:11,238 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:11,238 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:11,238 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:11,238 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:11,239 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:11,239 [Thread-406] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:11,239 [Thread-406] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:11,239 [Thread-406] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:11,240 [Thread-406] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:11,240 [Thread-406] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:11
2020-04-02 05:07:11,240 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:11,240 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:11,240 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:11,240 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:11,286 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:11,286 [Thread-406] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:11,287 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:11,288 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:11,288 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:11,288 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:11,288 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:11,294 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:11,294 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:11,294 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:11,294 [Thread-406] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:11,294 [Thread-406] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:11,294 [Thread-406] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:11,294 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:11,294 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:11,295 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:11,295 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:11,295 [Thread-406] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:11,295 [Thread-406] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:11,295 [Thread-406] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:11,296 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:11,296 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:11,296 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:11,296 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:11,296 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:11,296 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:11,311 [Thread-406] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:11,312 [Thread-406] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:11,314 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:11,314 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:11,315 [Thread-406] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000063, cpktTxId=0000000000000000063)
2020-04-02 05:07:11,316 [Thread-406] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 3 INodes.
2020-04-02 05:07:11,316 [Thread-406] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:11,316 [Thread-406] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 63 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000063
2020-04-02 05:07:11,317 [Thread-406] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@576e5b4e expecting start txid #64
2020-04-02 05:07:11,317 [Thread-406] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000064-0000000000000000065, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000064-0000000000000000065 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:11,317 [Thread-406] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000064-0000000000000000065' to transaction ID 64
2020-04-02 05:07:11,324 [Thread-406] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000064-0000000000000000065, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000064-0000000000000000065 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:11,324 [Thread-406] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@5380d1f expecting start txid #66
2020-04-02 05:07:11,324 [Thread-406] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000066-0000000000000000106, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000066-0000000000000000106 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:11,324 [Thread-406] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000066-0000000000000000106' to transaction ID 64
2020-04-02 05:07:11,330 [Thread-406] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000066-0000000000000000106, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000066-0000000000000000106 of size 2177 edits # 41 loaded in 0 seconds
2020-04-02 05:07:11,331 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:11,331 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 107
2020-04-02 05:07:11,342 [Thread-406] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:11,342 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 45 msecs
2020-04-02 05:07:11,342 [Thread-406] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:11,343 [Thread-406] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:11,343 [Socket Reader #1 for port 40645] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40645
2020-04-02 05:07:11,348 [Thread-406] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:40645 to access this namenode/service.
2020-04-02 05:07:11,348 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:11,384 [Thread-406] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:11,401 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:11,402 [Thread-406] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:11,402 [Thread-406] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:11,402 [Thread-406] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:11,407 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:11,423 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:11,423 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:11,423 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:11,423 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:11,423 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:11,423 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 22 msec
2020-04-02 05:07:11,425 [IPC Server listener on 40645] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40645: starting
2020-04-02 05:07:11,434 [Thread-406] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:40645
2020-04-02 05:07:11,434 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:11,434 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:11,445 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 11 milliseconds
name space=7
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:11,474 [Thread-406] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 40645 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:11,475 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:11,476 [Thread-406] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:11,477 [Thread-406] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:11,487 [CacheReplicationMonitor(402587416)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:11,489 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:11,489 [Thread-406] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:11,489 [Thread-406] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:11,490 [Thread-406] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:11,490 [Thread-406] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:11,490 [Thread-406] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:11,490 [Thread-406] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:11,491 [Thread-406] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34967
2020-04-02 05:07:11,491 [Thread-406] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:11,491 [Thread-406] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:11,493 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:11,495 [Thread-406] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:11,495 [Thread-406] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:11,495 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:11,497 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:11,499 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:11,499 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:11,499 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:11,500 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33482
2020-04-02 05:07:11,500 [Thread-406] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:11,510 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7396241f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:11,511 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6e34a6fa{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:11,520 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@52f44d0a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:11,523 [Thread-406] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5bcee02c{HTTP/1.1,[http/1.1]}{localhost:33482}
2020-04-02 05:07:11,524 [Thread-406] INFO  server.Server (Server.java:doStart(419)) - Started @14781ms
2020-04-02 05:07:11,562 [Thread-406] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40606
2020-04-02 05:07:11,563 [Thread-406] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:11,563 [Thread-406] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:11,563 [Thread-406] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:11,570 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@55c35e70] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:11,570 [Socket Reader #1 for port 33833] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33833
2020-04-02 05:07:11,581 [Thread-406] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33833
2020-04-02 05:07:11,595 [Thread-406] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:11,595 [Thread-406] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:11,596 [Thread-458] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40645 starting to offer service
2020-04-02 05:07:11,597 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:11,597 [IPC Server listener on 33833] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33833: starting
2020-04-02 05:07:11,603 [Thread-406] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33833 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:11,652 [IPC Server handler 0 on 40645] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:11,653 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:11,653 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:11,653 [Thread-458] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40645
2020-04-02 05:07:11,655 [Thread-458] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:11,656 [Thread-458] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:11,658 [Thread-458] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:11,669 [Thread-458] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:11,670 [Thread-458] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:11,679 [Thread-458] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:11,679 [Thread-458] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:11,680 [Thread-458] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:11,682 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:11,682 [Thread-458] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:11,693 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:11,695 [Thread-458] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:11,695 [Thread-458] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:11,696 [Thread-458] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:11,697 [Thread-458] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:11,697 [Thread-458] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:11,697 [Thread-458] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:11,697 [Thread-458] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:11,698 [Thread-473] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:11,699 [Thread-473] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 50404
2020-04-02 05:07:11,702 [Thread-474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:11,703 [Thread-474] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:11,716 [Thread-474] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 14ms
2020-04-02 05:07:11,753 [Thread-473] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 55ms
2020-04-02 05:07:11,753 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 57ms
2020-04-02 05:07:11,762 [Thread-476] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:11,782 [Thread-475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:11,783 [Thread-475] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:11,783 [Thread-475] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:07:11,783 [Thread-476] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:11,783 [IPC Server handler 1 on 40645] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:11,784 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:11,784 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:11,785 [Thread-476] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 23ms
2020-04-02 05:07:11,786 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 32ms
2020-04-02 05:07:11,787 [Thread-458] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:41 AM with interval of 21600000ms
2020-04-02 05:07:11,787 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814391360 ms.
2020-04-02 05:07:11,787 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814391361 ms.
2020-04-02 05:07:11,793 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:40645] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:40645 beginning handshake with NN
2020-04-02 05:07:11,798 [IPC Server handler 5 on 40645] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34967, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=40606, infoSecurePort=0, ipcPort=33833, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:11,798 [IPC Server handler 5 on 40645] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34967
2020-04-02 05:07:11,798 [IPC Server handler 5 on 40645] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:34967).
2020-04-02 05:07:11,834 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:40645] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:40645 successfully registered with NN
2020-04-02 05:07:11,838 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:40645] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40645 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:11,870 [IPC Server handler 6 on 40645] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:34967
2020-04-02 05:07:11,870 [IPC Server handler 6 on 40645] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:34967
2020-04-02 05:07:11,874 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf4c6981b1d4b0ec5: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:11,874 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf4c6981b1d4b0ec5: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:34967, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=40606, infoSecurePort=0, ipcPort=33833, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:11,874 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf4c6981b1d4b0ec5: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:11,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf4c6981b1d4b0ec5: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:34967, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=40606, infoSecurePort=0, ipcPort=33833, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 4, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:07:11,885 [IPC Server handler 3 on 40645] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:11,886 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:40645] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf4c6981b1d4b0ec5,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 14 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:11,886 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:40645] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:11,886 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:11,894 [IPC Server handler 9 on 40645] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:11,895 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:11,898 [IPC Server handler 8 on 40645] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:11,901 [Thread-406] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:11,902 [Thread-406] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:11,902 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 107, 107
2020-04-02 05:07:11,914 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 10 Number of transactions batched in Syncs: 106 Number of syncs: 3 SyncTimes(ms): 2 2 
2020-04-02 05:07:11,915 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000107 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000107-0000000000000000108
2020-04-02 05:07:11,915 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000107 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000107-0000000000000000108
2020-04-02 05:07:11,930 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000108 using no compression
2020-04-02 05:07:11,930 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000108 using no compression
2020-04-02 05:07:11,945 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000108 of size 878 bytes saved in 0 seconds .
2020-04-02 05:07:11,945 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000108 of size 878 bytes saved in 0 seconds .
2020-04-02 05:07:11,955 [Thread-406] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 63
2020-04-02 05:07:11,955 [Thread-406] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2020-04-02 05:07:11,955 [Thread-406] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000043, cpktTxId=0000000000000000043)
2020-04-02 05:07:11,959 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 109
2020-04-02 05:07:11,978 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:11,978 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:11,978 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:11,978 [Thread-406] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33833 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:11,978 [Thread-406] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:11,979 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@34944c46] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:11,980 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:11,981 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:11,992 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@52f44d0a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:11,992 [Thread-406] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5bcee02c{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:11,993 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6e34a6fa{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:11,993 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7396241f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:12,014 [Thread-406] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33833
2020-04-02 05:07:12,022 [IPC Server listener on 33833] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33833
2020-04-02 05:07:12,032 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:12,033 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:40645] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:12,033 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:40645] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:40645
2020-04-02 05:07:12,034 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:40645] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:12,034 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:40645] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:12,045 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:12,080 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:12,089 [Thread-406] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:12,089 [Thread-406] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:12,090 [Thread-406] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:12,091 [Thread-406] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:12,093 [Thread-406] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:12,093 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:12,093 [Thread-406] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 40645 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:12,093 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:12,098 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@79cfac4c] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:12,098 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@600c83e9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:12,098 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 109, 109
2020-04-02 05:07:12,113 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 7 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 2 
2020-04-02 05:07:12,115 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000109 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000109-0000000000000000110
2020-04-02 05:07:12,116 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000109 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000109-0000000000000000110
2020-04-02 05:07:12,116 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:12,116 [CacheReplicationMonitor(402587416)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:12,141 [Thread-406] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40645
2020-04-02 05:07:12,148 [IPC Server listener on 40645] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40645
2020-04-02 05:07:12,149 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:12,149 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:12,149 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:12,157 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:12,161 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:12,162 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1e3b821{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:12,167 [Thread-406] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@45aee076{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:12,167 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@31871b60{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:12,168 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@57f778b9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:12,171 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:12,174 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:12,175 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:12,181 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:12,182 [Thread-406] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:12,186 [Thread-406] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:12,188 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:12,188 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:12,189 [Thread-406] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:12,194 [Thread-406] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:12,200 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6026a811] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:12,200 [Thread-406] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:12,200 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:12,202 [Thread-406] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:12,203 [Thread-406] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:12,204 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:12,205 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:12,206 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:12,206 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:12,206 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:12,208 [Thread-406] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:12,208 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:12,208 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39538
2020-04-02 05:07:12,208 [Thread-406] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:12,211 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@37c38d1c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:12,212 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@78b71a92{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:12,218 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4456dac1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:12,219 [Thread-406] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2f7ae103{HTTP/1.1,[http/1.1]}{localhost:39538}
2020-04-02 05:07:12,220 [Thread-406] INFO  server.Server (Server.java:doStart(419)) - Started @15477ms
2020-04-02 05:07:12,252 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:12,253 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:12,253 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:12,253 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:12,253 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:12,253 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:12,254 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:12,254 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:12,254 [Thread-406] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:12,254 [Thread-406] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:12,255 [Thread-406] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:12,255 [Thread-406] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:12,255 [Thread-406] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:12
2020-04-02 05:07:12,255 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:12,255 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:12,256 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:12,256 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:12,267 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:12,268 [Thread-406] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:12,268 [Thread-406] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:12,268 [Thread-406] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:12,268 [Thread-406] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:12,268 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:12,269 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:12,269 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:12,269 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:12,269 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:12,269 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:12,269 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:12,270 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:12,270 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:12,270 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:12,271 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:12,290 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:12,290 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:12,291 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:12,291 [Thread-406] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:12,291 [Thread-406] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:12,291 [Thread-406] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:12,291 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:12,292 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:12,292 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:12,292 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:12,294 [Thread-406] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:12,294 [Thread-406] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:12,294 [Thread-406] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:12,295 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:12,295 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:12,295 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:12,296 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:12,296 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:12,296 [Thread-406] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:12,301 [Thread-406] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:12,302 [Thread-406] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:12,304 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:12,305 [Thread-406] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:12,306 [Thread-406] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000108, cpktTxId=0000000000000000108)
2020-04-02 05:07:12,307 [Thread-406] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 7 INodes.
2020-04-02 05:07:12,308 [Thread-406] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:12,309 [Thread-406] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 108 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000108
2020-04-02 05:07:12,309 [Thread-406] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@44ac765d expecting start txid #109
2020-04-02 05:07:12,309 [Thread-406] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000109-0000000000000000110, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000109-0000000000000000110 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:12,309 [Thread-406] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000109-0000000000000000110' to transaction ID 109
2020-04-02 05:07:12,310 [Thread-406] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000109-0000000000000000110, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000109-0000000000000000110 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:12,310 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:12,313 [Thread-406] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 111
2020-04-02 05:07:12,328 [Thread-406] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:12,328 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 30 msecs
2020-04-02 05:07:12,329 [Thread-406] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:12,329 [Thread-406] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:12,330 [Socket Reader #1 for port 34459] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34459
2020-04-02 05:07:12,345 [Thread-406] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:34459 to access this namenode/service.
2020-04-02 05:07:12,346 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:12,391 [Thread-406] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:12,393 [Thread-406] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:12,403 [Thread-406] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:12,404 [Thread-406] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:12,404 [Thread-406] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:12,413 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:12,413 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:12,413 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:12,413 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:12,418 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:12,418 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2020-04-02 05:07:12,418 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:12,422 [IPC Server listener on 34459] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34459: starting
2020-04-02 05:07:12,448 [Thread-406] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:34459
2020-04-02 05:07:12,449 [Thread-406] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:12,449 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:12,494 [Thread-406] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 45 milliseconds
name space=7
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:12,501 [Thread-406] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 34459 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:12,502 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:12,503 [Thread-406] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:12,504 [Thread-406] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:12,505 [Thread-406] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:12,505 [Thread-406] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:12,505 [Thread-406] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:12,505 [Thread-406] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:12,526 [Thread-406] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:12,526 [Thread-406] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:12,526 [Thread-406] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:12,527 [Thread-406] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37478
2020-04-02 05:07:12,527 [Thread-406] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:12,527 [Thread-406] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:12,526 [CacheReplicationMonitor(546769656)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:12,528 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:12,529 [Thread-406] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:12,532 [Thread-406] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:12,532 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:12,533 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:12,533 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:12,533 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:12,533 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:12,534 [Thread-406] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44040
2020-04-02 05:07:12,534 [Thread-406] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:12,535 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@36c49883{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:12,536 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@23fd20df{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:12,541 [Thread-406] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@60c0ced0{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:12,542 [Thread-406] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a6a9b61{HTTP/1.1,[http/1.1]}{localhost:44040}
2020-04-02 05:07:12,542 [Thread-406] INFO  server.Server (Server.java:doStart(419)) - Started @15800ms
2020-04-02 05:07:12,562 [Thread-406] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39837
2020-04-02 05:07:12,563 [Thread-406] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:12,563 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4fee48ab] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:12,563 [Thread-406] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:12,564 [Thread-406] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:12,565 [Socket Reader #1 for port 42550] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42550
2020-04-02 05:07:12,572 [Thread-406] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42550
2020-04-02 05:07:12,577 [Thread-406] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:12,578 [Thread-406] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:12,579 [Thread-530] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34459 starting to offer service
2020-04-02 05:07:12,599 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:12,603 [IPC Server listener on 42550] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42550: starting
2020-04-02 05:07:12,604 [Thread-406] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42550 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:12,636 [IPC Server handler 2 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,645 [Thread-530] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:34459
2020-04-02 05:07:12,647 [Thread-530] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:12,647 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:12,648 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:12,649 [Thread-530] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:12,655 [Thread-530] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:12,665 [Thread-530] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:12,666 [Thread-530] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:12,681 [Thread-530] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:12,681 [Thread-530] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:12,685 [Thread-530] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:12,688 [Thread-530] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:12,690 [Thread-530] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:12,695 [Thread-530] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:12,697 [Thread-530] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:12,697 [Thread-530] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:12,699 [Thread-530] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:12,700 [Thread-530] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:12,700 [Thread-530] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:12,700 [Thread-530] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:12,700 [Thread-530] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:12,703 [Thread-545] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:12,703 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:12,704 [Thread-546] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:12,704 [Thread-545] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 50404
2020-04-02 05:07:12,713 [Thread-546] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 11ms
2020-04-02 05:07:12,720 [Thread-545] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 17ms
2020-04-02 05:07:12,721 [Thread-530] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 21ms
2020-04-02 05:07:12,723 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:12,732 [Thread-548] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:12,732 [Thread-547] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:12,733 [Thread-547] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 10ms
2020-04-02 05:07:12,733 [Thread-548] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:12,738 [Thread-548] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 5ms
2020-04-02 05:07:12,738 [Thread-530] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 16ms
2020-04-02 05:07:12,739 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814390408 ms.
2020-04-02 05:07:12,739 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814390409 ms.
2020-04-02 05:07:12,740 [Thread-530] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:43 AM with interval of 21600000ms
2020-04-02 05:07:12,742 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34459] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:34459 beginning handshake with NN
2020-04-02 05:07:12,746 [IPC Server handler 0 on 34459] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37478, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=39837, infoSecurePort=0, ipcPort=42550, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:12,747 [IPC Server handler 0 on 34459] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:37478
2020-04-02 05:07:12,747 [IPC Server handler 0 on 34459] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:37478).
2020-04-02 05:07:12,764 [IPC Server handler 3 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,766 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34459] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:34459 successfully registered with NN
2020-04-02 05:07:12,766 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34459] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:34459 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:12,769 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:37478
2020-04-02 05:07:12,769 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:12,774 [IPC Server handler 4 on 34459] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:37478
2020-04-02 05:07:12,774 [IPC Server handler 4 on 34459] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:37478
2020-04-02 05:07:12,782 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x31934868029344de: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:12,782 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x31934868029344de: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:37478, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=39837, infoSecurePort=0, ipcPort=42550, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:12,783 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x31934868029344de: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:12,785 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x31934868029344de: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:37478, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=39837, infoSecurePort=0, ipcPort=42550, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 4, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:07:12,786 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34459] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x31934868029344de,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:12,786 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34459] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:12,871 [IPC Server handler 5 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,872 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:12,875 [IPC Server handler 6 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,876 [Thread-406] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:12,878 [IPC Server handler 8 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p4	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,881 [IPC Server handler 9 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p4	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRemoveXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRemoveXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testListXAttrs
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:12,894 [IPC Server handler 1 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 34459, call Call#212 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:47428: java.io.FileNotFoundException: cannot find /p5
2020-04-02 05:07:12,916 [IPC Server handler 2 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p5	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:12,930 [IPC Server handler 0 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:12,932 [IPC Server handler 3 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p5	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,938 [IPC Server handler 4 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:12,941 [IPC Server handler 7 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p5	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:12,946 [IPC Server handler 5 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p5	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,951 [IPC Server handler 6 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p5	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:12,957 [IPC Server handler 8 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p5/child5	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:12,962 [IPC Server handler 9 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p5/child5	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:12,964 [IPC Server handler 1 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p5/child5	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:12,974 [IPC Server handler 2 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p5/child5	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,975 [IPC Server handler 2 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34459, call Call#223 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:47448: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p5":root:supergroup:drwx---r--
2020-04-02 05:07:12,982 [IPC Server handler 0 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p5	dst=null	perm=root:supergroup:rwx----w-	proto=rpc
2020-04-02 05:07:12,991 [IPC Server handler 3 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p5/child5	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,992 [IPC Server handler 3 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 34459, call Call#225 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:47448: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p5":root:supergroup:drwx----w-
2020-04-02 05:07:12,995 [IPC Server handler 4 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p5	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:12,998 [IPC Server handler 7 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p5/child5	dst=null	perm=null	proto=rpc
2020-04-02 05:07:12,999 [IPC Server handler 7 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 34459, call Call#227 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.listXAttrs from 127.0.0.1:47448: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p5/child5":root:supergroup:drwx------
2020-04-02 05:07:13,008 [IPC Server handler 5 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p5/child5	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:13,014 [IPC Server handler 6 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p5/child5	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:13,017 [IPC Server handler 8 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p5/child5	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,019 [IPC Server handler 9 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=listXAttrs	src=/p5/child5	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testListXAttrs
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testListXAttrs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRemoveXAttrPermissions
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:13,030 [IPC Server handler 1 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p6	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:13,038 [IPC Server handler 2 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,042 [IPC Server handler 0 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,046 [IPC Server handler 3 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,055 [IPC Server handler 4 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,070 [IPC Server handler 7 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,075 [IPC Server handler 5 on 34459] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 5 on 34459, call Call#238 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:47428
java.io.IOException: No matching attributes found for remove operation
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.removeXAttr(FSDirXAttrOp.java:184)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.removeXAttr(FSNamesystem.java:7775)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.removeXAttr(NameNodeRpcServer.java:2200)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.removeXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1648)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:13,086 [IPC Server handler 6 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,110 [IPC Server handler 8 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,110 [IPC Server handler 8 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 34459, call Call#240 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:47450: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: trusted.foo
2020-04-02 05:07:13,121 [IPC Server handler 9 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p6	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,143 [IPC Server handler 1 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:13,211 [IPC Server handler 2 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,211 [IPC Server handler 2 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34459, call Call#243 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:47450: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=WRITE, inode="/p6":root:supergroup:drwx------
2020-04-02 05:07:13,219 [IPC Server handler 0 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p6/child6	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:13,226 [IPC Server handler 3 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6/child6	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:13,231 [IPC Server handler 4 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p6/child6	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:13,236 [IPC Server handler 7 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p6/child6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,236 [IPC Server handler 7 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 7 on 34459, call Call#247 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:47450: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p6":root:supergroup:drwx------
2020-04-02 05:07:13,241 [IPC Server handler 5 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:13,244 [IPC Server handler 6 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p6/child6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,244 [IPC Server handler 6 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 6 on 34459, call Call#249 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:47450: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p6":root:supergroup:drwx---r--
2020-04-02 05:07:13,247 [IPC Server handler 8 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:13,251 [IPC Server handler 9 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6/child6	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:13,254 [IPC Server handler 1 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p6/child6	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,254 [IPC Server handler 1 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 34459, call Call#252 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:47450: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=WRITE, inode="/p6/child6":root:supergroup:drwx-----x
2020-04-02 05:07:13,257 [IPC Server handler 2 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:13,261 [IPC Server handler 0 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p6/child6	dst=null	perm=root:supergroup:rwx---rw-	proto=rpc
2020-04-02 05:07:13,270 [IPC Server handler 3 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p6/child6	dst=null	perm=root:supergroup:rwx---rw-	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRemoveXAttrPermissions
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRemoveXAttrPermissions
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testXAttrAcl
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:13,289 [IPC Server handler 4 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p7	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:13,294 [IPC Server handler 7 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p7	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,295 [IPC Server handler 5 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setOwner	src=/p7	dst=null	perm=bruce:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,313 [IPC Server handler 6 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=bruce (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p7	dst=null	perm=bruce:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,317 [IPC Server handler 8 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,317 [IPC Server handler 8 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 34459, call Call#260 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:47466: org.apache.hadoop.security.AccessControlException: Permission denied: user=diana, access=READ, inode="/p7":bruce:supergroup:drwxr-x---
2020-04-02 05:07:13,341 [IPC Server handler 9 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=bruce (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/p7	dst=null	perm=bruce:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,351 [IPC Server handler 1 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,353 [IPC Server handler 2 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,353 [IPC Server handler 2 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 2 on 34459, call Call#263 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.removeXAttr from 127.0.0.1:47466: org.apache.hadoop.security.AccessControlException: Permission denied: user=diana, access=WRITE, inode="/p7":bruce:supergroup:drwxr-x---
2020-04-02 05:07:13,360 [IPC Server handler 0 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,361 [IPC Server handler 0 on 34459] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 34459, call Call#264 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:47466: org.apache.hadoop.security.AccessControlException: Permission denied: user=diana, access=WRITE, inode="/p7":bruce:supergroup:drwxr-x---
2020-04-02 05:07:13,367 [IPC Server handler 3 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=bruce (auth:SIMPLE)	ip=/127.0.0.1	cmd=modifyAclEntries	src=/p7	dst=null	perm=bruce:supergroup:rwxrwx---	proto=rpc
2020-04-02 05:07:13,368 [IPC Server handler 4 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p7	dst=null	perm=bruce:supergroup:rwxrwx---	proto=rpc
2020-04-02 05:07:13,373 [IPC Server handler 7 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p7	dst=null	perm=null	proto=rpc
2020-04-02 05:07:13,378 [IPC Server handler 5 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7	dst=null	perm=bruce:supergroup:rwxrwx---	proto=rpc
2020-04-02 05:07:13,384 [IPC Server handler 6 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=diana (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p7	dst=null	perm=bruce:supergroup:rwxrwx---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testXAttrAcl
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testXAttrAcl
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testCleanupXAttrs
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:13,388 [IPC Server handler 8 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p8	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:13,389 [IPC Server handler 9 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,394 [IPC Server handler 1 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,396 [IPC Server handler 2 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,397 [IPC Server handler 0 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,398 [IPC Server handler 3 on 34459] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:13,399 [Thread-559] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:13,399 [Thread-559] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:13,399 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 111, 157
2020-04-02 05:07:13,400 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 48 Total time for transactions(ms): 22 Number of transactions batched in Syncs: 110 Number of syncs: 49 SyncTimes(ms): 4 2 
2020-04-02 05:07:13,402 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000111 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000111-0000000000000000158
2020-04-02 05:07:13,404 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000111 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000111-0000000000000000158
2020-04-02 05:07:13,405 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000158 using no compression
2020-04-02 05:07:13,405 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000158 using no compression
2020-04-02 05:07:13,419 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000158 of size 1344 bytes saved in 0 seconds .
2020-04-02 05:07:13,422 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000158 of size 1344 bytes saved in 0 seconds .
2020-04-02 05:07:13,425 [Thread-559] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 108
2020-04-02 05:07:13,426 [Thread-559] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000063, cpktTxId=0000000000000000063)
2020-04-02 05:07:13,426 [Thread-559] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000063, cpktTxId=0000000000000000063)
2020-04-02 05:07:13,433 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 159
2020-04-02 05:07:13,454 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:13,455 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:13,455 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:13,455 [Thread-559] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42550 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:13,455 [Thread-559] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:13,455 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7b1fab98] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:13,464 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:13,465 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:13,965 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@60c0ced0{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:13,966 [Thread-559] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3a6a9b61{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:13,968 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@23fd20df{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:13,975 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@36c49883{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:14,013 [Thread-559] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42550
2020-04-02 05:07:14,017 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:14,017 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34459] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:14,017 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34459] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:34459
2020-04-02 05:07:14,018 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34459] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:14,018 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:34459] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:14,018 [IPC Server listener on 42550] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42550
2020-04-02 05:07:14,034 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:14,050 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:14,051 [Thread-559] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:14,051 [Thread-559] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:14,052 [Thread-559] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:14,052 [Thread-559] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:14,056 [Thread-559] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:14,056 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:14,056 [Thread-559] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 34459 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:14,056 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:14,057 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 159, 159
2020-04-02 05:07:14,058 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@45e801e3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:14,065 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 2 2 
2020-04-02 05:07:14,066 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000159 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160
2020-04-02 05:07:14,067 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000159 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000159-0000000000000000160
2020-04-02 05:07:14,065 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@212c742d] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:14,067 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:14,074 [CacheReplicationMonitor(546769656)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:14,079 [Thread-559] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34459
2020-04-02 05:07:14,081 [IPC Server listener on 34459] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34459
2020-04-02 05:07:14,081 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:14,091 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:14,093 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:14,124 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:14,124 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:14,141 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4456dac1{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:14,143 [Thread-559] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2f7ae103{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:14,145 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@78b71a92{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:14,147 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@37c38d1c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:14,154 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:14,176 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:14,176 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:14,183 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:14,184 [Thread-559] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:14,279 [Thread-559] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:14,289 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:14,289 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:14,289 [Thread-559] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:14,293 [Thread-559] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:14,317 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1d664619] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:14,317 [Thread-559] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:14,317 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:14,319 [Thread-559] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:14,320 [Thread-559] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:14,320 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:14,329 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:14,330 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:14,330 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:14,330 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:14,331 [Thread-559] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:14,331 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:14,332 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39485
2020-04-02 05:07:14,332 [Thread-559] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:14,333 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7730aa03{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:14,338 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@161f0695{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:14,343 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@27319a65{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:14,344 [Thread-559] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2e536610{HTTP/1.1,[http/1.1]}{localhost:39485}
2020-04-02 05:07:14,348 [Thread-559] INFO  server.Server (Server.java:doStart(419)) - Started @17606ms
2020-04-02 05:07:14,351 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:14,351 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:14,352 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:14,352 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:14,352 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:14,352 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:14,352 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:14,352 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:14,353 [Thread-559] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:14,353 [Thread-559] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:14,353 [Thread-559] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:14,353 [Thread-559] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:14,354 [Thread-559] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:14
2020-04-02 05:07:14,354 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:14,354 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:14,355 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:14,355 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:14,383 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:14,384 [Thread-559] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:14,384 [Thread-559] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:14,384 [Thread-559] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:14,385 [Thread-559] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:14,385 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:14,385 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:14,385 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:14,385 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:14,385 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:14,385 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:14,385 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:14,386 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:14,386 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:14,386 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:14,387 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:14,392 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:14,393 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:14,393 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:14,393 [Thread-559] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:14,393 [Thread-559] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:14,393 [Thread-559] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:14,393 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:14,393 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:14,394 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:14,394 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:14,395 [Thread-559] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:14,395 [Thread-559] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:14,396 [Thread-559] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:14,397 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:14,397 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:14,397 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:14,397 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:14,397 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:14,397 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:14,401 [Thread-559] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:14,402 [Thread-559] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:14,405 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:14,405 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:14,406 [Thread-559] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000158, cpktTxId=0000000000000000158)
2020-04-02 05:07:14,408 [Thread-559] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 13 INodes.
2020-04-02 05:07:14,411 [Thread-559] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:14,413 [Thread-559] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 158 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000158
2020-04-02 05:07:14,414 [Thread-559] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@7f79b4b5 expecting start txid #159
2020-04-02 05:07:14,414 [Thread-559] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000159-0000000000000000160 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:14,414 [Thread-559] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160' to transaction ID 159
2020-04-02 05:07:14,415 [Thread-559] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000159-0000000000000000160 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:14,415 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:14,417 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 161
2020-04-02 05:07:14,430 [Thread-559] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:14,430 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 32 msecs
2020-04-02 05:07:14,431 [Thread-559] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:14,431 [Thread-559] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:14,432 [Socket Reader #1 for port 36470] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 36470
2020-04-02 05:07:14,436 [Thread-559] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:36470 to access this namenode/service.
2020-04-02 05:07:14,437 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:14,466 [Thread-559] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:14,467 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:14,467 [Thread-559] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:14,468 [Thread-559] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:14,468 [Thread-559] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:14,473 [IPC Server listener on 36470] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 36470: starting
2020-04-02 05:07:14,473 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:14,474 [Thread-559] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:36470
2020-04-02 05:07:14,475 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:14,476 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:14,476 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:14,476 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:14,476 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:14,476 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 8 msec
2020-04-02 05:07:14,476 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:14,476 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:14,490 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 13 milliseconds
name space=13
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:14,500 [Thread-559] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 36470 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:14,501 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:14,502 [Thread-559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:14,502 [Thread-559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:14,503 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:14,503 [Thread-559] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:14,504 [Thread-559] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:14,504 [Thread-559] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:14,504 [Thread-559] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:14,504 [Thread-559] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:14,504 [Thread-559] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:14,505 [Thread-559] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36345
2020-04-02 05:07:14,505 [Thread-559] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:14,505 [Thread-559] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:14,511 [CacheReplicationMonitor(1180953602)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:14,516 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:14,518 [Thread-559] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:14,518 [Thread-559] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:14,519 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:14,520 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:14,521 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:14,521 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:14,521 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:14,522 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44495
2020-04-02 05:07:14,522 [Thread-559] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:14,524 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6cfc90c6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:14,527 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@c34e892{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:14,533 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@50825eff{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:14,536 [Thread-559] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@52341459{HTTP/1.1,[http/1.1]}{localhost:44495}
2020-04-02 05:07:14,536 [Thread-559] INFO  server.Server (Server.java:doStart(419)) - Started @17794ms
2020-04-02 05:07:14,553 [Thread-559] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45612
2020-04-02 05:07:14,553 [Thread-559] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:14,553 [Thread-559] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:14,553 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1de7937c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:14,555 [Thread-559] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:14,556 [Socket Reader #1 for port 45929] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45929
2020-04-02 05:07:14,577 [Thread-559] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45929
2020-04-02 05:07:14,581 [Thread-559] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:14,582 [Thread-559] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:14,582 [Thread-610] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36470 starting to offer service
2020-04-02 05:07:14,585 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:14,585 [IPC Server listener on 45929] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45929: starting
2020-04-02 05:07:14,588 [Thread-559] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45929 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:14,622 [IPC Server handler 1 on 36470] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:14,623 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:14,623 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:14,627 [Thread-610] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:36470
2020-04-02 05:07:14,628 [Thread-610] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:14,630 [Thread-610] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:14,632 [Thread-610] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:14,657 [Thread-610] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:14,657 [Thread-610] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:14,676 [Thread-610] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:14,676 [Thread-610] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:14,677 [Thread-610] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:14,680 [Thread-610] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:14,682 [Thread-610] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:14,684 [Thread-610] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:14,685 [Thread-610] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:14,686 [Thread-610] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:14,687 [Thread-610] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:14,687 [Thread-610] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:14,688 [Thread-610] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:14,688 [Thread-610] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:14,689 [Thread-610] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:14,689 [Thread-625] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:14,689 [Thread-626] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:14,690 [Thread-626] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:14,698 [Thread-625] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 50404
2020-04-02 05:07:14,707 [Thread-625] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 18ms
2020-04-02 05:07:14,732 [IPC Server handler 0 on 36470] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:14,734 [Thread-626] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 45ms
2020-04-02 05:07:14,734 [Thread-610] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 45ms
2020-04-02 05:07:14,736 [Thread-627] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:14,734 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:14,763 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:14,762 [Thread-628] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:14,763 [Thread-628] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:14,763 [Thread-628] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 0ms
2020-04-02 05:07:14,750 [Thread-627] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:14,764 [Thread-627] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 28ms
2020-04-02 05:07:14,765 [Thread-610] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 31ms
2020-04-02 05:07:14,766 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814388381 ms.
2020-04-02 05:07:14,767 [Thread-610] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:25 AM with interval of 21600000ms
2020-04-02 05:07:14,767 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814388381 ms.
2020-04-02 05:07:14,774 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:36470] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:36470 beginning handshake with NN
2020-04-02 05:07:14,777 [IPC Server handler 3 on 36470] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36345, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=45612, infoSecurePort=0, ipcPort=45929, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:14,777 [IPC Server handler 3 on 36470] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:36345
2020-04-02 05:07:14,778 [IPC Server handler 3 on 36470] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:36345).
2020-04-02 05:07:14,781 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:36470] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:36470 successfully registered with NN
2020-04-02 05:07:14,781 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:36470] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:36470 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:14,785 [IPC Server handler 4 on 36470] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:36345
2020-04-02 05:07:14,785 [IPC Server handler 4 on 36470] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:36345
2020-04-02 05:07:14,790 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa1a83c7ecf6aa94e: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:14,790 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa1a83c7ecf6aa94e: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:36345, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=45612, infoSecurePort=0, ipcPort=45929, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:14,790 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xa1a83c7ecf6aa94e: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:14,792 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xa1a83c7ecf6aa94e: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:36345, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=45612, infoSecurePort=0, ipcPort=45929, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 4, hasStaleStorage: false, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:07:14,793 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:36470] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xa1a83c7ecf6aa94e,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:14,793 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:36470] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:14,864 [IPC Server handler 6 on 36470] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:14,865 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:14,872 [IPC Server handler 8 on 36470] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:14,873 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:14,876 [IPC Server handler 9 on 36470] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:14,878 [IPC Server handler 7 on 36470] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:14,880 [IPC Server handler 1 on 36470] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:14,882 [IPC Server handler 2 on 36470] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:14,883 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:14,883 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:14,884 [Thread-559] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45929 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:14,884 [Thread-559] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:14,884 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@19fe3539] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:14,886 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:14,886 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:14,923 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@50825eff{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:14,924 [Thread-559] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@52341459{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:14,924 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@c34e892{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:14,925 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6cfc90c6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:14,927 [Thread-559] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45929
2020-04-02 05:07:14,933 [IPC Server listener on 45929] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45929
2020-04-02 05:07:14,933 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:36470] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:14,933 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:36470] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:36470
2020-04-02 05:07:14,933 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:36470] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:14,933 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:36470] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:14,934 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:14,952 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:15,035 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:15,044 [Thread-559] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:15,045 [Thread-559] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:15,046 [Thread-559] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:15,046 [Thread-559] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:15,056 [Thread-559] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:15,056 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:15,056 [Thread-559] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 36470 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:15,056 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:15,060 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 161, 165
2020-04-02 05:07:15,060 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@2748e97] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:15,060 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@b341066] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:15,060 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 6 Total time for transactions(ms): 2 Number of transactions batched in Syncs: 160 Number of syncs: 7 SyncTimes(ms): 6 2 
2020-04-02 05:07:15,061 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000161 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000161-0000000000000000166
2020-04-02 05:07:15,062 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000161 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000161-0000000000000000166
2020-04-02 05:07:15,062 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:15,063 [CacheReplicationMonitor(1180953602)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:15,069 [Thread-559] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 36470
2020-04-02 05:07:15,073 [IPC Server listener on 36470] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 36470
2020-04-02 05:07:15,074 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:15,074 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:15,073 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:15,092 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:15,094 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:15,099 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@27319a65{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:15,115 [Thread-559] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2e536610{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:15,122 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@161f0695{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:15,126 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7730aa03{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:15,129 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:15,130 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:15,130 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:15,143 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:15,144 [Thread-559] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:15,149 [Thread-559] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:15,151 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:15,151 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:15,151 [Thread-559] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:15,152 [Thread-559] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:15,157 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@31077252] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:15,158 [Thread-559] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:15,158 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:15,160 [Thread-559] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:15,160 [Thread-559] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:15,161 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:15,162 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:15,162 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:15,162 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:15,162 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:15,164 [Thread-559] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:15,164 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:15,165 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36976
2020-04-02 05:07:15,165 [Thread-559] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:15,195 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@645d4b0d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:15,206 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15221249{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:15,210 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5e976724{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:15,211 [Thread-559] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@26266116{HTTP/1.1,[http/1.1]}{localhost:36976}
2020-04-02 05:07:15,212 [Thread-559] INFO  server.Server (Server.java:doStart(419)) - Started @18469ms
2020-04-02 05:07:15,213 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:15,214 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:15,214 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:15,214 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:15,214 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:15,214 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:15,214 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:15,215 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:15,215 [Thread-559] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:15,215 [Thread-559] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:15,215 [Thread-559] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:15,216 [Thread-559] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:15,216 [Thread-559] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:15
2020-04-02 05:07:15,216 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:15,216 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:15,217 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:15,217 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:15,254 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:15,255 [Thread-559] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:15,255 [Thread-559] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:15,255 [Thread-559] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:15,255 [Thread-559] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:15,255 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:15,255 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:15,255 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:15,255 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:15,256 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:15,256 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:15,256 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:15,256 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:15,256 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:15,257 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:15,257 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:15,262 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:15,262 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:15,262 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:15,262 [Thread-559] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:15,262 [Thread-559] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:15,263 [Thread-559] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:15,263 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:15,263 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:15,263 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:15,263 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:15,264 [Thread-559] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:15,265 [Thread-559] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:15,265 [Thread-559] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:15,265 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:15,265 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:15,265 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:15,266 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:15,266 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:15,267 [Thread-559] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:15,270 [Thread-559] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:15,271 [Thread-559] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:15,273 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:15,273 [Thread-559] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:15,274 [Thread-559] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000158, cpktTxId=0000000000000000158)
2020-04-02 05:07:15,275 [Thread-559] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 13 INodes.
2020-04-02 05:07:15,277 [Thread-559] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:15,277 [Thread-559] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 158 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000158
2020-04-02 05:07:15,277 [Thread-559] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6ddbbb7 expecting start txid #159
2020-04-02 05:07:15,277 [Thread-559] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000159-0000000000000000160 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:15,277 [Thread-559] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160' to transaction ID 159
2020-04-02 05:07:15,278 [Thread-559] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000159-0000000000000000160 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:15,278 [Thread-559] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@6c50cc84 expecting start txid #161
2020-04-02 05:07:15,278 [Thread-559] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000161-0000000000000000166, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000161-0000000000000000166 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:15,279 [Thread-559] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000161-0000000000000000166' to transaction ID 159
2020-04-02 05:07:15,279 [Thread-559] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000161-0000000000000000166, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000161-0000000000000000166 of size 264 edits # 6 loaded in 0 seconds
2020-04-02 05:07:15,279 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:15,281 [Thread-559] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 167
2020-04-02 05:07:15,291 [Thread-559] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:15,292 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 25 msecs
2020-04-02 05:07:15,292 [Thread-559] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:15,292 [Thread-559] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:15,293 [Socket Reader #1 for port 38522] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38522
2020-04-02 05:07:15,298 [Thread-559] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38522 to access this namenode/service.
2020-04-02 05:07:15,298 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:15,343 [Thread-559] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:15,360 [Thread-559] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:15,361 [Thread-559] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:15,361 [Thread-559] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:15,361 [Thread-559] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:15,365 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:15,366 [IPC Server listener on 38522] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38522: starting
2020-04-02 05:07:15,369 [Thread-559] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38522
2020-04-02 05:07:15,381 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:15,381 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:15,381 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:15,381 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:15,381 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:15,381 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 21 msec
2020-04-02 05:07:15,389 [Thread-559] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:15,390 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:15,448 [Thread-559] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 58 milliseconds
name space=13
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:15,449 [Thread-559] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38522 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:15,450 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:15,456 [Thread-559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:15,457 [Thread-559] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:15,458 [CacheReplicationMonitor(2064104090)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:15,460 [Thread-559] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:15,460 [Thread-559] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:15,461 [Thread-559] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:15,463 [Thread-559] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:15,463 [Thread-559] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:15,464 [Thread-559] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:15,464 [Thread-559] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:15,464 [Thread-559] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39331
2020-04-02 05:07:15,468 [Thread-559] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:15,468 [Thread-559] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:15,469 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:15,470 [Thread-559] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:15,471 [Thread-559] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:15,471 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:15,472 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:15,472 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:15,472 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:15,472 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:15,473 [Thread-559] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46046
2020-04-02 05:07:15,473 [Thread-559] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:15,478 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@14434659{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:15,479 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@47f13309{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:15,483 [Thread-559] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5ba14b23{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:15,483 [Thread-559] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@16d3cb6b{HTTP/1.1,[http/1.1]}{localhost:46046}
2020-04-02 05:07:15,483 [Thread-559] INFO  server.Server (Server.java:doStart(419)) - Started @18741ms
2020-04-02 05:07:15,531 [Thread-559] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46213
2020-04-02 05:07:15,532 [Thread-559] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:15,532 [Thread-559] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:15,533 [Thread-559] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:15,534 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@598bf9d2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:15,534 [Socket Reader #1 for port 38771] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38771
2020-04-02 05:07:15,536 [Thread-559] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38771
2020-04-02 05:07:15,551 [Thread-559] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:15,551 [Thread-559] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:15,552 [Thread-682] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38522 starting to offer service
2020-04-02 05:07:15,562 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:15,564 [IPC Server listener on 38771] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38771: starting
2020-04-02 05:07:15,582 [Thread-559] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38771 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:15,596 [Thread-682] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38522
2020-04-02 05:07:15,600 [Thread-682] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:15,602 [Thread-682] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:15,633 [IPC Server handler 1 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:15,642 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:15,642 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:15,644 [Thread-682] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:15,655 [Thread-682] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:15,656 [Thread-682] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:15,667 [Thread-682] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:15,667 [Thread-682] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:15,668 [Thread-682] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:15,670 [Thread-682] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:15,672 [Thread-682] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:15,674 [Thread-682] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:15,674 [Thread-682] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:15,675 [Thread-682] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:15,685 [Thread-682] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:15,686 [Thread-682] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:15,687 [Thread-682] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:15,687 [Thread-682] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:15,687 [Thread-682] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:15,687 [Thread-697] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:15,687 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:15,688 [Thread-697] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 50404
2020-04-02 05:07:15,689 [Thread-698] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:15,700 [Thread-697] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 13ms
2020-04-02 05:07:15,700 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 12ms
2020-04-02 05:07:15,701 [Thread-682] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 14ms
2020-04-02 05:07:15,701 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:15,701 [Thread-700] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:15,707 [Thread-700] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:15,707 [Thread-699] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:15,707 [Thread-700] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 6ms
2020-04-02 05:07:15,708 [Thread-699] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 7ms
2020-04-02 05:07:15,709 [Thread-682] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 8ms
2020-04-02 05:07:15,710 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814387437 ms.
2020-04-02 05:07:15,711 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814387437 ms.
2020-04-02 05:07:15,711 [Thread-682] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:54 AM with interval of 21600000ms
2020-04-02 05:07:15,713 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38522] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:38522 beginning handshake with NN
2020-04-02 05:07:15,715 [IPC Server handler 2 on 38522] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39331, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=46213, infoSecurePort=0, ipcPort=38771, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:15,715 [IPC Server handler 2 on 38522] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:39331
2020-04-02 05:07:15,715 [IPC Server handler 2 on 38522] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:39331).
2020-04-02 05:07:15,719 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38522] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:38522 successfully registered with NN
2020-04-02 05:07:15,719 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38522] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38522 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:15,724 [IPC Server handler 3 on 38522] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:39331
2020-04-02 05:07:15,724 [IPC Server handler 3 on 38522] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:39331
2020-04-02 05:07:15,728 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb3187ecb6860b50a: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:15,729 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb3187ecb6860b50a: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:39331, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=46213, infoSecurePort=0, ipcPort=38771, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:07:15,729 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb3187ecb6860b50a: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:15,734 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb3187ecb6860b50a: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:39331, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=46213, infoSecurePort=0, ipcPort=38771, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 4, hasStaleStorage: false, processing time: 5 msecs, invalidatedBlocks: 0
2020-04-02 05:07:15,738 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38522] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb3187ecb6860b50a,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:15,738 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38522] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:15,748 [IPC Server handler 4 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:15,749 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:15,758 [IPC Server handler 8 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:15,759 [Thread-559] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:15,763 [IPC Server handler 7 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,768 [IPC Server handler 9 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,771 [IPC Server handler 5 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,772 [IPC Server handler 0 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,777 [IPC Server handler 1 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,781 [IPC Server handler 2 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p8	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,782 [IPC Server handler 3 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p8	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testCleanupXAttrs
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testCleanupXAttrs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testReplaceXAttr
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:15,786 [IPC Server handler 6 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p9	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:15,790 [IPC Server handler 4 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,791 [IPC Server handler 8 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,793 [IPC Server handler 7 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,794 [IPC Server handler 9 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p9	dst=null	perm=null	proto=rpc
2020-04-02 05:07:15,796 [IPC Server handler 5 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,797 [IPC Server handler 0 on 38522] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 0 on 38522, call Call#308 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:48838
java.io.IOException: XAttr: a1 does not exist. The CREATE flag must be specified.
	at org.apache.hadoop.fs.XAttrSetFlag.validate(XAttrSetFlag.java:66)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:342)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:272)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:15,803 [IPC Server handler 1 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,805 [IPC Server handler 2 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,806 [IPC Server handler 3 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:15,807 [IPC Server handler 6 on 38522] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p9	dst=null	perm=null	proto=rpc
2020-04-02 05:07:15,808 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:15,808 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:15,808 [Thread-704] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38771 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:15,808 [Thread-704] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:15,808 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@751911eb] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:15,810 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:15,810 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:15,840 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5ba14b23{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:15,840 [Thread-704] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@16d3cb6b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:15,841 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@47f13309{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:15,841 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@14434659{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:15,846 [Thread-704] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38771
2020-04-02 05:07:15,864 [IPC Server listener on 38771] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38771
2020-04-02 05:07:15,864 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:15,864 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38522] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:15,866 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38522] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:38522
2020-04-02 05:07:15,866 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38522] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:15,866 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:38522] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:15,880 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:15,908 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:15,913 [Thread-704] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:15,913 [Thread-704] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:15,914 [Thread-704] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:15,914 [Thread-704] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:15,915 [Thread-704] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:15,915 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:15,915 [Thread-704] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38522 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:15,915 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:15,915 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 167, 181
2020-04-02 05:07:15,915 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@650f9eb4] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:15,915 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@61a925d3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:15,916 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 16 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 166 Number of syncs: 17 SyncTimes(ms): 3 1 
2020-04-02 05:07:15,917 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000167 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000167-0000000000000000182
2020-04-02 05:07:15,918 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000167 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000167-0000000000000000182
2020-04-02 05:07:15,918 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:15,921 [CacheReplicationMonitor(2064104090)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:15,925 [Thread-704] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38522
2020-04-02 05:07:15,932 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:15,933 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:15,936 [IPC Server listener on 38522] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38522
2020-04-02 05:07:15,944 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:15,952 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:15,958 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:15,959 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5e976724{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:15,961 [Thread-704] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@26266116{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:15,961 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15221249{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:15,962 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@645d4b0d{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:15,963 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:15,964 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:15,966 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:15,975 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:15,979 [Thread-704] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:16,032 [Thread-704] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:16,048 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:16,048 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:16,048 [Thread-704] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:16,049 [Thread-704] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:16,054 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@489d2360] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:16,054 [Thread-704] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:16,055 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:16,060 [Thread-704] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:16,061 [Thread-704] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:16,061 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:16,062 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:16,062 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:16,063 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:16,063 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:16,064 [Thread-704] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:16,064 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:16,064 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41767
2020-04-02 05:07:16,064 [Thread-704] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:16,066 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@117c6507{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:16,066 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d4d7480{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:16,069 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@398cfea3{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:16,070 [Thread-704] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@58ad2f0e{HTTP/1.1,[http/1.1]}{localhost:41767}
2020-04-02 05:07:16,071 [Thread-704] INFO  server.Server (Server.java:doStart(419)) - Started @19329ms
2020-04-02 05:07:16,096 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:16,096 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:16,097 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:16,097 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:16,097 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:16,097 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:16,097 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:16,097 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:16,097 [Thread-704] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:16,097 [Thread-704] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:16,098 [Thread-704] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:16,098 [Thread-704] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:16,098 [Thread-704] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:16
2020-04-02 05:07:16,098 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:16,098 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:16,098 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:16,098 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:16,112 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:16,112 [Thread-704] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:16,113 [Thread-704] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:16,114 [Thread-704] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:16,114 [Thread-704] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:16,114 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:16,114 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:16,114 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:16,114 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:16,114 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:16,114 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:16,115 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:16,115 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:16,115 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:16,115 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:16,116 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:16,121 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:16,121 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:16,121 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:16,121 [Thread-704] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:16,121 [Thread-704] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:16,122 [Thread-704] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:16,122 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:16,122 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:16,122 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:16,122 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:16,124 [Thread-704] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:16,124 [Thread-704] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:16,124 [Thread-704] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:16,125 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:16,125 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:16,125 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:16,125 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:16,125 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:16,125 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:16,127 [Thread-704] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:16,128 [Thread-704] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:16,130 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:16,130 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:16,132 [Thread-704] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000158, cpktTxId=0000000000000000158)
2020-04-02 05:07:16,134 [Thread-704] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 13 INodes.
2020-04-02 05:07:16,135 [Thread-704] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:16,136 [Thread-704] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 158 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000158
2020-04-02 05:07:16,136 [Thread-704] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@1a547fb9 expecting start txid #159
2020-04-02 05:07:16,136 [Thread-704] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000159-0000000000000000160 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:16,137 [Thread-704] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160' to transaction ID 159
2020-04-02 05:07:16,137 [Thread-704] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000159-0000000000000000160, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000159-0000000000000000160 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:16,138 [Thread-704] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@207ecde0 expecting start txid #161
2020-04-02 05:07:16,138 [Thread-704] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000161-0000000000000000166, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000161-0000000000000000166 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:16,138 [Thread-704] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000161-0000000000000000166' to transaction ID 159
2020-04-02 05:07:16,139 [Thread-704] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000161-0000000000000000166, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000161-0000000000000000166 of size 264 edits # 6 loaded in 0 seconds
2020-04-02 05:07:16,139 [Thread-704] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@47932836 expecting start txid #167
2020-04-02 05:07:16,139 [Thread-704] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000167-0000000000000000182, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000167-0000000000000000182 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:16,139 [Thread-704] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000167-0000000000000000182' to transaction ID 159
2020-04-02 05:07:16,141 [Thread-704] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000167-0000000000000000182, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000167-0000000000000000182 of size 811 edits # 16 loaded in 0 seconds
2020-04-02 05:07:16,142 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:16,142 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 183
2020-04-02 05:07:16,150 [Thread-704] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:16,151 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 25 msecs
2020-04-02 05:07:16,151 [Thread-704] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:16,151 [Thread-704] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:16,152 [Socket Reader #1 for port 37015] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37015
2020-04-02 05:07:16,157 [Thread-704] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:37015 to access this namenode/service.
2020-04-02 05:07:16,159 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:16,198 [Thread-704] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:16,206 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:16,207 [Thread-704] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:16,207 [Thread-704] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:16,207 [Thread-704] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:16,216 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:16,216 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:16,216 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:16,217 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:16,217 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:16,217 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 10 msec
2020-04-02 05:07:16,219 [Thread-704] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:37015
2020-04-02 05:07:16,220 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:16,251 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:16,252 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:16,255 [IPC Server listener on 37015] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37015: starting
2020-04-02 05:07:16,276 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 14 milliseconds
name space=14
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:16,281 [Thread-704] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 37015 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:16,282 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:16,283 [Thread-704] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:16,284 [Thread-704] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:16,284 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:16,304 [CacheReplicationMonitor(123936786)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:16,310 [Thread-704] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:16,312 [Thread-704] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:16,313 [Thread-704] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:16,313 [Thread-704] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:16,313 [Thread-704] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:16,313 [Thread-704] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:16,314 [Thread-704] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33139
2020-04-02 05:07:16,314 [Thread-704] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:16,314 [Thread-704] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:16,320 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:16,321 [Thread-704] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:16,322 [Thread-704] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:16,322 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:16,332 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:16,333 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:16,333 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:16,333 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:16,337 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38280
2020-04-02 05:07:16,337 [Thread-704] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:16,339 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12891584{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:16,340 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@719782fd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:16,344 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3498953b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:16,344 [Thread-704] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@18d5c3fc{HTTP/1.1,[http/1.1]}{localhost:38280}
2020-04-02 05:07:16,345 [Thread-704] INFO  server.Server (Server.java:doStart(419)) - Started @19602ms
2020-04-02 05:07:16,370 [Thread-704] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41627
2020-04-02 05:07:16,371 [Thread-704] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:16,371 [Thread-704] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:16,372 [Thread-704] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:16,371 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@385e3756] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:16,373 [Socket Reader #1 for port 43624] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43624
2020-04-02 05:07:16,383 [Thread-704] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43624
2020-04-02 05:07:16,387 [Thread-704] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:16,388 [Thread-704] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:16,388 [Thread-755] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37015 starting to offer service
2020-04-02 05:07:16,389 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:16,389 [IPC Server listener on 43624] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43624: starting
2020-04-02 05:07:16,403 [Thread-704] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43624 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:16,414 [Thread-755] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:37015
2020-04-02 05:07:16,416 [Thread-755] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:16,423 [Thread-755] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:16,428 [IPC Server handler 2 on 37015] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,429 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:16,429 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:16,431 [Thread-755] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:16,442 [Thread-755] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:16,442 [Thread-755] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:16,455 [Thread-755] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:16,456 [Thread-755] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:16,457 [Thread-755] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:16,459 [Thread-755] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:16,460 [Thread-755] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:16,461 [Thread-755] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:16,461 [Thread-755] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:16,462 [Thread-755] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:16,472 [Thread-755] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:16,473 [Thread-755] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:16,473 [Thread-755] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:16,473 [Thread-755] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:16,473 [Thread-755] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:16,474 [Thread-770] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:16,477 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:16,478 [Thread-771] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:16,479 [Thread-770] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 50404
2020-04-02 05:07:16,488 [Thread-771] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 10ms
2020-04-02 05:07:16,502 [Thread-770] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 25ms
2020-04-02 05:07:16,502 [Thread-755] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 28ms
2020-04-02 05:07:16,503 [Thread-772] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:16,526 [Thread-773] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:16,526 [Thread-773] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:16,526 [Thread-773] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:07:16,538 [Thread-772] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:16,543 [Thread-772] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 40ms
2020-04-02 05:07:16,545 [IPC Server handler 3 on 37015] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,546 [Thread-755] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 43ms
2020-04-02 05:07:16,546 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:16,546 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:16,548 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814386599 ms.
2020-04-02 05:07:16,548 [Thread-755] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:57 AM with interval of 21600000ms
2020-04-02 05:07:16,548 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814386600 ms.
2020-04-02 05:07:16,555 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:37015] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:37015 beginning handshake with NN
2020-04-02 05:07:16,566 [IPC Server handler 5 on 37015] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33139, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=41627, infoSecurePort=0, ipcPort=43624, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:16,566 [IPC Server handler 5 on 37015] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:33139
2020-04-02 05:07:16,567 [IPC Server handler 5 on 37015] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:33139).
2020-04-02 05:07:16,574 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:37015] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:37015 successfully registered with NN
2020-04-02 05:07:16,574 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:37015] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:37015 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:16,580 [IPC Server handler 0 on 37015] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:33139
2020-04-02 05:07:16,580 [IPC Server handler 0 on 37015] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:33139
2020-04-02 05:07:16,586 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe1566769cf486ec6: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:16,586 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe1566769cf486ec6: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:33139, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=41627, infoSecurePort=0, ipcPort=43624, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:16,587 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe1566769cf486ec6: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:16,590 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe1566769cf486ec6: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:33139, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=41627, infoSecurePort=0, ipcPort=43624, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 4, hasStaleStorage: false, processing time: 3 msecs, invalidatedBlocks: 0
2020-04-02 05:07:16,591 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:37015] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe1566769cf486ec6,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:16,591 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:37015] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:16,648 [IPC Server handler 1 on 37015] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,650 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:16,653 [IPC Server handler 6 on 37015] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,654 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:16,658 [IPC Server handler 9 on 37015] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p9	dst=null	perm=null	proto=rpc
2020-04-02 05:07:16,659 [Thread-704] INFO  hdfs.StateChange (FSNamesystem.java:enterSafeMode(4593)) - STATE* Safe mode is ON.
It was turned on manually. Use "hdfs dfsadmin -safemode leave" to turn safe mode off.
2020-04-02 05:07:16,659 [Thread-704] INFO  namenode.FSImage (FSImage.java:saveNamespace(1101)) - Save namespace ...
2020-04-02 05:07:16,659 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 183, 183
2020-04-02 05:07:16,660 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 182 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-04-02 05:07:16,661 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000183 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000183-0000000000000000184
2020-04-02 05:07:16,662 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000183 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000183-0000000000000000184
2020-04-02 05:07:16,671 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000184 using no compression
2020-04-02 05:07:16,672 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000184 using no compression
2020-04-02 05:07:16,688 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000184 of size 1445 bytes saved in 0 seconds .
2020-04-02 05:07:16,690 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000184 of size 1445 bytes saved in 0 seconds .
2020-04-02 05:07:16,695 [Thread-704] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 2 images with txid >= 158
2020-04-02 05:07:16,695 [Thread-704] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000108, cpktTxId=0000000000000000108)
2020-04-02 05:07:16,695 [Thread-704] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:purgeImage(225)) - Purging old image FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage_0000000000000000108, cpktTxId=0000000000000000108)
2020-04-02 05:07:16,700 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 185
2020-04-02 05:07:16,710 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:saveNamespace(4419)) - New namespace image has been created
2020-04-02 05:07:16,710 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:16,711 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:16,711 [Thread-704] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43624 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:16,711 [Thread-704] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:16,713 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@73ce91e9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:16,715 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:16,717 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:16,753 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3498953b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:16,754 [Thread-704] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@18d5c3fc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:16,754 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@719782fd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:16,755 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@12891584{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:16,766 [Thread-704] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43624
2020-04-02 05:07:16,769 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:16,769 [IPC Server listener on 43624] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43624
2020-04-02 05:07:16,769 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:37015] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:16,770 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:37015] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:37015
2020-04-02 05:07:16,770 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:37015] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:16,770 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:37015] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:16,795 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:16,799 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:16,806 [Thread-704] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:16,806 [Thread-704] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:16,808 [Thread-704] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:16,808 [Thread-704] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:16,808 [Thread-704] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:16,809 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:16,809 [Thread-704] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 37015 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:16,809 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:16,809 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 185, 185
2020-04-02 05:07:16,809 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4b715228] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:16,809 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@3462a006] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:16,810 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 2 Total time for transactions(ms): 0 Number of transactions batched in Syncs: 0 Number of syncs: 3 SyncTimes(ms): 1 1 
2020-04-02 05:07:16,810 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000185 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000185-0000000000000000186
2020-04-02 05:07:16,811 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000185 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000185-0000000000000000186
2020-04-02 05:07:16,811 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:16,811 [CacheReplicationMonitor(123936786)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:16,822 [Thread-704] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37015
2020-04-02 05:07:16,827 [IPC Server listener on 37015] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37015
2020-04-02 05:07:16,827 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:16,827 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:16,827 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:16,835 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:16,836 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:16,837 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@398cfea3{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:16,838 [Thread-704] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@58ad2f0e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:16,839 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d4d7480{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:16,839 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@117c6507{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:16,839 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:16,847 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:16,847 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
2020-04-02 05:07:16,855 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:07:16,856 [Thread-704] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:07:16,860 [Thread-704] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:07:16,862 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:07:16,862 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:07:16,863 [Thread-704] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:07:16,863 [Thread-704] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:07:16,869 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@60f6ed6d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:16,869 [Thread-704] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:07:16,869 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:16,877 [Thread-704] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:16,878 [Thread-704] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:07:16,878 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:16,879 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:16,880 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:07:16,880 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:16,880 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:16,882 [Thread-704] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:07:16,882 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:07:16,882 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34976
2020-04-02 05:07:16,882 [Thread-704] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:16,884 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@8811581{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:16,884 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f8ae7a6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:16,888 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5345bed4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:07:16,889 [Thread-704] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@60eb9ac4{HTTP/1.1,[http/1.1]}{localhost:34976}
2020-04-02 05:07:16,890 [Thread-704] INFO  server.Server (Server.java:doStart(419)) - Started @20147ms
2020-04-02 05:07:16,902 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:07:16,902 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:07:16,903 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:07:16,903 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:07:16,903 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:07:16,903 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:07:16,903 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:07:16,903 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:07:16,904 [Thread-704] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:16,904 [Thread-704] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:07:16,904 [Thread-704] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:07:16,904 [Thread-704] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:07:16,905 [Thread-704] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:07:16
2020-04-02 05:07:16,905 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:07:16,905 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:16,905 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:07:16,905 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:07:16,916 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:07:16,916 [Thread-704] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:07:16,916 [Thread-704] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:07:16,916 [Thread-704] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:07:16,916 [Thread-704] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:07:16,916 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:07:16,916 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:07:16,916 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:07:16,916 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:07:16,917 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:07:16,917 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:07:16,917 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:07:16,917 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:07:16,917 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:16,917 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:07:16,917 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:07:16,927 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? true
2020-04-02 05:07:16,927 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:07:16,927 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:07:16,927 [Thread-704] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:07:16,927 [Thread-704] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:07:16,927 [Thread-704] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:07:16,928 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:07:16,928 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:16,928 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:07:16,928 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:07:16,931 [Thread-704] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:07:16,931 [Thread-704] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:07:16,931 [Thread-704] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:07:16,931 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:07:16,932 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:07:16,932 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:07:16,932 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:07:16,932 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:07:16,932 [Thread-704] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:07:16,934 [Thread-704] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:16,934 [Thread-704] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:16,936 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:07:16,936 [Thread-704] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:07:16,937 [Thread-704] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000184, cpktTxId=0000000000000000184)
2020-04-02 05:07:16,938 [Thread-704] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 14 INodes.
2020-04-02 05:07:16,940 [Thread-704] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:07:16,940 [Thread-704] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 184 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000184
2020-04-02 05:07:16,940 [Thread-704] INFO  namenode.FSImage (FSImage.java:loadEdits(887)) - Reading org.apache.hadoop.hdfs.server.namenode.RedundantEditLogInputStream@25c0c7a expecting start txid #185
2020-04-02 05:07:16,940 [Thread-704] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(158)) - Start loading edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000185-0000000000000000186, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000185-0000000000000000186 maxTxnsToRead = 9223372036854775807
2020-04-02 05:07:16,940 [Thread-704] INFO  namenode.RedundantEditLogInputStream (RedundantEditLogInputStream.java:nextOp(177)) - Fast-forwarding stream '/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000185-0000000000000000186' to transaction ID 185
2020-04-02 05:07:16,941 [Thread-704] INFO  namenode.FSImage (FSEditLogLoader.java:loadFSEdits(162)) - Edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000185-0000000000000000186, /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000185-0000000000000000186 of size 42 edits # 2 loaded in 0 seconds
2020-04-02 05:07:16,941 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:07:16,941 [Thread-704] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 187
2020-04-02 05:07:16,947 [Thread-704] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:07:16,948 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 15 msecs
2020-04-02 05:07:16,948 [Thread-704] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:07:16,948 [Thread-704] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:16,949 [Socket Reader #1 for port 33073] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33073
2020-04-02 05:07:16,973 [Thread-704] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33073 to access this namenode/service.
2020-04-02 05:07:16,973 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:07:17,054 [Thread-704] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:07:17,070 [Thread-704] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:07:17,070 [Thread-704] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:07:17,071 [Thread-704] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:07:17,072 [Thread-704] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:07:17,100 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:07:17,100 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:07:17,100 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:07:17,100 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:07:17,101 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:07:17,101 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 14 msec
2020-04-02 05:07:17,151 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:17,164 [IPC Server listener on 33073] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33073: starting
2020-04-02 05:07:17,166 [Thread-704] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33073
2020-04-02 05:07:17,166 [Thread-704] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:07:17,166 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:07:17,202 [Thread-704] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 36 milliseconds
name space=14
storage space=1024
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:07:17,215 [Thread-704] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33073 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:17,220 [CacheReplicationMonitor(1777097344)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:07:17,227 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:17,228 [Thread-704] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:17,229 [Thread-704] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:17,229 [Thread-704] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:07:17,230 [Thread-704] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:07:17,230 [Thread-704] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:17,230 [Thread-704] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:07:17,231 [Thread-704] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:07:17,231 [Thread-704] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:07:17,231 [Thread-704] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:07:17,232 [Thread-704] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35241
2020-04-02 05:07:17,232 [Thread-704] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:07:17,232 [Thread-704] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:07:17,233 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:17,234 [Thread-704] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:07:17,235 [Thread-704] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:07:17,235 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:07:17,236 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:07:17,237 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:07:17,237 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:07:17,237 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:07:17,244 [Thread-704] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40635
2020-04-02 05:07:17,244 [Thread-704] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:07:17,245 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b74f75b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:07:17,246 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7dfd6f8a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:07:17,249 [Thread-704] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@775630ee{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:07:17,250 [Thread-704] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@9bd456b{HTTP/1.1,[http/1.1]}{localhost:40635}
2020-04-02 05:07:17,250 [Thread-704] INFO  server.Server (Server.java:doStart(419)) - Started @20508ms
2020-04-02 05:07:17,269 [Thread-704] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40977
2020-04-02 05:07:17,270 [Thread-704] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:07:17,270 [Thread-704] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:07:17,270 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4a74b57a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:07:17,271 [Thread-704] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:07:17,271 [Socket Reader #1 for port 35091] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35091
2020-04-02 05:07:17,281 [Thread-704] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35091
2020-04-02 05:07:17,287 [Thread-704] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:07:17,288 [Thread-704] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:07:17,288 [Thread-828] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33073 starting to offer service
2020-04-02 05:07:17,302 [IPC Server listener on 35091] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35091: starting
2020-04-02 05:07:17,308 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:07:17,308 [Thread-704] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35091 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:17,348 [IPC Server handler 0 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,349 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:17,349 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:17,351 [Thread-828] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33073
2020-04-02 05:07:17,353 [Thread-828] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:07:17,361 [Thread-828] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:17,370 [Thread-828] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 9213@1b26ddd29aee
2020-04-02 05:07:17,392 [Thread-828] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:17,402 [Thread-828] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:17,423 [Thread-828] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:17,423 [Thread-828] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:17,426 [Thread-828] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1074675762;bpid=BP-1627096859-172.17.0.17-1585804019062;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1074675762;c=1585804019062;bpid=BP-1627096859-172.17.0.17-1585804019062;dnuuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:17,432 [Thread-828] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a6f147e-8ba2-45eb-9cfc-55223772985d
2020-04-02 05:07:17,437 [Thread-828] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:07:17,443 [Thread-828] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-afe7793b-8839-4536-91e9-98e46497afea
2020-04-02 05:07:17,445 [Thread-828] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:07:17,445 [Thread-828] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:07:17,446 [Thread-828] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:17,448 [Thread-828] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:07:17,448 [Thread-828] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:17,448 [Thread-828] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:07:17,481 [Thread-828] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:17,490 [Thread-843] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:17,490 [Thread-844] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:17,491 [Thread-843] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current: 50404
2020-04-02 05:07:17,491 [Thread-844] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current: 32839
2020-04-02 05:07:17,496 [IPC Server handler 2 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,498 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:07:17,498 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:07:17,503 [Thread-843] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 13ms
2020-04-02 05:07:17,505 [Thread-844] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1627096859-172.17.0.17-1585804019062 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 15ms
2020-04-02 05:07:17,506 [Thread-828] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1627096859-172.17.0.17-1585804019062: 24ms
2020-04-02 05:07:17,506 [Thread-845] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:07:17,506 [Thread-846] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:07:17,510 [Thread-845] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:17,510 [Thread-846] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062/current/replicas
2020-04-02 05:07:17,524 [Thread-845] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 18ms
2020-04-02 05:07:17,525 [Thread-846] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 16ms
2020-04-02 05:07:17,531 [Thread-828] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1627096859-172.17.0.17-1585804019062: 26ms
2020-04-02 05:07:17,539 [Thread-828] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:16 AM with interval of 21600000ms
2020-04-02 05:07:17,539 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea): no suitable block pools found to scan.  Waiting 1814385609 ms.
2020-04-02 05:07:17,542 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d): no suitable block pools found to scan.  Waiting 1814385606 ms.
2020-04-02 05:07:17,558 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:33073] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:33073 beginning handshake with NN
2020-04-02 05:07:17,563 [IPC Server handler 3 on 33073] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35241, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=40977, infoSecurePort=0, ipcPort=35091, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062) storage 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:17,563 [IPC Server handler 3 on 33073] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:35241
2020-04-02 05:07:17,564 [IPC Server handler 3 on 33073] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6 (127.0.0.1:35241).
2020-04-02 05:07:17,571 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:33073] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:33073 successfully registered with NN
2020-04-02 05:07:17,572 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:33073] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33073 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:07:17,588 [IPC Server handler 4 on 33073] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a6f147e-8ba2-45eb-9cfc-55223772985d for DN 127.0.0.1:35241
2020-04-02 05:07:17,588 [IPC Server handler 4 on 33073] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-afe7793b-8839-4536-91e9-98e46497afea for DN 127.0.0.1:35241
2020-04-02 05:07:17,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x8bd1bc9aaf17df9c: Processing first storage report for DS-afe7793b-8839-4536-91e9-98e46497afea from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:17,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x8bd1bc9aaf17df9c: from storage DS-afe7793b-8839-4536-91e9-98e46497afea node DatanodeRegistration(127.0.0.1:35241, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=40977, infoSecurePort=0, ipcPort=35091, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 1, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:07:17,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x8bd1bc9aaf17df9c: Processing first storage report for DS-8a6f147e-8ba2-45eb-9cfc-55223772985d from datanode 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6
2020-04-02 05:07:17,597 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x8bd1bc9aaf17df9c: from storage DS-8a6f147e-8ba2-45eb-9cfc-55223772985d node DatanodeRegistration(127.0.0.1:35241, datanodeUuid=7a8472c7-aaa8-46d8-988b-746c9d2a7fd6, infoPort=40977, infoSecurePort=0, ipcPort=35091, storageInfo=lv=-57;cid=testClusterID;nsid=1074675762;c=1585804019062), blocks: 4, hasStaleStorage: false, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:07:17,598 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:33073] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x8bd1bc9aaf17df9c,  containing 2 storage report(s), of which we sent 2. The reports had 5 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:07:17,598 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:33073] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:17,600 [IPC Server handler 6 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,603 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:17,607 [IPC Server handler 7 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,609 [Thread-704] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:07:17,612 [IPC Server handler 8 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p9	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,616 [IPC Server handler 9 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,619 [IPC Server handler 1 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p9	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testReplaceXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testReplaceXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testGetXAttrs
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:17,624 [IPC Server handler 0 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:17,626 [IPC Server handler 2 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,630 [IPC Server handler 3 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,633 [IPC Server handler 4 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,636 [IPC Server handler 5 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,644 [IPC Server handler 6 on 33073] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 6 on 33073, call Call#338 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:33892
java.io.IOException: At least one of the attributes provided was not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.getXAttrs(FSDirXAttrOp.java:129)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getXAttrs(FSNamesystem.java:7735)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getXAttrs(NameNodeRpcServer.java:2181)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getXAttrs(ClientNamenodeProtocolServerSideTranslatorPB.java:1627)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:17,652 [IPC Server handler 7 on 33073] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 7 on 33073, call Call#339 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:33892
java.io.IOException: At least one of the attributes provided was not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.getXAttrs(FSDirXAttrOp.java:129)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getXAttrs(FSNamesystem.java:7735)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getXAttrs(NameNodeRpcServer.java:2181)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.getXAttrs(ClientNamenodeProtocolServerSideTranslatorPB.java:1627)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:17,656 [IPC Server handler 8 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,657 [IPC Server handler 9 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,658 [IPC Server handler 1 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,676 [IPC Server handler 0 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,676 [IPC Server handler 0 on 33073] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 33073, call Call#343 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:33910: org.apache.hadoop.security.AccessControlException: User doesn't have permission for xattr: trusted.foo
2020-04-02 05:07:17,694 [IPC Server handler 2 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,702 [IPC Server handler 3 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p10	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:17,708 [IPC Server handler 4 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,709 [IPC Server handler 4 on 33073] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 33073, call Call#346 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:33910: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p10":root:supergroup:drwx------
2020-04-02 05:07:17,713 [IPC Server handler 5 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p10/child10	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:17,715 [IPC Server handler 6 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p10/child10	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:17,719 [IPC Server handler 7 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p10/child10	dst=null	perm=root:supergroup:rwx------	proto=rpc
2020-04-02 05:07:17,721 [IPC Server handler 8 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10/child10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,722 [IPC Server handler 8 on 33073] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 8 on 33073, call Call#350 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:33910: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p10":root:supergroup:drwx------
2020-04-02 05:07:17,729 [IPC Server handler 9 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p10	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:17,734 [IPC Server handler 1 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10/child10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,734 [IPC Server handler 1 on 33073] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 1 on 33073, call Call#352 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:33910: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=EXECUTE, inode="/p10":root:supergroup:drwx---r--
2020-04-02 05:07:17,745 [IPC Server handler 0 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p10	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:17,746 [IPC Server handler 2 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p10/child10	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:17,754 [IPC Server handler 3 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10/child10	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,754 [IPC Server handler 3 on 33073] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 3 on 33073, call Call#355 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.getXAttrs from 127.0.0.1:33910: org.apache.hadoop.security.AccessControlException: Permission denied: user=user, access=READ, inode="/p10/child10":root:supergroup:drwx-----x
2020-04-02 05:07:17,759 [IPC Server handler 4 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p10	dst=null	perm=root:supergroup:rwx-----x	proto=rpc
2020-04-02 05:07:17,766 [IPC Server handler 5 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p10/child10	dst=null	perm=root:supergroup:rwx---r--	proto=rpc
2020-04-02 05:07:17,769 [IPC Server handler 6 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=user (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p10/child10	dst=null	perm=null	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testGetXAttrs
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testGetXAttrs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRenameFileWithXAttr
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:17,777 [IPC Server handler 7 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p11	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:17,779 [IPC Server handler 8 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,781 [IPC Server handler 9 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,784 [IPC Server handler 1 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p11	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,791 [IPC Server handler 0 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename	src=/p11	dst=/p11-rename	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,792 [IPC Server handler 2 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p11-rename	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,794 [IPC Server handler 3 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p11-rename	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,797 [IPC Server handler 4 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p11-rename	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRenameFileWithXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testRenameFileWithXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testSetXAttr
[msx] perform reset as unitTestCounterInClass 11 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:17,805 [IPC Server handler 5 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/p12	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:07:17,807 [IPC Server handler 6 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,818 [IPC Server handler 7 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,824 [IPC Server handler 8 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p12	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,825 [IPC Server handler 9 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,836 [IPC Server handler 1 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,842 [IPC Server handler 0 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p12	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,848 [IPC Server handler 2 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,849 [IPC Server handler 3 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,851 [IPC Server handler 4 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,853 [IPC Server handler 5 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getXAttrs	src=/p12	dst=null	perm=null	proto=rpc
2020-04-02 05:07:17,860 [IPC Server handler 6 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,863 [IPC Server handler 7 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,865 [IPC Server handler 8 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,867 [IPC Server handler 9 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,870 [IPC Server handler 1 on 33073] INFO  ipc.Server (Server.java:logException(2722)) - IPC Server handler 1 on 33073, call Call#382 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:33892
java.io.IOException: Cannot add additional XAttr to inode, would exceed limit of 3
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setINodeXAttrs(FSDirXAttrOp.java:371)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.unprotectedSetXAttrs(FSDirXAttrOp.java:272)
	at org.apache.hadoop.hdfs.server.namenode.FSDirXAttrOp.setXAttr(FSDirXAttrOp.java:85)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.setXAttr(FSNamesystem.java:7714)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.setXAttr(NameNodeRpcServer.java:2170)
	at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.setXAttr(ClientNamenodeProtocolServerSideTranslatorPB.java:1615)
	at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:523)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:991)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:872)
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:818)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:07:17,874 [IPC Server handler 0 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,878 [IPC Server handler 2 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,886 [IPC Server handler 3 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=removeXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
2020-04-02 05:07:17,888 [IPC Server handler 4 on 33073] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 4 on 33073, call Call#386 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:33892: org.apache.hadoop.HadoopIllegalArgumentException: The XAttr is too big. The maximum combined size of the name and value is 37, but the total size is 50
2020-04-02 05:07:17,890 [IPC Server handler 5 on 33073] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 5 on 33073, call Call#387 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.setXAttr from 127.0.0.1:33892: org.apache.hadoop.HadoopIllegalArgumentException: The XAttr is too big. The maximum combined size of the name and value is 37, but the total size is 38
2020-04-02 05:07:17,896 [IPC Server handler 6 on 33073] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setXAttr	src=/p12	dst=null	perm=root:supergroup:rwxr-x---	proto=rpc
[msx] test Finished org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testSetXAttr
[msx] writeFile testName = org.apache.hadoop.hdfs.server.namenode.TestFileContextXAttr#testSetXAttr
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:07:17,899 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:07:17,899 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:07:17,899 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35091 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:17,899 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:07:17,899 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3e970eba] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:07:17,903 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8a6f147e-8ba2-45eb-9cfc-55223772985d) exiting.
2020-04-02 05:07:17,905 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-afe7793b-8839-4536-91e9-98e46497afea) exiting.
2020-04-02 05:07:17,964 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@775630ee{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:07:17,965 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@9bd456b{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:17,968 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7dfd6f8a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:17,970 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b74f75b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:18,016 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35091
2020-04-02 05:07:18,026 [IPC Server listener on 35091] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35091
2020-04-02 05:07:18,042 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:18,043 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:33073] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:07:18,043 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:33073] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6) service to localhost/127.0.0.1:33073
2020-04-02 05:07:18,043 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:33073] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1627096859-172.17.0.17-1585804019062 (Datanode Uuid 7a8472c7-aaa8-46d8-988b-746c9d2a7fd6)
2020-04-02 05:07:18,043 [BP-1627096859-172.17.0.17-1585804019062 heartbeating to localhost/127.0.0.1:33073] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1627096859-172.17.0.17-1585804019062
2020-04-02 05:07:18,053 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:18,068 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1627096859-172.17.0.17-1585804019062] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:07:18,074 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:07:18,077 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:07:18,079 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:07:18,079 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:07:18,082 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:07:18,082 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:07:18,082 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33073 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:07:18,082 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:18,082 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@7e6c6893] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:07:18,083 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 187, 229
2020-04-02 05:07:18,083 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@a825a85] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:07:18,083 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 44 Total time for transactions(ms): 1 Number of transactions batched in Syncs: 186 Number of syncs: 45 SyncTimes(ms): 3 1 
2020-04-02 05:07:18,085 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000187 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000187-0000000000000000230
2020-04-02 05:07:18,094 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000187 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000187-0000000000000000230
2020-04-02 05:07:18,101 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:07:18,102 [CacheReplicationMonitor(1777097344)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:07:18,109 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33073
2020-04-02 05:07:18,116 [IPC Server listener on 33073] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33073
2020-04-02 05:07:18,135 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:07:18,135 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:07:18,135 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:07:18,148 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:07:18,149 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:07:18,156 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5345bed4{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:07:18,190 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@60eb9ac4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:07:18,198 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f8ae7a6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:07:18,199 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@8811581{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:07:18,214 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:07:18,215 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:07:18,215 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

[msx] before_class
2020-04-02 05:09:23,501 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=2
Formatting using clusterid: testClusterID
2020-04-02 05:09:24,409 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:24,422 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:24,424 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:24,426 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:24,444 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:24,446 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:24,447 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:24,448 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:24,498 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:24,503 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:09:24,504 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:24,504 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:24,509 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:24,510 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:24
2020-04-02 05:09:24,515 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:24,516 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:24,519 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:09:24,519 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:24,544 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:09:24,551 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:24,551 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:24,552 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:24,552 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:24,553 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 2
2020-04-02 05:09:24,553 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:24,553 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:24,554 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:24,554 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:24,554 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:24,554 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:24,607 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:09:24,624 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:24,625 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:24,626 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:09:24,626 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:24,632 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:24,632 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:24,633 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:24,633 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:24,638 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:24,641 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:24,646 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:24,647 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:24,647 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:09:24,648 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:24,657 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:24,659 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:24,659 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:24,663 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:24,665 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:24,668 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:24,670 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:24,671 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:09:24,671 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:24,710 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:24,731 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:09:24,735 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:09:24,748 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:24,749 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:24,885 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:09:24,887 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:09:24,911 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:09:24,916 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:09:25,152 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:09:25,258 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:09:25,666 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:09:25,667 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:09:25,674 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:09:25,706 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:09:25,789 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@272113c4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:25,812 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:09:25,819 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:25,841 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3514ms
2020-04-02 05:09:25,972 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:25,978 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:09:25,979 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:25,987 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:25,990 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:09:25,990 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:25,991 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:26,027 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:09:26,028 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:09:26,037 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41401
2020-04-02 05:09:26,041 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:26,162 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4470fbd6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:26,166 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7098b907{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:26,209 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@52e7a6b2{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:09:26,219 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:41401}
2020-04-02 05:09:26,220 [main] INFO  server.Server (Server.java:doStart(419)) - Started @3893ms
2020-04-02 05:09:26,229 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:26,229 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:09:26,230 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:26,230 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:26,230 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:09:26,230 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:26,231 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:26,231 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:26,232 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:26,232 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:26,232 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:26,233 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:26,233 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:26
2020-04-02 05:09:26,234 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:26,234 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:26,234 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:09:26,235 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:26,239 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:09:26,240 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:26,241 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:26,241 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:26,242 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:26,242 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 2
2020-04-02 05:09:26,243 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:26,245 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:26,245 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:26,245 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:26,246 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:26,246 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:26,247 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:26,247 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:26,248 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:09:26,248 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:26,250 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:26,252 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:26,252 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:26,253 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:26,253 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:26,253 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:26,254 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:26,254 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:26,254 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:09:26,255 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:26,256 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:26,256 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:26,256 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:26,258 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:26,258 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:26,258 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:26,259 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:26,260 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:09:26,260 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:26,272 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 24038@dfeaa374b3e2
2020-04-02 05:09:26,276 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 24038@dfeaa374b3e2
2020-04-02 05:09:26,280 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:09:26,281 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:09:26,284 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:09:26,284 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:09:26,337 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:09:26,347 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:09:26,347 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:09:26,353 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:09:26,357 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:09:26,386 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:09:26,387 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 123 msecs
2020-04-02 05:09:26,583 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:09:26,595 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:26,610 [Socket Reader #1 for port 33223] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33223
2020-04-02 05:09:26,910 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33223 to access this namenode/service.
2020-04-02 05:09:26,916 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:09:27,030 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:09:27,054 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:09:27,055 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:09:27,057 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:09:27,057 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:09:27,060 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:09:27,060 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:09:27,060 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:09:27,060 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:09:27,060 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:09:27,060 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 5 msec
2020-04-02 05:09:27,102 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:27,102 [IPC Server listener on 33223] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33223: starting
2020-04-02 05:09:27,130 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33223
2020-04-02 05:09:27,134 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:09:27,135 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:09:27,139 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:09:27,143 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33223 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:27,150 [CacheReplicationMonitor(166729823)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:09:27,151 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:27,220 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:27,239 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:27,266 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:27,266 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:27,273 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:27,276 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:27,282 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:27,284 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:27,288 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:27,294 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40911
2020-04-02 05:09:27,296 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:27,297 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:27,345 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:27,352 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:27,353 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:27,354 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:27,356 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:27,357 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:27,357 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:27,358 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:27,368 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40255
2020-04-02 05:09:27,368 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:27,370 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@686449f9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:27,371 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@68b6f0d6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:27,377 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5dd91bca{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:27,378 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@40cb698e{HTTP/1.1,[http/1.1]}{localhost:40255}
2020-04-02 05:09:27,387 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5059ms
2020-04-02 05:09:27,911 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45122
2020-04-02 05:09:27,923 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:27,923 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:27,926 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@165b8a71] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:27,942 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:27,947 [Socket Reader #1 for port 41607] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41607
2020-04-02 05:09:27,963 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41607
2020-04-02 05:09:27,987 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:27,991 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:28,398 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33223 starting to offer service
2020-04-02 05:09:28,439 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:28,439 [IPC Server listener on 41607] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41607: starting
2020-04-02 05:09:28,443 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41607 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:28,445 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:28,447 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:28,447 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:28,449 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:28,449 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:28,449 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:28,449 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:28,450 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:28,457 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:28,458 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:28,460 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34838
2020-04-02 05:09:28,460 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:28,460 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:28,463 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:28,466 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:28,468 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:28,469 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:28,471 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:28,472 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:28,472 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:28,472 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:28,474 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35587
2020-04-02 05:09:28,474 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:28,476 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60fa3495{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:28,477 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@79e18e38{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:28,483 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@35fe2125{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:28,520 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@94f6bfb{HTTP/1.1,[http/1.1]}{localhost:35587}
2020-04-02 05:09:28,520 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6194ms
2020-04-02 05:09:28,643 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37886
2020-04-02 05:09:28,644 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2484f433] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:28,644 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:09:28,644 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:28,645 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:28,646 [Socket Reader #1 for port 41462] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41462
2020-04-02 05:09:28,658 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41462
2020-04-02 05:09:28,663 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:28,663 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:28,665 [Thread-83] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33223 starting to offer service
2020-04-02 05:09:28,677 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41462 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:28,680 [IPC Server listener on 41462] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41462: starting
2020-04-02 05:09:28,709 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:29,061 [Thread-83] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33223
2020-04-02 05:09:29,063 [Thread-83] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:29,069 [Thread-83] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 24038@dfeaa374b3e2
2020-04-02 05:09:29,070 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1986316399. Formatting...
2020-04-02 05:09:29,071 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2f9715ff-ace8-4776-b1de-9175467b4049 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:09:29,074 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33223
2020-04-02 05:09:29,074 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:29,076 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 24038@dfeaa374b3e2
2020-04-02 05:09:29,076 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1986316399. Formatting...
2020-04-02 05:09:29,077 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-11e9fd56-4531-46a1-9dc5-b40b9282d91e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:09:29,077 [Thread-83] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 24038@dfeaa374b3e2
2020-04-02 05:09:29,078 [Thread-83] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1986316399. Formatting...
2020-04-02 05:09:29,080 [Thread-83] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e76ec0c6-c992-400f-b5e9-62cd912c76bc for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:09:29,080 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 24038@dfeaa374b3e2
2020-04-02 05:09:29,081 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1986316399. Formatting...
2020-04-02 05:09:29,081 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ed5b25bd-16b9-4ee0-8cb0-a489fe4fe4e2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:09:29,095 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,096 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,097 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1775166591-172.17.0.16-1585804164696 is not formatted. Formatting ...
2020-04-02 05:09:29,097 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775166591-172.17.0.16-1585804164696 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current
2020-04-02 05:09:29,100 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,100 [Thread-83] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,100 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1775166591-172.17.0.16-1585804164696 is not formatted. Formatting ...
2020-04-02 05:09:29,101 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775166591-172.17.0.16-1585804164696 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696/current
2020-04-02 05:09:29,111 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,112 [Thread-83] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,112 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,113 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1775166591-172.17.0.16-1585804164696 is not formatted. Formatting ...
2020-04-02 05:09:29,113 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,113 [Thread-83] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775166591-172.17.0.16-1585804164696 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696/current
2020-04-02 05:09:29,113 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1775166591-172.17.0.16-1585804164696 is not formatted. Formatting ...
2020-04-02 05:09:29,114 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1775166591-172.17.0.16-1585804164696 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current
2020-04-02 05:09:29,116 [Thread-83] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1986316399;bpid=BP-1775166591-172.17.0.16-1585804164696;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1986316399;c=1585804164696;bpid=BP-1775166591-172.17.0.16-1585804164696;dnuuid=null
2020-04-02 05:09:29,118 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1986316399;bpid=BP-1775166591-172.17.0.16-1585804164696;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1986316399;c=1585804164696;bpid=BP-1775166591-172.17.0.16-1585804164696;dnuuid=null
2020-04-02 05:09:29,120 [Thread-83] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID cc93be0b-f1e0-4c31-8ce8-9f983943fd0e
2020-04-02 05:09:29,127 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5c2569a9-a4ad-4200-9514-a582e737543d
2020-04-02 05:09:29,261 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2f9715ff-ace8-4776-b1de-9175467b4049
2020-04-02 05:09:29,261 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-11e9fd56-4531-46a1-9dc5-b40b9282d91e
2020-04-02 05:09:29,262 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:09:29,262 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:09:29,265 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ed5b25bd-16b9-4ee0-8cb0-a489fe4fe4e2
2020-04-02 05:09:29,265 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:09:29,274 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e76ec0c6-c992-400f-b5e9-62cd912c76bc
2020-04-02 05:09:29,279 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:09:29,282 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:29,282 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:29,319 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:29,343 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:29,357 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:29,360 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:29,368 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:29,430 [Thread-83] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:29,430 [Thread-83] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:29,374 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:29,432 [Thread-83] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,432 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,437 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:29,465 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:29,465 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:29,467 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:29,571 [Thread-103] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1775166591-172.17.0.16-1585804164696 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 135ms
2020-04-02 05:09:29,571 [Thread-106] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1775166591-172.17.0.16-1585804164696 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 104ms
2020-04-02 05:09:29,587 [Thread-105] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1775166591-172.17.0.16-1585804164696 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 120ms
2020-04-02 05:09:29,587 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1775166591-172.17.0.16-1585804164696: 155ms
2020-04-02 05:09:29,588 [Thread-104] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1775166591-172.17.0.16-1585804164696 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 123ms
2020-04-02 05:09:29,589 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1775166591-172.17.0.16-1585804164696: 156ms
2020-04-02 05:09:29,591 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:29,591 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:29,591 [Thread-111] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/replicas doesn't exist 
2020-04-02 05:09:29,591 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:09:29,591 [Thread-114] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:09:29,592 [Thread-111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 1ms
2020-04-02 05:09:29,591 [Thread-112] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/replicas doesn't exist 
2020-04-02 05:09:29,592 [Thread-114] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696/current/replicas doesn't exist 
2020-04-02 05:09:29,591 [Thread-113] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696/current/replicas doesn't exist 
2020-04-02 05:09:29,614 [Thread-114] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 22ms
2020-04-02 05:09:29,617 [Thread-112] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 26ms
2020-04-02 05:09:29,617 [Thread-113] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 26ms
2020-04-02 05:09:29,617 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696: 27ms
2020-04-02 05:09:29,619 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:29,620 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:29,621 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-11e9fd56-4531-46a1-9dc5-b40b9282d91e): finished scanning block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,621 [Thread-83] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1775166591-172.17.0.16-1585804164696: 31ms
2020-04-02 05:09:29,623 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:09:29,623 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2f9715ff-ace8-4776-b1de-9175467b4049): finished scanning block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,626 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:09:29,626 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e76ec0c6-c992-400f-b5e9-62cd912c76bc): finished scanning block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,628 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:12 AM with interval of 21600000ms
2020-04-02 05:09:29,622 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1775166591-172.17.0.16-1585804164696 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:29,630 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ed5b25bd-16b9-4ee0-8cb0-a489fe4fe4e2): finished scanning block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,630 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:29,631 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:29,636 [Thread-83] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:47 AM with interval of 21600000ms
2020-04-02 05:09:29,660 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1775166591-172.17.0.16-1585804164696 (Datanode Uuid 5c2569a9-a4ad-4200-9514-a582e737543d) service to localhost/127.0.0.1:33223 beginning handshake with NN
2020-04-02 05:09:29,662 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1775166591-172.17.0.16-1585804164696 (Datanode Uuid cc93be0b-f1e0-4c31-8ce8-9f983943fd0e) service to localhost/127.0.0.1:33223 beginning handshake with NN
2020-04-02 05:09:29,672 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-11e9fd56-4531-46a1-9dc5-b40b9282d91e): no suitable block pools found to scan.  Waiting 1814399947 ms.
2020-04-02 05:09:29,674 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2f9715ff-ace8-4776-b1de-9175467b4049): no suitable block pools found to scan.  Waiting 1814399949 ms.
2020-04-02 05:09:29,674 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ed5b25bd-16b9-4ee0-8cb0-a489fe4fe4e2): no suitable block pools found to scan.  Waiting 1814399945 ms.
2020-04-02 05:09:29,674 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e76ec0c6-c992-400f-b5e9-62cd912c76bc): no suitable block pools found to scan.  Waiting 1814399949 ms.
2020-04-02 05:09:29,708 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40911, datanodeUuid=5c2569a9-a4ad-4200-9514-a582e737543d, infoPort=45122, infoSecurePort=0, ipcPort=41607, storageInfo=lv=-57;cid=testClusterID;nsid=1986316399;c=1585804164696) storage 5c2569a9-a4ad-4200-9514-a582e737543d
2020-04-02 05:09:29,710 [IPC Server handler 0 on 33223] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:40911
2020-04-02 05:09:29,711 [IPC Server handler 0 on 33223] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5c2569a9-a4ad-4200-9514-a582e737543d (127.0.0.1:40911).
2020-04-02 05:09:29,714 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34838, datanodeUuid=cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, infoPort=37886, infoSecurePort=0, ipcPort=41462, storageInfo=lv=-57;cid=testClusterID;nsid=1986316399;c=1585804164696) storage cc93be0b-f1e0-4c31-8ce8-9f983943fd0e
2020-04-02 05:09:29,714 [IPC Server handler 8 on 33223] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:34838
2020-04-02 05:09:29,714 [IPC Server handler 8 on 33223] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN cc93be0b-f1e0-4c31-8ce8-9f983943fd0e (127.0.0.1:34838).
2020-04-02 05:09:29,718 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1775166591-172.17.0.16-1585804164696 (Datanode Uuid 5c2569a9-a4ad-4200-9514-a582e737543d) service to localhost/127.0.0.1:33223 successfully registered with NN
2020-04-02 05:09:29,718 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33223 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:29,719 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1775166591-172.17.0.16-1585804164696 (Datanode Uuid cc93be0b-f1e0-4c31-8ce8-9f983943fd0e) service to localhost/127.0.0.1:33223 successfully registered with NN
2020-04-02 05:09:29,719 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33223 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:29,742 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:29,744 [IPC Server handler 3 on 33223] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2f9715ff-ace8-4776-b1de-9175467b4049 for DN 127.0.0.1:34838
2020-04-02 05:09:29,745 [IPC Server handler 3 on 33223] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e76ec0c6-c992-400f-b5e9-62cd912c76bc for DN 127.0.0.1:34838
2020-04-02 05:09:29,746 [IPC Server handler 1 on 33223] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-11e9fd56-4531-46a1-9dc5-b40b9282d91e for DN 127.0.0.1:40911
2020-04-02 05:09:29,758 [IPC Server handler 1 on 33223] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ed5b25bd-16b9-4ee0-8cb0-a489fe4fe4e2 for DN 127.0.0.1:40911
2020-04-02 05:09:29,759 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:34838
2020-04-02 05:09:29,759 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:29,778 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x521bdc7dfb169920: Processing first storage report for DS-ed5b25bd-16b9-4ee0-8cb0-a489fe4fe4e2 from datanode 5c2569a9-a4ad-4200-9514-a582e737543d
2020-04-02 05:09:29,780 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x521bdc7dfb169920: from storage DS-ed5b25bd-16b9-4ee0-8cb0-a489fe4fe4e2 node DatanodeRegistration(127.0.0.1:40911, datanodeUuid=5c2569a9-a4ad-4200-9514-a582e737543d, infoPort=45122, infoSecurePort=0, ipcPort=41607, storageInfo=lv=-57;cid=testClusterID;nsid=1986316399;c=1585804164696), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:09:29,780 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfd4cca51edf13550: Processing first storage report for DS-2f9715ff-ace8-4776-b1de-9175467b4049 from datanode cc93be0b-f1e0-4c31-8ce8-9f983943fd0e
2020-04-02 05:09:29,780 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfd4cca51edf13550: from storage DS-2f9715ff-ace8-4776-b1de-9175467b4049 node DatanodeRegistration(127.0.0.1:34838, datanodeUuid=cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, infoPort=37886, infoSecurePort=0, ipcPort=41462, storageInfo=lv=-57;cid=testClusterID;nsid=1986316399;c=1585804164696), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:29,781 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x521bdc7dfb169920: Processing first storage report for DS-11e9fd56-4531-46a1-9dc5-b40b9282d91e from datanode 5c2569a9-a4ad-4200-9514-a582e737543d
2020-04-02 05:09:29,781 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x521bdc7dfb169920: from storage DS-11e9fd56-4531-46a1-9dc5-b40b9282d91e node DatanodeRegistration(127.0.0.1:40911, datanodeUuid=5c2569a9-a4ad-4200-9514-a582e737543d, infoPort=45122, infoSecurePort=0, ipcPort=41607, storageInfo=lv=-57;cid=testClusterID;nsid=1986316399;c=1585804164696), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:29,781 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xfd4cca51edf13550: Processing first storage report for DS-e76ec0c6-c992-400f-b5e9-62cd912c76bc from datanode cc93be0b-f1e0-4c31-8ce8-9f983943fd0e
2020-04-02 05:09:29,782 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xfd4cca51edf13550: from storage DS-e76ec0c6-c992-400f-b5e9-62cd912c76bc node DatanodeRegistration(127.0.0.1:34838, datanodeUuid=cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, infoPort=37886, infoSecurePort=0, ipcPort=41462, storageInfo=lv=-57;cid=testClusterID;nsid=1986316399;c=1585804164696), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:29,815 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x521bdc7dfb169920,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 50 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:29,815 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,823 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xfd4cca51edf13550,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 6 msec to generate and 57 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:29,823 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:29,870 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:29,873 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:29,893 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:29,895 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:29,911 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/	dst=null	perm=root:supergroup:rwxrwxrwx	proto=rpc
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testTruncate
[msx] unitTestCounterInClass = 0
Apr 02, 2020 5:09:30 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.hdfs.server.namenode.web.resources
  org.apache.hadoop.hdfs.web.resources
Apr 02, 2020 5:09:30 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods
Apr 02, 2020 5:09:30 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.hdfs.web.resources.UserProvider
  class org.apache.hadoop.hdfs.web.resources.ExceptionHandler
Apr 02, 2020 5:09:30 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
Apr 02, 2020 5:09:31 AM com.sun.jersey.spi.inject.Errors processErrorMessages
WARNING: The following warnings have been detected with resource and/or provider classes:
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.putRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PutOpParam,org.apache.hadoop.hdfs.web.resources.DestinationParam,org.apache.hadoop.hdfs.web.resources.OwnerParam,org.apache.hadoop.hdfs.web.resources.GroupParam,org.apache.hadoop.hdfs.web.resources.PermissionParam,org.apache.hadoop.hdfs.web.resources.UnmaskedPermissionParam,org.apache.hadoop.hdfs.web.resources.OverwriteParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ReplicationParam,org.apache.hadoop.hdfs.web.resources.BlockSizeParam,org.apache.hadoop.hdfs.web.resources.ModificationTimeParam,org.apache.hadoop.hdfs.web.resources.AccessTimeParam,org.apache.hadoop.hdfs.web.resources.RenameOptionSetParam,org.apache.hadoop.hdfs.web.resources.CreateParentParam,org.apache.hadoop.hdfs.web.resources.TokenArgumentParam,org.apache.hadoop.hdfs.web.resources.AclPermissionParam,org.apache.hadoop.hdfs.web.resources.XAttrNameParam,org.apache.hadoop.hdfs.web.resources.XAttrValueParam,org.apache.hadoop.hdfs.web.resources.XAttrSetFlagParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.CreateFlagParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StoragePolicyParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.postRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.PostOpParam,org.apache.hadoop.hdfs.web.resources.ConcatSourcesParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.NewLengthParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.deleteRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.DeleteOpParam,org.apache.hadoop.hdfs.web.resources.RecursiveParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
  WARNING: A sub-resource method, public javax.ws.rs.core.Response org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getRoot(org.apache.hadoop.security.UserGroupInformation,org.apache.hadoop.hdfs.web.resources.DelegationParam,org.apache.hadoop.hdfs.web.resources.UserParam,org.apache.hadoop.hdfs.web.resources.DoAsParam,org.apache.hadoop.hdfs.web.resources.GetOpParam,org.apache.hadoop.hdfs.web.resources.OffsetParam,org.apache.hadoop.hdfs.web.resources.LengthParam,org.apache.hadoop.hdfs.web.resources.RenewerParam,org.apache.hadoop.hdfs.web.resources.BufferSizeParam,java.util.List,org.apache.hadoop.hdfs.web.resources.XAttrEncodingParam,org.apache.hadoop.hdfs.web.resources.ExcludeDatanodesParam,org.apache.hadoop.hdfs.web.resources.FsActionParam,org.apache.hadoop.hdfs.web.resources.SnapshotNameParam,org.apache.hadoop.hdfs.web.resources.OldSnapshotNameParam,org.apache.hadoop.hdfs.web.resources.TokenKindParam,org.apache.hadoop.hdfs.web.resources.TokenServiceParam,org.apache.hadoop.hdfs.web.resources.NoRedirectParam,org.apache.hadoop.hdfs.web.resources.StartAfterParam) throws java.io.IOException,java.lang.InterruptedException, with URI template, "/", is treated as a resource method
2020-04-02 05:09:31,355 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:31,622 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:31,655 [nioEventLoopGroup-3-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:09:31,683 [IPC Server handler 2 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:40911, 127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:31,924 [DataXceiver for client DFSClient_NONMAPREDUCE_-846683412_176 at /127.0.0.1:54650 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001 src: /127.0.0.1:54650 dest: /127.0.0.1:40911
2020-04-02 05:09:31,954 [DataXceiver for client DFSClient_NONMAPREDUCE_-846683412_176 at /127.0.0.1:50108 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001 src: /127.0.0.1:50108 dest: /127.0.0.1:34838
2020-04-02 05:09:32,045 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50108, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-846683412_176, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001, duration(ns): 44155796
2020-04-02 05:09:32,046 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:32,055 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54650, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-846683412_176, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001, duration(ns): 79936990
2020-04-02 05:09:32,055 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741825_1001, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838] terminating
2020-04-02 05:09:32,080 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:40911, 127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:32,092 [DataXceiver for client DFSClient_NONMAPREDUCE_-846683412_176 at /127.0.0.1:54808 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002 src: /127.0.0.1:54808 dest: /127.0.0.1:40911
2020-04-02 05:09:32,095 [DataXceiver for client DFSClient_NONMAPREDUCE_-846683412_176 at /127.0.0.1:50238 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002 src: /127.0.0.1:50238 dest: /127.0.0.1:34838
2020-04-02 05:09:32,122 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50238, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-846683412_176, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002, duration(ns): 23735212
2020-04-02 05:09:32,122 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:32,135 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54808, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-846683412_176, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002, duration(ns): 29255972
2020-04-02 05:09:32,135 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741826_1002, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838] terminating
2020-04-02 05:09:32,150 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-846683412_176
Apr 02, 2020 5:09:32 AM com.sun.jersey.spi.container.servlet.WebComponent filterFormParameters
WARNING: A servlet request, to the URI http://localhost:41401/webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=TRUNCATE&user.name=rootx&newlength=1024, contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected.
2020-04-02 05:09:32,182 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=truncate	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=webhdfs
2020-04-02 05:09:32,207 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,230 [main] INFO  hdfs.AppendTestUtil (AppendTestUtil.java:<clinit>(53)) - seed=1951509411609920601
2020-04-02 05:09:32,240 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,253 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,257 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,285 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:32,354 [nioEventLoopGroup-3-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=OPEN&user.name=rootx&namenoderpcaddress=localhost:33223&buffersize=4096&offset=0 200
2020-04-02 05:09:32,387 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=contentSummary	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,406 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,414 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testTruncate
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testTruncate
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testMkdirsFailsForSubdirectoryOfExistingFile
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:32,429 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:32,447 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,449 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:32,474 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:32,486 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,519 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:32,546 [nioEventLoopGroup-5-1] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:32,560 [IPC Server handler 3 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:32,565 [DataXceiver for client DFSClient_NONMAPREDUCE_727932571_368 at /127.0.0.1:55270 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741827_1003 src: /127.0.0.1:55270 dest: /127.0.0.1:40911
2020-04-02 05:09:32,602 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55270, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_727932571_368, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741827_1003, duration(ns): 27449841
2020-04-02 05:09:32,602 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:32,608 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741828_1004, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:32,615 [DataXceiver for client DFSClient_NONMAPREDUCE_727932571_368 at /127.0.0.1:55302 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741828_1004]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741828_1004 src: /127.0.0.1:55302 dest: /127.0.0.1:40911
2020-04-02 05:09:32,629 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55302, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_727932571_368, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741828_1004, duration(ns): 11463244
2020-04-02 05:09:32,629 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741828_1004, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741828_1004, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:32,635 [IPC Server handler 5 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_727932571_368
2020-04-02 05:09:32,647 [qtp485937598-530] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.ParentNotDirectoryException: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file (is not a directory)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkIsDirectory(FSPermissionChecker.java:638)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:314)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:242)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:193)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:606)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1801)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1819)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(FSDirectory.java:676)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3146)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1126)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:662)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:32,667 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file/subdir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,667 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.security.AccessControlException: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file (is not a directory)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(FSDirectory.java:679)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:114)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3102)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1154)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1101)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:32,681 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.ParentNotDirectoryException: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file (is not a directory)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkIsDirectory(FSPermissionChecker.java:638)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:314)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:242)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:193)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:606)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1801)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1819)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(FSDirectory.java:676)
	at org.apache.hadoop.hdfs.server.namenode.FSDirMkdirOp.mkdirs(FSDirMkdirOp.java:50)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.mkdirs(FSNamesystem.java:3146)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.mkdirs(NameNodeRpcServer.java:1126)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:662)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:32,701 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file/deep/sub/dir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:32,702 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.security.AccessControlException: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file (is not a directory)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(FSDirectory.java:679)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getFileInfo(FSDirStatAndListingOp.java:114)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getFileInfo(FSNamesystem.java:3102)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getFileInfo(NameNodeRpcServer.java:1154)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1101)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:32,711 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testMkdirsFailsForSubdirectoryOfExistingFile
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testMkdirsFailsForSubdirectoryOfExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testJsonParseClosesInputStream
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:32,741 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:32,759 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:32,763 [nioEventLoopGroup-3-3] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:32,766 [IPC Server handler 7 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741829_1005, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:32,772 [DataXceiver for client DFSClient_NONMAPREDUCE_-1470881242_178 at /127.0.0.1:50868 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741829_1005]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741829_1005 src: /127.0.0.1:50868 dest: /127.0.0.1:34838
2020-04-02 05:09:32,777 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50868, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1470881242_178, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741829_1005, duration(ns): 3596114
2020-04-02 05:09:32,778 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741829_1005, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741829_1005, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:32,781 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741830_1006, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:32,787 [DataXceiver for client DFSClient_NONMAPREDUCE_-1470881242_178 at /127.0.0.1:50880 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741830_1006]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741830_1006 src: /127.0.0.1:50880 dest: /127.0.0.1:34838
2020-04-02 05:09:32,799 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50880, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1470881242_178, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741830_1006, duration(ns): 9910879
2020-04-02 05:09:32,799 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741830_1006, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741830_1006, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:32,802 [IPC Server handler 3 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741830_1006 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:33,206 [IPC Server handler 2 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-1470881242_178
2020-04-02 05:09:33,456 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testJsonParseClosesInputStream
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testJsonParseClosesInputStream
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testConcat
[msx] perform reset as unitTestCounterInClass 3 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:33,469 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:33,476 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:33,496 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file1	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:33,499 [nioEventLoopGroup-3-4] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/hadoop/file1?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:09:33,504 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741831_1007, replicas=127.0.0.1:34838, 127.0.0.1:40911 for /test/hadoop/file1
2020-04-02 05:09:33,515 [DataXceiver for client DFSClient_NONMAPREDUCE_-1882816083_179 at /127.0.0.1:51136 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007 src: /127.0.0.1:51136 dest: /127.0.0.1:34838
2020-04-02 05:09:33,519 [DataXceiver for client DFSClient_NONMAPREDUCE_-1882816083_179 at /127.0.0.1:55718 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007 src: /127.0.0.1:55718 dest: /127.0.0.1:40911
2020-04-02 05:09:33,551 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55718, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1882816083_179, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007, duration(ns): 30120453
2020-04-02 05:09:33,551 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:33,564 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51136, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1882816083_179, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007, duration(ns): 37450425
2020-04-02 05:09:33,564 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741831_1007, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911] terminating
2020-04-02 05:09:33,571 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/hadoop/file1 is closed by DFSClient_NONMAPREDUCE_-1882816083_179
2020-04-02 05:09:33,587 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:33,611 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file2	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:33,612 [nioEventLoopGroup-3-5] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/hadoop/file2?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:09:33,624 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741832_1008, replicas=127.0.0.1:34838, 127.0.0.1:40911 for /test/hadoop/file2
2020-04-02 05:09:33,629 [DataXceiver for client DFSClient_NONMAPREDUCE_1176819049_180 at /127.0.0.1:51238 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008 src: /127.0.0.1:51238 dest: /127.0.0.1:34838
2020-04-02 05:09:33,635 [DataXceiver for client DFSClient_NONMAPREDUCE_1176819049_180 at /127.0.0.1:55828 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008 src: /127.0.0.1:55828 dest: /127.0.0.1:40911
2020-04-02 05:09:33,644 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55828, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1176819049_180, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008, duration(ns): 8062593
2020-04-02 05:09:33,645 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:33,646 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51238, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1176819049_180, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008, duration(ns): 9311658
2020-04-02 05:09:33,647 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741832_1008, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911] terminating
2020-04-02 05:09:33,648 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/hadoop/file2 is closed by DFSClient_NONMAPREDUCE_1176819049_180
2020-04-02 05:09:33,655 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:33,670 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/hadoop/file3	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:33,672 [nioEventLoopGroup-5-2] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/hadoop/file3?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:09:33,676 [IPC Server handler 5 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741833_1009, replicas=127.0.0.1:40911, 127.0.0.1:34838 for /test/hadoop/file3
2020-04-02 05:09:33,681 [DataXceiver for client DFSClient_NONMAPREDUCE_-621429608_369 at /127.0.0.1:56000 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009 src: /127.0.0.1:56000 dest: /127.0.0.1:40911
2020-04-02 05:09:33,683 [DataXceiver for client DFSClient_NONMAPREDUCE_-621429608_369 at /127.0.0.1:51440 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009 src: /127.0.0.1:51440 dest: /127.0.0.1:34838
2020-04-02 05:09:33,694 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51440, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-621429608_369, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009, duration(ns): 8688275
2020-04-02 05:09:33,694 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:33,698 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56000, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-621429608_369, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009, duration(ns): 11168731
2020-04-02 05:09:33,698 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741833_1009, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838] terminating
2020-04-02 05:09:33,700 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/hadoop/file3 is closed by DFSClient_NONMAPREDUCE_-621429608_369
2020-04-02 05:09:33,707 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:33,720 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/test/hadoop/catFile	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:33,722 [nioEventLoopGroup-5-3] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/test/hadoop/catFile?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=3&unmaskedpermission=666 201
2020-04-02 05:09:33,727 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741834_1010, replicas=127.0.0.1:40911, 127.0.0.1:34838 for /test/hadoop/catFile
2020-04-02 05:09:33,733 [DataXceiver for client DFSClient_NONMAPREDUCE_-1782531129_370 at /127.0.0.1:56180 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010 src: /127.0.0.1:56180 dest: /127.0.0.1:40911
2020-04-02 05:09:33,736 [DataXceiver for client DFSClient_NONMAPREDUCE_-1782531129_370 at /127.0.0.1:51612 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010 src: /127.0.0.1:51612 dest: /127.0.0.1:34838
2020-04-02 05:09:33,763 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51612, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1782531129_370, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010, duration(ns): 21155342
2020-04-02 05:09:33,765 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:33,770 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56180, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1782531129_370, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010, duration(ns): 27717424
2020-04-02 05:09:33,770 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741834_1010, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838] terminating
2020-04-02 05:09:33,772 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test/hadoop/catFile is closed by DFSClient_NONMAPREDUCE_-1782531129_370
2020-04-02 05:09:33,790 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/hadoop/catFile	dst=null	perm=null	proto=webhdfs
Apr 02, 2020 5:09:33 AM com.sun.jersey.spi.container.servlet.WebComponent filterFormParameters
WARNING: A servlet request, to the URI http://localhost:41401/webhdfs/v1/test/hadoop/catFile?op=CONCAT&user.name=rootx&sources=%2Ftest%2Fhadoop%2Ffile1%2C%2Ftest%2Fhadoop%2Ffile2%2C%2Ftest%2Fhadoop%2Ffile3, contains form parameters in the request body but the request body has been consumed by the servlet or a servlet filter accessing the request parameters. Only resource methods using @FormParam will work as expected. Resource methods consuming the request body by other means will not work as expected.
2020-04-02 05:09:33,807 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=concat	src=[/test/hadoop/file1, /test/hadoop/file2, /test/hadoop/file3]	dst=/test/hadoop/catFile	perm=rootx:supergroup:rw-r--r--	proto=webhdfs
2020-04-02 05:09:33,814 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/hadoop/file1	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:33,815 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /test/hadoop/file1
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:33,821 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/hadoop/file2	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:33,822 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /test/hadoop/file2
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:33,829 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/hadoop/file3	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:33,830 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /test/hadoop/file3
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:33,839 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/test/hadoop/catFile	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:33,846 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testConcat
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testConcat
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWorkingDirectory
[msx] perform reset as unitTestCounterInClass 4 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:33,857 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:33,863 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/existingDir1	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:33,872 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/existingDir2	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:33,884 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/existingDir2/foo	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:33,885 [nioEventLoopGroup-3-6] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/existingDir2/foo?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:33,889 [IPC Server handler 3 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741835_1011, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/existingDir2/foo
2020-04-02 05:09:33,896 [DataXceiver for client DFSClient_NONMAPREDUCE_-880491419_181 at /127.0.0.1:56596 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741835_1011]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741835_1011 src: /127.0.0.1:56596 dest: /127.0.0.1:40911
2020-04-02 05:09:33,907 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56596, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-880491419_181, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741835_1011, duration(ns): 7527221
2020-04-02 05:09:33,908 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741835_1011, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741835_1011, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:33,910 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741836_1012, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/existingDir2/foo
2020-04-02 05:09:33,914 [DataXceiver for client DFSClient_NONMAPREDUCE_-880491419_181 at /127.0.0.1:52064 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741836_1012]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741836_1012 src: /127.0.0.1:52064 dest: /127.0.0.1:34838
2020-04-02 05:09:33,921 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52064, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-880491419_181, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741836_1012, duration(ns): 3181658
2020-04-02 05:09:33,921 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741836_1012, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741836_1012, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:33,924 [IPC Server handler 4 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741836_1012 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/existingDir2/foo
2020-04-02 05:09:34,326 [IPC Server handler 7 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/existingDir2/foo is closed by DFSClient_NONMAPREDUCE_-880491419_181
2020-04-02 05:09:34,332 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/existingDir2/foo	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,333 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/existingDir2/foo	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,340 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/existingDir2/newDir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,346 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/existingDir2/newDir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,353 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWorkingDirectory
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWorkingDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithNoMatchingPathsAndNonTrivialFilter
[msx] perform reset as unitTestCounterInClass 5 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:34,360 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,365 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,365 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:34,376 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,390 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,402 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,407 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,466 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,486 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithNoMatchingPathsAndNonTrivialFilter
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithNoMatchingPathsAndNonTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToNonExistentDirectory
[msx] perform reset as unitTestCounterInClass 6 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:34,491 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,531 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:34,533 [nioEventLoopGroup-3-7] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:34,538 [IPC Server handler 2 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741837_1013, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:34,545 [DataXceiver for client DFSClient_NONMAPREDUCE_1501432715_182 at /127.0.0.1:57666 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741837_1013]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741837_1013 src: /127.0.0.1:57666 dest: /127.0.0.1:40911
2020-04-02 05:09:34,572 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57666, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1501432715_182, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741837_1013, duration(ns): 14848653
2020-04-02 05:09:34,573 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741837_1013, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741837_1013, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:34,580 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741838_1014, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:34,594 [DataXceiver for client DFSClient_NONMAPREDUCE_1501432715_182 at /127.0.0.1:53128 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741838_1014]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741838_1014 src: /127.0.0.1:53128 dest: /127.0.0.1:34838
2020-04-02 05:09:34,606 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:53128, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1501432715_182, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741838_1014, duration(ns): 8407437
2020-04-02 05:09:34,607 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741838_1014, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741838_1014, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:34,610 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1501432715_182
2020-04-02 05:09:34,634 [IPC Server handler 9 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:unprotectedRenameTo(387)) - DIR* FSDirectory.unprotectedRenameTo: rename destination parent /tmp/TestFSMainOperationsWebHdfs/test/nonExistent/newfile not found.
2020-04-02 05:09:34,635 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: rename destination parent /tmp/TestFSMainOperationsWebHdfs/test/nonExistent/newfile not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:34,643 [IPC Server handler 0 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:unprotectedRenameTo(387)) - DIR* FSDirectory.unprotectedRenameTo: rename destination parent /tmp/TestFSMainOperationsWebHdfs/test/nonExistent/newfile not found.
2020-04-02 05:09:34,644 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: rename destination parent /tmp/TestFSMainOperationsWebHdfs/test/nonExistent/newfile not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:34,649 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToNonExistentDirectory
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToNonExistentDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testDeleteEmptyDirectory
[msx] perform reset as unitTestCounterInClass 7 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:34,679 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,687 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,694 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,700 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,710 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,710 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:34,728 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testDeleteEmptyDirectory
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testDeleteEmptyDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryToNonExistentParent
[msx] perform reset as unitTestCounterInClass 8 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:34,754 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,761 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,766 [IPC Server handler 0 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:unprotectedRenameTo(387)) - DIR* FSDirectory.unprotectedRenameTo: rename destination parent /tmp/TestFSMainOperationsWebHdfs/test/nonExistent/newdir not found.
2020-04-02 05:09:34,766 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: rename destination parent /tmp/TestFSMainOperationsWebHdfs/test/nonExistent/newdir not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:34,772 [IPC Server handler 3 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:unprotectedRenameTo(387)) - DIR* FSDirectory.unprotectedRenameTo: rename destination parent /tmp/TestFSMainOperationsWebHdfs/test/nonExistent/newdir not found.
2020-04-02 05:09:34,772 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: rename destination parent /tmp/TestFSMainOperationsWebHdfs/test/nonExistent/newdir not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:389)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:34,781 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryToNonExistentParent
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryToNonExistentParent
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testInputStreamClosedTwice
[msx] perform reset as unitTestCounterInClass 9 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:34,791 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,807 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:34,818 [nioEventLoopGroup-3-8] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:34,821 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741839_1015, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:34,825 [DataXceiver for client DFSClient_NONMAPREDUCE_-121959792_183 at /127.0.0.1:58012 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741839_1015]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741839_1015 src: /127.0.0.1:58012 dest: /127.0.0.1:40911
2020-04-02 05:09:34,845 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58012, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-121959792_183, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741839_1015, duration(ns): 16352347
2020-04-02 05:09:34,845 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741839_1015, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741839_1015, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:34,857 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741840_1016, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:34,859 [DataXceiver for client DFSClient_NONMAPREDUCE_-121959792_183 at /127.0.0.1:58040 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741840_1016]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741840_1016 src: /127.0.0.1:58040 dest: /127.0.0.1:40911
2020-04-02 05:09:34,874 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58040, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-121959792_183, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741840_1016, duration(ns): 12371420
2020-04-02 05:09:34,874 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741840_1016, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741840_1016, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:34,876 [IPC Server handler 3 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-121959792_183
2020-04-02 05:09:34,891 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,892 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:34,897 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testInputStreamClosedTwice
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testInputStreamClosedTwice
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteOneBlock
[msx] perform reset as unitTestCounterInClass 10 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:34,902 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,911 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:34,931 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:34,934 [nioEventLoopGroup-3-9] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:34,942 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741841_1017, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:34,948 [DataXceiver for client DFSClient_NONMAPREDUCE_-1383806935_184 at /127.0.0.1:58196 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741841_1017]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741841_1017 src: /127.0.0.1:58196 dest: /127.0.0.1:40911
2020-04-02 05:09:34,969 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58196, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1383806935_184, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741841_1017, duration(ns): 15871711
2020-04-02 05:09:34,970 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741841_1017, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741841_1017, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:34,973 [IPC Server handler 0 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741841_1017 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:35,375 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-1383806935_184
2020-04-02 05:09:35,380 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,385 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,399 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,400 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,411 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:35,420 [nioEventLoopGroup-3-10] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=OPEN&user.name=rootx&namenoderpcaddress=localhost:33223&buffersize=4096&offset=0 200
2020-04-02 05:09:35,424 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,430 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,430 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:35,449 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteOneBlock
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteOneBlock
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGetFileStatusThrowsExceptionForNonExistentFile
[msx] perform reset as unitTestCounterInClass 11 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:35,459 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,466 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,466 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:35,482 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGetFileStatusThrowsExceptionForNonExistentFile
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGetFileStatusThrowsExceptionForNonExistentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusFilterWithNoMatches
[msx] perform reset as unitTestCounterInClass 12 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:35,489 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,494 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop2/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,495 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop2/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:35,503 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop2/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,542 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,550 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,556 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,562 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,569 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusFilterWithNoMatches
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusFilterWithNoMatches
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteEmptyFile
[msx] perform reset as unitTestCounterInClass 13 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:35,590 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,597 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,614 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:35,617 [nioEventLoopGroup-3-11] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:35,622 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-917974839_186
2020-04-02 05:09:35,638 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,648 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,654 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,658 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,668 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,669 [qtp485937598-40] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:35,675 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteEmptyFile
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteEmptyFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithSomePathMatchesAndTrivialFilter
[msx] perform reset as unitTestCounterInClass 14 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:35,681 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,686 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,686 [qtp485937598-40] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:35,694 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,699 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,708 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,712 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,718 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,725 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithSomePathMatchesAndTrivialFilter
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithSomePathMatchesAndTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testFsStatus
[msx] perform reset as unitTestCounterInClass 15 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:35,732 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,736 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2020-04-02 05:09:35,737 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,738 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741826_1002 replica FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2020-04-02 05:09:35,740 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741825_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:09:35,748 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741826_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741826
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testFsStatus
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testFsStatus
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatus
[msx] perform reset as unitTestCounterInClass 16 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:35,753 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,761 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/a	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,762 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/a
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:35,772 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/a	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,778 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/b	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,783 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/c/1	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,787 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,804 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,826 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/a	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:35,840 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatus
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatus
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsEmptyDirectory
[msx] perform reset as unitTestCounterInClass 17 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:35,845 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,852 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:35,883 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:35,885 [nioEventLoopGroup-5-4] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:35,896 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741842_1018, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
2020-04-02 05:09:35,901 [DataXceiver for client DFSClient_NONMAPREDUCE_760128159_371 at /127.0.0.1:59182 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741842_1018]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741842_1018 src: /127.0.0.1:59182 dest: /127.0.0.1:40911
2020-04-02 05:09:35,915 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59182, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_760128159_371, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741842_1018, duration(ns): 11746305
2020-04-02 05:09:35,916 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741842_1018, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741842_1018, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:35,926 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741843_1019, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
2020-04-02 05:09:35,929 [DataXceiver for client DFSClient_NONMAPREDUCE_760128159_371 at /127.0.0.1:59222 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741843_1019]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741843_1019 src: /127.0.0.1:59222 dest: /127.0.0.1:40911
2020-04-02 05:09:35,954 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59222, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_760128159_371, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741843_1019, duration(ns): 22496838
2020-04-02 05:09:35,954 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741843_1019, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741843_1019, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:35,961 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1 is closed by DFSClient_NONMAPREDUCE_760128159_371
2020-04-02 05:09:35,986 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:35,987 [nioEventLoopGroup-3-12] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:35,992 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741844_1020, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:35,996 [DataXceiver for client DFSClient_NONMAPREDUCE_1555031196_187 at /127.0.0.1:54678 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741844_1020]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741844_1020 src: /127.0.0.1:54678 dest: /127.0.0.1:34838
2020-04-02 05:09:36,017 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54678, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1555031196_187, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741844_1020, duration(ns): 14771416
2020-04-02 05:09:36,017 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741844_1020, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741844_1020, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,021 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741845_1021, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:36,024 [DataXceiver for client DFSClient_NONMAPREDUCE_1555031196_187 at /127.0.0.1:59282 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741845_1021]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741845_1021 src: /127.0.0.1:59282 dest: /127.0.0.1:40911
2020-04-02 05:09:36,052 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741845_1021, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59282, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1555031196_187, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741845_1021, duration(ns): 24480376
2020-04-02 05:09:36,052 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741845_1021, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741845_1021, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:36,055 [IPC Server handler 3 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741845_1021 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:36,456 [IPC Server handler 2 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2 is closed by DFSClient_NONMAPREDUCE_1555031196_187
2020-04-02 05:09:36,464 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:36,478 [IPC Server handler 1 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(537)) - DIR* FSDirectory.unprotectedRenameTo: rename destination /tmp/TestFSMainOperationsWebHdfs/test/new/newdir already exists
2020-04-02 05:09:36,478 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.FileAlreadyExistsException: rename destination /tmp/TestFSMainOperationsWebHdfs/test/new/newdir already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:539)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:36,488 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:37,166 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:37,170 [qtp485937598-530] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:37,185 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:37,190 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsEmptyDirectory
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsEmptyDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileAsExistingFile
[msx] perform reset as unitTestCounterInClass 18 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:37,197 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:37,231 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:37,246 [nioEventLoopGroup-5-5] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:37,251 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741846_1022, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:37,259 [DataXceiver for client DFSClient_NONMAPREDUCE_1079944382_372 at /127.0.0.1:55364 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741846_1022]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741846_1022 src: /127.0.0.1:55364 dest: /127.0.0.1:34838
2020-04-02 05:09:37,279 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55364, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1079944382_372, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741846_1022, duration(ns): 18216595
2020-04-02 05:09:37,280 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741846_1022, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741846_1022, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:37,285 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741847_1023, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:37,290 [DataXceiver for client DFSClient_NONMAPREDUCE_1079944382_372 at /127.0.0.1:59974 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741847_1023]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741847_1023 src: /127.0.0.1:59974 dest: /127.0.0.1:40911
2020-04-02 05:09:37,311 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741847_1023, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59974, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1079944382_372, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741847_1023, duration(ns): 15754546
2020-04-02 05:09:37,311 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741847_1023, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741847_1023, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:37,323 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1079944382_372
2020-04-02 05:09:37,351 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/new/existingFile	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:37,353 [nioEventLoopGroup-3-13] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/new/existingFile?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:37,363 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741848_1024, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/new/existingFile
2020-04-02 05:09:37,379 [DataXceiver for client DFSClient_NONMAPREDUCE_-2085023142_188 at /127.0.0.1:55456 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741848_1024]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741848_1024 src: /127.0.0.1:55456 dest: /127.0.0.1:34838
2020-04-02 05:09:37,408 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741848_1024, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:55456, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2085023142_188, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741848_1024, duration(ns): 24965242
2020-04-02 05:09:37,409 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741848_1024, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741848_1024, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:37,420 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741849_1025, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/new/existingFile
2020-04-02 05:09:37,423 [DataXceiver for client DFSClient_NONMAPREDUCE_-2085023142_188 at /127.0.0.1:60088 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741849_1025]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741849_1025 src: /127.0.0.1:60088 dest: /127.0.0.1:40911
2020-04-02 05:09:37,435 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741849_1025, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60088, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-2085023142_188, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741849_1025, duration(ns): 9473098
2020-04-02 05:09:37,435 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741849_1025, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741849_1025, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:37,441 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/new/existingFile is closed by DFSClient_NONMAPREDUCE_-2085023142_188
2020-04-02 05:09:37,453 [IPC Server handler 2 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(537)) - DIR* FSDirectory.unprotectedRenameTo: rename destination /tmp/TestFSMainOperationsWebHdfs/test/new/existingFile already exists
2020-04-02 05:09:37,453 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.FileAlreadyExistsException: rename destination /tmp/TestFSMainOperationsWebHdfs/test/new/existingFile already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:539)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:37,462 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=/tmp/TestFSMainOperationsWebHdfs/test/new/existingFile	perm=rootx:supergroup:rw-r--r--	proto=webhdfs
2020-04-02 05:09:37,465 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:37,465 [qtp485937598-530] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:37,471 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/new/existingFile	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:37,479 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileAsExistingFile
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileAsExistingFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteHalfABlock
[msx] perform reset as unitTestCounterInClass 19 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:37,485 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:37,491 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:37,515 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:37,517 [nioEventLoopGroup-5-6] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:37,526 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741850_1026, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:37,538 [DataXceiver for client DFSClient_NONMAPREDUCE_-623850519_373 at /127.0.0.1:60150 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741850_1026]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741850_1026 src: /127.0.0.1:60150 dest: /127.0.0.1:40911
2020-04-02 05:09:37,549 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741850_1026, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60150, dest: /127.0.0.1:40911, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-623850519_373, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741850_1026, duration(ns): 7129545
2020-04-02 05:09:37,549 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741850_1026, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741850_1026, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:37,550 [IPC Server handler 0 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741850_1026 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:37,952 [IPC Server handler 5 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-623850519_373
2020-04-02 05:09:37,961 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:37,966 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:37,969 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:37,970 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:37,978 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:37,986 [nioEventLoopGroup-3-14] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=OPEN&user.name=rootx&namenoderpcaddress=localhost:33223&buffersize=4096&offset=0 200
2020-04-02 05:09:37,991 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:37,994 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,001 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:38,007 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteHalfABlock
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteHalfABlock
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileAsExistingDirectory
[msx] perform reset as unitTestCounterInClass 20 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:38,015 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:38,039 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:38,040 [nioEventLoopGroup-3-15] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:38,046 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741851_1027, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:38,051 [DataXceiver for client DFSClient_NONMAPREDUCE_645421023_190 at /127.0.0.1:56024 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741851_1027]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741851_1027 src: /127.0.0.1:56024 dest: /127.0.0.1:34838
2020-04-02 05:09:38,065 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741851_1027, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56024, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_645421023_190, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741851_1027, duration(ns): 1731446
2020-04-02 05:09:38,066 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741851_1027, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741851_1027, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:38,070 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741852_1028, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:38,074 [DataXceiver for client DFSClient_NONMAPREDUCE_645421023_190 at /127.0.0.1:56050 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741852_1028]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741852_1028 src: /127.0.0.1:56050 dest: /127.0.0.1:34838
2020-04-02 05:09:38,082 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741852_1028, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56050, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_645421023_190, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741852_1028, duration(ns): 5846406
2020-04-02 05:09:38,083 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741852_1028, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741852_1028, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:38,084 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_645421023_190
2020-04-02 05:09:38,096 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/new/existingDir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:38,100 [IPC Server handler 0 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(531)) - DIR* FSDirectory.unprotectedRenameTo: Source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file and destination /tmp/TestFSMainOperationsWebHdfs/test/new/existingDir must both be directories
2020-04-02 05:09:38,101 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.IOException: Source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file and destination /tmp/TestFSMainOperationsWebHdfs/test/new/existingDir must both be directories
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:533)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:38,107 [IPC Server handler 1 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(531)) - DIR* FSDirectory.unprotectedRenameTo: Source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file and destination /tmp/TestFSMainOperationsWebHdfs/test/new/existingDir must both be directories
2020-04-02 05:09:38,107 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.IOException: Source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file and destination /tmp/TestFSMainOperationsWebHdfs/test/new/existingDir must both be directories
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:533)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:38,114 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileAsExistingDirectory
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileAsExistingDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusThrowsExceptionForNonExistentFile
[msx] perform reset as unitTestCounterInClass 21 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:38,126 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:38,136 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,138 [qtp485937598-637] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file does not exist.
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getDirectoryListing(NamenodeWebHdfsMethods.java:1262)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getListingStream(NamenodeWebHdfsMethods.java:1272)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1111)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:38,156 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusThrowsExceptionForNonExistentFile
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusThrowsExceptionForNonExistentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteOneAndAHalfBlocks
[msx] perform reset as unitTestCounterInClass 22 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:38,166 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:38,171 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:38,185 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:38,190 [nioEventLoopGroup-3-16] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:38,202 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741853_1029, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:38,208 [DataXceiver for client DFSClient_NONMAPREDUCE_-827094560_191 at /127.0.0.1:60716 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741853_1029]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741853_1029 src: /127.0.0.1:60716 dest: /127.0.0.1:40911
2020-04-02 05:09:38,227 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741853_1029, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60716, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-827094560_191, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741853_1029, duration(ns): 16049752
2020-04-02 05:09:38,227 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741853_1029, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741853_1029, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:38,234 [IPC Server handler 5 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741854_1030, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:38,237 [DataXceiver for client DFSClient_NONMAPREDUCE_-827094560_191 at /127.0.0.1:60732 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741854_1030]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741854_1030 src: /127.0.0.1:60732 dest: /127.0.0.1:40911
2020-04-02 05:09:38,242 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741854_1030, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60732, dest: /127.0.0.1:40911, bytes: 512, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-827094560_191, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741854_1030, duration(ns): 2316930
2020-04-02 05:09:38,242 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741854_1030, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741854_1030, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:38,243 [IPC Server handler 9 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741854_1030 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:38,647 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-827094560_191
2020-04-02 05:09:38,653 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,657 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,660 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,661 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,683 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:38,716 [nioEventLoopGroup-3-17] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=OPEN&user.name=rootx&namenoderpcaddress=localhost:33223&buffersize=4096&offset=0 200
2020-04-02 05:09:38,725 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:38,727 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741829_1005 replica FinalizedReplica, blk_1073741829_1005, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741829 for deletion
2020-04-02 05:09:38,728 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741830_1006 replica FinalizedReplica, blk_1073741830_1006, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741830 for deletion
2020-04-02 05:09:38,728 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741829_1005 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741829
2020-04-02 05:09:38,733 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741836_1012 replica FinalizedReplica, blk_1073741836_1012, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741836 for deletion
2020-04-02 05:09:38,734 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741836_1012 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741836
2020-04-02 05:09:38,735 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741838_1014 replica FinalizedReplica, blk_1073741838_1014, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741838 for deletion
2020-04-02 05:09:38,737 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741830_1006 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741830
2020-04-02 05:09:38,738 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741838_1014 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741838
2020-04-02 05:09:38,741 [nioEventLoopGroup-3-18] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=OPEN&user.name=rootx&namenoderpcaddress=localhost:33223&buffersize=4096&offset=1024 200
2020-04-02 05:09:38,744 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,751 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,751 [qtp485937598-40] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:38,758 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteOneAndAHalfBlocks
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteOneAndAHalfBlocks
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testOverwrite
[msx] perform reset as unitTestCounterInClass 23 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:38,763 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:38,777 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:38,798 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:38,810 [nioEventLoopGroup-3-19] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:38,814 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741855_1031, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:38,830 [DataXceiver for client DFSClient_NONMAPREDUCE_1436866917_194 at /127.0.0.1:33142 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741855_1031]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741855_1031 src: /127.0.0.1:33142 dest: /127.0.0.1:40911
2020-04-02 05:09:38,851 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741855_1031, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33142, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1436866917_194, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741855_1031, duration(ns): 17352181
2020-04-02 05:09:38,854 [IPC Server handler 5 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741856_1032, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:38,857 [DataXceiver for client DFSClient_NONMAPREDUCE_1436866917_194 at /127.0.0.1:33158 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741856_1032]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741856_1032 src: /127.0.0.1:33158 dest: /127.0.0.1:40911
2020-04-02 05:09:38,857 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741855_1031, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741855_1031, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:38,875 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741856_1032, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33158, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1436866917_194, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741856_1032, duration(ns): 2915670
2020-04-02 05:09:38,876 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741856_1032, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741856_1032, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:38,889 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1436866917_194
2020-04-02 05:09:38,898 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,902 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:38,933 [IPC Server handler 0 on 33223] INFO  ipc.Server (Server.java:logException(2715)) - IPC Server handler 0 on 33223, call Call#161 Retry#0 org.apache.hadoop.hdfs.protocol.ClientProtocol.create from 127.0.0.1:37962: org.apache.hadoop.fs.FileAlreadyExistsException: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file for client 127.0.0.1 already exists
2020-04-02 05:09:38,958 [nioEventLoopGroup-3-20] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 500
2020-04-02 05:09:38,987 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:38,989 [nioEventLoopGroup-3-21] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=2&unmaskedpermission=666 201
2020-04-02 05:09:38,997 [IPC Server handler 5 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741857_1033, replicas=127.0.0.1:34838, 127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:39,005 [DataXceiver for client DFSClient_NONMAPREDUCE_-926440258_196 at /127.0.0.1:56868 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033 src: /127.0.0.1:56868 dest: /127.0.0.1:34838
2020-04-02 05:09:39,010 [DataXceiver for client DFSClient_NONMAPREDUCE_-926440258_196 at /127.0.0.1:33224 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033 src: /127.0.0.1:33224 dest: /127.0.0.1:40911
2020-04-02 05:09:39,021 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33224, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926440258_196, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033, duration(ns): 8828050
2020-04-02 05:09:39,021 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,035 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56868, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926440258_196, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033, duration(ns): 9842828
2020-04-02 05:09:39,035 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741857_1033, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911] terminating
2020-04-02 05:09:39,041 [IPC Server handler 7 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741858_1034, replicas=127.0.0.1:40911, 127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:39,045 [DataXceiver for client DFSClient_NONMAPREDUCE_-926440258_196 at /127.0.0.1:33250 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034 src: /127.0.0.1:33250 dest: /127.0.0.1:40911
2020-04-02 05:09:39,047 [DataXceiver for client DFSClient_NONMAPREDUCE_-926440258_196 at /127.0.0.1:56906 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034 src: /127.0.0.1:56906 dest: /127.0.0.1:34838
2020-04-02 05:09:39,064 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56906, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926440258_196, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034, duration(ns): 16058363
2020-04-02 05:09:39,064 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,065 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33250, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-926440258_196, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034, duration(ns): 17163814
2020-04-02 05:09:39,065 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741858_1034, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:34838] terminating
2020-04-02 05:09:39,069 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-926440258_196
2020-04-02 05:09:39,076 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,079 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,085 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testOverwrite
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testOverwrite
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusFilterWithSomeMatches
[msx] perform reset as unitTestCounterInClass 24 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:39,090 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,094 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,094 [qtp485937598-530] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:39,103 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,107 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,113 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,117 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop2/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,121 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,127 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusFilterWithSomeMatches
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusFilterWithSomeMatches
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsNonExistentDirectory
[msx] perform reset as unitTestCounterInClass 25 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:39,133 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,141 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,167 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:39,168 [nioEventLoopGroup-5-7] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:39,175 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741859_1035, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
2020-04-02 05:09:39,183 [DataXceiver for client DFSClient_NONMAPREDUCE_-209622425_374 at /127.0.0.1:56972 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741859_1035]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741859_1035 src: /127.0.0.1:56972 dest: /127.0.0.1:34838
2020-04-02 05:09:39,218 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741859_1035, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:56972, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-209622425_374, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741859_1035, duration(ns): 14208548
2020-04-02 05:09:39,218 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741859_1035, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741859_1035, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,221 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741860_1036, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
2020-04-02 05:09:39,227 [DataXceiver for client DFSClient_NONMAPREDUCE_-209622425_374 at /127.0.0.1:57012 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741860_1036]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741860_1036 src: /127.0.0.1:57012 dest: /127.0.0.1:34838
2020-04-02 05:09:39,250 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741860_1036, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57012, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-209622425_374, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741860_1036, duration(ns): 14949361
2020-04-02 05:09:39,250 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741860_1036, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741860_1036, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,252 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1 is closed by DFSClient_NONMAPREDUCE_-209622425_374
2020-04-02 05:09:39,280 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:39,295 [nioEventLoopGroup-5-8] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:39,306 [IPC Server handler 3 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741861_1037, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:39,318 [DataXceiver for client DFSClient_NONMAPREDUCE_795751047_375 at /127.0.0.1:57026 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741861_1037]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741861_1037 src: /127.0.0.1:57026 dest: /127.0.0.1:34838
2020-04-02 05:09:39,330 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741861_1037, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57026, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_795751047_375, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741861_1037, duration(ns): 9820995
2020-04-02 05:09:39,331 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741861_1037, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741861_1037, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,334 [IPC Server handler 7 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741862_1038, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:39,338 [DataXceiver for client DFSClient_NONMAPREDUCE_795751047_375 at /127.0.0.1:57030 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741862_1038]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741862_1038 src: /127.0.0.1:57030 dest: /127.0.0.1:34838
2020-04-02 05:09:39,351 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741862_1038, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57030, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_795751047_375, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741862_1038, duration(ns): 8460757
2020-04-02 05:09:39,352 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741862_1038, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741862_1038, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,354 [IPC Server handler 2 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2 is closed by DFSClient_NONMAPREDUCE_795751047_375
2020-04-02 05:09:39,370 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/new	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,379 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[NONE])	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,384 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,384 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:39,394 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,402 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,405 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:39,416 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,416 [qtp485937598-530] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:39,423 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir/file1	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,434 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir/subdir/file2	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,438 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:39,450 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:39,471 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:39,475 [nioEventLoopGroup-5-9] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:39,480 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741863_1039, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
2020-04-02 05:09:39,487 [DataXceiver for client DFSClient_NONMAPREDUCE_243805222_376 at /127.0.0.1:57040 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741863_1039]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741863_1039 src: /127.0.0.1:57040 dest: /127.0.0.1:34838
2020-04-02 05:09:39,492 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741863_1039, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57040, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_243805222_376, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741863_1039, duration(ns): 1174281
2020-04-02 05:09:39,493 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741863_1039, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741863_1039, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,498 [IPC Server handler 3 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741864_1040, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
2020-04-02 05:09:39,501 [DataXceiver for client DFSClient_NONMAPREDUCE_243805222_376 at /127.0.0.1:57042 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741864_1040]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741864_1040 src: /127.0.0.1:57042 dest: /127.0.0.1:34838
2020-04-02 05:09:39,503 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741864_1040, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57042, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_243805222_376, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741864_1040, duration(ns): 1564671
2020-04-02 05:09:39,504 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741864_1040, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741864_1040, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,511 [IPC Server handler 7 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1 is closed by DFSClient_NONMAPREDUCE_243805222_376
2020-04-02 05:09:39,539 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:39,541 [nioEventLoopGroup-3-22] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:39,560 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741865_1041, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:39,567 [DataXceiver for client DFSClient_NONMAPREDUCE_-208784068_197 at /127.0.0.1:57046 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741865_1041]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741865_1041 src: /127.0.0.1:57046 dest: /127.0.0.1:34838
2020-04-02 05:09:39,586 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741865_1041, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57046, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-208784068_197, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741865_1041, duration(ns): 4915666
2020-04-02 05:09:39,586 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741865_1041, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741865_1041, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,588 [IPC Server handler 5 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741866_1042, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:39,596 [DataXceiver for client DFSClient_NONMAPREDUCE_-208784068_197 at /127.0.0.1:33394 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741866_1042]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741866_1042 src: /127.0.0.1:33394 dest: /127.0.0.1:40911
2020-04-02 05:09:39,598 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741866_1042, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33394, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-208784068_197, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741866_1042, duration(ns): 1164580
2020-04-02 05:09:39,599 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741866_1042, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741866_1042, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:39,600 [IPC Server handler 3 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741866_1042 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:40,003 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2 is closed by DFSClient_NONMAPREDUCE_-208784068_197
2020-04-02 05:09:40,008 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/new	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,013 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,016 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,017 [qtp485937598-530] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,022 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,027 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,028 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,033 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,033 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,038 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir/file1	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,042 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir/subdir/file2	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,046 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsNonExistentDirectory
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsNonExistentDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusSomeMatchesInDirectories
[msx] perform reset as unitTestCounterInClass 26 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:40,052 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,056 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,057 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,063 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,067 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,071 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,076 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop2/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,082 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,087 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusSomeMatchesInDirectories
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusSomeMatchesInDirectories
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithMultiplePathMatchesAndNonTrivialFilter
[msx] perform reset as unitTestCounterInClass 27 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:40,095 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,102 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,102 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,113 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,119 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,125 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,131 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,136 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,141 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithMultiplePathMatchesAndNonTrivialFilter
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithMultiplePathMatchesAndNonTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithMultipleWildCardMatchesAndTrivialFilter
[msx] perform reset as unitTestCounterInClass 28 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:40,146 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,150 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,151 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,156 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,168 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,185 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,195 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,203 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,218 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithMultipleWildCardMatchesAndTrivialFilter
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithMultipleWildCardMatchesAndTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteTwoBlocks
[msx] perform reset as unitTestCounterInClass 29 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:40,228 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,234 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,258 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:40,261 [nioEventLoopGroup-3-23] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:40,266 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741867_1043, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:40,271 [DataXceiver for client DFSClient_NONMAPREDUCE_1660822403_198 at /127.0.0.1:33690 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741867_1043]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741867_1043 src: /127.0.0.1:33690 dest: /127.0.0.1:40911
2020-04-02 05:09:40,288 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741867_1043, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:33690, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1660822403_198, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741867_1043, duration(ns): 1892542
2020-04-02 05:09:40,288 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741867_1043, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741867_1043, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:40,295 [IPC Server handler 7 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741868_1044, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:40,297 [DataXceiver for client DFSClient_NONMAPREDUCE_1660822403_198 at /127.0.0.1:57356 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741868_1044]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741868_1044 src: /127.0.0.1:57356 dest: /127.0.0.1:34838
2020-04-02 05:09:40,306 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741868_1044, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57356, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1660822403_198, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741868_1044, duration(ns): 4938267
2020-04-02 05:09:40,306 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741868_1044, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741868_1044, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:40,310 [IPC Server handler 2 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741868_1044 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:40,713 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1660822403_198
2020-04-02 05:09:40,733 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,737 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,740 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,741 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,762 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=rpc
2020-04-02 05:09:40,776 [nioEventLoopGroup-3-24] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 GET /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=OPEN&user.name=rootx&namenoderpcaddress=localhost:33223&buffersize=4096&offset=0 200
2020-04-02 05:09:40,788 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,795 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,796 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,803 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteTwoBlocks
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteReadAndDeleteTwoBlocks
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithEmptyPathResults
[msx] perform reset as unitTestCounterInClass 30 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:40,826 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,831 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,832 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,844 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,852 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,862 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,868 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,891 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,898 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithEmptyPathResults
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithEmptyPathResults
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusWithNoMatchesInPath
[msx] perform reset as unitTestCounterInClass 31 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:40,906 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,909 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,910 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,915 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,923 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,933 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,947 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop2/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,954 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,967 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusWithNoMatchesInPath
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusWithNoMatchesInPath
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusWithMultipleMatchesOfSingleChar
[msx] perform reset as unitTestCounterInClass 32 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:40,975 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,983 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:40,983 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:40,990 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:40,994 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,002 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,007 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop2/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,015 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,020 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusWithMultipleMatchesOfSingleChar
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusWithMultipleMatchesOfSingleChar
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusThrowsExceptionForUnreadableDir
[msx] perform reset as unitTestCounterInClass 33 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,026 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,036 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo/bar	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,040 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo	dst=null	perm=rootx:supergroup:---------	proto=webhdfs
2020-04-02 05:09:41,043 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,043 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.security.AccessControlException: Permission denied: user=rootx, access=READ_EXECUTE, inode="/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo":rootx:supergroup:d---------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:399)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:261)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:193)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1852)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1836)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPathAccess(FSDirectory.java:1786)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getListingInt(FSDirStatAndListingOp.java:79)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3784)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:1141)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getDirectoryListing(NamenodeWebHdfsMethods.java:1260)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getListingStream(NamenodeWebHdfsMethods.java:1272)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1111)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,054 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,062 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusThrowsExceptionForUnreadableDir
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testListStatusThrowsExceptionForUnreadableDir
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testCopyToLocalWithUseRawLocalFileSystemOption
[msx] perform reset as unitTestCounterInClass 34 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,069 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,085 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testCopyToLocalWithUseRawLocalFileSystemOption
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testCopyToLocalWithUseRawLocalFileSystemOption
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryToItself
[msx] perform reset as unitTestCounterInClass 35 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,091 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,096 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,100 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.FileAlreadyExistsException: The source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir and destination /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir are the same
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:363)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,105 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.FileAlreadyExistsException: The source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir and destination /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir are the same
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:363)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,111 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryToItself
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryToItself
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWDAbsolute
[msx] perform reset as unitTestCounterInClass 36 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,115 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,119 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/test/existingDir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,123 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWDAbsolute
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWDAbsolute
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteInNonExistentDirectory
[msx] perform reset as unitTestCounterInClass 37 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,134 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,141 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,142 [qtp485937598-530] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,158 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:41,161 [nioEventLoopGroup-5-10] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:41,168 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741869_1045, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:41,175 [DataXceiver for client DFSClient_NONMAPREDUCE_-256854583_377 at /127.0.0.1:34270 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741869_1045]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741869_1045 src: /127.0.0.1:34270 dest: /127.0.0.1:40911
2020-04-02 05:09:41,195 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741869_1045, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34270, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-256854583_377, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741869_1045, duration(ns): 17796889
2020-04-02 05:09:41,195 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741869_1045, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741869_1045, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,200 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741870_1046, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:41,202 [DataXceiver for client DFSClient_NONMAPREDUCE_-256854583_377 at /127.0.0.1:34296 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741870_1046]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741870_1046 src: /127.0.0.1:34296 dest: /127.0.0.1:40911
2020-04-02 05:09:41,226 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741870_1046, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34296, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-256854583_377, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741870_1046, duration(ns): 21945577
2020-04-02 05:09:41,231 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741870_1046, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741870_1046, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,241 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-256854583_377
2020-04-02 05:09:41,245 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,251 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,265 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,270 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteInNonExistentDirectory
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testWriteInNonExistentDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusWithMultipleWildCardMatches
[msx] perform reset as unitTestCounterInClass 38 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,277 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,281 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,281 [qtp485937598-512] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,287 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,290 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,294 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,302 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop2/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,311 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,324 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,331 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop2	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,337 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop2	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,341 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusWithMultipleWildCardMatches
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusWithMultipleWildCardMatches
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsFile
[msx] perform reset as unitTestCounterInClass 39 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,350 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,354 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,372 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newfile	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:41,382 [nioEventLoopGroup-5-11] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/new/newfile?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:41,388 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741871_1047, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/new/newfile
2020-04-02 05:09:41,398 [DataXceiver for client DFSClient_NONMAPREDUCE_238622416_378 at /127.0.0.1:34416 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741871_1047]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741871_1047 src: /127.0.0.1:34416 dest: /127.0.0.1:40911
2020-04-02 05:09:41,411 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741871_1047, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34416, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_238622416_378, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741871_1047, duration(ns): 11450750
2020-04-02 05:09:41,412 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741871_1047, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741871_1047, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,414 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741872_1048, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/new/newfile
2020-04-02 05:09:41,420 [DataXceiver for client DFSClient_NONMAPREDUCE_238622416_378 at /127.0.0.1:58074 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741872_1048]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741872_1048 src: /127.0.0.1:58074 dest: /127.0.0.1:34838
2020-04-02 05:09:41,432 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741872_1048, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58074, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_238622416_378, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741872_1048, duration(ns): 8524243
2020-04-02 05:09:41,432 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741872_1048, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741872_1048, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,433 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/new/newfile is closed by DFSClient_NONMAPREDUCE_238622416_378
2020-04-02 05:09:41,460 [IPC Server handler 9 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(531)) - DIR* FSDirectory.unprotectedRenameTo: Source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir and destination /tmp/TestFSMainOperationsWebHdfs/test/new/newfile must both be directories
2020-04-02 05:09:41,461 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.IOException: Source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir and destination /tmp/TestFSMainOperationsWebHdfs/test/new/newfile must both be directories
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:533)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,467 [IPC Server handler 3 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(531)) - DIR* FSDirectory.unprotectedRenameTo: Source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir and destination /tmp/TestFSMainOperationsWebHdfs/test/new/newfile must both be directories
2020-04-02 05:09:41,467 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.IOException: Source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir and destination /tmp/TestFSMainOperationsWebHdfs/test/new/newfile must both be directories
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:533)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,474 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsFile
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToExistingParent
[msx] perform reset as unitTestCounterInClass 40 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,479 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,510 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:41,512 [nioEventLoopGroup-3-25] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:41,515 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741873_1049, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:41,542 [DataXceiver for client DFSClient_NONMAPREDUCE_1651372230_200 at /127.0.0.1:58112 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741873_1049]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741873_1049 src: /127.0.0.1:58112 dest: /127.0.0.1:34838
2020-04-02 05:09:41,560 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741873_1049, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58112, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651372230_200, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741873_1049, duration(ns): 11293385
2020-04-02 05:09:41,561 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741873_1049, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741873_1049, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,562 [IPC Server handler 5 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741874_1050, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:41,567 [DataXceiver for client DFSClient_NONMAPREDUCE_1651372230_200 at /127.0.0.1:58126 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741874_1050]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741874_1050 src: /127.0.0.1:58126 dest: /127.0.0.1:34838
2020-04-02 05:09:41,605 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741874_1050, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58126, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1651372230_200, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741874_1050, duration(ns): 22351068
2020-04-02 05:09:41,605 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741874_1050, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741874_1050, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,607 [IPC Server handler 3 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_1651372230_200
2020-04-02 05:09:41,638 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/new	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,642 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=rename (options=[OVERWRITE])	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=/tmp/TestFSMainOperationsWebHdfs/test/new/newfile	perm=rootx:supergroup:rw-r--r--	proto=webhdfs
2020-04-02 05:09:41,647 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,648 [qtp485937598-637] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,672 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newfile	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:41,681 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToExistingParent
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToExistingParent
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToDestinationWithParentFile
[msx] perform reset as unitTestCounterInClass 41 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,694 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,707 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:41,717 [nioEventLoopGroup-3-26] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:41,727 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741875_1051, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:41,732 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741856_1032 replica FinalizedReplica, blk_1073741856_1032, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741856 for deletion
2020-04-02 05:09:41,732 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741825_1001 replica FinalizedReplica, blk_1073741825_1001, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741825 for deletion
2020-04-02 05:09:41,733 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741856_1032 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741856
2020-04-02 05:09:41,742 [DataXceiver for client DFSClient_NONMAPREDUCE_2115377924_201 at /127.0.0.1:34534 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741875_1051]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741875_1051 src: /127.0.0.1:34534 dest: /127.0.0.1:40911
2020-04-02 05:09:41,733 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741826_1002 replica FinalizedReplica, blk_1073741826_1002, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741826 for deletion
2020-04-02 05:09:41,753 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741825_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741825
2020-04-02 05:09:41,753 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741827_1003 replica FinalizedReplica, blk_1073741827_1003, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741827 for deletion
2020-04-02 05:09:41,754 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741828_1004 replica FinalizedReplica, blk_1073741828_1004, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741828 for deletion
2020-04-02 05:09:41,755 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741835_1011 replica FinalizedReplica, blk_1073741835_1011, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741835 for deletion
2020-04-02 05:09:41,756 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741827_1003 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741827
2020-04-02 05:09:41,757 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741826_1002 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741826
2020-04-02 05:09:41,757 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741837_1013 replica FinalizedReplica, blk_1073741837_1013, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741837 for deletion
2020-04-02 05:09:41,760 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741828_1004 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741828
2020-04-02 05:09:41,760 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741839_1015 replica FinalizedReplica, blk_1073741839_1015, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741839 for deletion
2020-04-02 05:09:41,761 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741840_1016 replica FinalizedReplica, blk_1073741840_1016, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741840 for deletion
2020-04-02 05:09:41,762 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741841_1017 replica FinalizedReplica, blk_1073741841_1017, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741841 for deletion
2020-04-02 05:09:41,762 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741835_1011 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741835
2020-04-02 05:09:41,763 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741839_1015 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741839
2020-04-02 05:09:41,764 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741841_1017 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741841
2020-04-02 05:09:41,761 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741837_1013 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741837
2020-04-02 05:09:41,763 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741842_1018 replica FinalizedReplica, blk_1073741842_1018, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741842 for deletion
2020-04-02 05:09:41,765 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741840_1016 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741840
2020-04-02 05:09:41,765 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741842_1018 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741842
2020-04-02 05:09:41,765 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741843_1019 replica FinalizedReplica, blk_1073741843_1019, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741843 for deletion
2020-04-02 05:09:41,766 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741845_1021 replica FinalizedReplica, blk_1073741845_1021, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741845 for deletion
2020-04-02 05:09:41,766 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741847_1023 replica FinalizedReplica, blk_1073741847_1023, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741847 for deletion
2020-04-02 05:09:41,767 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741845_1021 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741845
2020-04-02 05:09:41,767 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741849_1025 replica FinalizedReplica, blk_1073741849_1025, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741849 for deletion
2020-04-02 05:09:41,768 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741849_1025 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741849
2020-04-02 05:09:41,768 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741850_1026 replica FinalizedReplica, blk_1073741850_1026, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741850 for deletion
2020-04-02 05:09:41,769 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741853_1029 replica FinalizedReplica, blk_1073741853_1029, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741853 for deletion
2020-04-02 05:09:41,769 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741843_1019 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741843
2020-04-02 05:09:41,769 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741853_1029 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741853
2020-04-02 05:09:41,769 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741854_1030 replica FinalizedReplica, blk_1073741854_1030, FINALIZED
  getNumBytes()     = 512
  getBytesOnDisk()  = 512
  getVisibleLength()= 512
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741854 for deletion
2020-04-02 05:09:41,774 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741847_1023 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741847
2020-04-02 05:09:41,774 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_1073741855_1031 replica FinalizedReplica, blk_1073741855_1031, FINALIZED
  getNumBytes()     = 1024
  getBytesOnDisk()  = 1024
  getVisibleLength()= 1024
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741855 for deletion
2020-04-02 05:09:41,775 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741855_1031 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741855
2020-04-02 05:09:41,775 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741875_1051, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34534, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2115377924_201, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741875_1051, duration(ns): 18349377
2020-04-02 05:09:41,776 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741875_1051, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741875_1051, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,776 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741850_1026 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741850
2020-04-02 05:09:41,776 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1775166591-172.17.0.16-1585804164696 blk_1073741854_1030 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696/current/finalized/subdir0/subdir0/blk_1073741854
2020-04-02 05:09:41,778 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741876_1052, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:41,780 [DataXceiver for client DFSClient_NONMAPREDUCE_2115377924_201 at /127.0.0.1:58224 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741876_1052]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741876_1052 src: /127.0.0.1:58224 dest: /127.0.0.1:34838
2020-04-02 05:09:41,783 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741876_1052, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58224, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2115377924_201, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741876_1052, duration(ns): 1110291
2020-04-02 05:09:41,783 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741876_1052, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741876_1052, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,787 [IPC Server handler 5 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_2115377924_201
2020-04-02 05:09:41,818 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/parentFile	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:41,825 [nioEventLoopGroup-3-27] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/parentFile?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:41,829 [IPC Server handler 3 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741877_1053, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/parentFile
2020-04-02 05:09:41,836 [DataXceiver for client DFSClient_NONMAPREDUCE_694452224_202 at /127.0.0.1:34602 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741877_1053]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741877_1053 src: /127.0.0.1:34602 dest: /127.0.0.1:40911
2020-04-02 05:09:41,854 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741877_1053, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34602, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_694452224_202, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741877_1053, duration(ns): 16429868
2020-04-02 05:09:41,854 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741877_1053, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741877_1053, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,857 [IPC Server handler 7 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741878_1054, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/parentFile
2020-04-02 05:09:41,860 [DataXceiver for client DFSClient_NONMAPREDUCE_694452224_202 at /127.0.0.1:34624 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741878_1054]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741878_1054 src: /127.0.0.1:34624 dest: /127.0.0.1:40911
2020-04-02 05:09:41,885 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741878_1054, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34624, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_694452224_202, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741878_1054, duration(ns): 15815697
2020-04-02 05:09:41,885 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741878_1054, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741878_1054, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,890 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/parentFile is closed by DFSClient_NONMAPREDUCE_694452224_202
2020-04-02 05:09:41,918 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.ParentNotDirectoryException: /tmp/TestFSMainOperationsWebHdfs/test/parentFile (is not a directory)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkIsDirectory(FSPermissionChecker.java:638)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:314)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:242)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:193)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:606)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1801)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1819)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(FSDirectory.java:676)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:255)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,928 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.ParentNotDirectoryException: /tmp/TestFSMainOperationsWebHdfs/test/parentFile (is not a directory)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkIsDirectory(FSPermissionChecker.java:638)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:314)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:242)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:193)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkTraverse(FSPermissionChecker.java:606)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1801)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkTraverse(FSDirectory.java:1819)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.resolvePath(FSDirectory.java:676)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:255)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:41,934 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToDestinationWithParentFile
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToDestinationWithParentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testDeleteRecursively
[msx] perform reset as unitTestCounterInClass 42 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:41,938 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:41,948 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:41,949 [nioEventLoopGroup-3-28] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:41,953 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741879_1055, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:41,957 [DataXceiver for client DFSClient_NONMAPREDUCE_-358940063_203 at /127.0.0.1:34668 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741879_1055]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741879_1055 src: /127.0.0.1:34668 dest: /127.0.0.1:40911
2020-04-02 05:09:41,973 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741879_1055, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34668, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-358940063_203, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741879_1055, duration(ns): 15491906
2020-04-02 05:09:41,974 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741879_1055, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741879_1055, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:41,978 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741880_1056, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:41,983 [DataXceiver for client DFSClient_NONMAPREDUCE_-358940063_203 at /127.0.0.1:58330 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741880_1056]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741880_1056 src: /127.0.0.1:58330 dest: /127.0.0.1:34838
2020-04-02 05:09:42,000 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741880_1056, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58330, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-358940063_203, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741880_1056, duration(ns): 3716465
2020-04-02 05:09:42,001 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741880_1056, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741880_1056, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:42,002 [IPC Server handler 5 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741880_1056 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:42,404 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-358940063_203
2020-04-02 05:09:42,408 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/subdir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:42,411 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,419 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,422 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/subdir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,436 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.PathIsNotEmptyDirectoryException: `/tmp/TestFSMainOperationsWebHdfs/test/hadoop is non empty': Directory is not empty
	at org.apache.hadoop.hdfs.server.namenode.FSDirDeleteOp.delete(FSDirDeleteOp.java:116)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.delete(FSNamesystem.java:2998)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.delete(NameNodeRpcServer.java:1095)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.delete(NamenodeWebHdfsMethods.java:1390)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$6.run(NamenodeWebHdfsMethods.java:1370)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$6.run(NamenodeWebHdfsMethods.java:1367)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:42,439 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,444 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,448 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/subdir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,452 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,456 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,457 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:42,464 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,466 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:42,471 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/subdir	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,472 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/subdir
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:42,476 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testDeleteRecursively
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testDeleteRecursively
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testMkdirs
[msx] perform reset as unitTestCounterInClass 43 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:42,484 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:42,487 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,488 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:42,492 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,492 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:42,496 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:42,503 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,510 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,514 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:42,518 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,524 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,530 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,533 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,554 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,560 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,569 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testMkdirs
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testMkdirs
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusNonExistentFile
[msx] perform reset as unitTestCounterInClass 44 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:42,578 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:42,586 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoopfsdf	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,586 [qtp485937598-637] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoopfsdf
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:42,595 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoopfsdf	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,596 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File /tmp/TestFSMainOperationsWebHdfs/test/hadoopfsdf does not exist.
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getDirectoryListing(NamenodeWebHdfsMethods.java:1262)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getListingStream(NamenodeWebHdfsMethods.java:1272)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1111)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:42,602 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoopfsdf	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:42,602 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File /tmp/TestFSMainOperationsWebHdfs/test/hadoopfsdf does not exist.
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getDirectoryListing(NamenodeWebHdfsMethods.java:1262)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getListingStream(NamenodeWebHdfsMethods.java:1272)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1111)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:42,606 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusNonExistentFile
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusNonExistentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsNonEmptyDirectory
[msx] perform reset as unitTestCounterInClass 45 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:42,614 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:42,622 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:42,635 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:42,636 [nioEventLoopGroup-5-12] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:42,644 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741881_1057, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
2020-04-02 05:09:42,647 [DataXceiver for client DFSClient_NONMAPREDUCE_-1228075943_379 at /127.0.0.1:34982 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741881_1057]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741881_1057 src: /127.0.0.1:34982 dest: /127.0.0.1:40911
2020-04-02 05:09:42,665 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741881_1057, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:34982, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1228075943_379, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741881_1057, duration(ns): 16555713
2020-04-02 05:09:42,666 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741881_1057, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741881_1057, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:42,669 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741882_1058, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1
2020-04-02 05:09:42,678 [DataXceiver for client DFSClient_NONMAPREDUCE_-1228075943_379 at /127.0.0.1:58648 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741882_1058]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741882_1058 src: /127.0.0.1:58648 dest: /127.0.0.1:34838
2020-04-02 05:09:42,689 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741882_1058, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58648, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1228075943_379, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741882_1058, duration(ns): 9344007
2020-04-02 05:09:42,689 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741882_1058, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741882_1058, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:42,696 [IPC Server handler 6 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/file1 is closed by DFSClient_NONMAPREDUCE_-1228075943_379
2020-04-02 05:09:42,707 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:42,708 [nioEventLoopGroup-3-29] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:42,730 [IPC Server handler 2 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741883_1059, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:42,735 [DataXceiver for client DFSClient_NONMAPREDUCE_331138306_204 at /127.0.0.1:35018 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741883_1059]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741883_1059 src: /127.0.0.1:35018 dest: /127.0.0.1:40911
2020-04-02 05:09:42,746 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741883_1059, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35018, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_331138306_204, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741883_1059, duration(ns): 4016664
2020-04-02 05:09:42,746 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741883_1059, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741883_1059, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:42,748 [IPC Server handler 8 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741884_1060, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2
2020-04-02 05:09:42,754 [DataXceiver for client DFSClient_NONMAPREDUCE_331138306_204 at /127.0.0.1:58680 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741884_1060]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741884_1060 src: /127.0.0.1:58680 dest: /127.0.0.1:34838
2020-04-02 05:09:42,770 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741884_1060, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58680, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_331138306_204, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741884_1060, duration(ns): 14439223
2020-04-02 05:09:42,770 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741884_1060, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741884_1060, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:42,779 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/subdir/file2 is closed by DFSClient_NONMAPREDUCE_331138306_204
2020-04-02 05:09:42,794 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:42,809 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/new/newdir/file1	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:42,811 [nioEventLoopGroup-5-13] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/new/newdir/file1?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:42,814 [IPC Server handler 4 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741885_1061, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/new/newdir/file1
2020-04-02 05:09:42,823 [DataXceiver for client DFSClient_NONMAPREDUCE_2136344130_380 at /127.0.0.1:35062 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741885_1061]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741885_1061 src: /127.0.0.1:35062 dest: /127.0.0.1:40911
2020-04-02 05:09:42,837 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741885_1061, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35062, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2136344130_380, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741885_1061, duration(ns): 11711932
2020-04-02 05:09:42,837 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741885_1061, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741885_1061, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:42,846 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741886_1062, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/new/newdir/file1
2020-04-02 05:09:42,848 [DataXceiver for client DFSClient_NONMAPREDUCE_2136344130_380 at /127.0.0.1:35084 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741886_1062]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741886_1062 src: /127.0.0.1:35084 dest: /127.0.0.1:40911
2020-04-02 05:09:42,852 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741886_1062, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35084, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_2136344130_380, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741886_1062, duration(ns): 2480481
2020-04-02 05:09:42,852 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741886_1062, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741886_1062, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:42,853 [IPC Server handler 5 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741886_1062 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/new/newdir/file1
2020-04-02 05:09:43,257 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/new/newdir/file1 is closed by DFSClient_NONMAPREDUCE_2136344130_380
2020-04-02 05:09:43,261 [IPC Server handler 3 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(537)) - DIR* FSDirectory.unprotectedRenameTo: rename destination /tmp/TestFSMainOperationsWebHdfs/test/new/newdir already exists
2020-04-02 05:09:43,262 [qtp485937598-637] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.FileAlreadyExistsException: rename destination /tmp/TestFSMainOperationsWebHdfs/test/new/newdir already exists
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:539)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:43,267 [IPC Server handler 6 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateOverwrite(546)) - DIR* FSDirectory.unprotectedRenameTo: rename destination directory is not empty: /tmp/TestFSMainOperationsWebHdfs/test/new/newdir
2020-04-02 05:09:43,267 [qtp485937598-38] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.IOException: rename destination directory is not empty: /tmp/TestFSMainOperationsWebHdfs/test/new/newdir
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateOverwrite(FSDirRenameOp.java:548)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:380)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:43,272 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsNonEmptyDirectory
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameDirectoryAsNonEmptyDirectory
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testDeleteNonExistentFile
[msx] perform reset as unitTestCounterInClass 46 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:43,277 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,287 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:43,288 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:43,297 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:43,301 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testDeleteNonExistentFile
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testDeleteNonExistentFile
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameNonExistentPath
[msx] perform reset as unitTestCounterInClass 47 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:43,307 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,313 [IPC Server handler 5 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateRenameSource(560)) - DIR* FSDirectory.unprotectedRenameTo: rename source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/nonExistent is not found.
2020-04-02 05:09:43,316 [qtp485937598-37] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: rename source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/nonExistent is not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateRenameSource(FSDirRenameOp.java:562)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:359)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:43,323 [main] INFO  util.log (FSMainOperationsBaseTest.java:testRenameNonExistentPath(800)) - XXX
java.io.FileNotFoundException: rename source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/nonExistent is not found.
	at sun.reflect.GeneratedConstructorAccessor63.newInstance(Unknown Source)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:121)
	at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:110)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.toIOException(WebHdfsFileSystem.java:549)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$800(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.shouldRetry(WebHdfsFileSystem.java:884)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:850)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.access$100(WebHdfsFileSystem.java:649)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner$1.run(WebHdfsFileSystem.java:687)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.run(WebHdfsFileSystem.java:683)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.rename(WebHdfsFileSystem.java:1156)
	at org.apache.hadoop.fs.FSMainOperationsBaseTest.rename(FSMainOperationsBaseTest.java:1154)
	at org.apache.hadoop.fs.FSMainOperationsBaseTest.testRenameNonExistentPath(FSMainOperationsBaseTest.java:797)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:365)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeWithRerun(JUnit4Provider.java:273)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:238)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:159)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:384)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:345)
	at org.apache.maven.surefire.booter.ForkedBooter.execute(ForkedBooter.java:126)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:418)
Caused by: org.apache.hadoop.ipc.RemoteException(java.io.FileNotFoundException): rename source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/nonExistent is not found.
	at org.apache.hadoop.hdfs.web.JsonUtilClient.toRemoteException(JsonUtilClient.java:85)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.validateResponse(WebHdfsFileSystem.java:510)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem.access$200(WebHdfsFileSystem.java:135)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.connect(WebHdfsFileSystem.java:746)
	at org.apache.hadoop.hdfs.web.WebHdfsFileSystem$AbstractRunner.runWithRetry(WebHdfsFileSystem.java:821)
	... 38 more
2020-04-02 05:09:43,342 [IPC Server handler 9 on 33223] WARN  hdfs.StateChange (FSDirRenameOp.java:validateRenameSource(560)) - DIR* FSDirectory.unprotectedRenameTo: rename source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/nonExistent is not found.
2020-04-02 05:09:43,343 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: rename source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/nonExistent is not found.
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.validateRenameSource(FSDirRenameOp.java:562)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:359)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:43,352 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameNonExistentPath
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameNonExistentPath
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusThrowsExceptionForUnreadableDir
[msx] perform reset as unitTestCounterInClass 48 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:43,359 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,370 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo/bar	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,375 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo	dst=null	perm=rootx:supergroup:---------	proto=webhdfs
2020-04-02 05:09:43,383 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=false	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:43,383 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.security.AccessControlException: Permission denied: user=rootx, access=READ_EXECUTE, inode="/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo":rootx:supergroup:d---------
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.check(FSPermissionChecker.java:399)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:261)
	at org.apache.hadoop.hdfs.server.namenode.FSPermissionChecker.checkPermission(FSPermissionChecker.java:193)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1852)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPermission(FSDirectory.java:1836)
	at org.apache.hadoop.hdfs.server.namenode.FSDirectory.checkPathAccess(FSDirectory.java:1786)
	at org.apache.hadoop.hdfs.server.namenode.FSDirStatAndListingOp.getListingInt(FSDirStatAndListingOp.java:79)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getListing(FSNamesystem.java:3784)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.getListing(NameNodeRpcServer.java:1141)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getDirectoryListing(NamenodeWebHdfsMethods.java:1260)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.getListingStream(NamenodeWebHdfsMethods.java:1272)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1111)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:43,392 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=setPermission	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/dir/foo	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,395 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusThrowsExceptionForUnreadableDir
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusThrowsExceptionForUnreadableDir
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGetWrappedInputStream
[msx] perform reset as unitTestCounterInClass 49 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:43,400 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,439 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:43,440 [nioEventLoopGroup-5-14] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:43,448 [IPC Server handler 3 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741887_1063, replicas=127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:43,455 [DataXceiver for client DFSClient_NONMAPREDUCE_-1419841036_381 at /127.0.0.1:35326 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741887_1063]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741887_1063 src: /127.0.0.1:35326 dest: /127.0.0.1:40911
2020-04-02 05:09:43,483 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741887_1063, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35326, dest: /127.0.0.1:40911, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1419841036_381, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741887_1063, duration(ns): 13448100
2020-04-02 05:09:43,483 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741887_1063, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741887_1063, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:43,491 [IPC Server handler 7 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741888_1064, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:43,506 [DataXceiver for client DFSClient_NONMAPREDUCE_-1419841036_381 at /127.0.0.1:58996 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741888_1064]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741888_1064 src: /127.0.0.1:58996 dest: /127.0.0.1:34838
2020-04-02 05:09:43,518 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741888_1064, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58996, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1419841036_381, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741888_1064, duration(ns): 10542061
2020-04-02 05:09:43,519 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741888_1064, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741888_1064, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:43,522 [IPC Server handler 0 on 33223] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741888_1064 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:43,926 [IPC Server handler 1 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_-1419841036_381
2020-04-02 05:09:43,931 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:43,931 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:43,935 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGetWrappedInputStream
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGetWrappedInputStream
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithMultiplePathWildcardsAndNonTrivialFilter
[msx] perform reset as unitTestCounterInClass 50 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:43,939 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,943 [IPC Server handler 3 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:43,943 [qtp485937598-48] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
java.io.FileNotFoundException: File does not exist: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.get(NamenodeWebHdfsMethods.java:1103)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1032)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$4.run(NamenodeWebHdfsMethods.java:1027)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:43,956 [IPC Server handler 6 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/aaa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,962 [IPC Server handler 7 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axa	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,966 [IPC Server handler 4 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,969 [IPC Server handler 0 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/axx	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,973 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=listStatus	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop	dst=null	perm=null	proto=webhdfs
2020-04-02 05:09:43,979 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithMultiplePathWildcardsAndNonTrivialFilter
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testGlobStatusFilterWithMultiplePathWildcardsAndNonTrivialFilter
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testOutputStreamClosedTwice
[msx] perform reset as unitTestCounterInClass 51 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:43,986 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:43,995 [IPC Server handler 9 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:44,000 [nioEventLoopGroup-3-30] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=true&permission=644&replication=2&unmaskedpermission=666 201
2020-04-02 05:09:44,014 [IPC Server handler 3 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741889_1065, replicas=127.0.0.1:34838, 127.0.0.1:40911 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:44,020 [DataXceiver for client DFSClient_NONMAPREDUCE_806066576_205 at /127.0.0.1:59290 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065 src: /127.0.0.1:59290 dest: /127.0.0.1:34838
2020-04-02 05:09:44,022 [DataXceiver for client DFSClient_NONMAPREDUCE_806066576_205 at /127.0.0.1:35648 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065 src: /127.0.0.1:35648 dest: /127.0.0.1:40911
2020-04-02 05:09:44,056 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:35648, dest: /127.0.0.1:40911, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_806066576_205, offset: 0, srvID: 5c2569a9-a4ad-4200-9514-a582e737543d, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065, duration(ns): 32678427
2020-04-02 05:09:44,057 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:44,059 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911]] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59290, dest: /127.0.0.1:34838, bytes: 2, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_806066576_205, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065, duration(ns): 22732558
2020-04-02 05:09:44,059 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911]] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741889_1065, type=HAS_DOWNSTREAM_IN_PIPELINE, downstreams=1:[127.0.0.1:40911] terminating
2020-04-02 05:09:44,061 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_806066576_205
2020-04-02 05:09:44,067 [IPC Server handler 2 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testOutputStreamClosedTwice
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testOutputStreamClosedTwice
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToItself
[msx] perform reset as unitTestCounterInClass 52 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:44,076 [IPC Server handler 1 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=rootx:supergroup:rwxr-xr-x	proto=webhdfs
2020-04-02 05:09:44,087 [IPC Server handler 5 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file	dst=null	perm=rootx:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:44,091 [nioEventLoopGroup-3-31] INFO  datanode.webhdfs (WebHdfsHandler.java:run(148)) - 127.0.0.1 PUT /webhdfs/v1/tmp/TestFSMainOperationsWebHdfs/test/hadoop/file?op=CREATE&user.name=rootx&namenoderpcaddress=localhost:33223&blocksize=1024&buffersize=4096&createflag=&createparent=true&overwrite=false&permission=644&replication=1&unmaskedpermission=666 201
2020-04-02 05:09:44,103 [IPC Server handler 9 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741890_1066, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:44,113 [DataXceiver for client DFSClient_NONMAPREDUCE_535545631_206 at /127.0.0.1:59350 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741890_1066]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741890_1066 src: /127.0.0.1:59350 dest: /127.0.0.1:34838
2020-04-02 05:09:44,142 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741890_1066, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59350, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_535545631_206, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741890_1066, duration(ns): 15448042
2020-04-02 05:09:44,143 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741890_1066, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741890_1066, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:44,148 [IPC Server handler 7 on 33223] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741891_1067, replicas=127.0.0.1:34838 for /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file
2020-04-02 05:09:44,153 [DataXceiver for client DFSClient_NONMAPREDUCE_535545631_206 at /127.0.0.1:59376 [Receiving block BP-1775166591-172.17.0.16-1585804164696:blk_1073741891_1067]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1775166591-172.17.0.16-1585804164696:blk_1073741891_1067 src: /127.0.0.1:59376 dest: /127.0.0.1:34838
2020-04-02 05:09:44,162 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741891_1067, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59376, dest: /127.0.0.1:34838, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_535545631_206, offset: 0, srvID: cc93be0b-f1e0-4c31-8ce8-9f983943fd0e, blockid: BP-1775166591-172.17.0.16-1585804164696:blk_1073741891_1067, duration(ns): 7559704
2020-04-02 05:09:44,163 [PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741891_1067, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1775166591-172.17.0.16-1585804164696:blk_1073741891_1067, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:44,170 [IPC Server handler 0 on 33223] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file is closed by DFSClient_NONMAPREDUCE_535545631_206
2020-04-02 05:09:44,176 [qtp485937598-36] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.FileAlreadyExistsException: The source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file and destination /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file are the same
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:363)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:44,182 [qtp485937598-637] TRACE resources.ExceptionHandler (ExceptionHandler.java:toResponse(73)) - GOT EXCEPITION
org.apache.hadoop.fs.FileAlreadyExistsException: The source /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file and destination /tmp/TestFSMainOperationsWebHdfs/test/hadoop/file are the same
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.unprotectedRenameTo(FSDirRenameOp.java:363)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameTo(FSDirRenameOp.java:293)
	at org.apache.hadoop.hdfs.server.namenode.FSDirRenameOp.renameToInt(FSDirRenameOp.java:243)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.renameTo(FSNamesystem.java:2959)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rename2(NameNodeRpcServer.java:1055)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods.put(NamenodeWebHdfsMethods.java:683)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:592)
	at org.apache.hadoop.hdfs.server.namenode.web.resources.NamenodeWebHdfsMethods$2.run(NamenodeWebHdfsMethods.java:589)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:72)
	at org.apache.hadoop.ipc.ExternalCall.run(ExternalCall.java:29)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2678)
2020-04-02 05:09:44,187 [IPC Server handler 8 on 33223] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=rootx (auth:SIMPLE)	ip=/127.0.0.1	cmd=delete	src=/tmp/TestFSMainOperationsWebHdfs/test	dst=null	perm=null	proto=webhdfs
[msx] test Finished org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToItself
[msx] writeFile testName = org.apache.hadoop.hdfs.web.TestFSMainOperationsWebHdfs#testRenameFileToItself
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:44,190 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:09:44,190 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:09:44,190 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41462 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:44,191 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:44,191 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5e8f9e2d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:44,198 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-2f9715ff-ace8-4776-b1de-9175467b4049) exiting.
2020-04-02 05:09:44,199 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e76ec0c6-c992-400f-b5e9-62cd912c76bc) exiting.
2020-04-02 05:09:44,409 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@35fe2125{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:44,437 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@94f6bfb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:44,438 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@79e18e38{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:44,439 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60fa3495{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:44,449 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41462
2020-04-02 05:09:44,454 [IPC Server listener on 41462] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41462
2020-04-02 05:09:44,456 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:44,456 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:44,457 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1775166591-172.17.0.16-1585804164696 (Datanode Uuid cc93be0b-f1e0-4c31-8ce8-9f983943fd0e) service to localhost/127.0.0.1:33223
2020-04-02 05:09:44,457 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775166591-172.17.0.16-1585804164696 (Datanode Uuid cc93be0b-f1e0-4c31-8ce8-9f983943fd0e)
2020-04-02 05:09:44,457 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:44,469 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1775166591-172.17.0.16-1585804164696] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:44,478 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1775166591-172.17.0.16-1585804164696] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:44,481 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:44,489 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:44,491 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:44,491 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:44,495 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:44,495 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:09:44,495 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41607 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:44,495 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:44,495 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@655f7ea] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:44,507 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-ed5b25bd-16b9-4ee0-8cb0-a489fe4fe4e2) exiting.
2020-04-02 05:09:44,507 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-11e9fd56-4531-46a1-9dc5-b40b9282d91e) exiting.
2020-04-02 05:09:44,650 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5dd91bca{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:44,657 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@40cb698e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:44,668 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@68b6f0d6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:44,668 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@686449f9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:44,670 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41607
2020-04-02 05:09:44,690 [IPC Server listener on 41607] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41607
2020-04-02 05:09:44,690 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:44,690 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:44,698 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1775166591-172.17.0.16-1585804164696 (Datanode Uuid 5c2569a9-a4ad-4200-9514-a582e737543d) service to localhost/127.0.0.1:33223
2020-04-02 05:09:44,698 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1775166591-172.17.0.16-1585804164696 (Datanode Uuid 5c2569a9-a4ad-4200-9514-a582e737543d)
2020-04-02 05:09:44,698 [BP-1775166591-172.17.0.16-1585804164696 heartbeating to localhost/127.0.0.1:33223] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1775166591-172.17.0.16-1585804164696
2020-04-02 05:09:44,708 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1775166591-172.17.0.16-1585804164696] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:44,717 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1775166591-172.17.0.16-1585804164696] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:44,720 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:44,722 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:44,723 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:44,724 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:44,730 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:44,730 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:09:44,730 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33223 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:44,731 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:44,731 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 539
2020-04-02 05:09:44,732 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 540 Total time for transactions(ms): 83 Number of transactions batched in Syncs: 149 Number of syncs: 392 SyncTimes(ms): 22 9 
2020-04-02 05:09:44,732 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@319bc845] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:09:44,734 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000540
2020-04-02 05:09:44,734 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@1a9c38eb] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:09:44,735 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000540
2020-04-02 05:09:44,739 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:09:44,740 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33223
2020-04-02 05:09:44,745 [CacheReplicationMonitor(166729823)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:09:44,753 [IPC Server listener on 33223] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33223
2020-04-02 05:09:44,757 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:09:44,757 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:09:44,762 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:44,811 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:44,811 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:09:44,819 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@52e7a6b2{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:09:44,827 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@404bbcbd{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:44,828 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7098b907{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:44,828 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4470fbd6{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:44,833 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:09:44,836 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:09:44,837 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

[msx] before_class
2020-04-02 05:08:51,817 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(225)) - Configuration:
2020-04-02 05:08:51,824 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(226)) - ---------------------------------------------------------------
2020-04-02 05:08:51,827 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   debug: false
2020-04-02 05:08:51,827 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   transport: TCP
2020-04-02 05:08:51,828 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.ticket.lifetime: 86400000
2020-04-02 05:08:51,828 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.name: EXAMPLE
2020-04-02 05:08:51,828 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.port: 0
2020-04-02 05:08:51,829 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   org.domain: COM
2020-04-02 05:08:51,829 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   max.renewable.lifetime: 604800000
2020-04-02 05:08:51,829 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   instance: DefaultKrbServer
2020-04-02 05:08:51,829 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(228)) -   kdc.bind.address: localhost
2020-04-02 05:08:51,830 [main] INFO  minikdc.MiniKdc (MiniKdc.java:<init>(230)) - ---------------------------------------------------------------
2020-04-02 05:08:51,948 [main] INFO  minikdc.MiniKdc (MiniKdc.java:start(285)) - MiniKdc started.
2020-04-02 05:08:53,277 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @2484ms
2020-04-02 05:08:53,464 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.kms is not defined
2020-04-02 05:08:53,482 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:53,487 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context kms
2020-04-02 05:08:53,488 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:53,488 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:53,559 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45018
2020-04-02 05:08:53,562 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:53,643 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d3a388c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:53,645 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6bedbc4d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-kms/3.1.2/hadoop-kms-3.1.2.jar!/webapps/static,AVAILABLE}
2020-04-02 05:08:53,768 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(88)) - -------------------------------------------------------------
2020-04-02 05:08:53,768 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(89)) -   Java runtime version : 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08
2020-04-02 05:08:53,769 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(91)) -   User: root
2020-04-02 05:08:53,772 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(92)) -   KMS Hadoop Version: 3.1.2
2020-04-02 05:08:53,773 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(93)) - -------------------------------------------------------------
2020-04-02 05:08:53,776 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'CREATE' ACL '*'
2020-04-02 05:08:53,777 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'DELETE' ACL '*'
2020-04-02 05:08:53,777 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'ROLLOVER' ACL '*'
2020-04-02 05:08:53,777 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'GET' ACL '*'
2020-04-02 05:08:53,777 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'GET_KEYS' ACL '*'
2020-04-02 05:08:53,777 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'GET_METADATA' ACL '*'
2020-04-02 05:08:53,778 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'SET_KEY_MATERIAL' ACL '*'
2020-04-02 05:08:53,778 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'GENERATE_EEK' ACL '*'
2020-04-02 05:08:53,778 [main] INFO  server.KMSACLs (KMSACLs.java:setKMSACLs(107)) - 'DECRYPT_EEK' ACL '*'
2020-04-02 05:08:53,780 [main] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(185)) - default.key.acl. for KEY_OP 'READ' is set to '*'
2020-04-02 05:08:53,780 [main] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(185)) - default.key.acl. for KEY_OP 'MANAGEMENT' is set to '*'
2020-04-02 05:08:53,780 [main] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(185)) - default.key.acl. for KEY_OP 'GENERATE_EEK' is set to '*'
2020-04-02 05:08:53,780 [main] INFO  server.KMSACLs (KMSACLs.java:parseAclsWithPrefix(185)) - default.key.acl. for KEY_OP 'DECRYPT_EEK' is set to '*'
2020-04-02 05:08:53,889 [main] INFO  server.KMSAudit (KMSAudit.java:initializeAuditLoggers(157)) - Initializing audit logger class org.apache.hadoop.crypto.key.kms.server.SimpleKMSAuditLogger
2020-04-02 05:08:54,449 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(143)) - Initialized KeyProvider CachingKeyProvider: jceks://file@/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/kms.keystore
2020-04-02 05:08:54,469 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(157)) - Initialized KeyProviderCryptoExtension EagerKeyGeneratorKeyProviderCryptoExtension: KeyProviderCryptoExtension: CachingKeyProvider: jceks://file@/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/kms.keystore
2020-04-02 05:08:54,469 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(162)) - Default key bitlength is 128
2020-04-02 05:08:54,470 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextInitialized(163)) - KMS Started
2020-04-02 05:08:54,501 [main] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:08:54,523 [main] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:08:54,526 [Thread[Thread-13,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:08:54,526 [Thread[Thread-13,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
Apr 02, 2020 5:08:54 AM com.sun.jersey.api.core.PackagesResourceConfig init
INFO: Scanning for root resource and provider classes in the packages:
  org.apache.hadoop.crypto.key.kms.server
Apr 02, 2020 5:08:54 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Root resource classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMS
Apr 02, 2020 5:08:54 AM com.sun.jersey.api.core.ScanningResourceConfig logClasses
INFO: Provider classes found:
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONReader
  class org.apache.hadoop.crypto.key.kms.server.KMSExceptionsProvider
  class org.apache.hadoop.crypto.key.kms.server.KMSJSONWriter
Apr 02, 2020 5:08:54 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2020-04-02 05:08:56,971 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@654b72c0{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/tmp/kms/webapp/,AVAILABLE}{/kms}
2020-04-02 05:08:56,984 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@46b695ec{HTTP/1.1,[http/1.1]}{localhost:45018}
2020-04-02 05:08:56,985 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6191ms
2020-04-02 05:08:57,235 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:08:57,332 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:08:57,387 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:08:57,387 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - KMS metrics system started
2020-04-02 05:08:57,407 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5b78fdb1] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
[msx] test Started org.apache.hadoop.hdfs.TestSecureEncryptionZoneWithKMS#testSecureEncryptionZoneWithKMS
[msx] unitTestCounterInClass = 0
2020-04-02 05:08:57,506 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
Formatting using clusterid: testClusterID
2020-04-02 05:08:57,936 [Thread-19] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:57,960 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@8fd3b74
2020-04-02 05:08:57,962 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:57,963 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:57,963 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:08:57,964 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:57,964 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:57,964 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:58,013 [Thread-19] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:58,018 [Thread-19] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:08:58,018 [Thread-19] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:58,019 [Thread-19] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:58,022 [Thread-19] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:58,023 [Thread-19] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:58
2020-04-02 05:08:58,025 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:58,025 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:58,027 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:08:58,028 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:58,047 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:08:58,048 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:08:58,063 [Thread-19] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:58,064 [Thread-19] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:58,064 [Thread-19] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:58,064 [Thread-19] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:58,064 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:08:58,064 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:58,065 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:58,065 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:08:58,065 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:58,065 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:58,065 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:58,085 [Thread-19] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:08:58,100 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:58,101 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:58,101 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:08:58,101 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:58,108 [Thread-19] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:58,127 [Thread-19] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:58,127 [Thread-19] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:58,128 [Thread-19] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:58,133 [Thread-19] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(212)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2020-04-02 05:08:58,674 [Thread-19] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:58,677 [Thread-19] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:58,688 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:58,689 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:58,689 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:08:58,689 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:58,700 [Thread-19] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:58,701 [Thread-19] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:58,701 [Thread-19] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:58,710 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:58,716 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:58,719 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:58,720 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:58,738 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:08:58,738 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:58,787 [Thread-19] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:08:58,793 [Thread-19] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:08:58,795 [Thread-19] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:08:58,819 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:58,820 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:08:59,003 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:59,004 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:08:59,020 [Thread-19] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:08:59,025 [Thread-19] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:08:59,036 [Thread-19] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:08:59,037 [Thread-19] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:08:59,040 [Thread-19] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:08:59,151 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804139101,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:08:59,170 [Thread-19] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab
2020-04-02 05:08:59,199 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@39c5f226] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:08:59,200 [Thread-19] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:08:59,201 [Thread-19] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:08:59,202 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:59,203 [Thread-19] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:08:59,206 [Thread-19] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:08:59,206 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:08:59,208 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:08:59,209 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:08:59,209 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:08:59,209 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:08:59,247 [Thread-19] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:08:59,247 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:08:59,249 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:08:59,250 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:08:59,250 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41791
2020-04-02 05:08:59,251 [Thread-19] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:08:59,255 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27caf145{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:08:59,257 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e9da520{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:08:59,263 [Thread-19] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:08:59,265 [Thread-19] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:08:59,266 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@14b4025b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:08:59,280 [Thread-19] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@673c8cf7(server,h=[],w=[]) for SslContextFactory@543d930d(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/trustKS.jks)
2020-04-02 05:08:59,291 [Thread-19] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7cae1c10{SSL,[ssl, http/1.1]}{localhost:41791}
2020-04-02 05:08:59,292 [Thread-19] INFO  server.Server (Server.java:doStart(419)) - Started @8498ms
2020-04-02 05:08:59,303 [Thread-19] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:08:59,316 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@6b7c759c
2020-04-02 05:08:59,317 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:08:59,317 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:08:59,318 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:08:59,318 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:08:59,318 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:08:59,318 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:08:59,326 [Thread-19] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:08:59,327 [Thread-19] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:08:59,327 [Thread-19] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:08:59,328 [Thread-19] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:08:59,328 [Thread-19] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:08:59
2020-04-02 05:08:59,329 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:08:59,329 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:59,329 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:08:59,330 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:08:59,341 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:08:59,350 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:08:59,358 [Thread-19] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:08:59,359 [Thread-19] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:08:59,359 [Thread-19] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:08:59,360 [Thread-19] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:08:59,360 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:08:59,360 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:08:59,360 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:08:59,360 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:08:59,360 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:08:59,360 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:08:59,361 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:08:59,361 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:08:59,361 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:59,362 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:08:59,362 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:08:59,366 [Thread-19] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:08:59,367 [Thread-19] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:08:59,367 [Thread-19] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:08:59,367 [Thread-19] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:08:59,367 [Thread-19] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(212)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2020-04-02 05:08:59,368 [Thread-19] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:08:59,368 [Thread-19] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:08:59,368 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:08:59,368 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:59,369 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:08:59,369 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:08:59,373 [Thread-19] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:08:59,373 [Thread-19] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:08:59,373 [Thread-19] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:08:59,374 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:08:59,374 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:08:59,374 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:08:59,374 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:08:59,375 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:08:59,375 [Thread-19] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:08:59,383 [Thread-19] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 16091@b1fc8b48a924
2020-04-02 05:08:59,386 [Thread-19] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 16091@b1fc8b48a924
2020-04-02 05:08:59,388 [Thread-19] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:08:59,389 [Thread-19] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:08:59,389 [Thread-19] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:08:59,390 [Thread-19] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:08:59,433 [Thread-19] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:08:59,442 [Thread-19] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:08:59,443 [Thread-19] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:08:59,450 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:08:59,453 [Thread-19] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:08:59,481 [Thread-19] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:08:59,481 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 106 msecs
2020-04-02 05:08:59,670 [Thread-19] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:08:59,686 [Thread-19] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:08:59,700 [Socket Reader #1 for port 33159] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33159
2020-04-02 05:08:59,747 [Thread-19] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33159 to access this namenode/service.
2020-04-02 05:08:59,750 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:08:59,803 [Thread-19] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:08:59,826 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@83c42d3] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:08:59,837 [Thread-19] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:08:59,840 [Thread-19] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:08:59,841 [Thread-19] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:08:59,841 [Thread-19] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:08:59,851 [Thread-19] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:08:59,869 [Thread[Thread-48,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:08:59,881 [Thread[Thread-48,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:08:59,869 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:08:59,887 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:08:59,887 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:08:59,888 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:08:59,888 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:08:59,888 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 35 msec
2020-04-02 05:08:59,903 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:08:59,913 [Thread-19] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33159
2020-04-02 05:08:59,916 [IPC Server listener on 33159] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33159: starting
2020-04-02 05:08:59,917 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:08:59,929 [Thread-19] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:08:59,934 [Thread-19] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 4 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:08:59,937 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(325)) - Starting up re-encrypt thread with interval=60000 millisecond.
2020-04-02 05:08:59,961 [CacheReplicationMonitor(1033506336)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:08:59,975 [Thread-19] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33159 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:08:59,964 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2020-04-02 05:08:59,984 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:00,015 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804140014,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:00,054 [Thread-19] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab
2020-04-02 05:09:00,074 [Thread-19] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:00,101 [Thread-19] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:00,138 [Thread-19] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:00,139 [Thread-19] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:00,148 [Thread-19] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:00,152 [Thread-19] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:00,156 [Thread-19] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:00,158 [Thread-19] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:00,164 [Thread-19] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:00,174 [Thread-19] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42311
2020-04-02 05:09:00,178 [Thread-19] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:00,178 [Thread-19] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:00,215 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:00,217 [Thread-19] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:00,218 [Thread-19] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:00,218 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:00,220 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:00,229 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:00,229 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:00,230 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:00,242 [Thread-19] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39318
2020-04-02 05:09:00,242 [Thread-19] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:00,248 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b560ff9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:00,249 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2ac9dd3c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:00,255 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@52a3c391{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:00,256 [Thread-19] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5a9235d8{HTTP/1.1,[http/1.1]}{localhost:39318}
2020-04-02 05:09:00,259 [Thread-19] INFO  server.Server (Server.java:doStart(419)) - Started @9466ms
2020-04-02 05:09:00,704 [Thread-19] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:33267
2020-04-02 05:09:00,705 [Thread-19] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:00,705 [Thread-19] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:00,722 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@44a7dbc3] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:00,730 [Thread-19] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:00,730 [Socket Reader #1 for port 41782] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41782
2020-04-02 05:09:00,737 [Thread-19] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41782
2020-04-02 05:09:00,752 [Thread-19] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:00,755 [Thread-19] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:00,796 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:00,797 [IPC Server listener on 41782] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41782: starting
2020-04-02 05:09:00,781 [Thread-78] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33159 starting to offer service
2020-04-02 05:09:00,868 [Thread-19] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41782 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:01,239 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804141237,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:01,303 [Socket Reader #1 for port 33159] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:01,542 [Thread-78] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33159
2020-04-02 05:09:01,544 [Socket Reader #1 for port 33159] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:01,544 [Thread-78] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:01,564 [Thread-78] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 16091@b1fc8b48a924
2020-04-02 05:09:01,564 [Thread-78] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 657540639. Formatting...
2020-04-02 05:09:01,565 [Thread-78] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d0dd3c67-53bc-4d58-ab4f-bb33acc9191e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:09:01,584 [Thread-78] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 16091@b1fc8b48a924
2020-04-02 05:09:01,584 [Thread-78] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 657540639. Formatting...
2020-04-02 05:09:01,585 [Thread-78] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-59314118-055f-45ad-bf09-67fe097bb75a for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:09:01,616 [Thread-78] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:09:01,616 [Thread-78] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:09:01,617 [Thread-78] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1052642678-172.17.0.15-1585804138775 is not formatted. Formatting ...
2020-04-02 05:09:01,617 [Thread-78] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1052642678-172.17.0.15-1585804138775 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1052642678-172.17.0.15-1585804138775/current
2020-04-02 05:09:01,639 [Thread-78] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:09:01,639 [Thread-78] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:09:01,639 [Thread-78] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1052642678-172.17.0.15-1585804138775 is not formatted. Formatting ...
2020-04-02 05:09:01,639 [Thread-78] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1052642678-172.17.0.15-1585804138775 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1052642678-172.17.0.15-1585804138775/current
2020-04-02 05:09:01,642 [Thread-78] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=657540639;bpid=BP-1052642678-172.17.0.15-1585804138775;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=657540639;c=1585804138775;bpid=BP-1052642678-172.17.0.15-1585804138775;dnuuid=null
2020-04-02 05:09:01,644 [Thread-78] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ab11b474-8ed8-417a-8739-50b317ad1d0a
2020-04-02 05:09:01,687 [IPC Server handler 3 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,714 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:01,714 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:01,817 [IPC Server handler 5 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,818 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:01,818 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:01,827 [Thread-78] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d0dd3c67-53bc-4d58-ab4f-bb33acc9191e
2020-04-02 05:09:01,827 [Thread-78] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:09:01,831 [Thread-78] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-59314118-055f-45ad-bf09-67fe097bb75a
2020-04-02 05:09:01,832 [Thread-78] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:09:01,837 [Thread-78] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:01,849 [Thread-78] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:01,860 [Thread-78] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:01,861 [Thread-78] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:01,861 [Thread-78] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:01,862 [Thread-78] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:09:01,863 [Thread-96] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1052642678-172.17.0.15-1585804138775 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:01,863 [Thread-97] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1052642678-172.17.0.15-1585804138775 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:01,890 [Thread-97] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1052642678-172.17.0.15-1585804138775 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 26ms
2020-04-02 05:09:01,910 [Thread-96] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1052642678-172.17.0.15-1585804138775 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 46ms
2020-04-02 05:09:01,910 [Thread-78] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1052642678-172.17.0.15-1585804138775: 47ms
2020-04-02 05:09:01,914 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1052642678-172.17.0.15-1585804138775 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:01,914 [Thread-100] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1052642678-172.17.0.15-1585804138775/current/replicas doesn't exist 
2020-04-02 05:09:01,916 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1052642678-172.17.0.15-1585804138775 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:01,916 [Thread-101] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1052642678-172.17.0.15-1585804138775/current/replicas doesn't exist 
2020-04-02 05:09:01,917 [Thread-100] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1052642678-172.17.0.15-1585804138775 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:09:01,921 [Thread-101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1052642678-172.17.0.15-1585804138775 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 6ms
2020-04-02 05:09:01,922 [IPC Server handler 7 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:01,923 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:01,923 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:01,925 [Thread-78] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1052642678-172.17.0.15-1585804138775: 13ms
2020-04-02 05:09:01,928 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1052642678-172.17.0.15-1585804138775 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:01,928 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1052642678-172.17.0.15-1585804138775 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:01,930 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d0dd3c67-53bc-4d58-ab4f-bb33acc9191e): finished scanning block pool BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:09:01,930 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-59314118-055f-45ad-bf09-67fe097bb75a): finished scanning block pool BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:09:01,941 [Thread-78] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:22 AM with interval of 21600000ms
2020-04-02 05:09:01,948 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1052642678-172.17.0.15-1585804138775 (Datanode Uuid ab11b474-8ed8-417a-8739-50b317ad1d0a) service to localhost/127.0.0.1:33159 beginning handshake with NN
2020-04-02 05:09:01,964 [IPC Server handler 4 on 33159] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42311, datanodeUuid=ab11b474-8ed8-417a-8739-50b317ad1d0a, infoPort=0, infoSecurePort=33267, ipcPort=41782, storageInfo=lv=-57;cid=testClusterID;nsid=657540639;c=1585804138775) storage ab11b474-8ed8-417a-8739-50b317ad1d0a
2020-04-02 05:09:01,966 [IPC Server handler 4 on 33159] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:42311
2020-04-02 05:09:01,970 [IPC Server handler 4 on 33159] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ab11b474-8ed8-417a-8739-50b317ad1d0a (127.0.0.1:42311).
2020-04-02 05:09:01,979 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1052642678-172.17.0.15-1585804138775 (Datanode Uuid ab11b474-8ed8-417a-8739-50b317ad1d0a) service to localhost/127.0.0.1:33159 successfully registered with NN
2020-04-02 05:09:01,979 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-1052642678-172.17.0.15-1585804138775 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:09:01,991 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d0dd3c67-53bc-4d58-ab4f-bb33acc9191e): no suitable block pools found to scan.  Waiting 1814399937 ms.
2020-04-02 05:09:01,991 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-59314118-055f-45ad-bf09-67fe097bb75a): no suitable block pools found to scan.  Waiting 1814399937 ms.
2020-04-02 05:09:01,979 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:09:01,992 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33159 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:02,041 [IPC Server handler 3 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:02,051 [IPC Server handler 5 on 33159] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d0dd3c67-53bc-4d58-ab4f-bb33acc9191e for DN 127.0.0.1:42311
2020-04-02 05:09:02,051 [IPC Server handler 5 on 33159] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-59314118-055f-45ad-bf09-67fe097bb75a for DN 127.0.0.1:42311
2020-04-02 05:09:02,055 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2718)) - No heartbeat from DataNode: 127.0.0.1:42311
2020-04-02 05:09:02,055 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:02,081 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x86608dc292997132: Processing first storage report for DS-d0dd3c67-53bc-4d58-ab4f-bb33acc9191e from datanode ab11b474-8ed8-417a-8739-50b317ad1d0a
2020-04-02 05:09:02,085 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x86608dc292997132: from storage DS-d0dd3c67-53bc-4d58-ab4f-bb33acc9191e node DatanodeRegistration(127.0.0.1:42311, datanodeUuid=ab11b474-8ed8-417a-8739-50b317ad1d0a, infoPort=0, infoSecurePort=33267, ipcPort=41782, storageInfo=lv=-57;cid=testClusterID;nsid=657540639;c=1585804138775), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,085 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x86608dc292997132: Processing first storage report for DS-59314118-055f-45ad-bf09-67fe097bb75a from datanode ab11b474-8ed8-417a-8739-50b317ad1d0a
2020-04-02 05:09:02,086 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x86608dc292997132: from storage DS-59314118-055f-45ad-bf09-67fe097bb75a node DatanodeRegistration(127.0.0.1:42311, datanodeUuid=ab11b474-8ed8-417a-8739-50b317ad1d0a, infoPort=0, infoSecurePort=33267, ipcPort=41782, storageInfo=lv=-57;cid=testClusterID;nsid=657540639;c=1585804138775), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:09:02,108 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x86608dc292997132,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 4 msec to generate and 39 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:02,109 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:09:02,157 [IPC Server handler 0 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:02,161 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:02,171 [IPC Server handler 1 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:02,173 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:02,191 [IPC Server handler 9 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:02,192 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:02,357 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804142355,hdfs/localhost for HTTP/localhost@EXAMPLE.COM
Apr 02, 2020 5:09:02 AM com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator buildModelAndSchemas
SEVERE: Failed to generate the schema for the JAX-B elements
com.sun.xml.bind.v2.runtime.IllegalAnnotationsException: 2 counts of IllegalAnnotationExceptions
java.util.Map is an interface, and JAXB can't handle interfaces.
	this problem is related to the following location:
		at java.util.Map
java.util.Map does not have a no-arg default constructor.
	this problem is related to the following location:
		at java.util.Map

	at com.sun.xml.bind.v2.runtime.IllegalAnnotationsException$Builder.check(IllegalAnnotationsException.java:106)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.getTypeInfoSet(JAXBContextImpl.java:489)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.<init>(JAXBContextImpl.java:319)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl$JAXBContextBuilder.build(JAXBContextImpl.java:1170)
	at com.sun.xml.bind.v2.ContextFactory.createContext(ContextFactory.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:247)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:234)
	at javax.xml.bind.ContextFinder.find(ContextFinder.java:441)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:641)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:584)
	at com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator.buildModelAndSchemas(WadlGeneratorJAXBGrammarGenerator.java:169)
	at com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator.createExternalGrammar(AbstractWadlGeneratorGrammarGenerator.java:405)
	at com.sun.jersey.server.wadl.WadlBuilder.generate(WadlBuilder.java:149)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:119)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:138)
	at com.sun.jersey.server.impl.wadl.WadlMethodFactory$WadlOptionsMethodDispatcher.dispatch(WadlMethodFactory.java:110)
	at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.crypto.key.kms.server.KMSMDCFilter.doFilter(KMSMDCFilter.java:84)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:644)
	at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:304)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)
	at org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter.doFilter(KMSAuthenticationFilter.java:142)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:536)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.execute(ExecuteProduceConsume.java:100)
	at org.eclipse.jetty.io.ManagedSelector.run(ManagedSelector.java:147)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)

Apr 02, 2020 5:09:02 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:02 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:02 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:02 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:02 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:02 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:02 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:02 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
2020-04-02 05:09:02,982 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(589)) - Successfully warmed up 0 EDEKs.
2020-04-02 05:09:03,003 [qtp132577100-332] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=CREATE_KEY, key=test_key, user=hdfs] UserProvidedMaterial:false Description:test_key
2020-04-02 05:09:03,038 [IPC Server handler 3 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/test-dir/TestEZ1	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,569 [IPC Server handler 8 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=setOwner	src=/test-dir/TestEZ1	dst=null	perm=oozie_user:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,587 [qtp132577100-31] WARN  server.AuthenticationFilter (AuthenticationFilter.java:doFilter(525)) - AuthenticationToken ignored: org.apache.hadoop.security.authentication.util.SignerException: Invalid signature
2020-04-02 05:09:03,607 [qtp132577100-31] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(90)) - UNAUTHENTICATED RemoteHost:127.0.0.1 Method:GET URL:http://localhost:45018/kms/v1/key/test_key/_metadata ErrorMsg:'org.apache.hadoop.security.authentication.util.SignerException: Invalid signature'
2020-04-02 05:09:03,646 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804143645,hdfs/localhost for HTTP/localhost@EXAMPLE.COM
Apr 02, 2020 5:09:03 AM com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator buildModelAndSchemas
SEVERE: Failed to generate the schema for the JAX-B elements
com.sun.xml.bind.v2.runtime.IllegalAnnotationsException: 2 counts of IllegalAnnotationExceptions
java.util.Map is an interface, and JAXB can't handle interfaces.
	this problem is related to the following location:
		at java.util.Map
java.util.Map does not have a no-arg default constructor.
	this problem is related to the following location:
		at java.util.Map

	at com.sun.xml.bind.v2.runtime.IllegalAnnotationsException$Builder.check(IllegalAnnotationsException.java:106)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.getTypeInfoSet(JAXBContextImpl.java:489)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.<init>(JAXBContextImpl.java:319)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl$JAXBContextBuilder.build(JAXBContextImpl.java:1170)
	at com.sun.xml.bind.v2.ContextFactory.createContext(ContextFactory.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:247)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:234)
	at javax.xml.bind.ContextFinder.find(ContextFinder.java:441)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:641)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:584)
	at com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator.buildModelAndSchemas(WadlGeneratorJAXBGrammarGenerator.java:169)
	at com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator.createExternalGrammar(AbstractWadlGeneratorGrammarGenerator.java:405)
	at com.sun.jersey.server.wadl.WadlBuilder.generate(WadlBuilder.java:149)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:119)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:138)
	at com.sun.jersey.server.impl.wadl.WadlMethodFactory$WadlOptionsMethodDispatcher.dispatch(WadlMethodFactory.java:110)
	at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.crypto.key.kms.server.KMSMDCFilter.doFilter(KMSMDCFilter.java:84)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:644)
	at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:304)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)
	at org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter.doFilter(KMSAuthenticationFilter.java:142)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:536)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)

Apr 02, 2020 5:09:03 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:03 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:03 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:03 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:03 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:03 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:03 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
2020-04-02 05:09:03,696 [qtp132577100-28] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_METADATA, key=test_key, user=hdfs] 
2020-04-02 05:09:03,944 [qtp132577100-29] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=GENERATE_EEK, key=test_key, user=hdfs, accessCount=1, interval=0ms] 
2020-04-02 05:09:03,960 [IPC Server handler 6 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/test-dir/TestEZ1	dst=null	perm=oozie_user:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:03,970 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804143969,oozie/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:04,010 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804144009,oozie/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:04,039 [Socket Reader #1 for port 33159] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for oozie/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:04,060 [IPC Server handler 9 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=oozie_user (auth:PROXY) via oozie/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/test-dir/TestEZ1	dst=null	perm=oozie_user:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:04,127 [IPC Server handler 1 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=oozie_user (auth:PROXY) via oozie/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/test-dir/TestEZ1/testData.0.dat	dst=null	perm=oozie_user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:04,231 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804144231,oozie/localhost for HTTP/localhost@EXAMPLE.COM
Apr 02, 2020 5:09:04 AM com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator buildModelAndSchemas
SEVERE: Failed to generate the schema for the JAX-B elements
com.sun.xml.bind.v2.runtime.IllegalAnnotationsException: 2 counts of IllegalAnnotationExceptions
java.util.Map is an interface, and JAXB can't handle interfaces.
	this problem is related to the following location:
		at java.util.Map
java.util.Map does not have a no-arg default constructor.
	this problem is related to the following location:
		at java.util.Map

	at com.sun.xml.bind.v2.runtime.IllegalAnnotationsException$Builder.check(IllegalAnnotationsException.java:106)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.getTypeInfoSet(JAXBContextImpl.java:489)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.<init>(JAXBContextImpl.java:319)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl$JAXBContextBuilder.build(JAXBContextImpl.java:1170)
	at com.sun.xml.bind.v2.ContextFactory.createContext(ContextFactory.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:247)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:234)
	at javax.xml.bind.ContextFinder.find(ContextFinder.java:441)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:641)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:584)
	at com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator.buildModelAndSchemas(WadlGeneratorJAXBGrammarGenerator.java:169)
	at com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator.createExternalGrammar(AbstractWadlGeneratorGrammarGenerator.java:405)
	at com.sun.jersey.server.wadl.WadlBuilder.generate(WadlBuilder.java:149)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:119)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:138)
	at com.sun.jersey.server.impl.wadl.WadlMethodFactory$WadlOptionsMethodDispatcher.dispatch(WadlMethodFactory.java:110)
	at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.crypto.key.kms.server.KMSMDCFilter.doFilter(KMSMDCFilter.java:84)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:644)
	at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:304)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)
	at org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter.doFilter(KMSAuthenticationFilter.java:142)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:536)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)

Apr 02, 2020 5:09:04 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:04 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:04 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:04 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:04 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:04 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:04 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:04 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
2020-04-02 05:09:04,433 [qtp132577100-31] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditEvent(59)) - OK[op=DECRYPT_EEK, key=test_key, user=oozie_user, accessCount=1, interval=0ms] 
2020-04-02 05:09:04,464 [IPC Server handler 2 on 33159] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741825_1001, replicas=127.0.0.1:42311 for /test-dir/TestEZ1/testData.0.dat
2020-04-02 05:09:04,598 [DataXceiver for client DFSClient_NONMAPREDUCE_1817888193_49 at /127.0.0.1:45252 [Receiving block BP-1052642678-172.17.0.15-1585804138775:blk_1073741825_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1052642678-172.17.0.15-1585804138775:blk_1073741825_1001 src: /127.0.0.1:45252 dest: /127.0.0.1:42311
2020-04-02 05:09:04,671 [PacketResponder: BP-1052642678-172.17.0.15-1585804138775:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45252, dest: /127.0.0.1:42311, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1817888193_49, offset: 0, srvID: ab11b474-8ed8-417a-8739-50b317ad1d0a, blockid: BP-1052642678-172.17.0.15-1585804138775:blk_1073741825_1001, duration(ns): 23563913
2020-04-02 05:09:04,674 [PacketResponder: BP-1052642678-172.17.0.15-1585804138775:blk_1073741825_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1052642678-172.17.0.15-1585804138775:blk_1073741825_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:04,692 [IPC Server handler 7 on 33159] INFO  namenode.FSNamesystem (FSNamesystem.java:checkBlocksComplete(2908)) - BLOCK* blk_1073741825_1001 is COMMITTED but not COMPLETE(numNodes= 0 <  minimum = 1) in file /test-dir/TestEZ1/testData.0.dat
2020-04-02 05:09:05,099 [IPC Server handler 1 on 33159] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test-dir/TestEZ1/testData.0.dat is closed by DFSClient_NONMAPREDUCE_1817888193_49
2020-04-02 05:09:05,102 [IPC Server handler 0 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=oozie_user (auth:PROXY) via oozie/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/test-dir/TestEZ1	dst=null	perm=oozie_user:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,108 [IPC Server handler 2 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=oozie_user (auth:PROXY) via oozie/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/test-dir/TestEZ1/testData.1.dat	dst=null	perm=oozie_user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,127 [IPC Server handler 5 on 33159] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741826_1002, replicas=127.0.0.1:42311 for /test-dir/TestEZ1/testData.1.dat
2020-04-02 05:09:05,151 [DataXceiver for client DFSClient_NONMAPREDUCE_1817888193_49 at /127.0.0.1:45720 [Receiving block BP-1052642678-172.17.0.15-1585804138775:blk_1073741826_1002]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1052642678-172.17.0.15-1585804138775:blk_1073741826_1002 src: /127.0.0.1:45720 dest: /127.0.0.1:42311
2020-04-02 05:09:05,185 [PacketResponder: BP-1052642678-172.17.0.15-1585804138775:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45720, dest: /127.0.0.1:42311, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1817888193_49, offset: 0, srvID: ab11b474-8ed8-417a-8739-50b317ad1d0a, blockid: BP-1052642678-172.17.0.15-1585804138775:blk_1073741826_1002, duration(ns): 30272756
2020-04-02 05:09:05,194 [PacketResponder: BP-1052642678-172.17.0.15-1585804138775:blk_1073741826_1002, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1052642678-172.17.0.15-1585804138775:blk_1073741826_1002, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,200 [IPC Server handler 6 on 33159] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test-dir/TestEZ1/testData.1.dat is closed by DFSClient_NONMAPREDUCE_1817888193_49
2020-04-02 05:09:05,206 [IPC Server handler 7 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=oozie_user (auth:PROXY) via oozie/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/test-dir/TestEZ1	dst=null	perm=oozie_user:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:05,220 [qtp132577100-28] WARN  server.AuthenticationFilter (AuthenticationFilter.java:doFilter(525)) - AuthenticationToken ignored: AuthenticationToken expired
2020-04-02 05:09:05,222 [qtp132577100-28] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(90)) - UNAUTHENTICATED RemoteHost:127.0.0.1 Method:GET URL:http://localhost:45018/kms/v1/key/test_key/_eek?num_keys=1&eek_op=generate ErrorMsg:'AuthenticationToken expired'
2020-04-02 05:09:05,246 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804145245,hdfs/localhost for HTTP/localhost@EXAMPLE.COM
2020-04-02 05:09:05,284 [IPC Server handler 4 on 33159] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=oozie_user (auth:PROXY) via oozie/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=create	src=/test-dir/TestEZ1/testData.2.dat	dst=null	perm=oozie_user:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:09:05,316 [qtp132577100-29] WARN  server.AuthenticationFilter (AuthenticationFilter.java:doFilter(525)) - AuthenticationToken ignored: AuthenticationToken expired
2020-04-02 05:09:05,318 [qtp132577100-29] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(90)) - UNAUTHENTICATED RemoteHost:127.0.0.1 Method:POST URL:http://localhost:45018/kms/v1/keyversion/test_key%400/_eek?eek_op=decrypt&doAs=oozie_user ErrorMsg:'AuthenticationToken expired'
2020-04-02 05:09:05,335 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804145334,oozie/localhost for HTTP/localhost@EXAMPLE.COM
Apr 02, 2020 5:09:05 AM com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator buildModelAndSchemas
SEVERE: Failed to generate the schema for the JAX-B elements
com.sun.xml.bind.v2.runtime.IllegalAnnotationsException: 2 counts of IllegalAnnotationExceptions
java.util.Map is an interface, and JAXB can't handle interfaces.
	this problem is related to the following location:
		at java.util.Map
java.util.Map does not have a no-arg default constructor.
	this problem is related to the following location:
		at java.util.Map

	at com.sun.xml.bind.v2.runtime.IllegalAnnotationsException$Builder.check(IllegalAnnotationsException.java:106)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.getTypeInfoSet(JAXBContextImpl.java:489)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.<init>(JAXBContextImpl.java:319)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl$JAXBContextBuilder.build(JAXBContextImpl.java:1170)
	at com.sun.xml.bind.v2.ContextFactory.createContext(ContextFactory.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:247)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:234)
	at javax.xml.bind.ContextFinder.find(ContextFinder.java:441)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:641)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:584)
	at com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator.buildModelAndSchemas(WadlGeneratorJAXBGrammarGenerator.java:169)
	at com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator.createExternalGrammar(AbstractWadlGeneratorGrammarGenerator.java:405)
	at com.sun.jersey.server.wadl.WadlBuilder.generate(WadlBuilder.java:149)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:119)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:138)
	at com.sun.jersey.server.impl.wadl.WadlMethodFactory$WadlOptionsMethodDispatcher.dispatch(WadlMethodFactory.java:110)
	at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.crypto.key.kms.server.KMSMDCFilter.doFilter(KMSMDCFilter.java:84)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:644)
	at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:304)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)
	at org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter.doFilter(KMSAuthenticationFilter.java:142)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:536)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)

Apr 02, 2020 5:09:05 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:05 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:05 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:05 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:05 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:05 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:05 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:05 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
2020-04-02 05:09:05,395 [IPC Server handler 3 on 33159] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_1073741827_1003, replicas=127.0.0.1:42311 for /test-dir/TestEZ1/testData.2.dat
2020-04-02 05:09:05,402 [DataXceiver for client DFSClient_NONMAPREDUCE_1817888193_49 at /127.0.0.1:45952 [Receiving block BP-1052642678-172.17.0.15-1585804138775:blk_1073741827_1003]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1052642678-172.17.0.15-1585804138775:blk_1073741827_1003 src: /127.0.0.1:45952 dest: /127.0.0.1:42311
2020-04-02 05:09:05,428 [PacketResponder: BP-1052642678-172.17.0.15-1585804138775:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45952, dest: /127.0.0.1:42311, bytes: 1024, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_1817888193_49, offset: 0, srvID: ab11b474-8ed8-417a-8739-50b317ad1d0a, blockid: BP-1052642678-172.17.0.15-1585804138775:blk_1073741827_1003, duration(ns): 13458006
2020-04-02 05:09:05,429 [PacketResponder: BP-1052642678-172.17.0.15-1585804138775:blk_1073741827_1003, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1052642678-172.17.0.15-1585804138775:blk_1073741827_1003, type=LAST_IN_PIPELINE terminating
2020-04-02 05:09:05,435 [IPC Server handler 1 on 33159] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /test-dir/TestEZ1/testData.2.dat is closed by DFSClient_NONMAPREDUCE_1817888193_49
2020-04-02 05:09:05,439 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:09:05,439 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:09:05,439 [Thread-19] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41782 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:05,439 [Thread-19] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:05,440 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@36b68a07] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:05,446 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-59314118-055f-45ad-bf09-67fe097bb75a) exiting.
2020-04-02 05:09:05,446 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-d0dd3c67-53bc-4d58-ab4f-bb33acc9191e) exiting.
2020-04-02 05:09:05,594 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@52a3c391{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:05,606 [Thread-19] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5a9235d8{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:05,607 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2ac9dd3c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:05,607 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b560ff9{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:05,633 [Thread-19] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41782
2020-04-02 05:09:05,667 [IPC Server listener on 41782] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41782
2020-04-02 05:09:05,669 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:05,669 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1052642678-172.17.0.15-1585804138775 (Datanode Uuid ab11b474-8ed8-417a-8739-50b317ad1d0a) service to localhost/127.0.0.1:33159
2020-04-02 05:09:05,681 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:05,776 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1052642678-172.17.0.15-1585804138775 (Datanode Uuid ab11b474-8ed8-417a-8739-50b317ad1d0a)
2020-04-02 05:09:05,776 [BP-1052642678-172.17.0.15-1585804138775 heartbeating to localhost/127.0.0.1:33159] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1052642678-172.17.0.15-1585804138775
2020-04-02 05:09:05,802 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1052642678-172.17.0.15-1585804138775] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:05,829 [Thread-19] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:05,829 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1052642678-172.17.0.15-1585804138775] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:05,832 [Thread-19] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:05,832 [Thread-19] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:05,833 [Thread-19] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:05,842 [Thread-19] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:05,843 [Thread-19] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:09:05,843 [Thread-19] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33159 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:05,843 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:05,843 [Thread[Thread-48,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:09:05,845 [Thread-19] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 22
2020-04-02 05:09:05,845 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@446dbc48] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:09:05,846 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@799601c6] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:09:05,846 [Thread-19] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 23 Total time for transactions(ms): 537 Number of transactions batched in Syncs: 4 Number of syncs: 20 SyncTimes(ms): 2 10 
2020-04-02 05:09:05,852 [Thread-19] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000023
2020-04-02 05:09:05,853 [Thread-19] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000023
2020-04-02 05:09:05,854 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:09:05,864 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(334)) - Re-encrypt handler interrupted. Exiting
2020-04-02 05:09:05,865 [CacheReplicationMonitor(1033506336)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:09:05,867 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(266)) - Re-encryption updater thread interrupted. Exiting.
2020-04-02 05:09:05,868 [Thread-19] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33159
2020-04-02 05:09:05,872 [IPC Server listener on 33159] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33159
2020-04-02 05:09:05,882 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:09:05,882 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:09:05,881 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:05,952 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:05,952 [Thread-19] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:09:05,960 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@14b4025b{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:09:05,962 [Thread-19] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7cae1c10{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:09:05,963 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e9da520{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:05,963 [Thread-19] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27caf145{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.TestSecureEncryptionZoneWithKMS#testSecureEncryptionZoneWithKMS
[msx] writeFile testName = org.apache.hadoop.hdfs.TestSecureEncryptionZoneWithKMS#testSecureEncryptionZoneWithKMS
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.TestSecureEncryptionZoneWithKMS#testCreateZoneAfterAuthTokenExpiry
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:06,017 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=1
2020-04-02 05:09:06,032 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804146031,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:06,041 [Thread-126] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab
Formatting using clusterid: testClusterID
2020-04-02 05:09:06,042 [Thread-126] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:06,053 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@2e088d12
2020-04-02 05:09:06,053 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:06,053 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:06,054 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:06,054 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:06,054 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:06,054 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:06,055 [Thread-126] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:06,055 [Thread-126] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:06,055 [Thread-126] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:06,056 [Thread-126] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:06,056 [Thread-126] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:06
2020-04-02 05:09:06,056 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:06,056 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:06,057 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:09:06,057 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:06,085 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:09:06,085 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:09:06,086 [Thread-126] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:06,086 [Thread-126] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:06,086 [Thread-126] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:06,086 [Thread-126] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:06,086 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:09:06,086 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:06,087 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:06,087 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:06,087 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:06,087 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:06,087 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:06,087 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:06,087 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:06,087 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:09:06,088 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:06,093 [Thread-126] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:06,094 [Thread-126] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:06,094 [Thread-126] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:06,094 [Thread-126] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:06,094 [Thread-126] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(212)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2020-04-02 05:09:06,094 [Thread-126] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:06,094 [Thread-126] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:06,094 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:06,094 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:06,095 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:09:06,095 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:06,097 [Thread-126] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:06,097 [Thread-126] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:06,097 [Thread-126] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:06,097 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:06,097 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:06,097 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:06,097 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:06,098 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:09:06,098 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:06,100 [Thread-126] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:06,114 [Thread-126] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:09:06,117 [Thread-126] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:09:06,129 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:06,129 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:09:06,136 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 489 bytes saved in 0 seconds .
2020-04-02 05:09:06,155 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 489 bytes saved in 0 seconds .
2020-04-02 05:09:06,158 [Thread-126] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:09:06,162 [Thread-126] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:09:06,163 [Thread-126] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - NameNode metrics system started (again)
2020-04-02 05:09:06,163 [Thread-126] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:09:06,164 [Thread-126] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:09:06,175 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804146170,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:06,179 [Thread-126] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab
2020-04-02 05:09:06,194 [Thread-126] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1593)) - Starting web server as: HTTP/localhost@EXAMPLE.COM
2020-04-02 05:09:06,195 [Thread-126] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1618)) - Starting Web-server for hdfs at: https://localhost:0
2020-04-02 05:09:06,195 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:06,198 [Thread-126] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:06,199 [Thread-126] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:09:06,199 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:06,201 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:06,204 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:09:06,204 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:06,204 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:06,198 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4fda108a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:06,207 [Thread-126] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:09:06,207 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:09:06,207 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to fsck
2020-04-02 05:09:06,207 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addInternalServlet(866)) - Adding Kerberos (SPNEGO) filter to imagetransfer
2020-04-02 05:09:06,208 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41567
2020-04-02 05:09:06,208 [Thread-126] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:06,213 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6b558a8b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:06,213 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@55876080{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:06,219 [Thread-126] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:09:06,219 [Thread-126] INFO  server.KerberosAuthenticationHandler (KerberosAuthenticationHandler.java:init(164)) - Using keytab /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab, for principal HTTP/localhost@EXAMPLE.COM
2020-04-02 05:09:06,220 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@63e845f4{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:09:06,221 [Thread-126] INFO  ssl.SslContextFactory (SslContextFactory.java:load(290)) - x509=X509@78bc73b6(server,h=[],w=[]) for SslContextFactory@4f57536e(file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/serverKS.jks,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/trustKS.jks)
2020-04-02 05:09:06,223 [Thread-126] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d2e3dc7{SSL,[ssl, http/1.1]}{localhost:41567}
2020-04-02 05:09:06,223 [Thread-126] INFO  server.Server (Server.java:doStart(419)) - Started @15430ms
2020-04-02 05:09:06,225 [Thread-126] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:09:06,227 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: KeyProviderCryptoExtension: org.apache.hadoop.crypto.key.kms.LoadBalancingKMSClientProvider@723e02de
2020-04-02 05:09:06,227 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:09:06,227 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:09:06,227 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:06,227 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:09:06,227 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:09:06,228 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:09:06,228 [Thread-126] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:06,228 [Thread-126] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:09:06,228 [Thread-126] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:09:06,228 [Thread-126] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:09:06,229 [Thread-126] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:09:06
2020-04-02 05:09:06,229 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:09:06,229 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:06,229 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:09:06,229 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:09:06,245 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = true
2020-04-02 05:09:06,245 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(601)) - dfs.block.access.key.update.interval=600 min(s), dfs.block.access.token.lifetime=600 min(s), dfs.encrypt.data.transfer.algorithm=null
2020-04-02 05:09:06,246 [Thread-126] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:09:06,246 [Thread-126] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:09:06,246 [Thread-126] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:09:06,246 [Thread-126] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:09:06,246 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 1
2020-04-02 05:09:06,247 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:09:06,247 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:09:06,247 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:09:06,247 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 3000ms
2020-04-02 05:09:06,247 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:09:06,247 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:09:06,247 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:09:06,247 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:06,248 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:09:06,248 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:09:06,253 [Thread-126] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:09:06,253 [Thread-126] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:09:06,253 [Thread-126] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:09:06,253 [Thread-126] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:09:06,254 [Thread-126] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:<init>(212)) - Configured throttleLimitHandlerRatio=1.0 for re-encryption
2020-04-02 05:09:06,254 [Thread-126] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:09:06,254 [Thread-126] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:09:06,254 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:09:06,254 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:06,254 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:09:06,254 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:09:06,256 [Thread-126] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:09:06,256 [Thread-126] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:09:06,256 [Thread-126] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:09:06,256 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:09:06,256 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:09:06,256 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:09:06,256 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:09:06,256 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:09:06,256 [Thread-126] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:09:06,259 [Thread-126] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 16091@b1fc8b48a924
2020-04-02 05:09:06,266 [Thread-126] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 16091@b1fc8b48a924
2020-04-02 05:09:06,275 [Thread-126] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:09:06,276 [Thread-126] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:09:06,276 [Thread-126] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:09:06,276 [Thread-126] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:09:06,286 [Thread-126] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:09:06,295 [Thread-126] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:09:06,295 [Thread-126] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:09:06,296 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:09:06,300 [Thread-126] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:09:06,326 [Thread-126] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:09:06,326 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 68 msecs
2020-04-02 05:09:06,327 [Thread-126] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:09:06,327 [Thread-126] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:06,328 [Socket Reader #1 for port 33300] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33300
2020-04-02 05:09:06,344 [Thread-126] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:33300 to access this namenode/service.
2020-04-02 05:09:06,345 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:09:06,424 [Thread-126] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:09:06,446 [Thread-126] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:09:06,447 [Thread-126] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:09:06,447 [Thread-126] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:09:06,448 [Thread-126] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:09:06,453 [org.apache.hadoop.hdfs.server.blockmanagement.HeartbeatManager$Monitor@3fbf8247] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:updateKeys(240)) - Updating block keys
2020-04-02 05:09:06,469 [Thread-126] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:09:06,478 [Thread[Thread-155,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(679)) - Starting expired delegation token remover thread, tokenRemoverScanInterval=60 min(s)
2020-04-02 05:09:06,482 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:06,482 [IPC Server listener on 33300] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33300: starting
2020-04-02 05:09:06,494 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:09:06,502 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:09:06,504 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:09:06,526 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:09:06,526 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:09:06,526 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 80 msec
2020-04-02 05:09:06,523 [Thread[Thread-155,5,main]] INFO  delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:updateCurrentKey(347)) - Updating the current master key for generating delegation tokens
2020-04-02 05:09:06,530 [Thread-126] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:33300
2020-04-02 05:09:06,531 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:09:06,531 [Thread-126] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:09:06,532 [Thread-126] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:09:06,534 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(325)) - Starting up re-encrypt thread with interval=60000 millisecond.
2020-04-02 05:09:06,536 [Thread-126] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 33300 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:06,536 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(571)) - Warming up 0 EDEKs... (initialDelay=3000, retryInterval=1000)
2020-04-02 05:09:06,537 [CacheReplicationMonitor(1806582729)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:09:06,548 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:06,581 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804146580,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:06,595 [Thread-126] INFO  security.UserGroupInformation (UserGroupInformation.java:loginUserFromKeytab(1008)) - Login successful for user hdfs/localhost@EXAMPLE.COM using keytab file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/4ac95512-e807-4580-8022-7030732f8e2e/test.keytab
2020-04-02 05:09:06,596 [Thread-126] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:06,602 [Thread-126] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:06,651 [Thread-126] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:09:06,652 [Thread-126] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:09:06,652 [Thread-126] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:06,653 [Thread-126] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:09:06,654 [Thread-126] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is 127.0.0.1
2020-04-02 05:09:06,654 [Thread-126] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:09:06,655 [Thread-126] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:09:06,657 [Thread-126] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41619
2020-04-02 05:09:06,657 [Thread-126] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:09:06,658 [Thread-126] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:09:06,677 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:06,696 [Thread-126] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:09:06,714 [Thread-126] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:09:06,715 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:09:06,716 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:09:06,717 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:09:06,718 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:09:06,718 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:09:06,720 [Thread-126] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39570
2020-04-02 05:09:06,721 [Thread-126] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:09:06,724 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7501ff83{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:09:06,725 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@69cc0182{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:09:06,740 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@765c5847{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:09:06,741 [Thread-126] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6ab63474{HTTP/1.1,[http/1.1]}{localhost:39570}
2020-04-02 05:09:06,742 [Thread-126] INFO  server.Server (Server.java:doStart(419)) - Started @15948ms
2020-04-02 05:09:06,914 [Thread-126] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(276)) - Listening HTTPS traffic on /127.0.0.1:40681
2020-04-02 05:09:06,914 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@16ffaf24] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:09:06,914 [Thread-126] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:06,915 [Thread-126] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:09:06,915 [Thread-126] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:09:06,916 [Socket Reader #1 for port 45790] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45790
2020-04-02 05:09:06,921 [Thread-126] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45790
2020-04-02 05:09:06,943 [Thread-126] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:09:06,943 [Thread-126] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:09:06,944 [Thread-184] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33300 starting to offer service
2020-04-02 05:09:06,950 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:09:06,950 [IPC Server listener on 45790] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45790: starting
2020-04-02 05:09:06,955 [Thread-126] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45790 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:06,980 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804146979,hdfs/localhost for hdfs/localhost@EXAMPLE.COM
2020-04-02 05:09:07,012 [Socket Reader #1 for port 33300] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:07,052 [IPC Server handler 0 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:07,054 [Socket Reader #1 for port 33300] INFO  ipc.Server (Server.java:saslProcess(1845)) - Auth successful for hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)
2020-04-02 05:09:07,060 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:07,060 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:07,078 [Thread-184] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:33300
2020-04-02 05:09:07,080 [Thread-184] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:09:07,082 [Thread-184] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 16091@b1fc8b48a924
2020-04-02 05:09:07,083 [Thread-184] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1617757126. Formatting...
2020-04-02 05:09:07,083 [Thread-184] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8575d694-f70d-4f2f-9530-b6816b6a3bd0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:09:07,086 [Thread-184] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 16091@b1fc8b48a924
2020-04-02 05:09:07,087 [Thread-184] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1617757126. Formatting...
2020-04-02 05:09:07,087 [Thread-184] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-85145d2e-d1fd-4b0a-af05-22417f43ffc7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:09:07,115 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:07,115 [Thread-184] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:07,115 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-956281073-172.17.0.15-1585804146100 is not formatted. Formatting ...
2020-04-02 05:09:07,115 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-956281073-172.17.0.15-1585804146100 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-956281073-172.17.0.15-1585804146100/current
2020-04-02 05:09:07,146 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:07,147 [Thread-184] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:07,147 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-956281073-172.17.0.15-1585804146100 is not formatted. Formatting ...
2020-04-02 05:09:07,147 [Thread-184] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-956281073-172.17.0.15-1585804146100 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-956281073-172.17.0.15-1585804146100/current
2020-04-02 05:09:07,151 [Thread-184] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1617757126;bpid=BP-956281073-172.17.0.15-1585804146100;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1617757126;c=1585804146100;bpid=BP-956281073-172.17.0.15-1585804146100;dnuuid=null
2020-04-02 05:09:07,153 [Thread-184] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7eff76a6-9d8b-4ba3-a131-87e711c7db05
2020-04-02 05:09:07,156 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8575d694-f70d-4f2f-9530-b6816b6a3bd0
2020-04-02 05:09:07,156 [Thread-184] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:09:07,161 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-85145d2e-d1fd-4b0a-af05-22417f43ffc7
2020-04-02 05:09:07,161 [Thread-184] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:09:07,169 [Thread-184] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:09:07,170 [IPC Server handler 3 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:07,171 [Thread-184] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:07,171 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:07,171 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:07,183 [Thread-184] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:07,183 [Thread-184] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:07,183 [Thread-184] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:07,187 [Thread-184] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:07,188 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-956281073-172.17.0.15-1585804146100 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:07,190 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-956281073-172.17.0.15-1585804146100 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:07,241 [Thread-199] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-956281073-172.17.0.15-1585804146100 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 52ms
2020-04-02 05:09:07,254 [Thread-200] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-956281073-172.17.0.15-1585804146100 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 64ms
2020-04-02 05:09:07,254 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-956281073-172.17.0.15-1585804146100: 67ms
2020-04-02 05:09:07,256 [Thread-203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-956281073-172.17.0.15-1585804146100 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:09:07,256 [Thread-203] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-956281073-172.17.0.15-1585804146100/current/replicas doesn't exist 
2020-04-02 05:09:07,256 [Thread-204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-956281073-172.17.0.15-1585804146100 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:09:07,257 [Thread-204] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-956281073-172.17.0.15-1585804146100/current/replicas doesn't exist 
2020-04-02 05:09:07,259 [Thread-204] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-956281073-172.17.0.15-1585804146100 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 2ms
2020-04-02 05:09:07,259 [Thread-203] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-956281073-172.17.0.15-1585804146100 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 3ms
2020-04-02 05:09:07,262 [Thread-184] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-956281073-172.17.0.15-1585804146100: 8ms
2020-04-02 05:09:07,263 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-956281073-172.17.0.15-1585804146100 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:09:07,264 [Thread-184] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:52 AM with interval of 21600000ms
2020-04-02 05:09:07,264 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8575d694-f70d-4f2f-9530-b6816b6a3bd0): finished scanning block pool BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:07,265 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8575d694-f70d-4f2f-9530-b6816b6a3bd0): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:09:07,265 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-956281073-172.17.0.15-1585804146100 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:09:07,271 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-85145d2e-d1fd-4b0a-af05-22417f43ffc7): finished scanning block pool BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:07,271 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-956281073-172.17.0.15-1585804146100 (Datanode Uuid 7eff76a6-9d8b-4ba3-a131-87e711c7db05) service to localhost/127.0.0.1:33300 beginning handshake with NN
2020-04-02 05:09:07,272 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-85145d2e-d1fd-4b0a-af05-22417f43ffc7): no suitable block pools found to scan.  Waiting 1814399991 ms.
2020-04-02 05:09:07,289 [IPC Server handler 1 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:07,291 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:09:07,291 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:09:07,295 [IPC Server handler 4 on 33300] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41619, datanodeUuid=7eff76a6-9d8b-4ba3-a131-87e711c7db05, infoPort=0, infoSecurePort=40681, ipcPort=45790, storageInfo=lv=-57;cid=testClusterID;nsid=1617757126;c=1585804146100) storage 7eff76a6-9d8b-4ba3-a131-87e711c7db05
2020-04-02 05:09:07,298 [IPC Server handler 4 on 33300] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /default-rack/127.0.0.1:41619
2020-04-02 05:09:07,298 [IPC Server handler 4 on 33300] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7eff76a6-9d8b-4ba3-a131-87e711c7db05 (127.0.0.1:41619).
2020-04-02 05:09:07,307 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-956281073-172.17.0.15-1585804146100 (Datanode Uuid 7eff76a6-9d8b-4ba3-a131-87e711c7db05) service to localhost/127.0.0.1:33300 successfully registered with NN
2020-04-02 05:09:07,307 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] INFO  datanode.DataNode (DataNode.java:registerBlockPoolWithSecretManager(1625)) - Block token params received from NN: for block pool BP-956281073-172.17.0.15-1585804146100 keyUpdateInterval=600 min(s), tokenLifetime=600 min(s)
2020-04-02 05:09:07,307 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] INFO  block.BlockTokenSecretManager (BlockTokenSecretManager.java:addKeys(210)) - Setting block keys
2020-04-02 05:09:07,307 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:33300 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:09:07,326 [IPC Server handler 5 on 33300] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8575d694-f70d-4f2f-9530-b6816b6a3bd0 for DN 127.0.0.1:41619
2020-04-02 05:09:07,326 [IPC Server handler 5 on 33300] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-85145d2e-d1fd-4b0a-af05-22417f43ffc7 for DN 127.0.0.1:41619
2020-04-02 05:09:07,350 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe9d9d5b7c78e5e49: Processing first storage report for DS-85145d2e-d1fd-4b0a-af05-22417f43ffc7 from datanode 7eff76a6-9d8b-4ba3-a131-87e711c7db05
2020-04-02 05:09:07,350 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe9d9d5b7c78e5e49: from storage DS-85145d2e-d1fd-4b0a-af05-22417f43ffc7 node DatanodeRegistration(127.0.0.1:41619, datanodeUuid=7eff76a6-9d8b-4ba3-a131-87e711c7db05, infoPort=0, infoSecurePort=40681, ipcPort=45790, storageInfo=lv=-57;cid=testClusterID;nsid=1617757126;c=1585804146100), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:07,350 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe9d9d5b7c78e5e49: Processing first storage report for DS-8575d694-f70d-4f2f-9530-b6816b6a3bd0 from datanode 7eff76a6-9d8b-4ba3-a131-87e711c7db05
2020-04-02 05:09:07,350 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe9d9d5b7c78e5e49: from storage DS-8575d694-f70d-4f2f-9530-b6816b6a3bd0 node DatanodeRegistration(127.0.0.1:41619, datanodeUuid=7eff76a6-9d8b-4ba3-a131-87e711c7db05, infoPort=0, infoSecurePort=40681, ipcPort=45790, storageInfo=lv=-57;cid=testClusterID;nsid=1617757126;c=1585804146100), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:09:07,352 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe9d9d5b7c78e5e49,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:09:07,352 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:07,402 [IPC Server handler 7 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:07,406 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:07,411 [IPC Server handler 8 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:07,426 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:07,431 [IPC Server handler 9 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:09:07,432 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:09:07,439 [pool-1-thread-1] INFO  request.AsRequest (AsRequest.java:issueTicket(112)) - AS_REQ ISSUE: authtime 1585804147438,hdfs/localhost@EXAMPLE.COM for krbtgt/EXAMPLE.COM@EXAMPLE.COM
2020-04-02 05:09:07,441 [Thread-126] INFO  hdfs.TestSecureEncryptionZoneWithKMS (TestSecureEncryptionZoneWithKMS.java:testCreateZoneAfterAuthTokenExpiry(324)) - Created ugi: hdfs/localhost@EXAMPLE.COM (auth:KERBEROS) 
2020-04-02 05:09:07,447 [IPC Server handler 0 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/expire1	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:07,492 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804147491,hdfs/localhost for HTTP/localhost@EXAMPLE.COM
Apr 02, 2020 5:09:07 AM com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator buildModelAndSchemas
SEVERE: Failed to generate the schema for the JAX-B elements
com.sun.xml.bind.v2.runtime.IllegalAnnotationsException: 2 counts of IllegalAnnotationExceptions
java.util.Map is an interface, and JAXB can't handle interfaces.
	this problem is related to the following location:
		at java.util.Map
java.util.Map does not have a no-arg default constructor.
	this problem is related to the following location:
		at java.util.Map

	at com.sun.xml.bind.v2.runtime.IllegalAnnotationsException$Builder.check(IllegalAnnotationsException.java:106)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.getTypeInfoSet(JAXBContextImpl.java:489)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.<init>(JAXBContextImpl.java:319)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl$JAXBContextBuilder.build(JAXBContextImpl.java:1170)
	at com.sun.xml.bind.v2.ContextFactory.createContext(ContextFactory.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:247)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:234)
	at javax.xml.bind.ContextFinder.find(ContextFinder.java:441)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:641)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:584)
	at com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator.buildModelAndSchemas(WadlGeneratorJAXBGrammarGenerator.java:169)
	at com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator.createExternalGrammar(AbstractWadlGeneratorGrammarGenerator.java:405)
	at com.sun.jersey.server.wadl.WadlBuilder.generate(WadlBuilder.java:149)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:119)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:138)
	at com.sun.jersey.server.impl.wadl.WadlMethodFactory$WadlOptionsMethodDispatcher.dispatch(WadlMethodFactory.java:110)
	at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.crypto.key.kms.server.KMSMDCFilter.doFilter(KMSMDCFilter.java:84)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:644)
	at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:304)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)
	at org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter.doFilter(KMSAuthenticationFilter.java:142)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:536)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)

Apr 02, 2020 5:09:07 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:07 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:07 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:07 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:07 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:07 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:07 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
2020-04-02 05:09:07,541 [qtp132577100-29] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_METADATA, key=test_key, user=hdfs] 
2020-04-02 05:09:07,552 [IPC Server handler 2 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/expire1	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:07,555 [IPC Server handler 3 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=mkdirs	src=/expire2	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:07,556 [Thread-126] INFO  hdfs.TestSecureEncryptionZoneWithKMS (TestSecureEncryptionZoneWithKMS.java:lambda$testCreateZoneAfterAuthTokenExpiry$0(334)) - Sleeping 2000 seconds to wait for kms auth token expiration
2020-04-02 05:09:09,538 [Warm Up EDEK Cache Thread #0] INFO  namenode.NameNode (FSDirEncryptionZoneOp.java:run(589)) - Successfully warmed up 0 EDEKs.
2020-04-02 05:09:09,566 [qtp132577100-29] WARN  server.AuthenticationFilter (AuthenticationFilter.java:doFilter(525)) - AuthenticationToken ignored: org.apache.hadoop.security.authentication.util.SignerException: Invalid signature
2020-04-02 05:09:09,567 [qtp132577100-29] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(90)) - UNAUTHENTICATED RemoteHost:127.0.0.1 Method:GET URL:http://localhost:45018/kms/v1/key/test_key/_metadata ErrorMsg:'org.apache.hadoop.security.authentication.util.SignerException: Invalid signature'
2020-04-02 05:09:09,586 [pool-1-thread-1] INFO  request.TgsRequest (TgsRequest.java:issueTicket(115)) - TGS_REQ ISSUE: authtime 1585804149585,hdfs/localhost for HTTP/localhost@EXAMPLE.COM
Apr 02, 2020 5:09:09 AM com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator buildModelAndSchemas
SEVERE: Failed to generate the schema for the JAX-B elements
com.sun.xml.bind.v2.runtime.IllegalAnnotationsException: 2 counts of IllegalAnnotationExceptions
java.util.Map is an interface, and JAXB can't handle interfaces.
	this problem is related to the following location:
		at java.util.Map
java.util.Map does not have a no-arg default constructor.
	this problem is related to the following location:
		at java.util.Map

	at com.sun.xml.bind.v2.runtime.IllegalAnnotationsException$Builder.check(IllegalAnnotationsException.java:106)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.getTypeInfoSet(JAXBContextImpl.java:489)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl.<init>(JAXBContextImpl.java:319)
	at com.sun.xml.bind.v2.runtime.JAXBContextImpl$JAXBContextBuilder.build(JAXBContextImpl.java:1170)
	at com.sun.xml.bind.v2.ContextFactory.createContext(ContextFactory.java:145)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:247)
	at javax.xml.bind.ContextFinder.newInstance(ContextFinder.java:234)
	at javax.xml.bind.ContextFinder.find(ContextFinder.java:441)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:641)
	at javax.xml.bind.JAXBContext.newInstance(JAXBContext.java:584)
	at com.sun.jersey.server.wadl.generators.WadlGeneratorJAXBGrammarGenerator.buildModelAndSchemas(WadlGeneratorJAXBGrammarGenerator.java:169)
	at com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator.createExternalGrammar(AbstractWadlGeneratorGrammarGenerator.java:405)
	at com.sun.jersey.server.wadl.WadlBuilder.generate(WadlBuilder.java:149)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:119)
	at com.sun.jersey.server.impl.wadl.WadlApplicationContextImpl.getApplication(WadlApplicationContextImpl.java:138)
	at com.sun.jersey.server.impl.wadl.WadlMethodFactory$WadlOptionsMethodDispatcher.dispatch(WadlMethodFactory.java:110)
	at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)
	at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)
	at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)
	at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)
	at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)
	at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)
	at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:733)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:790)
	at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:848)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1772)
	at org.apache.hadoop.crypto.key.kms.server.KMSMDCFilter.doFilter(KMSMDCFilter.java:84)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:644)
	at org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationFilter.doFilter(DelegationTokenAuthenticationFilter.java:304)
	at org.apache.hadoop.security.authentication.server.AuthenticationFilter.doFilter(AuthenticationFilter.java:592)
	at org.apache.hadoop.crypto.key.kms.server.KMSAuthenticationFilter.doFilter(KMSAuthenticationFilter.java:142)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1751)
	at org.apache.hadoop.http.HttpServer2$QuotingInputFilter.doFilter(HttpServer2.java:1605)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.apache.hadoop.http.NoCacheFilter.doFilter(NoCacheFilter.java:45)
	at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1759)
	at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:582)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)
	at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:548)
	at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:226)
	at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1180)
	at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:512)
	at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:185)
	at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1112)
	at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)
	at org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:119)
	at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:134)
	at org.eclipse.jetty.server.Server.handle(Server.java:536)
	at org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:333)
	at org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:251)
	at org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:283)
	at org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:108)
	at org.eclipse.jetty.io.SelectChannelEndPoint$2.run(SelectChannelEndPoint.java:93)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.executeProduceConsume(ExecuteProduceConsume.java:303)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.produceConsume(ExecuteProduceConsume.java:148)
	at org.eclipse.jetty.util.thread.strategy.ExecuteProduceConsume.run(ExecuteProduceConsume.java:136)
	at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:671)
	at org.eclipse.jetty.util.thread.QueuedThreadPool$2.run(QueuedThreadPool.java:589)
	at java.lang.Thread.run(Thread.java:748)

Apr 02, 2020 5:09:09 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:09 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:09 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
Apr 02, 2020 5:09:09 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:09 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:09 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class java.util.Map
Apr 02, 2020 5:09:09 AM com.sun.jersey.server.wadl.generators.AbstractWadlGeneratorGrammarGenerator attachTypes
INFO: Couldn't find grammar element for class javax.ws.rs.core.Response
2020-04-02 05:09:09,634 [qtp132577100-46] INFO  kms-audit (SimpleKMSAuditLogger.java:logAuditSimpleFormat(93)) - OK[op=GET_METADATA, key=test_key, user=hdfs] 
2020-04-02 05:09:09,642 [IPC Server handler 1 on 33300] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=hdfs/localhost@EXAMPLE.COM (auth:KERBEROS)	ip=/127.0.0.1	cmd=createEncryptionZone	src=/expire2	dst=null	perm=hdfs:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:09:09,644 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:09:09,644 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:09:09,644 [Thread-126] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45790 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:09,644 [Thread-126] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:09:09,646 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@12eed558] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:09:09,653 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-85145d2e-d1fd-4b0a-af05-22417f43ffc7) exiting.
2020-04-02 05:09:09,653 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-8575d694-f70d-4f2f-9530-b6816b6a3bd0) exiting.
2020-04-02 05:09:09,730 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@765c5847{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:09:09,731 [Thread-126] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6ab63474{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:09,731 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@69cc0182{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:09,732 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7501ff83{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:09,734 [Thread-126] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45790
2020-04-02 05:09:09,737 [IPC Server listener on 45790] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45790
2020-04-02 05:09:09,738 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:09:09,746 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-956281073-172.17.0.15-1585804146100 (Datanode Uuid 7eff76a6-9d8b-4ba3-a131-87e711c7db05) service to localhost/127.0.0.1:33300
2020-04-02 05:09:09,737 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:09,847 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-956281073-172.17.0.15-1585804146100 (Datanode Uuid 7eff76a6-9d8b-4ba3-a131-87e711c7db05)
2020-04-02 05:09:09,847 [BP-956281073-172.17.0.15-1585804146100 heartbeating to localhost/127.0.0.1:33300] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-956281073-172.17.0.15-1585804146100
2020-04-02 05:09:09,862 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-956281073-172.17.0.15-1585804146100] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:09,867 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-956281073-172.17.0.15-1585804146100] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:09:09,871 [Thread-126] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:09:09,871 [Thread-126] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:09:09,871 [Thread-126] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:09:09,871 [Thread-126] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:09:09,875 [Thread-126] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:09:09,875 [Thread-126] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:09:09,875 [Thread-126] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 33300 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:09:09,875 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:09,876 [Thread[Thread-155,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:09:09,882 [Thread-126] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 7
2020-04-02 05:09:09,883 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@34ef8171] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:09:09,884 [Thread-126] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 8 Total time for transactions(ms): 4 Number of transactions batched in Syncs: 0 Number of syncs: 9 SyncTimes(ms): 2 2 
2020-04-02 05:09:09,885 [Thread-126] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:09:09,886 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@316b1d46] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:09:09,886 [Thread-126] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000008
2020-04-02 05:09:09,891 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:09:09,892 [CacheReplicationMonitor(1806582729)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:09:09,895 [Thread-126] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33300
2020-04-02 05:09:09,895 [reencryptionUpdaterThread #0] WARN  namenode.ReencryptionUpdater (ReencryptionUpdater.java:run(266)) - Re-encryption updater thread interrupted. Exiting.
2020-04-02 05:09:09,895 [reencryptionHandlerThread #0] INFO  namenode.ReencryptionHandler (ReencryptionHandler.java:run(334)) - Re-encrypt handler interrupted. Exiting
2020-04-02 05:09:09,918 [IPC Server listener on 33300] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33300
2020-04-02 05:09:09,930 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:09:09,931 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:09:09,930 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:09:09,944 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:09:09,945 [Thread-126] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:09:09,949 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@63e845f4{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:09:09,955 [Thread-126] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d2e3dc7{SSL,[ssl, http/1.1]}{localhost:0}
2020-04-02 05:09:09,955 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@55876080{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:09:09,955 [Thread-126] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6b558a8b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
[msx] test Finished org.apache.hadoop.hdfs.TestSecureEncryptionZoneWithKMS#testCreateZoneAfterAuthTokenExpiry
[msx] writeFile testName = org.apache.hadoop.hdfs.TestSecureEncryptionZoneWithKMS#testCreateZoneAfterAuthTokenExpiry
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:09:09,974 [main] INFO  impl.DefaultInternalKdcServerImpl (DefaultInternalKdcServerImpl.java:doStop(102)) - Default Internal kdc server stopped.
2020-04-02 05:09:10,980 [main] INFO  minikdc.MiniKdc (MiniKdc.java:stop(359)) - MiniKdc stopped.
2020-04-02 05:09:10,981 [Thread[Thread-13,5,main]] ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(700)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2020-04-02 05:09:10,983 [main] INFO  server.KMSWebApp (KMSWebApp.java:contextDestroyed(191)) - KMS Stopped
2020-04-02 05:09:10,983 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@654b72c0{/,null,UNAVAILABLE}{/kms}
2020-04-02 05:09:10,990 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@46b695ec{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:09:10,990 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6bedbc4d{/static,jar:file:/root/.m2/repository/org/apache/hadoop/hadoop-kms/3.1.2/hadoop-kms-3.1.2.jar!/webapps/static,UNAVAILABLE}
2020-04-02 05:09:10,991 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d3a388c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:09:11,003 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:09:11,013 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:09:11,014 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] all testRunFinished

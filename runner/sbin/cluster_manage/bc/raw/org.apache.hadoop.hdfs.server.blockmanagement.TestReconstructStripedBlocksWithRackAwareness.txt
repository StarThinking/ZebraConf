[msx] before_class
[msx] test Started org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness#testChooseExcessReplicasToDelete
[msx] unitTestCounterInClass = 0
2020-04-02 05:05:45,890 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=10
Formatting using clusterid: testClusterID
2020-04-02 05:05:46,696 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:46,714 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:46,715 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:46,717 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:46,733 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:46,734 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:46,734 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:46,735 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:46,775 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:46,781 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - hadoop.configured.node.mapping is deprecated. Instead, use net.topology.configured.node.mapping
2020-04-02 05:05:46,791 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:46,792 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:46,798 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:46,799 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:46
2020-04-02 05:05:46,802 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:46,804 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:46,807 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:05:46,807 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:46,828 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:46,831 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:05:46,835 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:46,835 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:46,836 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:46,836 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:46,836 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:46,837 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:46,837 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:46,837 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:46,838 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:05:46,838 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:46,838 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:46,877 [main] INFO  namenode.FSDirectory (SerialNumberManager.java:initialize(77)) - GLOBAL serial map: bits=24 maxEntries=16777215
2020-04-02 05:05:46,893 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:46,893 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:46,894 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:05:46,894 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:46,900 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:46,900 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:46,900 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:46,901 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:46,905 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:46,908 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:46,913 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:46,913 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:46,914 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:05:46,914 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:46,921 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:46,921 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:46,921 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:46,926 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:46,926 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:46,930 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:46,931 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:46,931 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:05:46,932 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:46,973 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:46,988 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:05:46,995 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:05:47,039 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:47,046 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:05:47,199 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:47,199 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 391 bytes saved in 0 seconds .
2020-04-02 05:05:47,220 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:05:47,224 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:05:47,360 [main] INFO  beanutils.FluentPropertyBeanIntrospector (FluentPropertyBeanIntrospector.java:introspect(147)) - Error when creating PropertyDescriptor for public final void org.apache.commons.configuration2.AbstractConfiguration.setProperty(java.lang.String,java.lang.Object)! Ignoring this property.
2020-04-02 05:05:47,413 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:05:47,886 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:05:47,886 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:05:47,894 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:05:47,926 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:05:47,972 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2d710f1a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:47,997 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:05:48,003 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:48,021 [main] INFO  util.log (Log.java:initialized(192)) - Logging initialized @3705ms
2020-04-02 05:05:48,160 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:48,165 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:05:48,166 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:48,175 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:48,178 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:05:48,179 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:48,179 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:48,213 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:05:48,213 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:05:48,223 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39197
2020-04-02 05:05:48,226 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:48,305 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@565f390{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:48,310 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f67a4d3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:48,373 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7fc4780b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:05:48,384 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6b58b9e9{HTTP/1.1,[http/1.1]}{localhost:39197}
2020-04-02 05:05:48,385 [main] INFO  server.Server (Server.java:doStart(419)) - Started @4069ms
2020-04-02 05:05:48,397 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:05:48,399 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:05:48,400 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:05:48,401 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:05:48,402 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:05:48,402 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:05:48,402 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:05:48,403 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:05:48,410 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:48,411 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:05:48,412 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:05:48,412 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:05:48,413 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:05:48
2020-04-02 05:05:48,413 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:05:48,413 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:48,414 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:05:48,414 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:05:48,428 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:05:48,440 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:05:48,440 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:05:48,441 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:05:48,441 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:05:48,441 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:05:48,441 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:05:48,442 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:05:48,442 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:05:48,442 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:05:48,442 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:05:48,442 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:05:48,443 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:05:48,443 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:05:48,443 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:48,444 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:05:48,444 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:05:48,446 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:05:48,450 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:05:48,450 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:05:48,450 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:05:48,451 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:05:48,451 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:05:48,451 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:05:48,452 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:48,452 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:05:48,452 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:05:48,453 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:05:48,454 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:05:48,454 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:05:48,454 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:05:48,454 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:05:48,455 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:05:48,455 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:05:48,455 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:05:48,455 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:05:48,460 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:48,464 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:48,466 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:05:48,466 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:05:48,467 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:05:48,467 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:05:48,537 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:05:48,549 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:05:48,549 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:05:48,565 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:05:48,567 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:05:48,606 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:05:48,607 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 150 msecs
2020-04-02 05:05:48,834 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:05:48,848 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:48,874 [Socket Reader #1 for port 40253] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40253
2020-04-02 05:05:49,213 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:40253 to access this namenode/service.
2020-04-02 05:05:49,217 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:05:49,242 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:05:49,252 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@340da44c] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:05:49,292 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:05:49,293 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:05:49,293 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:05:49,294 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:05:49,298 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:49,299 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:49,299 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:49,299 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:49,299 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:49,299 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 6 msec
2020-04-02 05:05:49,398 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:49,409 [IPC Server listener on 40253] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40253: starting
2020-04-02 05:05:49,411 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:40253
2020-04-02 05:05:49,415 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:05:49,415 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:05:49,419 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 3 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:05:49,450 [CacheReplicationMonitor(562268318)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:05:49,450 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 40253 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:49,457 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:49,457 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 0 with hostname set to: host1
2020-04-02 05:05:49,457 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host1 to rack /r1
2020-04-02 05:05:49,537 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:49,553 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:49,628 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:49,628 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:49,633 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:49,636 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:49,640 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1
2020-04-02 05:05:49,641 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:49,646 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:49,653 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41997
2020-04-02 05:05:49,656 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:49,656 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:49,683 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:49,686 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:49,687 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:49,687 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:49,689 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:49,690 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:49,690 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:49,691 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:49,694 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44467
2020-04-02 05:05:49,695 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:49,696 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3fa2213{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:49,699 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6f0b0a5e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:49,704 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4da602fc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:49,705 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2a8d39c4{HTTP/1.1,[http/1.1]}{localhost:44467}
2020-04-02 05:05:49,710 [main] INFO  server.Server (Server.java:doStart(419)) - Started @5390ms
2020-04-02 05:05:50,195 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40610
2020-04-02 05:05:50,203 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@625e134e] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:50,205 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:50,208 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:50,224 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:50,234 [Socket Reader #1 for port 33344] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33344
2020-04-02 05:05:50,252 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33344
2020-04-02 05:05:50,267 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:50,270 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:50,275 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:50,797 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:41997 to rack /r1
2020-04-02 05:05:50,798 [IPC Server listener on 33344] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33344: starting
2020-04-02 05:05:50,802 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:50,803 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33344 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:50,798 [Thread-59] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:50,814 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:50,814 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 1 with hostname set to: host2
2020-04-02 05:05:50,814 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host2 to rack /r1
2020-04-02 05:05:50,816 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:50,817 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:50,820 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:50,820 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:50,821 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:50,821 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:50,821 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host2
2020-04-02 05:05:50,822 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:50,822 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:50,824 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:43800
2020-04-02 05:05:50,825 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:50,827 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:50,829 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:50,833 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:50,834 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:50,835 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:50,837 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:50,838 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:50,838 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:50,842 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:50,843 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 36339
2020-04-02 05:05:50,844 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:50,868 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@172ca72b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:50,871 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@71e5f61d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:50,957 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1d71006f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:50,958 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5b6813df{HTTP/1.1,[http/1.1]}{localhost:36339}
2020-04-02 05:05:50,959 [main] INFO  server.Server (Server.java:doStart(419)) - Started @6643ms
2020-04-02 05:05:51,117 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34062
2020-04-02 05:05:51,126 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b58f754] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:51,126 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:51,126 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:51,127 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:51,142 [Socket Reader #1 for port 44149] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44149
2020-04-02 05:05:51,194 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44149
2020-04-02 05:05:51,201 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:51,202 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:51,203 [Thread-84] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:51,204 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:43800 to rack /r1
2020-04-02 05:05:51,214 [IPC Server listener on 44149] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44149: starting
2020-04-02 05:05:51,259 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:51,276 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:51,286 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44149 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:51,299 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:51,300 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 2 with hostname set to: host3
2020-04-02 05:05:51,300 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host3 to rack /r2
2020-04-02 05:05:51,302 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:51,303 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:51,321 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:51,322 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:51,322 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:51,323 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:51,323 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host3
2020-04-02 05:05:51,323 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:51,324 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:51,325 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35501
2020-04-02 05:05:51,325 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:51,325 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:51,330 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:51,332 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:51,339 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:51,339 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:51,361 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:51,362 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:51,363 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:51,363 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:51,366 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46066
2020-04-02 05:05:51,366 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:51,377 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@f9879ac{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:51,379 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5f4d427e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:51,403 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6a1d204a{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:51,404 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@62dae245{HTTP/1.1,[http/1.1]}{localhost:46066}
2020-04-02 05:05:51,404 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7088ms
2020-04-02 05:05:51,474 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36148
2020-04-02 05:05:51,478 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:51,478 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6fff253c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:51,478 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:51,491 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:51,518 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33832
2020-04-02 05:05:51,522 [Socket Reader #1 for port 33832] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33832
2020-04-02 05:05:51,563 [Thread-84] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:51,568 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:51,569 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:51,571 [Thread-84] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:51,573 [Thread-59] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:51,574 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:51,575 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:51,574 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:35501 to rack /r2
2020-04-02 05:05:51,574 [Thread-107] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:51,583 [IPC Server listener on 33832] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33832: starting
2020-04-02 05:05:51,583 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3bd2d739-652f-43b6-bafa-55bbd38d35e9 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:05:51,584 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:51,587 [Thread-84] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:51,588 [Thread-84] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:51,588 [Thread-84] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-81923dbc-f5be-4b79-8b1f-9605f3653621 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:05:51,590 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33832 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:51,592 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:51,592 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 3 with hostname set to: host4
2020-04-02 05:05:51,593 [Thread-59] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:51,597 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host4 to rack /r2
2020-04-02 05:05:51,598 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:51,611 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:05:51,611 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:51,611 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:51,611 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-fda3df25-01a3-4c39-9345-25f199e82d5f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:05:51,612 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:51,627 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:51,627 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:51,628 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:51,628 [Thread-59] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:51,628 [Thread-59] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:51,628 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host4
2020-04-02 05:05:51,629 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:51,628 [Thread-59] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:05:51,631 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:51,632 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38424
2020-04-02 05:05:51,633 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:51,633 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:51,633 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,633 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,635 [Thread-107] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:51,634 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:51,637 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:51,638 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:51,639 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:51,642 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:51,642 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:51,643 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:51,644 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:51,644 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:51,644 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:51,645 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 32932
2020-04-02 05:05:51,645 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:51,646 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,646 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,646 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:51,646 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:51,684 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@15a902e7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:51,684 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4a3e3e8b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:51,703 [Thread-107] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:51,720 [Thread-107] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:51,720 [Thread-107] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:51,721 [Thread-107] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c4de8663-3d5d-4218-a940-fe05a03be608 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:05:51,708 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,722 [Thread-59] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,722 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:51,722 [Thread-59] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:51,723 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2c177f9e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:51,724 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5db4c359{HTTP/1.1,[http/1.1]}{localhost:32932}
2020-04-02 05:05:51,724 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7408ms
2020-04-02 05:05:51,730 [Thread-59] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:51,733 [Thread-107] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:51,734 [Thread-107] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:51,734 [Thread-107] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5bbf2341-2961-4c29-befb-739dd64564e1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:05:51,716 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,754 [Thread-84] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,754 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:51,754 [Thread-84] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:51,802 [Thread-59] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0
2020-04-02 05:05:51,845 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34631
2020-04-02 05:05:51,846 [Thread-84] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:51,850 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:51,850 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@18e7143f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:51,850 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:51,851 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:51,852 [Socket Reader #1 for port 43354] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43354
2020-04-02 05:05:51,854 [Thread-84] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 85926ba2-f735-4868-aba2-eb03bdc45514
2020-04-02 05:05:51,855 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43354
2020-04-02 05:05:51,863 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:51,864 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:51,864 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,864 [Thread-107] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,864 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:51,865 [Thread-130] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:51,865 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:51,865 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:38424 to rack /r2
2020-04-02 05:05:51,865 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:51,866 [IPC Server listener on 43354] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43354: starting
2020-04-02 05:05:51,902 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43354 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:51,904 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:51,904 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 4 with hostname set to: host5
2020-04-02 05:05:51,904 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host5 to rack /r3
2020-04-02 05:05:51,905 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:05:51,939 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:51,943 [Thread-130] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:51,958 [Thread-130] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:51,959 [Thread-130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:51,959 [Thread-130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:51,978 [Thread-130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d0b2c649-7c2f-44ea-b11a-1bb494c5c1f1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:05:51,981 [Thread-130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:51,982 [Thread-130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:51,982 [Thread-130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e8d0a170-95ab-41d6-9ed1-db660e3e6270 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:05:51,987 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:51,987 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:51,987 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:51,987 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:51,988 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host5
2020-04-02 05:05:51,988 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:51,988 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:51,989 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35859
2020-04-02 05:05:51,989 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:51,989 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:51,999 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:51,999 [Thread-107] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,000 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:52,000 [Thread-107] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:52,002 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,003 [Thread-107] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:52,004 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,012 [Thread-130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,013 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:52,013 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:52,005 [Thread-107] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 964fc2f8-64f9-4638-9cc9-6edd4b859fe4
2020-04-02 05:05:52,004 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:52,018 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:52,018 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,020 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:52,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:52,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:52,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:52,022 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33505
2020-04-02 05:05:52,022 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:52,026 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7cbee484{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:52,027 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62923ee6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:52,044 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@a486d78{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:52,045 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@cdc3aae{HTTP/1.1,[http/1.1]}{localhost:33505}
2020-04-02 05:05:52,046 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7730ms
2020-04-02 05:05:52,049 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,050 [Thread-130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,050 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:52,050 [Thread-130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:52,055 [Thread-130] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:52,059 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35621
2020-04-02 05:05:52,060 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:52,060 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5dcbb60] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:52,060 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:52,061 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:52,063 [Socket Reader #1 for port 43173] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43173
2020-04-02 05:05:52,067 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43173
2020-04-02 05:05:52,083 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:52,084 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:52,085 [Thread-153] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:52,098 [Thread-130] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 01d45740-4e21-4654-83ca-6d32e3ca1f0a
2020-04-02 05:05:52,099 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:35859 to rack /r3
2020-04-02 05:05:52,100 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:52,100 [IPC Server listener on 43173] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43173: starting
2020-04-02 05:05:52,102 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43173 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:52,112 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:05:52,112 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 5 with hostname set to: host6
2020-04-02 05:05:52,112 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host6 to rack /r3
2020-04-02 05:05:52,159 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:05:52,170 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:05:52,191 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:52,191 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:52,192 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,192 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:52,192 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host6
2020-04-02 05:05:52,193 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,193 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:52,194 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:45830
2020-04-02 05:05:52,194 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:52,194 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:52,198 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,200 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:52,201 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:52,201 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,198 [Thread-153] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:52,215 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:52,231 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:52,231 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:52,231 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:52,232 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34747
2020-04-02 05:05:52,232 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:52,233 [Thread-153] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:52,235 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3b9d6699{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:52,236 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@21694e53{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:52,241 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2a2da905{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:52,242 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@24f360b2{HTTP/1.1,[http/1.1]}{localhost:34747}
2020-04-02 05:05:52,242 [main] INFO  server.Server (Server.java:doStart(419)) - Started @7926ms
2020-04-02 05:05:52,245 [Thread-153] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:52,245 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:52,245 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-291b14cb-dad8-4b5b-b6b4-e46eb4534755 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:05:52,251 [Thread-153] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:52,275 [Thread-153] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:52,275 [Thread-153] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-27efd51f-713a-4a53-8ef8-bf26c25ffbd2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:05:52,314 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:52,317 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,317 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,317 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38960
2020-04-02 05:05:52,318 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:52,318 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:52,319 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@302fec27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:52,319 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:52,320 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:52,321 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:52,322 [Socket Reader #1 for port 40788] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40788
2020-04-02 05:05:52,362 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40788
2020-04-02 05:05:52,373 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,374 [Thread-153] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,374 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:52,374 [Thread-153] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:52,376 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:52,377 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:52,381 [Thread-153] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:52,386 [Thread-153] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 65d7ec62-7df3-4aea-a092-96ed63492864
2020-04-02 05:05:52,387 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:45830 to rack /r3
2020-04-02 05:05:52,387 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d0b2c649-7c2f-44ea-b11a-1bb494c5c1f1
2020-04-02 05:05:52,387 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:05:52,389 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:52,391 [IPC Server listener on 40788] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40788: starting
2020-04-02 05:05:52,398 [Thread-176] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:52,393 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-fda3df25-01a3-4c39-9345-25f199e82d5f
2020-04-02 05:05:52,404 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:05:52,408 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40788 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:52,409 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e8d0a170-95ab-41d6-9ed1-db660e3e6270
2020-04-02 05:05:52,409 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:05:52,409 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:05:52,409 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 6 with hostname set to: host7
2020-04-02 05:05:52,410 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host7 to rack /r4
2020-04-02 05:05:52,411 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:05:52,413 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:05:52,415 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:52,415 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:52,416 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,416 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:52,416 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host7
2020-04-02 05:05:52,416 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,417 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:52,418 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46654
2020-04-02 05:05:52,418 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:52,418 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:52,419 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,421 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:52,446 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:52,446 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,448 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:52,448 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:52,449 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:52,449 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:52,460 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42186
2020-04-02 05:05:52,460 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:52,462 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-291b14cb-dad8-4b5b-b6b4-e46eb4534755
2020-04-02 05:05:52,463 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:05:52,465 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-27efd51f-713a-4a53-8ef8-bf26c25ffbd2
2020-04-02 05:05:52,465 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:05:52,470 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3bd2d739-652f-43b6-bafa-55bbd38d35e9
2020-04-02 05:05:52,470 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:05:52,391 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c4de8663-3d5d-4218-a940-fe05a03be608
2020-04-02 05:05:52,473 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:05:52,475 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5bbf2341-2961-4c29-befb-739dd64564e1
2020-04-02 05:05:52,475 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:05:52,476 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-81923dbc-f5be-4b79-8b1f-9605f3653621
2020-04-02 05:05:52,482 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac
2020-04-02 05:05:52,482 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:05:52,483 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:05:52,489 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2c95ac9e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:52,491 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@459f7aa3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:52,499 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5db99216{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:52,504 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3ec11999{HTTP/1.1,[http/1.1]}{localhost:42186}
2020-04-02 05:05:52,504 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8188ms
2020-04-02 05:05:52,505 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:52,506 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:52,504 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:52,507 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:52,507 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:52,527 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:41083
2020-04-02 05:05:52,529 [Thread-176] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:52,533 [Thread-176] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:52,533 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:52,533 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:52,534 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:52,535 [Socket Reader #1 for port 43241] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43241
2020-04-02 05:05:52,535 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@9f46d94] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:52,539 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43241
2020-04-02 05:05:52,530 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:52,531 [Thread-107] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:52,542 [Thread-176] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:52,542 [Thread-176] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:52,542 [Thread-176] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5154819c-dcb2-4c2e-8979-26b719a52e7f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:05:52,549 [Thread-107] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:52,549 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:52,572 [Thread-107] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:52,584 [Thread-107] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:52,572 [Thread-59] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:52,579 [Thread-176] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:52,573 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:52,573 [Thread-130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:05:52,588 [Thread-176] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:52,587 [Thread-153] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:05:52,590 [Thread-176] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e7fee019-8e95-4054-8cff-a3087cf75913 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:05:52,591 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:52,592 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:52,593 [Thread-209] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:52,593 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:46654 to rack /r4
2020-04-02 05:05:52,593 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:52,594 [IPC Server listener on 43241] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43241: starting
2020-04-02 05:05:52,605 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,605 [Thread-176] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,605 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:52,605 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:52,614 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43241 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:52,636 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:05:52,637 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 7 with hostname set to: host8
2020-04-02 05:05:52,637 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host8 to rack /r4
2020-04-02 05:05:52,638 [Thread-153] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:05:52,638 [Thread-153] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:52,638 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:52,639 [Thread-84] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:52,639 [Thread-84] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:52,638 [Thread-153] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:52,639 [Thread-130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:05:52,639 [Thread-130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:52,639 [Thread-130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:52,640 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:05:52,640 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:05:52,651 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:52,662 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:52,662 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,662 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:52,663 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host8
2020-04-02 05:05:52,663 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:52,663 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:52,662 [Thread-107] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,665 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:52,665 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:52,669 [Thread-59] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:52,670 [Thread-153] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,670 [Thread-59] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,670 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:05:52,678 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:52,678 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46235
2020-04-02 05:05:52,679 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:52,679 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:52,681 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:52,701 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:05:52,706 [Thread-84] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,706 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:52,707 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,708 [Thread-130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,708 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:05:52,708 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:05:52,719 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:52,719 [Thread-209] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:52,735 [Thread-209] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:52,735 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:52,735 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:52,739 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:52,739 [Thread-209] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:52,739 [Thread-209] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c5aed756-c99c-4dd5-a405-e1960059d54b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:05:52,747 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:52,753 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:52,755 [Thread-209] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:52,756 [Thread-209] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:52,756 [Thread-209] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-976dccca-5683-46d4-adcb-953c4f29b8ba for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:05:52,775 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:52,776 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:52,776 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:52,808 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40058
2020-04-02 05:05:52,809 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:52,825 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,826 [Thread-209] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,826 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:52,827 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:52,815 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,829 [Thread-176] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,829 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:52,830 [Thread-176] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:52,836 [Thread-176] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:52,839 [Thread-176] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID df4788ff-a0ca-46f0-876e-2f10617407dd
2020-04-02 05:05:52,917 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,917 [Thread-209] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:52,918 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:52,918 [Thread-209] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:52,930 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3dd69f5a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:52,930 [Thread-209] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:52,931 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1ee4730{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:52,932 [Thread-209] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 695c8241-88f4-404a-bbed-e96743005a31
2020-04-02 05:05:52,936 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5154819c-dcb2-4c2e-8979-26b719a52e7f
2020-04-02 05:05:52,937 [Thread-176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:05:52,939 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e7fee019-8e95-4054-8cff-a3087cf75913
2020-04-02 05:05:52,939 [Thread-176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:05:52,939 [Thread-176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:52,941 [Thread-176] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:05:52,946 [Thread-176] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:05:52,946 [Thread-176] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:05:52,946 [Thread-176] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:05:52,956 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@410954b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:52,957 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{localhost:40058}
2020-04-02 05:05:52,958 [main] INFO  server.Server (Server.java:doStart(419)) - Started @8642ms
2020-04-02 05:05:52,967 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c5aed756-c99c-4dd5-a405-e1960059d54b
2020-04-02 05:05:52,967 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:05:52,969 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-976dccca-5683-46d4-adcb-953c4f29b8ba
2020-04-02 05:05:52,969 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:05:52,970 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:52,971 [Thread-209] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:05:53,023 [Thread-209] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:05:53,046 [Thread-209] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:05:53,047 [Thread-209] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:05:53,058 [Thread-231] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 350ms
2020-04-02 05:05:53,062 [Thread-176] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,064 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:05:53,074 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:05:53,135 [Thread-209] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,136 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:05:53,136 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:05:53,162 [Thread-232] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 453ms
2020-04-02 05:05:53,165 [Thread-230] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 418ms
2020-04-02 05:05:53,172 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 464ms
2020-04-02 05:05:53,178 [Thread-224] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 497ms
2020-04-02 05:05:53,190 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:05:53,190 [Thread-254] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,195 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:05:53,195 [Thread-255] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,197 [Thread-255] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 2ms
2020-04-02 05:05:53,199 [Thread-222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 534ms
2020-04-02 05:05:53,200 [Thread-229] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 495ms
2020-04-02 05:05:53,201 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 495ms
2020-04-02 05:05:53,202 [Thread-223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 532ms
2020-04-02 05:05:53,202 [Thread-225] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 501ms
2020-04-02 05:05:53,202 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 533ms
2020-04-02 05:05:53,203 [Thread-226] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 525ms
2020-04-02 05:05:53,203 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 533ms
2020-04-02 05:05:53,233 [Thread-221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 568ms
2020-04-02 05:05:53,233 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:05:53,234 [Thread-259] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,234 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:05:53,234 [Thread-263] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,235 [Thread-263] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:05:53,242 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 579ms
2020-04-02 05:05:53,247 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:05:53,248 [Thread-266] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,248 [Thread-254] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 58ms
2020-04-02 05:05:53,249 [Thread-266] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:05:53,257 [Thread-130] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 80ms
2020-04-02 05:05:53,266 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:05:53,266 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:05:53,266 [Thread-257] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,267 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-d0b2c649-7c2f-44ea-b11a-1bb494c5c1f1): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,256 [Thread-259] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 22ms
2020-04-02 05:05:53,270 [Thread-59] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 67ms
2020-04-02 05:05:53,273 [Thread-257] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 8ms
2020-04-02 05:05:53,255 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:05:53,275 [Thread-264] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,254 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:05:53,276 [Thread-258] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,276 [Thread-258] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 0ms
2020-04-02 05:05:53,281 [Thread-59] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 11:01 AM with interval of 21600000ms
2020-04-02 05:05:53,252 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:05:53,252 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:05:53,285 [Thread-265] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,284 [Thread-267] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,276 [Thread-264] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-04-02 05:05:53,285 [Thread-153] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 82ms
2020-04-02 05:05:53,286 [Thread-265] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 1ms
2020-04-02 05:05:53,286 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:05:53,286 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:05:53,286 [Thread-267] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 2ms
2020-04-02 05:05:53,286 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-27efd51f-713a-4a53-8ef8-bf26c25ffbd2): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,286 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-291b14cb-dad8-4b5b-b6b4-e46eb4534755): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,294 [Thread-251] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 220ms
2020-04-02 05:05:53,274 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:05:53,295 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,274 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:05:53,296 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-fda3df25-01a3-4c39-9345-25f199e82d5f): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,278 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:05:53,296 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-e8d0a170-95ab-41d6-9ed1-db660e3e6270): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,297 [Thread-84] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 97ms
2020-04-02 05:05:53,301 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:05:53,302 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-3bd2d739-652f-43b6-bafa-55bbd38d35e9): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,302 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:05:53,303 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-81923dbc-f5be-4b79-8b1f-9605f3653621): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,286 [Thread-153] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:32 AM with interval of 21600000ms
2020-04-02 05:05:53,304 [Thread-107] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 61ms
2020-04-02 05:05:53,305 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:05:53,305 [Thread-107] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:55 AM with interval of 21600000ms
2020-04-02 05:05:53,305 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:05:53,306 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c4de8663-3d5d-4218-a940-fe05a03be608): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,305 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-5bbf2341-2961-4c29-befb-739dd64564e1): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,307 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35039
2020-04-02 05:05:53,307 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:53,307 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:53,308 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:53,385 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-5bbf2341-2961-4c29-befb-739dd64564e1): no suitable block pools found to scan.  Waiting 1814399920 ms.
2020-04-02 05:05:53,386 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c4de8663-3d5d-4218-a940-fe05a03be608): no suitable block pools found to scan.  Waiting 1814399919 ms.
2020-04-02 05:05:53,386 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-d0b2c649-7c2f-44ea-b11a-1bb494c5c1f1): no suitable block pools found to scan.  Waiting 1814399879 ms.
2020-04-02 05:05:53,387 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45403
2020-04-02 05:05:53,388 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-291b14cb-dad8-4b5b-b6b4-e46eb4534755): no suitable block pools found to scan.  Waiting 1814399898 ms.
2020-04-02 05:05:53,390 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-27efd51f-713a-4a53-8ef8-bf26c25ffbd2): no suitable block pools found to scan.  Waiting 1814399896 ms.
2020-04-02 05:05:53,393 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:53,393 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:53,394 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@51f49060] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:53,394 [Thread-287] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:53,394 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:46235 to rack /r4
2020-04-02 05:05:53,395 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:53,395 [IPC Server listener on 45403] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45403: starting
2020-04-02 05:05:53,396 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45403 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:53,397 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:05:53,397 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 8 with hostname set to: host9
2020-04-02 05:05:53,397 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host9 to rack /r5
2020-04-02 05:05:53,398 [Socket Reader #1 for port 45403] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45403
2020-04-02 05:05:53,401 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:05:53,402 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:05:53,404 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:53,404 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:53,404 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:53,404 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:53,405 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:53,405 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host9
2020-04-02 05:05:53,405 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:53,406 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:53,407 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36807
2020-04-02 05:05:53,407 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:53,407 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:53,409 [Thread-253] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 274ms
2020-04-02 05:05:53,410 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:53,412 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:53,412 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-fda3df25-01a3-4c39-9345-25f199e82d5f): no suitable block pools found to scan.  Waiting 1814399859 ms.
2020-04-02 05:05:53,413 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-e8d0a170-95ab-41d6-9ed1-db660e3e6270): no suitable block pools found to scan.  Waiting 1814399865 ms.
2020-04-02 05:05:53,413 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:53,413 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:53,413 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-3bd2d739-652f-43b6-bafa-55bbd38d35e9): no suitable block pools found to scan.  Waiting 1814399885 ms.
2020-04-02 05:05:53,414 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-81923dbc-f5be-4b79-8b1f-9605f3653621): no suitable block pools found to scan.  Waiting 1814399884 ms.
2020-04-02 05:05:53,412 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac): no suitable block pools found to scan.  Waiting 1814399859 ms.
2020-04-02 05:05:53,298 [Thread-84] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:20 AM with interval of 21600000ms
2020-04-02 05:05:53,297 [Thread-130] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:34 AM with interval of 21600000ms
2020-04-02 05:05:53,431 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:53,431 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:53,432 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:53,432 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:53,433 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33704
2020-04-02 05:05:53,433 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:53,483 [Thread-250] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 419ms
2020-04-02 05:05:53,491 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 85926ba2-f735-4868-aba2-eb03bdc45514) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:53,492 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 964fc2f8-64f9-4638-9cc9-6edd4b859fe4) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:53,492 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 01d45740-4e21-4654-83ca-6d32e3ca1f0a) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:53,492 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 65d7ec62-7df3-4aea-a092-96ed63492864) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:53,498 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 436ms
2020-04-02 05:05:53,500 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:05:53,500 [Thread-306] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,501 [Thread-306] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-04-02 05:05:53,507 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:05:53,507 [Thread-307] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,510 [Thread-307] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 3ms
2020-04-02 05:05:53,517 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4108fa66{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:53,567 [Thread-176] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 69ms
2020-04-02 05:05:53,567 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:53,517 [Thread-252] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 381ms
2020-04-02 05:05:53,569 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:05:53,577 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e0aadd0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:53,577 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-e7fee019-8e95-4054-8cff-a3087cf75913): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,578 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-e7fee019-8e95-4054-8cff-a3087cf75913): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-04-02 05:05:53,567 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:05:53,582 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5154819c-dcb2-4c2e-8979-26b719a52e7f): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,581 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 447ms
2020-04-02 05:05:53,586 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:05:53,586 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:05:53,586 [Thread-310] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,586 [Thread-309] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:53,590 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5154819c-dcb2-4c2e-8979-26b719a52e7f): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-04-02 05:05:53,591 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@63f34b70{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:53,591 [Thread-176] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:38 AM with interval of 21600000ms
2020-04-02 05:05:53,592 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@641856{HTTP/1.1,[http/1.1]}{localhost:33704}
2020-04-02 05:05:53,619 [Thread-309] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 33ms
2020-04-02 05:05:53,626 [IPC Server handler 2 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35859, datanodeUuid=65d7ec62-7df3-4aea-a092-96ed63492864, infoPort=35621, infoSecurePort=0, ipcPort=43173, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 65d7ec62-7df3-4aea-a092-96ed63492864
2020-04-02 05:05:53,629 [IPC Server handler 2 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:35859
2020-04-02 05:05:53,629 [Thread-310] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 43ms
2020-04-02 05:05:53,641 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid df4788ff-a0ca-46f0-876e-2f10617407dd) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:53,637 [IPC Server handler 2 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 65d7ec62-7df3-4aea-a092-96ed63492864 (127.0.0.1:35859).
2020-04-02 05:05:53,645 [Thread-209] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 63ms
2020-04-02 05:05:53,645 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:05:53,646 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-976dccca-5683-46d4-adcb-953c4f29b8ba): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,646 [Thread-209] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:51 AM with interval of 21600000ms
2020-04-02 05:05:53,646 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:05:53,646 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-976dccca-5683-46d4-adcb-953c4f29b8ba): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:05:53,646 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-c5aed756-c99c-4dd5-a405-e1960059d54b): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,647 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-c5aed756-c99c-4dd5-a405-e1960059d54b): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:05:53,662 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 695c8241-88f4-404a-bbed-e96743005a31) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:53,663 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9303ms
2020-04-02 05:05:53,666 [IPC Server handler 8 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35501, datanodeUuid=964fc2f8-64f9-4638-9cc9-6edd4b859fe4, infoPort=36148, infoSecurePort=0, ipcPort=33832, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 964fc2f8-64f9-4638-9cc9-6edd4b859fe4
2020-04-02 05:05:53,679 [IPC Server handler 8 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:35501
2020-04-02 05:05:53,680 [IPC Server handler 8 on 40253] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:checkIfClusterIsNowMultiRack(1386)) - DN 127.0.0.1:35501 joining cluster has expanded a formerly single-rack cluster to be multi-rack. Re-checking all blocks for replication, since they should now be replicated cross-rack
2020-04-02 05:05:53,690 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 65d7ec62-7df3-4aea-a092-96ed63492864) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:53,690 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:53,709 [IPC Server handler 8 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 964fc2f8-64f9-4638-9cc9-6edd4b859fe4 (127.0.0.1:35501).
2020-04-02 05:05:53,728 [IPC Server handler 5 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:43800, datanodeUuid=85926ba2-f735-4868-aba2-eb03bdc45514, infoPort=34062, infoSecurePort=0, ipcPort=44149, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 85926ba2-f735-4868-aba2-eb03bdc45514
2020-04-02 05:05:53,729 [IPC Server handler 5 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:43800
2020-04-02 05:05:53,729 [IPC Server handler 5 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 85926ba2-f735-4868-aba2-eb03bdc45514 (127.0.0.1:43800).
2020-04-02 05:05:53,734 [IPC Server handler 4 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:45830, datanodeUuid=df4788ff-a0ca-46f0-876e-2f10617407dd, infoPort=38960, infoSecurePort=0, ipcPort=40788, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage df4788ff-a0ca-46f0-876e-2f10617407dd
2020-04-02 05:05:53,734 [IPC Server handler 4 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:45830
2020-04-02 05:05:53,734 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 964fc2f8-64f9-4638-9cc9-6edd4b859fe4) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:53,734 [IPC Server handler 4 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN df4788ff-a0ca-46f0-876e-2f10617407dd (127.0.0.1:45830).
2020-04-02 05:05:53,734 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:53,735 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 85926ba2-f735-4868-aba2-eb03bdc45514) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:53,735 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:53,735 [IPC Server handler 0 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41997, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=40610, infoSecurePort=0, ipcPort=33344, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0
2020-04-02 05:05:53,735 [IPC Server handler 0 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:41997
2020-04-02 05:05:53,735 [IPC Server handler 0 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0 (127.0.0.1:41997).
2020-04-02 05:05:53,736 [IPC Server handler 3 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38424, datanodeUuid=01d45740-4e21-4654-83ca-6d32e3ca1f0a, infoPort=34631, infoSecurePort=0, ipcPort=43354, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 01d45740-4e21-4654-83ca-6d32e3ca1f0a
2020-04-02 05:05:53,736 [IPC Server handler 3 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:38424
2020-04-02 05:05:53,737 [IPC Server handler 3 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 01d45740-4e21-4654-83ca-6d32e3ca1f0a (127.0.0.1:38424).
2020-04-02 05:05:53,737 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:05:53,737 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:05:53,737 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:05:53,737 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:05:53,737 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:05:53,737 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 9 msec
2020-04-02 05:05:53,752 [IPC Server handler 1 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46654, datanodeUuid=695c8241-88f4-404a-bbed-e96743005a31, infoPort=41083, infoSecurePort=0, ipcPort=43241, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 695c8241-88f4-404a-bbed-e96743005a31
2020-04-02 05:05:53,753 [IPC Server handler 1 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:46654
2020-04-02 05:05:53,753 [IPC Server handler 1 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 695c8241-88f4-404a-bbed-e96743005a31 (127.0.0.1:46654).
2020-04-02 05:05:53,759 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37716
2020-04-02 05:05:53,760 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:53,760 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2f66e802] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:53,760 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:53,761 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 01d45740-4e21-4654-83ca-6d32e3ca1f0a) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:53,761 [Thread-287] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:53,761 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:53,766 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:53,778 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:53,766 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid df4788ff-a0ca-46f0-876e-2f10617407dd) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:53,786 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:53,763 [Thread-287] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:53,773 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:53,772 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 695c8241-88f4-404a-bbed-e96743005a31) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:53,794 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:53,809 [Thread-287] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:53,810 [Thread-287] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:53,810 [Thread-287] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:05:53,819 [Socket Reader #1 for port 40725] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40725
2020-04-02 05:05:53,828 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40725
2020-04-02 05:05:53,833 [Thread-287] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:53,834 [Thread-287] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:53,834 [Thread-287] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-32007c7c-4eb7-4e69-a5c4-678bc7faa25d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:05:53,834 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:53,835 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:53,864 [Thread-323] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:53,865 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:36807 to rack /r5
2020-04-02 05:05:53,868 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:53,870 [IPC Server listener on 40725] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40725: starting
2020-04-02 05:05:53,899 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,899 [Thread-287] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,899 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:53,900 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:53,901 [IPC Server handler 6 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3bd2d739-652f-43b6-bafa-55bbd38d35e9 for DN 127.0.0.1:43800
2020-04-02 05:05:53,901 [IPC Server handler 6 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-81923dbc-f5be-4b79-8b1f-9605f3653621 for DN 127.0.0.1:43800
2020-04-02 05:05:53,914 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40725 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:53,951 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:05:53,951 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 9 with hostname set to: host10
2020-04-02 05:05:53,951 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host10 to rack /r6
2020-04-02 05:05:53,953 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:05:53,960 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,960 [Thread-287] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:53,960 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:53,961 [Thread-287] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:53,962 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:05:53,963 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:53,963 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:53,964 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:53,964 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:53,964 [Thread-287] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:53,964 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host10
2020-04-02 05:05:53,964 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:53,964 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:53,965 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40813
2020-04-02 05:05:53,965 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:53,965 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:53,966 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:53,935 [IPC Server handler 7 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-291b14cb-dad8-4b5b-b6b4-e46eb4534755 for DN 127.0.0.1:35859
2020-04-02 05:05:53,967 [IPC Server handler 7 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-27efd51f-713a-4a53-8ef8-bf26c25ffbd2 for DN 127.0.0.1:35859
2020-04-02 05:05:53,968 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:53,970 [Thread-287] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 084895d6-29b8-4e9d-8605-d70653e3ccc2
2020-04-02 05:05:53,970 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:53,971 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:53,994 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:53,995 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:53,995 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:53,995 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:53,996 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43216
2020-04-02 05:05:53,996 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:54,001 [IPC Server handler 2 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c4de8663-3d5d-4218-a940-fe05a03be608 for DN 127.0.0.1:35501
2020-04-02 05:05:54,002 [IPC Server handler 2 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5bbf2341-2961-4c29-befb-739dd64564e1 for DN 127.0.0.1:35501
2020-04-02 05:05:54,002 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55
2020-04-02 05:05:54,003 [Thread-287] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:05:54,005 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-32007c7c-4eb7-4e69-a5c4-678bc7faa25d
2020-04-02 05:05:54,006 [Thread-287] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:05:54,006 [Thread-287] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:54,008 [Thread-287] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:05:54,017 [IPC Server handler 8 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c5aed756-c99c-4dd5-a405-e1960059d54b for DN 127.0.0.1:46654
2020-04-02 05:05:54,017 [IPC Server handler 8 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-976dccca-5683-46d4-adcb-953c4f29b8ba for DN 127.0.0.1:46654
2020-04-02 05:05:54,022 [IPC Server handler 4 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5154819c-dcb2-4c2e-8979-26b719a52e7f for DN 127.0.0.1:45830
2020-04-02 05:05:54,058 [Thread-287] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:05:54,058 [Thread-287] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:05:54,064 [IPC Server handler 4 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e7fee019-8e95-4054-8cff-a3087cf75913 for DN 127.0.0.1:45830
2020-04-02 05:05:54,070 [Thread-323] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:54,075 [IPC Server handler 3 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d0b2c649-7c2f-44ea-b11a-1bb494c5c1f1 for DN 127.0.0.1:38424
2020-04-02 05:05:54,076 [Thread-323] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:54,079 [Thread-287] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:05:54,080 [Thread-323] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:54,118 [IPC Server handler 3 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e8d0a170-95ab-41d6-9ed1-db660e3e6270 for DN 127.0.0.1:38424
2020-04-02 05:05:54,129 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7d373bcf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:54,130 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5dda6f9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:54,131 [Thread-323] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:54,131 [Thread-323] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:05:54,138 [Thread-287] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,139 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:05:54,139 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:05:54,175 [IPC Server handler 3 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35859, datanodeUuid=65d7ec62-7df3-4aea-a092-96ed63492864, infoPort=35621, infoSecurePort=0, ipcPort=43173, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:54,181 [IPC Server handler 0 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fda3df25-01a3-4c39-9345-25f199e82d5f for DN 127.0.0.1:41997
2020-04-02 05:05:54,192 [IPC Server handler 1 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46654, datanodeUuid=695c8241-88f4-404a-bbed-e96743005a31, infoPort=41083, infoSecurePort=0, ipcPort=43241, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:54,194 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@287f94b1{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:54,194 [Thread-323] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:54,195 [Thread-323] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:54,195 [Thread-323] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8f13ebd6-d78f-40fb-bf2f-2665f4b04cf4 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:05:54,195 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@30b34287{HTTP/1.1,[http/1.1]}{localhost:43216}
2020-04-02 05:05:54,195 [main] INFO  server.Server (Server.java:doStart(419)) - Started @9879ms
2020-04-02 05:05:54,206 [IPC Server handler 0 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac for DN 127.0.0.1:41997
2020-04-02 05:05:54,227 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x591fa0e60644fe0: Processing first storage report for DS-c5aed756-c99c-4dd5-a405-e1960059d54b from datanode 695c8241-88f4-404a-bbed-e96743005a31
2020-04-02 05:05:54,254 [IPC Server handler 2 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:43800, datanodeUuid=85926ba2-f735-4868-aba2-eb03bdc45514, infoPort=34062, infoSecurePort=0, ipcPort=44149, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:54,254 [IPC Server handler 8 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:38424, datanodeUuid=01d45740-4e21-4654-83ca-6d32e3ca1f0a, infoPort=34631, infoSecurePort=0, ipcPort=43354, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:54,269 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x591fa0e60644fe0: from storage DS-c5aed756-c99c-4dd5-a405-e1960059d54b node DatanodeRegistration(127.0.0.1:46654, datanodeUuid=695c8241-88f4-404a-bbed-e96743005a31, infoPort=41083, infoSecurePort=0, ipcPort=43241, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 26 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,269 [IPC Server handler 7 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35501, datanodeUuid=964fc2f8-64f9-4638-9cc9-6edd4b859fe4, infoPort=36148, infoSecurePort=0, ipcPort=33832, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:54,278 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6a154cd0e9db3192: Processing first storage report for DS-291b14cb-dad8-4b5b-b6b4-e46eb4534755 from datanode 65d7ec62-7df3-4aea-a092-96ed63492864
2020-04-02 05:05:54,278 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6a154cd0e9db3192: from storage DS-291b14cb-dad8-4b5b-b6b4-e46eb4534755 node DatanodeRegistration(127.0.0.1:35859, datanodeUuid=65d7ec62-7df3-4aea-a092-96ed63492864, infoPort=35621, infoSecurePort=0, ipcPort=43173, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,279 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaf32a731fb58776d: Processing first storage report for DS-81923dbc-f5be-4b79-8b1f-9605f3653621 from datanode 85926ba2-f735-4868-aba2-eb03bdc45514
2020-04-02 05:05:54,283 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaf32a731fb58776d: from storage DS-81923dbc-f5be-4b79-8b1f-9605f3653621 node DatanodeRegistration(127.0.0.1:43800, datanodeUuid=85926ba2-f735-4868-aba2-eb03bdc45514, infoPort=34062, infoSecurePort=0, ipcPort=44149, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,291 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3c207acfb5eaf41a: Processing first storage report for DS-e8d0a170-95ab-41d6-9ed1-db660e3e6270 from datanode 01d45740-4e21-4654-83ca-6d32e3ca1f0a
2020-04-02 05:05:54,291 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3c207acfb5eaf41a: from storage DS-e8d0a170-95ab-41d6-9ed1-db660e3e6270 node DatanodeRegistration(127.0.0.1:38424, datanodeUuid=01d45740-4e21-4654-83ca-6d32e3ca1f0a, infoPort=34631, infoSecurePort=0, ipcPort=43354, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb933a785636aa752: Processing first storage report for DS-c4de8663-3d5d-4218-a940-fe05a03be608 from datanode 964fc2f8-64f9-4638-9cc9-6edd4b859fe4
2020-04-02 05:05:54,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb933a785636aa752: from storage DS-c4de8663-3d5d-4218-a940-fe05a03be608 node DatanodeRegistration(127.0.0.1:35501, datanodeUuid=964fc2f8-64f9-4638-9cc9-6edd4b859fe4, infoPort=36148, infoSecurePort=0, ipcPort=33832, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6a154cd0e9db3192: Processing first storage report for DS-27efd51f-713a-4a53-8ef8-bf26c25ffbd2 from datanode 65d7ec62-7df3-4aea-a092-96ed63492864
2020-04-02 05:05:54,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6a154cd0e9db3192: from storage DS-27efd51f-713a-4a53-8ef8-bf26c25ffbd2 node DatanodeRegistration(127.0.0.1:35859, datanodeUuid=65d7ec62-7df3-4aea-a092-96ed63492864, infoPort=35621, infoSecurePort=0, ipcPort=43173, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x591fa0e60644fe0: Processing first storage report for DS-976dccca-5683-46d4-adcb-953c4f29b8ba from datanode 695c8241-88f4-404a-bbed-e96743005a31
2020-04-02 05:05:54,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x591fa0e60644fe0: from storage DS-976dccca-5683-46d4-adcb-953c4f29b8ba node DatanodeRegistration(127.0.0.1:46654, datanodeUuid=695c8241-88f4-404a-bbed-e96743005a31, infoPort=41083, infoSecurePort=0, ipcPort=43241, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xaf32a731fb58776d: Processing first storage report for DS-3bd2d739-652f-43b6-bafa-55bbd38d35e9 from datanode 85926ba2-f735-4868-aba2-eb03bdc45514
2020-04-02 05:05:54,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xaf32a731fb58776d: from storage DS-3bd2d739-652f-43b6-bafa-55bbd38d35e9 node DatanodeRegistration(127.0.0.1:43800, datanodeUuid=85926ba2-f735-4868-aba2-eb03bdc45514, infoPort=34062, infoSecurePort=0, ipcPort=44149, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,292 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x3c207acfb5eaf41a: Processing first storage report for DS-d0b2c649-7c2f-44ea-b11a-1bb494c5c1f1 from datanode 01d45740-4e21-4654-83ca-6d32e3ca1f0a
2020-04-02 05:05:54,293 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x3c207acfb5eaf41a: from storage DS-d0b2c649-7c2f-44ea-b11a-1bb494c5c1f1 node DatanodeRegistration(127.0.0.1:38424, datanodeUuid=01d45740-4e21-4654-83ca-6d32e3ca1f0a, infoPort=34631, infoSecurePort=0, ipcPort=43354, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,287 [IPC Server handler 9 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:45830, datanodeUuid=df4788ff-a0ca-46f0-876e-2f10617407dd, infoPort=38960, infoSecurePort=0, ipcPort=40788, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:54,293 [IPC Server handler 3 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x6a154cd0e9db3192
2020-04-02 05:05:54,293 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x591fa0e60644fe0
2020-04-02 05:05:54,293 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xaf32a731fb58776d
2020-04-02 05:05:54,294 [IPC Server handler 8 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x3c207acfb5eaf41a
2020-04-02 05:05:54,294 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb933a785636aa752: Processing first storage report for DS-5bbf2341-2961-4c29-befb-739dd64564e1 from datanode 964fc2f8-64f9-4638-9cc9-6edd4b859fe4
2020-04-02 05:05:54,294 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb933a785636aa752: from storage DS-5bbf2341-2961-4c29-befb-739dd64564e1 node DatanodeRegistration(127.0.0.1:35501, datanodeUuid=964fc2f8-64f9-4638-9cc9-6edd4b859fe4, infoPort=36148, infoSecurePort=0, ipcPort=33832, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,295 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x65689c4706f7ad88: Processing first storage report for DS-5154819c-dcb2-4c2e-8979-26b719a52e7f from datanode df4788ff-a0ca-46f0-876e-2f10617407dd
2020-04-02 05:05:54,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x65689c4706f7ad88: from storage DS-5154819c-dcb2-4c2e-8979-26b719a52e7f node DatanodeRegistration(127.0.0.1:45830, datanodeUuid=df4788ff-a0ca-46f0-876e-2f10617407dd, infoPort=38960, infoSecurePort=0, ipcPort=40788, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,296 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb933a785636aa752
2020-04-02 05:05:54,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x65689c4706f7ad88: Processing first storage report for DS-e7fee019-8e95-4054-8cff-a3087cf75913 from datanode df4788ff-a0ca-46f0-876e-2f10617407dd
2020-04-02 05:05:54,296 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x65689c4706f7ad88: from storage DS-e7fee019-8e95-4054-8cff-a3087cf75913 node DatanodeRegistration(127.0.0.1:45830, datanodeUuid=df4788ff-a0ca-46f0-876e-2f10617407dd, infoPort=38960, infoSecurePort=0, ipcPort=40788, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,296 [IPC Server handler 9 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x65689c4706f7ad88
2020-04-02 05:05:54,303 [Thread-342] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 165ms
2020-04-02 05:05:54,306 [Thread-343] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 167ms
2020-04-02 05:05:54,306 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 169ms
2020-04-02 05:05:54,307 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:05:54,307 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:05:54,307 [Thread-346] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:54,307 [Thread-347] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:54,308 [Thread-346] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 1ms
2020-04-02 05:05:54,308 [Thread-347] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 1ms
2020-04-02 05:05:54,318 [Thread-287] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 11ms
2020-04-02 05:05:54,318 [Thread-287] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:49 AM with interval of 21600000ms
2020-04-02 05:05:54,321 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 084895d6-29b8-4e9d-8605-d70653e3ccc2) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:54,322 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:05:54,322 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,323 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:05:54,327 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:05:54,328 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-32007c7c-4eb7-4e69-a5c4-678bc7faa25d): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,328 [IPC Server handler 4 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46235, datanodeUuid=084895d6-29b8-4e9d-8605-d70653e3ccc2, infoPort=35039, infoSecurePort=0, ipcPort=45403, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 084895d6-29b8-4e9d-8605-d70653e3ccc2
2020-04-02 05:05:54,329 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-32007c7c-4eb7-4e69-a5c4-678bc7faa25d): no suitable block pools found to scan.  Waiting 1814399989 ms.
2020-04-02 05:05:54,329 [IPC Server handler 4 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:46235
2020-04-02 05:05:54,329 [IPC Server handler 4 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 084895d6-29b8-4e9d-8605-d70653e3ccc2 (127.0.0.1:46235).
2020-04-02 05:05:54,330 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 084895d6-29b8-4e9d-8605-d70653e3ccc2) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:54,331 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:54,336 [IPC Server handler 5 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55 for DN 127.0.0.1:46235
2020-04-02 05:05:54,342 [IPC Server handler 5 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-32007c7c-4eb7-4e69-a5c4-678bc7faa25d for DN 127.0.0.1:46235
2020-04-02 05:05:54,354 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x3c207acfb5eaf41a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 183 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,354 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,354 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x591fa0e60644fe0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 262 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,355 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,358 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x6a154cd0e9db3192,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 70 msec to generate and 270 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,358 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,359 [IPC Server handler 6 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46235, datanodeUuid=084895d6-29b8-4e9d-8605-d70653e3ccc2, infoPort=35039, infoSecurePort=0, ipcPort=45403, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:54,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd57b74f7435e674c: Processing first storage report for DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55 from datanode 084895d6-29b8-4e9d-8605-d70653e3ccc2
2020-04-02 05:05:54,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd57b74f7435e674c: from storage DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55 node DatanodeRegistration(127.0.0.1:46235, datanodeUuid=084895d6-29b8-4e9d-8605-d70653e3ccc2, infoPort=35039, infoSecurePort=0, ipcPort=45403, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd57b74f7435e674c: Processing first storage report for DS-32007c7c-4eb7-4e69-a5c4-678bc7faa25d from datanode 084895d6-29b8-4e9d-8605-d70653e3ccc2
2020-04-02 05:05:54,360 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd57b74f7435e674c: from storage DS-32007c7c-4eb7-4e69-a5c4-678bc7faa25d node DatanodeRegistration(127.0.0.1:46235, datanodeUuid=084895d6-29b8-4e9d-8605-d70653e3ccc2, infoPort=35039, infoSecurePort=0, ipcPort=45403, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,360 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd57b74f7435e674c
2020-04-02 05:05:54,361 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x65689c4706f7ad88,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 8 msec to generate and 270 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,362 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,362 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb933a785636aa752,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 16 msec to generate and 270 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,362 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,362 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xaf32a731fb58776d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 69 msec to generate and 267 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,369 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,370 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd57b74f7435e674c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,370 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,370 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40930
2020-04-02 05:05:54,371 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@3676ac27] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:54,371 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:54,371 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:54,371 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:54,372 [Socket Reader #1 for port 34719] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34719
2020-04-02 05:05:54,377 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34719
2020-04-02 05:05:54,391 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:54,392 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:54,403 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:40813 to rack /r6
2020-04-02 05:05:54,403 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:54,403 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,404 [IPC Server listener on 34719] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34719: starting
2020-04-02 05:05:54,404 [Thread-323] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,404 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:54,404 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:54,406 [Thread-357] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:54,407 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:54,408 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34719 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:54,456 [Thread-357] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:54,467 [Thread-357] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:54,477 [Thread-357] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:54,477 [Thread-357] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:54,477 [Thread-357] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9245e945-5932-42b9-94b7-cdbfb2c9212b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-04-02 05:05:54,478 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,478 [Thread-323] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,478 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:54,478 [Thread-323] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:54,480 [Thread-323] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:54,486 [Thread-323] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 2b3dd053-685c-468b-91ec-266cbdf48622
2020-04-02 05:05:54,489 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178
2020-04-02 05:05:54,493 [Thread-323] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:05:54,496 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8f13ebd6-d78f-40fb-bf2f-2665f4b04cf4
2020-04-02 05:05:54,497 [Thread-323] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:05:54,498 [Thread-323] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:54,497 [Thread-357] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:54,502 [Thread-357] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 682194418. Formatting...
2020-04-02 05:05:54,502 [Thread-357] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e8b34061-86ed-4596-b930-d48d3a3c36e0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-04-02 05:05:54,503 [Thread-323] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:05:54,513 [Thread-357] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,514 [Thread-357] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,514 [Thread-323] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:05:54,526 [Thread-323] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:05:54,514 [Thread-357] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:54,531 [Thread-357] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:54,534 [Thread-323] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:05:54,586 [Thread-323] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,588 [Thread-357] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,588 [Thread-357] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,588 [Thread-357] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-1856199950-172.17.0.13-1585803946960 is not formatted. Formatting ...
2020-04-02 05:05:54,588 [Thread-357] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1856199950-172.17.0.13-1585803946960 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1856199950-172.17.0.13-1585803946960/current
2020-04-02 05:05:54,594 [Thread-370] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:05:54,594 [Thread-357] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=null
2020-04-02 05:05:54,596 [Thread-371] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:05:54,602 [Thread-357] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 556a9dea-8cbc-413c-968e-471ac319e89c
2020-04-02 05:05:54,615 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9245e945-5932-42b9-94b7-cdbfb2c9212b
2020-04-02 05:05:54,616 [Thread-357] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-04-02 05:05:54,617 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e8b34061-86ed-4596-b930-d48d3a3c36e0
2020-04-02 05:05:54,622 [Thread-357] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-04-02 05:05:54,622 [Thread-357] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:54,624 [Thread-357] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:05:54,683 [Thread-357] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:05:54,683 [Thread-357] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:05:54,683 [Thread-357] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:05:54,711 [Thread-357] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,734 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:05:54,734 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:05:54,761 [Thread-370] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 167ms
2020-04-02 05:05:54,777 [Thread-371] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 181ms
2020-04-02 05:05:54,777 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 192ms
2020-04-02 05:05:54,778 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:05:54,778 [Thread-378] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:54,779 [Thread-378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 1ms
2020-04-02 05:05:54,779 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:05:54,779 [Thread-379] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:54,780 [Thread-379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 1ms
2020-04-02 05:05:54,794 [Thread-323] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 16ms
2020-04-02 05:05:54,795 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:05:54,796 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-8f13ebd6-d78f-40fb-bf2f-2665f4b04cf4): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,797 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:05:54,798 [Thread-323] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:33 AM with interval of 21600000ms
2020-04-02 05:05:54,798 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-8f13ebd6-d78f-40fb-bf2f-2665f4b04cf4): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:05:54,798 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,816 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178): no suitable block pools found to scan.  Waiting 1814399979 ms.
2020-04-02 05:05:54,816 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 2b3dd053-685c-468b-91ec-266cbdf48622) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:54,822 [IPC Server handler 4 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36807, datanodeUuid=2b3dd053-685c-468b-91ec-266cbdf48622, infoPort=37716, infoSecurePort=0, ipcPort=40725, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 2b3dd053-685c-468b-91ec-266cbdf48622
2020-04-02 05:05:54,823 [IPC Server handler 4 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:36807
2020-04-02 05:05:54,824 [IPC Server handler 4 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2b3dd053-685c-468b-91ec-266cbdf48622 (127.0.0.1:36807).
2020-04-02 05:05:54,825 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 2b3dd053-685c-468b-91ec-266cbdf48622) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:54,825 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:54,841 [Thread-377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 107ms
2020-04-02 05:05:54,847 [Thread-376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 113ms
2020-04-02 05:05:54,849 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 138ms
2020-04-02 05:05:54,852 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:05:54,852 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:05:54,864 [Thread-386] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:54,864 [Thread-386] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 0ms
2020-04-02 05:05:54,866 [Thread-385] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:54,867 [Thread-385] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 15ms
2020-04-02 05:05:54,874 [Thread-357] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 24ms
2020-04-02 05:05:54,875 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:05:54,875 [Thread-357] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:46 AM with interval of 21600000ms
2020-04-02 05:05:54,875 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-9245e945-5932-42b9-94b7-cdbfb2c9212b): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,885 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 556a9dea-8cbc-413c-968e-471ac319e89c) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:54,891 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:05:54,892 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-e8b34061-86ed-4596-b930-d48d3a3c36e0): finished scanning block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,892 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-e8b34061-86ed-4596-b930-d48d3a3c36e0): no suitable block pools found to scan.  Waiting 1814399982 ms.
2020-04-02 05:05:54,893 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-9245e945-5932-42b9-94b7-cdbfb2c9212b): no suitable block pools found to scan.  Waiting 1814399981 ms.
2020-04-02 05:05:54,898 [IPC Server handler 2 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178 for DN 127.0.0.1:36807
2020-04-02 05:05:54,899 [IPC Server handler 2 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8f13ebd6-d78f-40fb-bf2f-2665f4b04cf4 for DN 127.0.0.1:36807
2020-04-02 05:05:54,910 [IPC Server handler 1 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40813, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40930, infoSecurePort=0, ipcPort=34719, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 556a9dea-8cbc-413c-968e-471ac319e89c
2020-04-02 05:05:54,911 [IPC Server handler 1 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:40813
2020-04-02 05:05:54,911 [IPC Server handler 1 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 556a9dea-8cbc-413c-968e-471ac319e89c (127.0.0.1:40813).
2020-04-02 05:05:54,912 [IPC Server handler 1 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36807, datanodeUuid=2b3dd053-685c-468b-91ec-266cbdf48622, infoPort=37716, infoSecurePort=0, ipcPort=40725, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:54,912 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc4636b629dd6a3cd: Processing first storage report for DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178 from datanode 2b3dd053-685c-468b-91ec-266cbdf48622
2020-04-02 05:05:54,913 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc4636b629dd6a3cd: from storage DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178 node DatanodeRegistration(127.0.0.1:36807, datanodeUuid=2b3dd053-685c-468b-91ec-266cbdf48622, infoPort=37716, infoSecurePort=0, ipcPort=40725, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,913 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 556a9dea-8cbc-413c-968e-471ac319e89c) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:54,913 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc4636b629dd6a3cd: Processing first storage report for DS-8f13ebd6-d78f-40fb-bf2f-2665f4b04cf4 from datanode 2b3dd053-685c-468b-91ec-266cbdf48622
2020-04-02 05:05:54,913 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc4636b629dd6a3cd: from storage DS-8f13ebd6-d78f-40fb-bf2f-2665f4b04cf4 node DatanodeRegistration(127.0.0.1:36807, datanodeUuid=2b3dd053-685c-468b-91ec-266cbdf48622, infoPort=37716, infoSecurePort=0, ipcPort=40725, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,913 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:54,913 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xc4636b629dd6a3cd
2020-04-02 05:05:54,914 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc4636b629dd6a3cd,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,914 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:54,924 [IPC Server handler 8 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9245e945-5932-42b9-94b7-cdbfb2c9212b for DN 127.0.0.1:40813
2020-04-02 05:05:54,924 [IPC Server handler 8 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e8b34061-86ed-4596-b930-d48d3a3c36e0 for DN 127.0.0.1:40813
2020-04-02 05:05:54,929 [IPC Server handler 9 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40813, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40930, infoSecurePort=0, ipcPort=34719, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:54,929 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd4e44c668530b178: Processing first storage report for DS-e8b34061-86ed-4596-b930-d48d3a3c36e0 from datanode 556a9dea-8cbc-413c-968e-471ac319e89c
2020-04-02 05:05:54,929 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd4e44c668530b178: from storage DS-e8b34061-86ed-4596-b930-d48d3a3c36e0 node DatanodeRegistration(127.0.0.1:40813, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40930, infoSecurePort=0, ipcPort=34719, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,929 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd4e44c668530b178: Processing first storage report for DS-9245e945-5932-42b9-94b7-cdbfb2c9212b from datanode 556a9dea-8cbc-413c-968e-471ac319e89c
2020-04-02 05:05:54,929 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd4e44c668530b178: from storage DS-9245e945-5932-42b9-94b7-cdbfb2c9212b node DatanodeRegistration(127.0.0.1:40813, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40930, infoSecurePort=0, ipcPort=34719, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:54,929 [IPC Server handler 9 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd4e44c668530b178
2020-04-02 05:05:54,934 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd4e44c668530b178,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:54,935 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:55,290 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:55,309 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:55,337 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:55,341 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:55,518 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:55,525 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:05:55,576 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:05:55,585 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2280)) - MiniDFSCluster Stopping DataNode host10:40813 from a total of 10 datanodes.
2020-04-02 05:05:55,585 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34719 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:55,586 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:55,595 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4d411036] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:55,598 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-e8b34061-86ed-4596-b930-d48d3a3c36e0) exiting.
2020-04-02 05:05:55,599 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-9245e945-5932-42b9-94b7-cdbfb2c9212b) exiting.
2020-04-02 05:05:55,745 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@287f94b1{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:55,845 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@30b34287{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:55,846 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5dda6f9{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:55,846 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7d373bcf{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:55,879 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34719
2020-04-02 05:05:55,880 [IPC Server listener on 34719] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34719
2020-04-02 05:05:55,894 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:55,895 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:55,895 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 556a9dea-8cbc-413c-968e-471ac319e89c) service to localhost/127.0.0.1:40253
2020-04-02 05:05:55,895 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 556a9dea-8cbc-413c-968e-471ac319e89c)
2020-04-02 05:05:55,895 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:55,944 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:55,953 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:55,990 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:55,991 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:55,992 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:55,992 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:56,005 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:56,008 [main] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(752)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:40813, removeBlocksFromBlockMap true
2020-04-02 05:05:56,009 [main] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:40813
2020-04-02 05:05:56,009 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(121)) - stop datanode host10
2020-04-02 05:05:56,016 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:05:56,081 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:05:56,104 [main] WARN  erasurecode.ErasureCodeNative (ErasureCodeNative.java:<clinit>(55)) - ISA-L support is not available in your platform... using builtin-java codec where applicable
2020-04-02 05:05:56,356 [IPC Server handler 0 on 40253] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:05:56,363 [IPC Server handler 0 on 40253] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-5154819c-dcb2-4c2e-8979-26b719a52e7f:NORMAL:127.0.0.1:45830, [DISK]DS-81923dbc-f5be-4b79-8b1f-9605f3653621:NORMAL:127.0.0.1:43800, [DISK]DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55:NORMAL:127.0.0.1:46235, [DISK]DS-c4de8663-3d5d-4218-a940-fe05a03be608:NORMAL:127.0.0.1:35501, [DISK]DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178:NORMAL:127.0.0.1:36807]
2020-04-02 05:05:56,363 [IPC Server handler 0 on 40253] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:46235, 127.0.0.1:36807, 127.0.0.1:45830, 127.0.0.1:43800, 127.0.0.1:35501]
2020-04-02 05:05:56,379 [IPC Server handler 0 on 40253] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:45830, 127.0.0.1:35859, 127.0.0.1:46235, 127.0.0.1:46654, 127.0.0.1:36807, 127.0.0.1:43800, 127.0.0.1:41997, 127.0.0.1:38424, 127.0.0.1:35501 for /foo
2020-04-02 05:05:56,518 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:56,795 [DataXceiver for client DFSClient_NONMAPREDUCE_932570579_1 at /127.0.0.1:38656 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775790_1001 src: /127.0.0.1:38656 dest: /127.0.0.1:46235
2020-04-02 05:05:56,799 [DataXceiver for client DFSClient_NONMAPREDUCE_932570579_1 at /127.0.0.1:36390 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775792_1001 src: /127.0.0.1:36390 dest: /127.0.0.1:45830
2020-04-02 05:05:56,798 [DataXceiver for client DFSClient_NONMAPREDUCE_932570579_1 at /127.0.0.1:39602 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775787_1001 src: /127.0.0.1:39602 dest: /127.0.0.1:43800
2020-04-02 05:05:56,842 [DataXceiver for client DFSClient_NONMAPREDUCE_932570579_1 at /127.0.0.1:43154 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775788_1001 src: /127.0.0.1:43154 dest: /127.0.0.1:36807
2020-04-02 05:05:56,834 [DataXceiver for client DFSClient_NONMAPREDUCE_932570579_1 at /127.0.0.1:45192 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775791_1001 src: /127.0.0.1:45192 dest: /127.0.0.1:35859
2020-04-02 05:05:56,890 [DataXceiver for client DFSClient_NONMAPREDUCE_932570579_1 at /127.0.0.1:54222 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775789_1001 src: /127.0.0.1:54222 dest: /127.0.0.1:46654
2020-04-02 05:05:56,995 [IPC Server handler 7 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41997, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=40610, infoSecurePort=0, ipcPort=33344, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:56,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7a79bcfbb32d46ee: Processing first storage report for DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac from datanode 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0
2020-04-02 05:05:56,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7a79bcfbb32d46ee: from storage DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac node DatanodeRegistration(127.0.0.1:41997, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=40610, infoSecurePort=0, ipcPort=33344, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:56,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7a79bcfbb32d46ee: Processing first storage report for DS-fda3df25-01a3-4c39-9345-25f199e82d5f from datanode 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0
2020-04-02 05:05:56,998 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7a79bcfbb32d46ee: from storage DS-fda3df25-01a3-4c39-9345-25f199e82d5f node DatanodeRegistration(127.0.0.1:41997, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=40610, infoSecurePort=0, ipcPort=33344, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:56,998 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x7a79bcfbb32d46ee
2020-04-02 05:05:56,999 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x7a79bcfbb32d46ee,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:56,999 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:57,366 [IPC Server handler 4 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46235, datanodeUuid=084895d6-29b8-4e9d-8605-d70653e3ccc2, infoPort=35039, infoSecurePort=0, ipcPort=45403, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:57,371 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:46235 size 134217728 replicaState = RBW
2020-04-02 05:05:57,371 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:57,372 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:46235
2020-04-02 05:05:57,372 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46235 receiving: 1, received: 0, deleted: 0
2020-04-02 05:05:57,506 [DataXceiver for client DFSClient_NONMAPREDUCE_932570579_1 at /127.0.0.1:40914 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001 src: /127.0.0.1:40914 dest: /127.0.0.1:41997
2020-04-02 05:05:57,524 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:57,671 [DataXceiver for client DFSClient_NONMAPREDUCE_932570579_1 at /127.0.0.1:43114 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775785_1001 src: /127.0.0.1:43114 dest: /127.0.0.1:38424
2020-04-02 05:05:57,798 [DataXceiver for client DFSClient_NONMAPREDUCE_932570579_1 at /127.0.0.1:46918 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775784_1001 src: /127.0.0.1:46918 dest: /127.0.0.1:35501
2020-04-02 05:05:57,899 [IPC Server handler 5 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36807, datanodeUuid=2b3dd053-685c-468b-91ec-266cbdf48622, infoPort=37716, infoSecurePort=0, ipcPort=40725, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:57,899 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:36807 size 134217728 replicaState = RBW
2020-04-02 05:05:57,899 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:57,899 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:36807
2020-04-02 05:05:57,899 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36807 receiving: 1, received: 0, deleted: 0
2020-04-02 05:05:58,194 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:36390, dest: /127.0.0.1:45830, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_932570579_1, offset: 0, srvID: df4788ff-a0ca-46f0-876e-2f10617407dd, blockid: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775792_1001, duration(ns): 1164182004
2020-04-02 05:05:58,195 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:58,207 [IPC Server handler 6 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:45830, datanodeUuid=df4788ff-a0ca-46f0-876e-2f10617407dd, infoPort=38960, infoSecurePort=0, ipcPort=40788, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:58,207 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:45830 size 2097152 replicaState = FINALIZED
2020-04-02 05:05:58,207 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:58,208 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:45830 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:05:58,209 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:45830
2020-04-02 05:05:58,209 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:45830 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:58,203 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45192, dest: /127.0.0.1:35859, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_932570579_1, offset: 0, srvID: 65d7ec62-7df3-4aea-a092-96ed63492864, blockid: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775791_1001, duration(ns): 1174476779
2020-04-02 05:05:58,210 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:58,212 [IPC Server handler 4 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35859, datanodeUuid=65d7ec62-7df3-4aea-a092-96ed63492864, infoPort=35621, infoSecurePort=0, ipcPort=43173, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:58,213 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:35859 size 2097152 replicaState = FINALIZED
2020-04-02 05:05:58,213 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:58,213 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:35859 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:05:58,213 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:35859
2020-04-02 05:05:58,213 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35859 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:58,218 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:38656, dest: /127.0.0.1:46235, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_932570579_1, offset: 0, srvID: 084895d6-29b8-4e9d-8605-d70653e3ccc2, blockid: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775790_1001, duration(ns): 1203056437
2020-04-02 05:05:58,219 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:58,220 [IPC Server handler 0 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46235, datanodeUuid=084895d6-29b8-4e9d-8605-d70653e3ccc2, infoPort=35039, infoSecurePort=0, ipcPort=45403, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:58,221 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:46235 size 2097152 replicaState = FINALIZED
2020-04-02 05:05:58,221 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:58,221 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:46235 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:05:58,221 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:46235
2020-04-02 05:05:58,221 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46235 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:58,226 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:54222, dest: /127.0.0.1:46654, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_932570579_1, offset: 0, srvID: 695c8241-88f4-404a-bbed-e96743005a31, blockid: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775789_1001, duration(ns): 1202343918
2020-04-02 05:05:58,227 [IPC Server handler 2 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46654, datanodeUuid=695c8241-88f4-404a-bbed-e96743005a31, infoPort=41083, infoSecurePort=0, ipcPort=43241, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:58,228 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:58,229 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:46654 size 2097152 replicaState = FINALIZED
2020-04-02 05:05:58,229 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:58,229 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:46654 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:05:58,229 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:46654
2020-04-02 05:05:58,229 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46654 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:58,244 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43154, dest: /127.0.0.1:36807, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_932570579_1, offset: 0, srvID: 2b3dd053-685c-468b-91ec-266cbdf48622, blockid: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775788_1001, duration(ns): 1198184529
2020-04-02 05:05:58,244 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:58,266 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:39602, dest: /127.0.0.1:43800, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_932570579_1, offset: 0, srvID: 85926ba2-f735-4868-aba2-eb03bdc45514, blockid: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775787_1001, duration(ns): 1220566458
2020-04-02 05:05:58,266 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:58,270 [IPC Server handler 5 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36807, datanodeUuid=2b3dd053-685c-468b-91ec-266cbdf48622, infoPort=37716, infoSecurePort=0, ipcPort=40725, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:58,270 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:36807 size 2097152 replicaState = FINALIZED
2020-04-02 05:05:58,271 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:58,271 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36807 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:05:58,271 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:36807
2020-04-02 05:05:58,271 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36807 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:58,280 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:40914, dest: /127.0.0.1:41997, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_932570579_1, offset: 0, srvID: 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, blockid: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001, duration(ns): 748736290
2020-04-02 05:05:58,280 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:58,286 [IPC Server handler 7 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:41997, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=40610, infoSecurePort=0, ipcPort=33344, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:58,287 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:41997 size 2097152 replicaState = FINALIZED
2020-04-02 05:05:58,287 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:58,287 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:41997 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:05:58,287 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:41997
2020-04-02 05:05:58,287 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:41997 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:58,288 [IPC Server handler 3 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:43800, datanodeUuid=85926ba2-f735-4868-aba2-eb03bdc45514, infoPort=34062, infoSecurePort=0, ipcPort=44149, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:58,289 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:43800 size 2097152 replicaState = FINALIZED
2020-04-02 05:05:58,289 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:58,289 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:43800 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:05:58,289 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:43800
2020-04-02 05:05:58,289 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:43800 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:58,297 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43114, dest: /127.0.0.1:38424, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_932570579_1, offset: 0, srvID: 01d45740-4e21-4654-83ca-6d32e3ca1f0a, blockid: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775785_1001, duration(ns): 584114005
2020-04-02 05:05:58,297 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:58,316 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46918, dest: /127.0.0.1:35501, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_932570579_1, offset: 0, srvID: 964fc2f8-64f9-4638-9cc9-6edd4b859fe4, blockid: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775784_1001, duration(ns): 511883092
2020-04-02 05:05:58,316 [PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:05:58,320 [IPC Server handler 1 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38424, datanodeUuid=01d45740-4e21-4654-83ca-6d32e3ca1f0a, infoPort=34631, infoSecurePort=0, ipcPort=43354, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:58,320 [IPC Server handler 1 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:35501, datanodeUuid=964fc2f8-64f9-4638-9cc9-6edd4b859fe4, infoPort=36148, infoSecurePort=0, ipcPort=33832, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:05:58,321 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:38424 size 2097152 replicaState = FINALIZED
2020-04-02 05:05:58,321 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:58,321 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38424 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:05:58,322 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:38424
2020-04-02 05:05:58,322 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38424 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:58,322 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:35501 size 2097152 replicaState = FINALIZED
2020-04-02 05:05:58,322 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:05:58,322 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:35501 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:05:58,322 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:35501
2020-04-02 05:05:58,322 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:35501 receiving: 0, received: 1, deleted: 0
2020-04-02 05:05:58,341 [IPC Server handler 9 on 40253] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /foo is closed by DFSClient_NONMAPREDUCE_932570579_1
2020-04-02 05:05:58,346 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2280)) - MiniDFSCluster Stopping DataNode host1:41997 from a total of 9 datanodes.
2020-04-02 05:05:58,347 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33344 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:58,347 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:05:58,347 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3543df7d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:05:58,357 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac) exiting.
2020-04-02 05:05:58,358 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-fda3df25-01a3-4c39-9345-25f199e82d5f) exiting.
2020-04-02 05:05:58,484 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4da602fc{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:05:58,486 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2a8d39c4{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:05:58,490 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6f0b0a5e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:05:58,490 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3fa2213{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:05:58,501 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33344
2020-04-02 05:05:58,580 [IPC Server listener on 33344] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33344
2020-04-02 05:05:58,580 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:05:58,581 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:05:58,580 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:05:58,589 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0) service to localhost/127.0.0.1:40253
2020-04-02 05:05:58,589 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0)
2020-04-02 05:05:58,589 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:58,602 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:58,621 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:05:58,640 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:05:58,641 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:05:58,642 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:05:58,642 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:05:58,645 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:05:58,645 [main] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(752)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:41997, removeBlocksFromBlockMap true
2020-04-02 05:05:58,645 [main] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775792_1001 from 127.0.0.1:41997
2020-04-02 05:05:58,647 [main] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:05:58,648 [main] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r1/127.0.0.1:41997
2020-04-02 05:05:58,648 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(121)) - stop datanode host1
2020-04-02 05:05:58,650 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:05:58,662 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:05:58,668 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:05:58,677 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:05:58,678 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:58,678 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:05:58,678 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host10
2020-04-02 05:05:58,678 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:05:58,679 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:05:58,679 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:39052
2020-04-02 05:05:58,679 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:05:58,679 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:05:58,691 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:58,693 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:05:58,698 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:05:58,698 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:05:58,699 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:05:58,700 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:05:58,700 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:05:58,701 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:05:58,702 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44724
2020-04-02 05:05:58,702 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:05:58,713 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@18e8473e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:05:58,714 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1a38ba58{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:05:58,720 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@24b52d3e{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:05:58,721 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@15deb1dc{HTTP/1.1,[http/1.1]}{localhost:44724}
2020-04-02 05:05:58,721 [main] INFO  server.Server (Server.java:doStart(419)) - Started @14405ms
2020-04-02 05:05:58,758 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40617
2020-04-02 05:05:58,759 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:05:58,759 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:05:58,759 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:05:58,762 [Socket Reader #1 for port 33814] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33814
2020-04-02 05:05:58,762 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@57a4d5ee] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:05:58,771 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33814
2020-04-02 05:05:58,787 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:05:58,787 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:05:58,788 [Thread-443] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:05:58,789 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:05:58,789 [IPC Server listener on 33814] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33814: starting
2020-04-02 05:05:58,791 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33814 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:05:58,799 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:58,801 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:58,801 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:58,819 [Thread-443] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:05:58,821 [Thread-443] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:05:58,822 [Thread-443] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:58,826 [Thread-443] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:05:58,846 [Thread-443] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:58,846 [Thread-443] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:58,857 [Thread-443] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:58,859 [Thread-443] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:58,860 [Thread-443] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=556a9dea-8cbc-413c-968e-471ac319e89c
2020-04-02 05:05:58,863 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9245e945-5932-42b9-94b7-cdbfb2c9212b
2020-04-02 05:05:58,864 [Thread-443] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-04-02 05:05:58,865 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e8b34061-86ed-4596-b930-d48d3a3c36e0
2020-04-02 05:05:58,866 [Thread-443] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-04-02 05:05:58,866 [Thread-443] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:05:58,867 [Thread-443] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:05:58,868 [Thread-443] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:05:58,869 [Thread-443] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:05:58,869 [Thread-443] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:05:58,869 [Thread-443] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:58,869 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:05:58,872 [Thread-456] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1856199950-172.17.0.13-1585803946960/current: 24576
2020-04-02 05:05:58,886 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:05:58,903 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:58,905 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:58,905 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:58,922 [Thread-457] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1856199950-172.17.0.13-1585803946960/current: 24576
2020-04-02 05:05:58,959 [Thread-457] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 73ms
2020-04-02 05:05:58,959 [Thread-456] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 89ms
2020-04-02 05:05:58,963 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 94ms
2020-04-02 05:05:58,964 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:05:58,964 [Thread-459] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:05:58,964 [Thread-458] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:58,965 [Thread-459] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:05:58,974 [Thread-459] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 10ms
2020-04-02 05:05:58,986 [Thread-458] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 21ms
2020-04-02 05:05:58,987 [Thread-443] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 23ms
2020-04-02 05:05:59,002 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-e8b34061-86ed-4596-b930-d48d3a3c36e0): no suitable block pools found to scan.  Waiting 1814395872 ms.
2020-04-02 05:05:59,002 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-9245e945-5932-42b9-94b7-cdbfb2c9212b): no suitable block pools found to scan.  Waiting 1814395872 ms.
2020-04-02 05:05:59,006 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,007 [Thread-443] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:27 AM with interval of 21600000ms
2020-04-02 05:05:59,008 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:05:59,008 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:05:59,022 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 556a9dea-8cbc-413c-968e-471ac319e89c) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:05:59,023 [IPC Server handler 5 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:39052, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40617, infoSecurePort=0, ipcPort=33814, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 556a9dea-8cbc-413c-968e-471ac319e89c
2020-04-02 05:05:59,023 [IPC Server handler 5 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1076)) - BLOCK* registerDatanode: 127.0.0.1:40813 is replaced by DatanodeRegistration(127.0.0.1:39052, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40617, infoSecurePort=0, ipcPort=33814, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) with the same storageID 556a9dea-8cbc-413c-968e-471ac319e89c
2020-04-02 05:05:59,023 [IPC Server handler 5 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:40813
2020-04-02 05:05:59,023 [IPC Server handler 5 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:39052
2020-04-02 05:05:59,024 [IPC Server handler 5 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-e8b34061-86ed-4596-b930-d48d3a3c36e0:NORMAL:127.0.0.1:39052 failed.
2020-04-02 05:05:59,024 [IPC Server handler 5 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-9245e945-5932-42b9-94b7-cdbfb2c9212b:NORMAL:127.0.0.1:39052 failed.
2020-04-02 05:05:59,024 [IPC Server handler 5 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-e8b34061-86ed-4596-b930-d48d3a3c36e0:FAILED:127.0.0.1:39052 from DataNode 127.0.0.1:39052
2020-04-02 05:05:59,024 [IPC Server handler 5 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-9245e945-5932-42b9-94b7-cdbfb2c9212b:FAILED:127.0.0.1:39052 from DataNode 127.0.0.1:39052
2020-04-02 05:05:59,025 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 556a9dea-8cbc-413c-968e-471ac319e89c) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:05:59,025 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:05:59,028 [IPC Server handler 7 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9245e945-5932-42b9-94b7-cdbfb2c9212b for DN 127.0.0.1:39052
2020-04-02 05:05:59,029 [IPC Server handler 7 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e8b34061-86ed-4596-b930-d48d3a3c36e0 for DN 127.0.0.1:39052
2020-04-02 05:05:59,033 [IPC Server handler 7 on 40253] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 556a9dea-8cbc-413c-968e-471ac319e89c (127.0.0.1:39052) requested a lease even though it wasn't yet registered.  Registering now.
2020-04-02 05:05:59,033 [IPC Server handler 7 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 556a9dea-8cbc-413c-968e-471ac319e89c (127.0.0.1:39052).
2020-04-02 05:05:59,038 [IPC Server handler 3 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:39052, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40617, infoSecurePort=0, ipcPort=33814, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:05:59,038 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb5d785070bfb351e: Processing first storage report for DS-e8b34061-86ed-4596-b930-d48d3a3c36e0 from datanode 556a9dea-8cbc-413c-968e-471ac319e89c
2020-04-02 05:05:59,038 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb5d785070bfb351e: from storage DS-e8b34061-86ed-4596-b930-d48d3a3c36e0 node DatanodeRegistration(127.0.0.1:39052, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40617, infoSecurePort=0, ipcPort=33814, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:59,039 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb5d785070bfb351e: Processing first storage report for DS-9245e945-5932-42b9-94b7-cdbfb2c9212b from datanode 556a9dea-8cbc-413c-968e-471ac319e89c
2020-04-02 05:05:59,039 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb5d785070bfb351e: from storage DS-9245e945-5932-42b9-94b7-cdbfb2c9212b node DatanodeRegistration(127.0.0.1:39052, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40617, infoSecurePort=0, ipcPort=33814, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:05:59,039 [IPC Server handler 3 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb5d785070bfb351e
2020-04-02 05:05:59,049 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb5d785070bfb351e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:05:59,063 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:05:59,110 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,118 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:05:59,122 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,126 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:05:59,128 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,243 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,245 [IPC Server handler 0 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:05:59,246 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,352 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,354 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:05:59,354 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,460 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,462 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:05:59,462 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,568 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,570 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:05:59,570 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,587 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:<init>(47)) - Creating an ErasureCodingWork to blk_-9223372036854775792_1001 reconstruct 
2020-04-02 05:05:59,587 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=1}
2020-04-02 05:05:59,588 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseLocalRack(634)) - Failed to choose from local rack (location = /r3), retry with the rack of the next replica (location = /r3)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:831)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:719)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:626)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:586)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:416)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:292)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:143)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1862)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1814)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4550)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:59,594 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseFromNextRack(666)) - Failed to choose from the next rack (location = /r3), retry choosing randomly
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:831)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:719)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseFromNextRack(BlockPlacementPolicyDefault.java:662)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:638)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:586)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:416)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:292)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:143)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1862)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1814)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4550)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:05:59,595 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-5154819c-dcb2-4c2e-8979-26b719a52e7f:NORMAL:127.0.0.1:45830, [DISK]DS-291b14cb-dad8-4b5b-b6b4-e46eb4534755:NORMAL:127.0.0.1:35859, [DISK]DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55:NORMAL:127.0.0.1:46235, [DISK]DS-c5aed756-c99c-4dd5-a405-e1960059d54b:NORMAL:127.0.0.1:46654, [DISK]DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178:NORMAL:127.0.0.1:36807, [DISK]DS-3bd2d739-652f-43b6-bafa-55bbd38d35e9:NORMAL:127.0.0.1:43800, [DISK]DS-d0b2c649-7c2f-44ea-b11a-1bb494c5c1f1:NORMAL:127.0.0.1:38424, [DISK]DS-c4de8663-3d5d-4218-a940-fe05a03be608:NORMAL:127.0.0.1:35501, [DISK]DS-e8b34061-86ed-4596-b930-d48d3a3c36e0:NORMAL:127.0.0.1:39052]
2020-04-02 05:05:59,595 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:46654, 127.0.0.1:46235, 127.0.0.1:36807, 127.0.0.1:45830, 127.0.0.1:35859, 127.0.0.1:43800, 127.0.0.1:39052, 127.0.0.1:38424, 127.0.0.1:35501]
2020-04-02 05:05:59,599 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (DatanodeDescriptor.java:addBlockToBeErasureCoded(658)) - Adding block reconstruction task BlockECReconstructionInfo(
  Recovering BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775792_1001 From: [127.0.0.1:45830, 127.0.0.1:35859, 127.0.0.1:46235, 127.0.0.1:46654, 127.0.0.1:36807, 127.0.0.1:43800, 127.0.0.1:38424, 127.0.0.1:35501] To: [[127.0.0.1:39052])
 Block Indices: [0, 1, 2, 3, 4, 5, 7, 8]to 127.0.0.1:39052, current queue size is 1
2020-04-02 05:05:59,599 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:validateReconstructionWork(2054)) - BLOCK* block blk_-9223372036854775792_1001 is moved from neededReconstruction to pendingReconstruction
2020-04-02 05:05:59,600 [RedundancyMonitor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-04-02 05:05:59,600 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1895)) - BLOCK* ask [127.0.0.1:45830, 127.0.0.1:35859, 127.0.0.1:46235, 127.0.0.1:46654, 127.0.0.1:36807, 127.0.0.1:43800, 127.0.0.1:38424, 127.0.0.1:35501] to replicate blk_-9223372036854775792_1001 to datanode(s) 127.0.0.1:39052
2020-04-02 05:05:59,600 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:05:59,675 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,689 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:05:59,690 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,804 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,806 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:05:59,807 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,916 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:05:59,919 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:05:59,920 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,033 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,035 [IPC Server handler 8 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:00,036 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,141 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,143 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:00,144 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,255 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,258 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:00,258 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,363 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,365 [IPC Server handler 9 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:00,365 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,498 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,501 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:00,502 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,615 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,617 [IPC Server handler 0 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:00,618 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,627 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:00,738 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,739 [IPC Server handler 5 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:00,740 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,844 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,847 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:00,847 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,953 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:00,958 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:00,958 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,063 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,065 [IPC Server handler 8 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:01,065 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,169 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,174 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:01,175 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,286 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,288 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:01,289 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,392 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,396 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:01,396 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,505 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,509 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:01,510 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,614 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,616 [IPC Server handler 8 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:01,616 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,628 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:01,720 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,722 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:01,722 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,826 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,828 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:01,828 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,935 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:01,937 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:01,938 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,041 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,045 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:02,045 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,046 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(793)) - DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY
2020-04-02 05:06:02,147 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,150 [IPC Server handler 0 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:02,153 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,186 [DataXceiver for client  at /127.0.0.1:51050 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001 src: /127.0.0.1:51050 dest: /127.0.0.1:39052
2020-04-02 05:06:02,265 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,285 [IPC Server handler 5 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:02,285 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,328 [DataXceiver for client  at /127.0.0.1:51050 [Receiving block BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-1856199950-172.17.0.13-1585803946960:blk_-9223372036854775786_1001 src: /127.0.0.1:51050 dest: /127.0.0.1:39052 of size 2097152
2020-04-02 05:06:02,344 [IPC Server handler 7 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:39052, datanodeUuid=556a9dea-8cbc-413c-968e-471ac319e89c, infoPort=40617, infoSecurePort=0, ipcPort=33814, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:06:02,345 [Block report processor] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:decrement(108)) - Removing pending reconstruction for blk_-9223372036854775792_1001
2020-04-02 05:06:02,345 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:39052 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:02,345 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:02,345 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:39052 is added to blk_-9223372036854775792_1001 (size=12582912)
2020-04-02 05:06:02,345 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:39052
2020-04-02 05:06:02,345 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:39052 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:02,395 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,398 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:02,398 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,403 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:02,404 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:02,405 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:02,406 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:02,406 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:02,406 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:02,407 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1
2020-04-02 05:06:02,408 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:02,411 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:02,412 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34832
2020-04-02 05:06:02,413 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:02,413 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:02,414 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:02,416 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:02,419 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:02,420 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:02,421 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:02,421 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:02,422 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:02,422 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:02,423 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44789
2020-04-02 05:06:02,423 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:02,431 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3f3c966c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:02,431 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4102b1b1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:02,437 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4201a617{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:02,446 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42344efe{HTTP/1.1,[http/1.1]}{localhost:44789}
2020-04-02 05:06:02,447 [main] INFO  server.Server (Server.java:doStart(419)) - Started @18131ms
2020-04-02 05:06:02,467 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36588
2020-04-02 05:06:02,467 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1bb9aa43] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:02,468 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:02,468 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:02,468 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:02,469 [Socket Reader #1 for port 45991] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45991
2020-04-02 05:06:02,474 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45991
2020-04-02 05:06:02,502 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:02,502 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:02,503 [Thread-489] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253 starting to offer service
2020-04-02 05:06:02,506 [IPC Server listener on 45991] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45991: starting
2020-04-02 05:06:02,513 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:02,530 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45991 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:02,531 [Thread-489] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:40253
2020-04-02 05:06:02,538 [Thread-489] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:02,538 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,539 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:02,540 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:02,541 [Thread-489] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:02,543 [Thread-489] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:02,553 [Thread-489] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:02,554 [Thread-489] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:02,563 [Thread-489] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:02,564 [Thread-489] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:02,568 [Thread-489] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=682194418;bpid=BP-1856199950-172.17.0.13-1585803946960;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=682194418;c=1585803946960;bpid=BP-1856199950-172.17.0.13-1585803946960;dnuuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0
2020-04-02 05:06:02,577 [Thread-489] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-fda3df25-01a3-4c39-9345-25f199e82d5f
2020-04-02 05:06:02,578 [Thread-489] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:06:02,579 [Thread-489] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac
2020-04-02 05:06:02,580 [Thread-489] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:02,580 [Thread-489] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:02,581 [Thread-489] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:02,610 [Thread-489] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:02,610 [Thread-489] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:02,610 [Thread-489] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:02,629 [Thread-489] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:02,631 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:02,631 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:02,633 [Thread-503] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1856199950-172.17.0.13-1585803946960/current: 24576
2020-04-02 05:06:02,633 [Thread-502] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960/current: 2138119
2020-04-02 05:06:02,634 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:02,645 [Thread-503] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 14ms
2020-04-02 05:06:02,654 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,656 [Thread-502] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1856199950-172.17.0.13-1585803946960 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 25ms
2020-04-02 05:06:02,656 [Thread-489] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1856199950-172.17.0.13-1585803946960: 26ms
2020-04-02 05:06:02,660 [Thread-504] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:02,662 [Thread-505] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:02,662 [Thread-505] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas doesn't exist 
2020-04-02 05:06:02,666 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:02,668 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:02,667 [Thread-504] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960/current/replicas
2020-04-02 05:06:02,668 [Thread-504] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 7ms
2020-04-02 05:06:02,678 [Thread-505] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 16ms
2020-04-02 05:06:02,678 [Thread-489] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1856199950-172.17.0.13-1585803946960: 22ms
2020-04-02 05:06:02,679 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac): no suitable block pools found to scan.  Waiting 1814390592 ms.
2020-04-02 05:06:02,679 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-fda3df25-01a3-4c39-9345-25f199e82d5f): no suitable block pools found to scan.  Waiting 1814390592 ms.
2020-04-02 05:06:02,679 [Thread-489] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 11:00 AM with interval of 21600000ms
2020-04-02 05:06:02,681 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0) service to localhost/127.0.0.1:40253 beginning handshake with NN
2020-04-02 05:06:02,684 [IPC Server handler 8 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34832, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=36588, infoSecurePort=0, ipcPort=45991, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) storage 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0
2020-04-02 05:06:02,685 [IPC Server handler 8 on 40253] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1076)) - BLOCK* registerDatanode: 127.0.0.1:41997 is replaced by DatanodeRegistration(127.0.0.1:34832, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=36588, infoSecurePort=0, ipcPort=45991, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) with the same storageID 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0
2020-04-02 05:06:02,685 [IPC Server handler 8 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r1/127.0.0.1:41997
2020-04-02 05:06:02,685 [IPC Server handler 8 on 40253] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:34832
2020-04-02 05:06:02,685 [IPC Server handler 8 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac:NORMAL:127.0.0.1:34832 failed.
2020-04-02 05:06:02,685 [IPC Server handler 8 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-fda3df25-01a3-4c39-9345-25f199e82d5f:NORMAL:127.0.0.1:34832 failed.
2020-04-02 05:06:02,685 [IPC Server handler 8 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-fda3df25-01a3-4c39-9345-25f199e82d5f:FAILED:127.0.0.1:34832 from DataNode 127.0.0.1:34832
2020-04-02 05:06:02,685 [IPC Server handler 8 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac:FAILED:127.0.0.1:34832 from DataNode 127.0.0.1:34832
2020-04-02 05:06:02,686 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0) service to localhost/127.0.0.1:40253 successfully registered with NN
2020-04-02 05:06:02,686 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:40253 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:02,692 [IPC Server handler 0 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-fda3df25-01a3-4c39-9345-25f199e82d5f for DN 127.0.0.1:34832
2020-04-02 05:06:02,692 [IPC Server handler 0 on 40253] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac for DN 127.0.0.1:34832
2020-04-02 05:06:02,693 [IPC Server handler 0 on 40253] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0 (127.0.0.1:34832) requested a lease even though it wasn't yet registered.  Registering now.
2020-04-02 05:06:02,693 [IPC Server handler 0 on 40253] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0 (127.0.0.1:34832).
2020-04-02 05:06:02,710 [IPC Server handler 2 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34832, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=36588, infoSecurePort=0, ipcPort=45991, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:06:02,710 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd8b0fc3c43f7b1e8: Processing first storage report for DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac from datanode 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0
2020-04-02 05:06:02,710 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd8b0fc3c43f7b1e8: from storage DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac node DatanodeRegistration(127.0.0.1:34832, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=36588, infoSecurePort=0, ipcPort=45991, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:02,711 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd8b0fc3c43f7b1e8: Processing first storage report for DS-fda3df25-01a3-4c39-9345-25f199e82d5f from datanode 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0
2020-04-02 05:06:02,711 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2778)) - Initial report of block blk_-9223372036854775786 on 127.0.0.1:34832 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:02,711 [Block report processor] TRACE blockmanagement.BlockManager (BlockManager.java:processExtraRedundancyBlock(3603)) - BLOCK* processExtraRedundancyBlock: Postponing blk_-9223372036854775792_1001 since storage [DISK]DS-fda3df25-01a3-4c39-9345-25f199e82d5f:NORMAL:127.0.0.1:34832 does not yet have up-to-date information.
2020-04-02 05:06:02,712 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd8b0fc3c43f7b1e8: from storage DS-fda3df25-01a3-4c39-9345-25f199e82d5f node DatanodeRegistration(127.0.0.1:34832, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=36588, infoSecurePort=0, ipcPort=45991, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 1, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:02,712 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd8b0fc3c43f7b1e8
2020-04-02 05:06:02,712 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd8b0fc3c43f7b1e8,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 1 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:02,712 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:02,771 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,774 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:02,777 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:offerService(695)) - Forcing a full block report to localhost/127.0.0.1:40253
2020-04-02 05:06:02,779 [IPC Server handler 4 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34832, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=36588, infoSecurePort=0, ipcPort=45991, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), reports.length=2
2020-04-02 05:06:02,779 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd8b0fc3c43f7b1e9: from storage DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac node DatanodeRegistration(127.0.0.1:34832, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=36588, infoSecurePort=0, ipcPort=45991, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:02,779 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:reportDiffSorted(2859)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:34832 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:02,779 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:reportDiffSortedInner(2926)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:02,779 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd8b0fc3c43f7b1e9: from storage DS-fda3df25-01a3-4c39-9345-25f199e82d5f node DatanodeRegistration(127.0.0.1:34832, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=36588, infoSecurePort=0, ipcPort=45991, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:02,779 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd8b0fc3c43f7b1e9
2020-04-02 05:06:02,780 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd8b0fc3c43f7b1e9,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:02,780 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:02,879 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,882 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:02,882 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,987 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:02,989 [IPC Server handler 3 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:02,989 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,092 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,095 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:03,095 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,205 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,207 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:03,207 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,311 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,314 [IPC Server handler 0 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:03,315 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,418 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,430 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:03,431 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,543 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,545 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:03,545 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,634 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:03,635 [RedundancyMonitor] DEBUG BlockStateChange (ExcessRedundancyMap.java:add(86)) - BLOCK* ExcessRedundancyMap.add(127.0.0.1:34832, blk_-9223372036854775792_1001)
2020-04-02 05:06:03,635 [RedundancyMonitor] DEBUG BlockStateChange (InvalidateBlocks.java:add(190)) - BLOCK* InvalidateBlocks: add blk_-9223372036854775786_1001 to 127.0.0.1:34832
2020-04-02 05:06:03,635 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:processChosenExcessRedundancy(3762)) - BLOCK* chooseExcessRedundancies: ([DISK]DS-fda3df25-01a3-4c39-9345-25f199e82d5f:NORMAL:127.0.0.1:34832, blk_-9223372036854775792_1001) is added to invalidated blocks set
2020-04-02 05:06:03,635 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:rescanPostponedMisreplicatedBlocks(2626)) - BLOCK* rescanPostponedMisreplicatedBlocks: Re-scanned block blk_-9223372036854775792_1001, result is OVER_REPLICATED
2020-04-02 05:06:03,636 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:rescanPostponedMisreplicatedBlocks(2637)) - Rescan of postponedMisreplicatedBlocks completed in 2 msecs. 0 blocks are left. 1 blocks were removed.
2020-04-02 05:06:03,649 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,651 [IPC Server handler 9 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:03,651 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,757 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,758 [IPC Server handler 8 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:03,759 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,866 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,868 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:03,869 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,972 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:03,974 [IPC Server handler 3 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:03,975 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,079 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,086 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:04,086 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,189 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,191 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:04,192 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,299 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,301 [IPC Server handler 0 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:04,301 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,411 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,421 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:04,422 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,530 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,535 [IPC Server handler 3 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:04,536 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,638 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:04,638 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:34832 to delete [blk_-9223372036854775786_1001]
2020-04-02 05:06:04,647 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,649 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:04,649 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,782 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,784 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:04,784 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,898 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:04,900 [IPC Server handler 0 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:04,901 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,018 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,022 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,022 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,128 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,131 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,131 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,234 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,236 [IPC Server handler 9 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,237 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,340 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,342 [IPC Server handler 8 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,343 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,446 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,448 [IPC Server handler 5 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,448 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,552 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,553 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,554 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,638 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:05,658 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,660 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,660 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,767 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,769 [IPC Server handler 5 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,770 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,787 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:deleteAsync(225)) - Scheduling blk_-9223372036854775786_1001 replica FinalizedReplica, blk_-9223372036854775786_1001, FINALIZED
  getNumBytes()     = 2097152
  getBytesOnDisk()  = 2097152
  getVisibleLength()= 2097152
  getVolume()       = /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
  getBlockURI()     = file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960/current/finalized/subdir0/subdir0/blk_-9223372036854775786 for deletion
2020-04-02 05:06:05,790 [Async disk worker #0 for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:run(333)) - Deleted BP-1856199950-172.17.0.13-1585803946960 blk_-9223372036854775786_1001 URI file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960/current/finalized/subdir0/subdir0/blk_-9223372036854775786
2020-04-02 05:06:05,874 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,882 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,883 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,990 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:05,992 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:05,992 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,097 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,099 [IPC Server handler 0 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:06,100 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,203 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,206 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:06,207 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,310 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,312 [IPC Server handler 3 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:06,312 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,415 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,417 [IPC Server handler 9 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:06,418 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,520 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,523 [IPC Server handler 8 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:06,523 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,632 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,635 [IPC Server handler 5 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:06,635 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,639 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:06,740 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,741 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:06,742 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,845 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,848 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:06,849 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,951 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:06,953 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:06,954 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,056 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,064 [IPC Server handler 0 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:07,065 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,168 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,174 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:07,174 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,280 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,283 [IPC Server handler 3 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:07,283 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,390 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,392 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:07,393 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,496 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,497 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:07,498 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,601 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,603 [IPC Server handler 0 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:07,603 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,639 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:07,706 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,708 [IPC Server handler 2 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:07,708 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,811 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,813 [IPC Server handler 3 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:07,813 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,916 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:07,917 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:07,918 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,020 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,022 [IPC Server handler 4 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,023 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,126 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,128 [IPC Server handler 5 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,128 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,232 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,234 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,234 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,337 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,338 [IPC Server handler 6 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,339 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,441 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,443 [IPC Server handler 9 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,444 [IPC Server handler 9 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,546 [IPC Server handler 4 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,548 [IPC Server handler 8 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,549 [IPC Server handler 8 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,640 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:08,651 [IPC Server handler 0 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,653 [IPC Server handler 5 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,653 [IPC Server handler 5 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,756 [IPC Server handler 6 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,758 [IPC Server handler 1 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,759 [IPC Server handler 1 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,787 [IPC Server handler 8 on 40253] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34832, datanodeUuid=7f5375fd-1e1e-4313-afd5-2014b6a8ffb0, infoPort=36588, infoSecurePort=0, ipcPort=45991, storageInfo=lv=-57;cid=testClusterID;nsid=682194418;c=1585803946960) 1 blocks.
2020-04-02 05:06:08,788 [Block report processor] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775792_1001 from 127.0.0.1:34832
2020-04-02 05:06:08,788 [Block report processor] DEBUG BlockStateChange (ExcessRedundancyMap.java:remove(106)) - BLOCK* ExcessRedundancyMap.remove(127.0.0.1:34832, blk_-9223372036854775792_1001)
2020-04-02 05:06:08,788 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block DELETED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:34832
2020-04-02 05:06:08,788 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34832 receiving: 0, received: 0, deleted: 1
2020-04-02 05:06:08,863 [IPC Server handler 2 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=getfileinfo	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,864 [IPC Server handler 7 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,865 [IPC Server handler 7 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,875 [IPC Server handler 3 on 40253] DEBUG blockmanagement.BlockManager (BlockManager.java:createLocatedBlocks(1339)) - blocks = [blk_-9223372036854775792_1001]
2020-04-02 05:06:08,875 [IPC Server handler 3 on 40253] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=open	src=/foo	dst=null	perm=null	proto=rpc
2020-04-02 05:06:08,877 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:08,878 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 9
2020-04-02 05:06:08,878 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45991 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:08,878 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@41de5768] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:08,879 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:08,884 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-cb8d3c49-22c7-4af5-ac61-6be129b8b3ac) exiting.
2020-04-02 05:06:08,887 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-fda3df25-01a3-4c39-9345-25f199e82d5f) exiting.
2020-04-02 05:06:08,977 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4201a617{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:08,979 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42344efe{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:08,979 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4102b1b1{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:08,979 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3f3c966c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:09,012 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45991
2020-04-02 05:06:09,023 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:09,023 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0) service to localhost/127.0.0.1:40253
2020-04-02 05:06:09,023 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 7f5375fd-1e1e-4313-afd5-2014b6a8ffb0)
2020-04-02 05:06:09,023 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:09,047 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,052 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,053 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:09,067 [IPC Server listener on 45991] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45991
2020-04-02 05:06:09,085 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:09,091 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:09,093 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:09,094 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:09,126 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:09,126 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:06:09,126 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33814 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:09,127 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:09,129 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@74d7184a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:09,139 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-e8b34061-86ed-4596-b930-d48d3a3c36e0) exiting.
2020-04-02 05:06:09,139 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-9245e945-5932-42b9-94b7-cdbfb2c9212b) exiting.
2020-04-02 05:06:09,245 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@24b52d3e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:09,246 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@15deb1dc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:09,246 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1a38ba58{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:09,247 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@18e8473e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:09,258 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33814
2020-04-02 05:06:09,383 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:09,383 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 556a9dea-8cbc-413c-968e-471ac319e89c) service to localhost/127.0.0.1:40253
2020-04-02 05:06:09,383 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 556a9dea-8cbc-413c-968e-471ac319e89c)
2020-04-02 05:06:09,383 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:09,385 [IPC Server listener on 33814] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33814
2020-04-02 05:06:09,386 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:09,405 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,425 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,458 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:09,459 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:09,461 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:09,461 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:09,468 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:09,468 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:06:09,469 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40725 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:09,469 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:09,471 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-8f13ebd6-d78f-40fb-bf2f-2665f4b04cf4) exiting.
2020-04-02 05:06:09,474 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@62d363ab] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:09,477 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-0c97531c-3e6e-46b7-96a8-49dc9e8f5178) exiting.
2020-04-02 05:06:09,566 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@63f34b70{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:09,566 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@641856{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:09,567 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e0aadd0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:09,567 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4108fa66{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:09,584 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40725
2020-04-02 05:06:09,608 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:09,608 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 2b3dd053-685c-468b-91ec-266cbdf48622) service to localhost/127.0.0.1:40253
2020-04-02 05:06:09,608 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 2b3dd053-685c-468b-91ec-266cbdf48622)
2020-04-02 05:06:09,608 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:09,609 [IPC Server listener on 40725] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40725
2020-04-02 05:06:09,618 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:09,642 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:09,644 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,654 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,689 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:09,689 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:09,701 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:09,701 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:09,716 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:09,717 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:06:09,717 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45403 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:09,717 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:09,721 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@780ec4a5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:09,730 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-32007c7c-4eb7-4e69-a5c4-678bc7faa25d) exiting.
2020-04-02 05:06:09,731 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-68ef1f6b-900b-425b-bd54-5ad192ac1e55) exiting.
2020-04-02 05:06:09,778 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@410954b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:09,782 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7fb9f71f{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:09,782 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1ee4730{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:09,798 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3dd69f5a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:09,799 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45403
2020-04-02 05:06:09,801 [IPC Server listener on 45403] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45403
2020-04-02 05:06:09,802 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:09,802 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:09,802 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 084895d6-29b8-4e9d-8605-d70653e3ccc2) service to localhost/127.0.0.1:40253
2020-04-02 05:06:09,802 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 084895d6-29b8-4e9d-8605-d70653e3ccc2)
2020-04-02 05:06:09,802 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:09,854 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,871 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:09,891 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:09,891 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:09,912 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:09,912 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:09,946 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:09,946 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:06:09,946 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43241 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:09,946 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:09,947 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4940809c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:09,958 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-c5aed756-c99c-4dd5-a405-e1960059d54b) exiting.
2020-04-02 05:06:09,959 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-976dccca-5683-46d4-adcb-953c4f29b8ba) exiting.
2020-04-02 05:06:10,064 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5db99216{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:10,066 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3ec11999{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:10,066 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@459f7aa3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:10,067 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2c95ac9e{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:10,075 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43241
2020-04-02 05:06:10,088 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:10,088 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:10,088 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 695c8241-88f4-404a-bbed-e96743005a31) service to localhost/127.0.0.1:40253
2020-04-02 05:06:10,089 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 695c8241-88f4-404a-bbed-e96743005a31)
2020-04-02 05:06:10,089 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:10,096 [IPC Server listener on 43241] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43241
2020-04-02 05:06:10,121 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:10,121 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:10,153 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:10,162 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:10,175 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:10,175 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:10,210 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:10,210 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:06:10,210 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40788 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:10,211 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:10,211 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@32fe9d0a] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:10,233 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-e7fee019-8e95-4054-8cff-a3087cf75913) exiting.
2020-04-02 05:06:10,233 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-5154819c-dcb2-4c2e-8979-26b719a52e7f) exiting.
2020-04-02 05:06:10,340 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2a2da905{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:10,346 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@24f360b2{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:10,354 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@21694e53{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:10,355 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3b9d6699{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:10,395 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40788
2020-04-02 05:06:10,484 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:10,484 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid df4788ff-a0ca-46f0-876e-2f10617407dd) service to localhost/127.0.0.1:40253
2020-04-02 05:06:10,485 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid df4788ff-a0ca-46f0-876e-2f10617407dd)
2020-04-02 05:06:10,485 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:10,485 [IPC Server listener on 40788] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40788
2020-04-02 05:06:10,485 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:10,529 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:10,542 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:10,571 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:10,571 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:10,576 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:10,576 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:10,590 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:10,590 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:06:10,590 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43173 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:10,590 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:10,591 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@76a82f33] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:10,603 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-27efd51f-713a-4a53-8ef8-bf26c25ffbd2) exiting.
2020-04-02 05:06:10,605 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-291b14cb-dad8-4b5b-b6b4-e46eb4534755) exiting.
2020-04-02 05:06:10,646 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:10,690 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@a486d78{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:10,693 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@cdc3aae{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:10,694 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62923ee6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:10,694 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7cbee484{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:10,713 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43173
2020-04-02 05:06:10,751 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:10,751 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:10,751 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 65d7ec62-7df3-4aea-a092-96ed63492864) service to localhost/127.0.0.1:40253
2020-04-02 05:06:10,752 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 65d7ec62-7df3-4aea-a092-96ed63492864)
2020-04-02 05:06:10,752 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:10,753 [IPC Server listener on 43173] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43173
2020-04-02 05:06:10,782 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:10,795 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:10,898 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:10,898 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:10,913 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:10,913 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:10,941 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:10,942 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:06:10,942 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43354 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:10,942 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:10,942 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@4a8a60bc] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:10,953 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-e8d0a170-95ab-41d6-9ed1-db660e3e6270) exiting.
2020-04-02 05:06:10,957 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-d0b2c649-7c2f-44ea-b11a-1bb494c5c1f1) exiting.
2020-04-02 05:06:10,986 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2c177f9e{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:10,990 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5db4c359{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:10,991 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4a3e3e8b{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:10,991 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@15a902e7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:11,062 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43354
2020-04-02 05:06:11,134 [IPC Server listener on 43354] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43354
2020-04-02 05:06:11,138 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:11,134 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:11,142 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 01d45740-4e21-4654-83ca-6d32e3ca1f0a) service to localhost/127.0.0.1:40253
2020-04-02 05:06:11,142 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 01d45740-4e21-4654-83ca-6d32e3ca1f0a)
2020-04-02 05:06:11,142 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:11,185 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:11,221 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:11,245 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:11,246 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:11,250 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:11,251 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:11,288 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:11,288 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:11,289 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33832 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:11,289 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:11,289 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1e5f4170] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:11,297 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-5bbf2341-2961-4c29-befb-739dd64564e1) exiting.
2020-04-02 05:06:11,302 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-c4de8663-3d5d-4218-a940-fe05a03be608) exiting.
2020-04-02 05:06:11,426 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6a1d204a{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:11,435 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@62dae245{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:11,436 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5f4d427e{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:11,436 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@f9879ac{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:11,498 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33832
2020-04-02 05:06:11,510 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:11,510 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:11,510 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 964fc2f8-64f9-4638-9cc9-6edd4b859fe4) service to localhost/127.0.0.1:40253
2020-04-02 05:06:11,511 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 964fc2f8-64f9-4638-9cc9-6edd4b859fe4)
2020-04-02 05:06:11,511 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:11,512 [IPC Server listener on 33832] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33832
2020-04-02 05:06:11,549 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:11,580 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:11,580 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:11,581 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:11,590 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:11,591 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:11,592 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:11,592 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:11,592 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44149 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:11,592 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:11,592 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2c9399a4] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:11,603 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-3bd2d739-652f-43b6-bafa-55bbd38d35e9) exiting.
2020-04-02 05:06:11,604 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-81923dbc-f5be-4b79-8b1f-9605f3653621) exiting.
2020-04-02 05:06:11,649 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:11,667 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1d71006f{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:11,674 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5b6813df{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:11,696 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@71e5f61d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:11,696 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@172ca72b{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:11,727 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44149
2020-04-02 05:06:11,737 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 85926ba2-f735-4868-aba2-eb03bdc45514) service to localhost/127.0.0.1:40253
2020-04-02 05:06:11,783 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:11,783 [IPC Server listener on 44149] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44149
2020-04-02 05:06:11,842 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1856199950-172.17.0.13-1585803946960 (Datanode Uuid 85926ba2-f735-4868-aba2-eb03bdc45514)
2020-04-02 05:06:11,842 [BP-1856199950-172.17.0.13-1585803946960 heartbeating to localhost/127.0.0.1:40253] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1856199950-172.17.0.13-1585803946960
2020-04-02 05:06:11,853 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:11,861 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1856199950-172.17.0.13-1585803946960] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:11,872 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:11,872 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:11,884 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:11,884 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:11,885 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:11,886 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:11,886 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 40253 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:11,886 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:11,887 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:06:11,888 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@25e2ab5a] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:11,889 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@35e5d0e5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:11,889 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 193 Number of transactions batched in Syncs: 0 Number of syncs: 10 SyncTimes(ms): 1 1 
2020-04-02 05:06:11,890 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:06:11,891 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:06:11,893 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:11,894 [CacheReplicationMonitor(562268318)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:11,895 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40253
2020-04-02 05:06:11,909 [IPC Server listener on 40253] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40253
2020-04-02 05:06:11,910 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:11,910 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:11,909 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:11,925 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@340da44c] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:12,032 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:12,032 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:12,082 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7fc4780b{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:12,096 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6b58b9e9{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:12,097 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f67a4d3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:12,097 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@565f390{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:12,102 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:12,105 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:12,106 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness#testChooseExcessReplicasToDelete
[msx] writeFile testName = org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness#testChooseExcessReplicasToDelete
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness#testReconstructForNotEnoughRacks
[msx] perform reset as unitTestCounterInClass 1 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:12,164 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:testReconstructForNotEnoughRacks(147)) - cluster hosts: [host1, host2, host3, host4, host5, host6, host7, host8, host9, host10], racks: [/r1, /r1, /r2, /r2, /r3, /r3, /r4, /r4, /r5, /r6]
2020-04-02 05:06:12,165 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=10
Formatting using clusterid: testClusterID
2020-04-02 05:06:12,168 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:12,169 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:12,169 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:12,169 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:12,169 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:12,169 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:12,169 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:12,170 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:12,170 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:12,170 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:06:12,170 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:12,171 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:12,171 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:12
2020-04-02 05:06:12,171 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:12,171 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,171 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:12,171 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:12,317 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:12,320 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:12,341 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:12,348 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:12,349 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:12,350 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:12,350 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:06:12,350 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:12,350 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:12,351 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:12,351 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:12,351 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:12,351 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:12,352 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:12,352 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,352 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:12,358 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:12,370 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:12,372 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:12,372 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:12,372 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:12,373 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:12,373 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:12,373 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:12,373 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,374 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:12,377 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:12,378 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:12,378 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:12,378 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:12,379 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:12,379 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:12,379 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:12,382 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,398 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:12,401 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:12,402 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:12,442 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:12,458 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:12,474 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:12,478 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:12,496 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:06:12,502 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:06:12,512 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:12,514 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:12,520 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:12,526 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:12,527 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:12,527 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:12,528 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:12,563 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:12,563 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:12,565 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:12,565 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1c65121] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:12,566 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:12,566 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:12,567 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:12,568 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:12,568 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:12,568 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:12,569 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:12,570 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:12,570 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42221
2020-04-02 05:06:12,570 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:12,591 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6ac4944a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:12,596 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@39fc6b2c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:12,607 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1db0ec27{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:12,608 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3d9fc57a{HTTP/1.1,[http/1.1]}{localhost:42221}
2020-04-02 05:06:12,608 [main] INFO  server.Server (Server.java:doStart(419)) - Started @28292ms
2020-04-02 05:06:12,610 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:12,611 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:12,611 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:12,611 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:12,611 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:12,611 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:12,611 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:12,611 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:12,612 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:12,612 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:06:12,612 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:12,612 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:12,613 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:12
2020-04-02 05:06:12,613 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:12,613 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,613 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:12,613 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:12,622 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:12,627 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:12,627 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:12,627 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:12,627 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:12,627 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:12,627 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:06:12,627 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:12,628 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:12,628 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:12,628 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:12,628 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:12,628 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:12,629 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:12,629 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,629 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:12,630 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:12,633 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:12,633 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:12,633 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:12,641 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:12,642 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:12,642 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:12,642 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:12,642 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,642 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.9 GB = 4.9 MB
2020-04-02 05:06:12,643 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:12,643 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:12,643 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:12,643 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:12,643 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:12,644 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:12,644 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:12,644 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:12,644 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.9 GB = 603.0 KB
2020-04-02 05:06:12,644 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:12,655 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:12,657 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:12,659 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:12,660 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:12,660 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:12,660 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:12,674 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:12,675 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:12,682 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:12,682 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:12,686 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:12,710 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:12,711 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 66 msecs
2020-04-02 05:06:12,711 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:12,712 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:12,716 [Socket Reader #1 for port 38036] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38036
2020-04-02 05:06:12,725 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:38036 to access this namenode/service.
2020-04-02 05:06:12,726 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:12,787 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:12,788 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@54e81b21] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:06:12,789 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:12,789 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:12,789 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:06:12,789 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:12,805 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:12,805 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:12,835 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:12,835 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:12,835 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:12,835 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:12,835 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 33 msec
2020-04-02 05:06:12,837 [IPC Server listener on 38036] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38036: starting
2020-04-02 05:06:12,838 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:38036
2020-04-02 05:06:12,839 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:12,839 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:12,839 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 0 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:12,840 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 38036 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:12,941 [CacheReplicationMonitor(604009340)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:12,993 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:12,994 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 0 with hostname set to: host1
2020-04-02 05:06:12,996 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host1 to rack /r1
2020-04-02 05:06:13,040 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:13,046 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:13,065 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:13,066 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:13,066 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,066 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:13,069 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1
2020-04-02 05:06:13,070 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,070 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:13,071 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33203
2020-04-02 05:06:13,071 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:13,071 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:13,073 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,074 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:13,080 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:13,081 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,082 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:13,083 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:13,083 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:13,083 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:13,084 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39352
2020-04-02 05:06:13,084 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:13,086 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@64d7b720{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:13,086 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5bb3d42d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:13,090 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@30865a90{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:13,090 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6134ac4a{HTTP/1.1,[http/1.1]}{localhost:39352}
2020-04-02 05:06:13,092 [main] INFO  server.Server (Server.java:doStart(419)) - Started @28775ms
2020-04-02 05:06:13,128 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34959
2020-04-02 05:06:13,129 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:13,129 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:13,129 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73e132e0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:13,130 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:13,131 [Socket Reader #1 for port 34685] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34685
2020-04-02 05:06:13,134 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34685
2020-04-02 05:06:13,152 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:13,155 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:13,157 [Thread-571] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:13,157 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:33203 to rack /r1
2020-04-02 05:06:13,158 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:13,158 [IPC Server listener on 34685] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34685: starting
2020-04-02 05:06:13,159 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34685 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,172 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:13,173 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 1 with hostname set to: host2
2020-04-02 05:06:13,173 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host2 to rack /r1
2020-04-02 05:06:13,174 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:13,175 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:13,192 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:13,192 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:13,192 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,192 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:13,193 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host2
2020-04-02 05:06:13,193 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,193 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:13,193 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37406
2020-04-02 05:06:13,194 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:13,194 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:13,195 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,197 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:13,206 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:13,206 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,207 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:13,208 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:13,208 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:13,208 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:13,209 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40370
2020-04-02 05:06:13,209 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:13,215 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ab9b447{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:13,216 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4f8caaf3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:13,253 [Thread-571] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:13,255 [Thread-571] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:13,261 [Thread-571] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:13,262 [Thread-571] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:13,262 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@53bf7094{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:13,262 [Thread-571] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0b152d58-24a6-420c-ad6a-7f73cf4d3171 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:13,262 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@26f1249d{HTTP/1.1,[http/1.1]}{localhost:40370}
2020-04-02 05:06:13,263 [main] INFO  server.Server (Server.java:doStart(419)) - Started @28947ms
2020-04-02 05:06:13,298 [Thread-571] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:13,298 [Thread-571] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:13,299 [Thread-571] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8a972036-9411-4c36-b97b-2d88eed67424 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:13,318 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45973
2020-04-02 05:06:13,326 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:13,326 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:13,328 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:13,328 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@a68df9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:13,334 [Socket Reader #1 for port 33004] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 33004
2020-04-02 05:06:13,354 [Thread-571] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,354 [Thread-571] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,354 [Thread-571] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:13,358 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:33004
2020-04-02 05:06:13,363 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:13,363 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:13,364 [Thread-595] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:13,364 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:37406 to rack /r1
2020-04-02 05:06:13,391 [Thread-571] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:13,410 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:13,410 [IPC Server listener on 33004] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 33004: starting
2020-04-02 05:06:13,377 [Thread-595] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:13,417 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 33004 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,418 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:13,418 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 2 with hostname set to: host3
2020-04-02 05:06:13,418 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host3 to rack /r2
2020-04-02 05:06:13,419 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:13,419 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:13,478 [Thread-571] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,480 [Thread-571] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,478 [Thread-595] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:13,481 [Thread-571] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:13,482 [Thread-571] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:13,483 [Thread-595] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:13,483 [Thread-595] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:13,483 [Thread-595] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0a75c363-880f-40b8-af71-017fdd589f4d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:06:13,488 [Thread-595] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:13,488 [Thread-595] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:13,488 [Thread-595] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-420b4f4f-b924-4a7a-8ecd-6af6132cf010 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:06:13,499 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:13,499 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:13,500 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,500 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:13,500 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host3
2020-04-02 05:06:13,500 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,500 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:13,501 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36674
2020-04-02 05:06:13,501 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:13,501 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:13,504 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,506 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:13,506 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:13,506 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,507 [Thread-595] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,507 [Thread-595] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,507 [Thread-595] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:13,507 [Thread-595] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:13,507 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:13,508 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:13,508 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:13,508 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:13,508 [Thread-571] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:13,508 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 39363
2020-04-02 05:06:13,509 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:13,512 [Thread-571] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 2047b1a2-0248-4bab-9b75-1a8bd68dad42
2020-04-02 05:06:13,514 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1929425f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:13,517 [Thread-571] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0b152d58-24a6-420c-ad6a-7f73cf4d3171
2020-04-02 05:06:13,523 [Thread-571] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:06:13,526 [Thread-571] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8a972036-9411-4c36-b97b-2d88eed67424
2020-04-02 05:06:13,526 [Thread-571] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:13,527 [Thread-571] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:13,528 [Thread-571] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:13,529 [Thread-571] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:13,529 [Thread-571] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:13,533 [Thread-571] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:13,567 [Thread-571] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,568 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27f3b6d6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:13,578 [Thread-614] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:13,583 [Thread-615] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:13,585 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@7da10b5b{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:13,589 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@219f4597{HTTP/1.1,[http/1.1]}{localhost:39363}
2020-04-02 05:06:13,604 [main] INFO  server.Server (Server.java:doStart(419)) - Started @29288ms
2020-04-02 05:06:13,586 [Thread-595] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,604 [Thread-595] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,605 [Thread-595] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:13,605 [Thread-595] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:13,639 [Thread-614] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 61ms
2020-04-02 05:06:13,652 [Thread-595] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:13,666 [Thread-595] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 18b1e12e-d15f-4706-9fc5-77c30f1a842d
2020-04-02 05:06:13,666 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42357
2020-04-02 05:06:13,667 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:13,667 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:13,668 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:13,668 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2e16b08d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:13,668 [Thread-615] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 86ms
2020-04-02 05:06:13,669 [Thread-571] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 102ms
2020-04-02 05:06:13,669 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0a75c363-880f-40b8-af71-017fdd589f4d
2020-04-02 05:06:13,670 [Thread-595] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:06:13,671 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-420b4f4f-b924-4a7a-8ecd-6af6132cf010
2020-04-02 05:06:13,671 [Thread-595] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:06:13,672 [Thread-595] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:13,673 [Thread-595] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:13,673 [Thread-621] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:13,673 [Thread-621] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:13,678 [Thread-621] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 5ms
2020-04-02 05:06:13,678 [Thread-623] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:13,678 [Thread-623] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:13,678 [Thread-623] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 1ms
2020-04-02 05:06:13,679 [Thread-595] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:13,679 [Thread-595] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:13,679 [Thread-595] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:13,694 [Thread-571] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 25ms
2020-04-02 05:06:13,694 [Thread-571] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:25 AM with interval of 21600000ms
2020-04-02 05:06:13,704 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44895
2020-04-02 05:06:13,703 [Thread-595] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,702 [Socket Reader #1 for port 44895] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44895
2020-04-02 05:06:13,715 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:13,715 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:13,715 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-8a972036-9411-4c36-b97b-2d88eed67424): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,716 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-8a972036-9411-4c36-b97b-2d88eed67424): no suitable block pools found to scan.  Waiting 1814399978 ms.
2020-04-02 05:06:13,716 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0b152d58-24a6-420c-ad6a-7f73cf4d3171): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,717 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0b152d58-24a6-420c-ad6a-7f73cf4d3171): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-04-02 05:06:13,718 [Thread-629] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:06:13,721 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:13,722 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:13,722 [Thread-633] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:13,722 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:36674 to rack /r2
2020-04-02 05:06:13,740 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:06:13,733 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 2047b1a2-0248-4bab-9b75-1a8bd68dad42) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:13,760 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44895 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:13,759 [IPC Server listener on 44895] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44895: starting
2020-04-02 05:06:13,759 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:13,764 [IPC Server handler 3 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33203, datanodeUuid=2047b1a2-0248-4bab-9b75-1a8bd68dad42, infoPort=34959, infoSecurePort=0, ipcPort=34685, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage 2047b1a2-0248-4bab-9b75-1a8bd68dad42
2020-04-02 05:06:13,767 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:13,767 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 3 with hostname set to: host4
2020-04-02 05:06:13,767 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host4 to rack /r2
2020-04-02 05:06:13,768 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:06:13,768 [IPC Server handler 3 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:33203
2020-04-02 05:06:13,768 [IPC Server handler 3 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 2047b1a2-0248-4bab-9b75-1a8bd68dad42 (127.0.0.1:33203).
2020-04-02 05:06:13,777 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:13,781 [Thread-629] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 63ms
2020-04-02 05:06:13,784 [Thread-633] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:13,785 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:13,785 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:13,847 [Thread-633] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:13,854 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,855 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:13,855 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host4
2020-04-02 05:06:13,855 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:13,858 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:13,858 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:38484
2020-04-02 05:06:13,858 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:13,858 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:13,864 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,867 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 2047b1a2-0248-4bab-9b75-1a8bd68dad42) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:13,867 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:13,867 [Thread-633] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:13,868 [Thread-633] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:13,868 [Thread-633] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6f25a350-f34c-45bf-b18b-4c952a30f504 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:06:13,872 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:13,886 [Thread-633] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:13,886 [Thread-633] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:13,886 [Thread-633] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a4999444-6a44-4c7d-9632-4297bde8079e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:06:13,906 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:13,907 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:13,910 [Thread-630] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 148ms
2020-04-02 05:06:13,910 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 195ms
2020-04-02 05:06:13,915 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:13,916 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:13,916 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:13,916 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:13,917 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34735
2020-04-02 05:06:13,917 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:13,919 [Thread-633] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,920 [Thread-633] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,920 [Thread-633] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:13,920 [Thread-633] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:13,921 [Thread-649] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:06:13,921 [Thread-649] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:13,950 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:13,953 [Thread-651] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:06:13,953 [Thread-651] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:13,954 [Thread-651] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 1ms
2020-04-02 05:06:13,959 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f34a967{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:13,960 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1d8e2eea{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:13,974 [IPC Server handler 0 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0b152d58-24a6-420c-ad6a-7f73cf4d3171 for DN 127.0.0.1:33203
2020-04-02 05:06:13,978 [Thread-649] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 57ms
2020-04-02 05:06:13,981 [Thread-595] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 72ms
2020-04-02 05:06:13,982 [Thread-595] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:35 AM with interval of 21600000ms
2020-04-02 05:06:13,982 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:13,983 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0a75c363-880f-40b8-af71-017fdd589f4d): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,983 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0a75c363-880f-40b8-af71-017fdd589f4d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:13,983 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:13,983 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-420b4f4f-b924-4a7a-8ecd-6af6132cf010): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,984 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-420b4f4f-b924-4a7a-8ecd-6af6132cf010): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:06:13,985 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 18b1e12e-d15f-4706-9fc5-77c30f1a842d) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:13,989 [Thread-633] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,989 [Thread-633] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:13,989 [IPC Server handler 0 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8a972036-9411-4c36-b97b-2d88eed67424 for DN 127.0.0.1:33203
2020-04-02 05:06:13,989 [Thread-633] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:13,990 [Thread-633] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:13,996 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2577d6c8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:13,999 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3163987e{HTTP/1.1,[http/1.1]}{localhost:34735}
2020-04-02 05:06:14,000 [main] INFO  server.Server (Server.java:doStart(419)) - Started @29684ms
2020-04-02 05:06:13,997 [IPC Server handler 2 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33203, datanodeUuid=2047b1a2-0248-4bab-9b75-1a8bd68dad42, infoPort=34959, infoSecurePort=0, ipcPort=34685, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:14,001 [IPC Server handler 1 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37406, datanodeUuid=18b1e12e-d15f-4706-9fc5-77c30f1a842d, infoPort=45973, infoSecurePort=0, ipcPort=33004, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage 18b1e12e-d15f-4706-9fc5-77c30f1a842d
2020-04-02 05:06:14,002 [IPC Server handler 1 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:37406
2020-04-02 05:06:14,002 [IPC Server handler 1 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 18b1e12e-d15f-4706-9fc5-77c30f1a842d (127.0.0.1:37406).
2020-04-02 05:06:13,997 [Thread-633] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:14,002 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x20b54e670a85781e: Processing first storage report for DS-8a972036-9411-4c36-b97b-2d88eed67424 from datanode 2047b1a2-0248-4bab-9b75-1a8bd68dad42
2020-04-02 05:06:14,003 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x20b54e670a85781e: from storage DS-8a972036-9411-4c36-b97b-2d88eed67424 node DatanodeRegistration(127.0.0.1:33203, datanodeUuid=2047b1a2-0248-4bab-9b75-1a8bd68dad42, infoPort=34959, infoSecurePort=0, ipcPort=34685, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:14,003 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 18b1e12e-d15f-4706-9fc5-77c30f1a842d) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:14,003 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:14,004 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x20b54e670a85781e: Processing first storage report for DS-0b152d58-24a6-420c-ad6a-7f73cf4d3171 from datanode 2047b1a2-0248-4bab-9b75-1a8bd68dad42
2020-04-02 05:06:14,004 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x20b54e670a85781e: from storage DS-0b152d58-24a6-420c-ad6a-7f73cf4d3171 node DatanodeRegistration(127.0.0.1:33203, datanodeUuid=2047b1a2-0248-4bab-9b75-1a8bd68dad42, infoPort=34959, infoSecurePort=0, ipcPort=34685, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:14,004 [IPC Server handler 2 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x20b54e670a85781e
2020-04-02 05:06:14,010 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x20b54e670a85781e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 15 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:14,011 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,018 [Thread-633] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5c029312-1ed1-4153-bc14-151f396cd82e
2020-04-02 05:06:14,022 [IPC Server handler 9 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0a75c363-880f-40b8-af71-017fdd589f4d for DN 127.0.0.1:37406
2020-04-02 05:06:14,022 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39424
2020-04-02 05:06:14,025 [Thread-633] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6f25a350-f34c-45bf-b18b-4c952a30f504
2020-04-02 05:06:14,029 [Thread-633] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:06:14,029 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:14,029 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:14,030 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:14,029 [IPC Server handler 9 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-420b4f4f-b924-4a7a-8ecd-6af6132cf010 for DN 127.0.0.1:37406
2020-04-02 05:06:14,031 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@44f9779c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:14,031 [Thread-633] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a4999444-6a44-4c7d-9632-4297bde8079e
2020-04-02 05:06:14,031 [Thread-633] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:06:14,032 [Thread-633] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:14,032 [IPC Server handler 8 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37406, datanodeUuid=18b1e12e-d15f-4706-9fc5-77c30f1a842d, infoPort=45973, infoSecurePort=0, ipcPort=33004, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:14,032 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2f5bbfb4e5d9cf1b: Processing first storage report for DS-420b4f4f-b924-4a7a-8ecd-6af6132cf010 from datanode 18b1e12e-d15f-4706-9fc5-77c30f1a842d
2020-04-02 05:06:14,032 [Socket Reader #1 for port 42206] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 42206
2020-04-02 05:06:14,032 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2f5bbfb4e5d9cf1b: from storage DS-420b4f4f-b924-4a7a-8ecd-6af6132cf010 node DatanodeRegistration(127.0.0.1:37406, datanodeUuid=18b1e12e-d15f-4706-9fc5-77c30f1a842d, infoPort=45973, infoSecurePort=0, ipcPort=33004, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:14,033 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x2f5bbfb4e5d9cf1b: Processing first storage report for DS-0a75c363-880f-40b8-af71-017fdd589f4d from datanode 18b1e12e-d15f-4706-9fc5-77c30f1a842d
2020-04-02 05:06:14,033 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x2f5bbfb4e5d9cf1b: from storage DS-0a75c363-880f-40b8-af71-017fdd589f4d node DatanodeRegistration(127.0.0.1:37406, datanodeUuid=18b1e12e-d15f-4706-9fc5-77c30f1a842d, infoPort=45973, infoSecurePort=0, ipcPort=33004, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:14,033 [IPC Server handler 8 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x2f5bbfb4e5d9cf1b
2020-04-02 05:06:14,033 [Thread-633] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:14,038 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x2f5bbfb4e5d9cf1b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 7 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:14,038 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,042 [Thread-633] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:14,042 [Thread-633] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:14,043 [Thread-633] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:14,061 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:42206
2020-04-02 05:06:14,063 [Thread-633] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,067 [Thread-663] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:06:14,068 [Thread-664] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:06:14,096 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:14,096 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:14,097 [Thread-669] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:14,102 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:38484 to rack /r2
2020-04-02 05:06:14,102 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:14,102 [IPC Server listener on 42206] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 42206: starting
2020-04-02 05:06:14,103 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 42206 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:14,104 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:14,104 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 4 with hostname set to: host5
2020-04-02 05:06:14,104 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host5 to rack /r3
2020-04-02 05:06:14,105 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:06:14,105 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:14,106 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:14,106 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:14,107 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:14,107 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:14,107 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host5
2020-04-02 05:06:14,107 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:14,108 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:14,108 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33541
2020-04-02 05:06:14,108 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:14,108 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:14,111 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:14,113 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:14,114 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:14,114 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:14,121 [Thread-663] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 54ms
2020-04-02 05:06:14,146 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:14,147 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:14,147 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:14,147 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:14,148 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40630
2020-04-02 05:06:14,148 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:14,163 [Thread-669] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:14,165 [Thread-669] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:14,174 [Thread-669] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:14,174 [Thread-669] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:14,175 [Thread-669] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-c37adb17-7d66-4a8c-9bdd-e13da2a362b1 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:06:14,179 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@d2387c8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:14,187 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1500e009{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:14,191 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5bdaf2ce{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:14,192 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42d236fb{HTTP/1.1,[http/1.1]}{localhost:40630}
2020-04-02 05:06:14,192 [main] INFO  server.Server (Server.java:doStart(419)) - Started @29876ms
2020-04-02 05:06:14,193 [Thread-669] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:14,194 [Thread-669] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:14,194 [Thread-669] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d848e0c6-36e8-4cb1-b11d-8e2be0adaf15 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:06:14,200 [Thread-664] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 133ms
2020-04-02 05:06:14,201 [Thread-633] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 138ms
2020-04-02 05:06:14,202 [Thread-686] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:06:14,202 [Thread-686] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:14,202 [Thread-686] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-04-02 05:06:14,241 [Thread-687] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:06:14,241 [Thread-687] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:14,252 [Thread-687] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 11ms
2020-04-02 05:06:14,252 [Thread-633] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 51ms
2020-04-02 05:06:14,252 [Thread-633] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:07 AM with interval of 21600000ms
2020-04-02 05:06:14,253 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:14,253 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:14,254 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a4999444-6a44-4c7d-9632-4297bde8079e): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,254 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6f25a350-f34c-45bf-b18b-4c952a30f504): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,254 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a4999444-6a44-4c7d-9632-4297bde8079e): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:06:14,255 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6f25a350-f34c-45bf-b18b-4c952a30f504): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:06:14,253 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:39221
2020-04-02 05:06:14,258 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:14,258 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:14,258 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:14,259 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@19f21b6b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:14,259 [Socket Reader #1 for port 43523] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43523
2020-04-02 05:06:14,262 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43523
2020-04-02 05:06:14,291 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,291 [Thread-669] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,291 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:14,291 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:14,292 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 5c029312-1ed1-4153-bc14-151f396cd82e) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:14,298 [IPC Server handler 6 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36674, datanodeUuid=5c029312-1ed1-4153-bc14-151f396cd82e, infoPort=42357, infoSecurePort=0, ipcPort=44895, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage 5c029312-1ed1-4153-bc14-151f396cd82e
2020-04-02 05:06:14,298 [IPC Server handler 6 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:36674
2020-04-02 05:06:14,299 [IPC Server handler 6 on 38036] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:checkIfClusterIsNowMultiRack(1386)) - DN 127.0.0.1:36674 joining cluster has expanded a formerly single-rack cluster to be multi-rack. Re-checking all blocks for replication, since they should now be replicated cross-rack
2020-04-02 05:06:14,299 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:14,299 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:14,302 [Thread-698] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:14,302 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:33541 to rack /r3
2020-04-02 05:06:14,303 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:14,303 [IPC Server listener on 43523] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43523: starting
2020-04-02 05:06:14,304 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43523 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:14,305 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:14,305 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 5 with hostname set to: host6
2020-04-02 05:06:14,305 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host6 to rack /r3
2020-04-02 05:06:14,306 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:06:14,313 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:14,344 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,344 [Thread-669] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,344 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:14,344 [Thread-669] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:14,349 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:14,349 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:14,353 [IPC Server handler 6 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5c029312-1ed1-4153-bc14-151f396cd82e (127.0.0.1:36674).
2020-04-02 05:06:14,354 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 5c029312-1ed1-4153-bc14-151f396cd82e) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:14,355 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:14,358 [Thread-669] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:14,359 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:14,359 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:14,359 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:14,359 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:14,359 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:14,359 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2020-04-02 05:06:14,378 [Thread-698] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:14,382 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:14,382 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:14,382 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host6
2020-04-02 05:06:14,382 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:14,382 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:14,383 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37939
2020-04-02 05:06:14,383 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:14,383 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:14,384 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:14,385 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:14,393 [Thread-698] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:14,394 [Thread-669] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a5efa792-723c-4068-901e-e38ee351ef30
2020-04-02 05:06:14,394 [IPC Server handler 4 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f25a350-f34c-45bf-b18b-4c952a30f504 for DN 127.0.0.1:36674
2020-04-02 05:06:14,394 [IPC Server handler 4 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a4999444-6a44-4c7d-9632-4297bde8079e for DN 127.0.0.1:36674
2020-04-02 05:06:14,395 [Thread-698] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:14,396 [Thread-698] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:14,396 [Thread-698] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-107e4a4d-7a98-4345-ac58-2d5c79e493aa for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:06:14,398 [IPC Server handler 3 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36674, datanodeUuid=5c029312-1ed1-4153-bc14-151f396cd82e, infoPort=42357, infoSecurePort=0, ipcPort=44895, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:14,398 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:14,398 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:14,399 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:14,399 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:14,400 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:14,400 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:14,400 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46107
2020-04-02 05:06:14,400 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:14,398 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6ba0bb2de72625b: Processing first storage report for DS-a4999444-6a44-4c7d-9632-4297bde8079e from datanode 5c029312-1ed1-4153-bc14-151f396cd82e
2020-04-02 05:06:14,402 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6ba0bb2de72625b: from storage DS-a4999444-6a44-4c7d-9632-4297bde8079e node DatanodeRegistration(127.0.0.1:36674, datanodeUuid=5c029312-1ed1-4153-bc14-151f396cd82e, infoPort=42357, infoSecurePort=0, ipcPort=44895, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 4 msecs, invalidatedBlocks: 0
2020-04-02 05:06:14,401 [Thread-698] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:14,402 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@b0964b2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:14,402 [Thread-698] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:14,403 [Thread-698] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ef2825cc-f5eb-465c-9fd4-76c8eb930a1d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:06:14,403 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f4037ed{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:14,406 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x6ba0bb2de72625b: Processing first storage report for DS-6f25a350-f34c-45bf-b18b-4c952a30f504 from datanode 5c029312-1ed1-4153-bc14-151f396cd82e
2020-04-02 05:06:14,406 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x6ba0bb2de72625b: from storage DS-6f25a350-f34c-45bf-b18b-4c952a30f504 node DatanodeRegistration(127.0.0.1:36674, datanodeUuid=5c029312-1ed1-4153-bc14-151f396cd82e, infoPort=42357, infoSecurePort=0, ipcPort=44895, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:14,406 [IPC Server handler 3 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x6ba0bb2de72625b
2020-04-02 05:06:14,407 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x6ba0bb2de72625b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 11 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:14,407 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,436 [Thread-698] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,441 [Thread-698] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,438 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29006752{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:14,443 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@470a9030{HTTP/1.1,[http/1.1]}{localhost:46107}
2020-04-02 05:06:14,443 [main] INFO  server.Server (Server.java:doStart(419)) - Started @30127ms
2020-04-02 05:06:14,451 [Thread-698] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:14,451 [Thread-698] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:14,452 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-c37adb17-7d66-4a8c-9bdd-e13da2a362b1
2020-04-02 05:06:14,460 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:06:14,462 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d848e0c6-36e8-4cb1-b11d-8e2be0adaf15
2020-04-02 05:06:14,486 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:06:14,486 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:14,528 [Thread-669] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:06:14,529 [Thread-669] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:06:14,529 [Thread-669] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:14,529 [Thread-669] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:14,535 [Thread-698] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,535 [Thread-698] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,535 [Thread-698] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:14,535 [Thread-698] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:14,537 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:36418
2020-04-02 05:06:14,538 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:14,539 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:14,539 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:14,540 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@27494e46] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:14,540 [Socket Reader #1 for port 35233] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35233
2020-04-02 05:06:14,543 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35233
2020-04-02 05:06:14,570 [Thread-698] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:14,573 [Thread-669] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,574 [Thread-721] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:06:14,575 [Thread-722] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:06:14,579 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:14,580 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:14,582 [Thread-725] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:14,582 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:37939 to rack /r3
2020-04-02 05:06:14,583 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:14,583 [IPC Server listener on 35233] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35233: starting
2020-04-02 05:06:14,584 [Thread-698] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID e734c7f8-e260-4a32-81ca-cb5f6a5e9d01
2020-04-02 05:06:14,591 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35233 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:14,592 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:14,592 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 6 with hostname set to: host7
2020-04-02 05:06:14,592 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host7 to rack /r4
2020-04-02 05:06:14,593 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:06:14,594 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:14,610 [Thread-725] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:14,614 [Thread-725] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:14,618 [Thread-725] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:14,642 [Thread-725] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:14,643 [Thread-725] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-7ce1b737-0eee-4f00-839c-4fec5e166377 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:06:14,622 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-107e4a4d-7a98-4345-ac58-2d5c79e493aa
2020-04-02 05:06:14,644 [Thread-698] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:06:14,621 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:14,644 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:14,645 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:14,645 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:14,645 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host7
2020-04-02 05:06:14,646 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:14,646 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:14,646 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:40403
2020-04-02 05:06:14,646 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:14,646 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:14,650 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:14,669 [Thread-725] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:14,729 [Thread-722] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 154ms
2020-04-02 05:06:14,712 [Thread-721] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 139ms
2020-04-02 05:06:14,695 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:14,673 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ef2825cc-f5eb-465c-9fd4-76c8eb930a1d
2020-04-02 05:06:14,734 [Thread-698] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:06:14,735 [Thread-698] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:14,735 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:14,735 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:14,736 [Thread-698] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:06:14,737 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:14,733 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 161ms
2020-04-02 05:06:14,737 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:14,737 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:14,737 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:14,738 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33368
2020-04-02 05:06:14,738 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:14,730 [Thread-725] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:14,739 [Thread-725] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-2adfadcc-fe85-46cc-a9fd-fcfeef7eb8bf for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:06:14,740 [Thread-698] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:06:14,741 [Thread-698] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:14,741 [Thread-698] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:14,743 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4fcc529{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:14,743 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4beddc56{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:14,748 [Thread-743] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:06:14,748 [Thread-743] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:14,749 [Thread-743] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-04-02 05:06:14,760 [Thread-725] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,760 [Thread-725] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,760 [Thread-725] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:14,760 [Thread-725] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:14,761 [Thread-747] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:06:14,761 [Thread-747] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:14,761 [Thread-747] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 0ms
2020-04-02 05:06:14,782 [Thread-669] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 45ms
2020-04-02 05:06:14,783 [Thread-669] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:23 AM with interval of 21600000ms
2020-04-02 05:06:14,783 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:06:14,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c37adb17-7d66-4a8c-9bdd-e13da2a362b1): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c37adb17-7d66-4a8c-9bdd-e13da2a362b1): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:14,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:14,784 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-d848e0c6-36e8-4cb1-b11d-8e2be0adaf15): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,785 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-d848e0c6-36e8-4cb1-b11d-8e2be0adaf15): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:06:14,786 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3cc20577{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:14,806 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid a5efa792-723c-4068-901e-e38ee351ef30) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:14,814 [Thread-698] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,815 [Thread-751] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:06:14,817 [Thread-752] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:06:14,834 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@33a630fa{HTTP/1.1,[http/1.1]}{localhost:33368}
2020-04-02 05:06:14,874 [main] INFO  server.Server (Server.java:doStart(419)) - Started @30558ms
2020-04-02 05:06:14,882 [IPC Server handler 1 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:38484, datanodeUuid=a5efa792-723c-4068-901e-e38ee351ef30, infoPort=39424, infoSecurePort=0, ipcPort=42206, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage a5efa792-723c-4068-901e-e38ee351ef30
2020-04-02 05:06:14,883 [IPC Server handler 1 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:38484
2020-04-02 05:06:14,883 [IPC Server handler 1 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a5efa792-723c-4068-901e-e38ee351ef30 (127.0.0.1:38484).
2020-04-02 05:06:14,884 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid a5efa792-723c-4068-901e-e38ee351ef30) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:14,884 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:14,886 [Thread-725] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,887 [Thread-725] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,903 [IPC Server handler 2 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-c37adb17-7d66-4a8c-9bdd-e13da2a362b1 for DN 127.0.0.1:38484
2020-04-02 05:06:14,914 [IPC Server handler 2 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d848e0c6-36e8-4cb1-b11d-8e2be0adaf15 for DN 127.0.0.1:38484
2020-04-02 05:06:14,919 [Thread-725] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:14,919 [Thread-725] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:14,922 [IPC Server handler 9 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:38484, datanodeUuid=a5efa792-723c-4068-901e-e38ee351ef30, infoPort=39424, infoSecurePort=0, ipcPort=42206, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:14,922 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xeb8f7e8dca6ee89b: Processing first storage report for DS-d848e0c6-36e8-4cb1-b11d-8e2be0adaf15 from datanode a5efa792-723c-4068-901e-e38ee351ef30
2020-04-02 05:06:14,922 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xeb8f7e8dca6ee89b: from storage DS-d848e0c6-36e8-4cb1-b11d-8e2be0adaf15 node DatanodeRegistration(127.0.0.1:38484, datanodeUuid=a5efa792-723c-4068-901e-e38ee351ef30, infoPort=39424, infoSecurePort=0, ipcPort=42206, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:14,923 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xeb8f7e8dca6ee89b: Processing first storage report for DS-c37adb17-7d66-4a8c-9bdd-e13da2a362b1 from datanode a5efa792-723c-4068-901e-e38ee351ef30
2020-04-02 05:06:14,923 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xeb8f7e8dca6ee89b: from storage DS-c37adb17-7d66-4a8c-9bdd-e13da2a362b1 node DatanodeRegistration(127.0.0.1:38484, datanodeUuid=a5efa792-723c-4068-901e-e38ee351ef30, infoPort=39424, infoSecurePort=0, ipcPort=42206, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:14,923 [IPC Server handler 9 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xeb8f7e8dca6ee89b
2020-04-02 05:06:14,924 [Thread-725] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:14,924 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xeb8f7e8dca6ee89b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:14,924 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,933 [Thread-751] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 117ms
2020-04-02 05:06:14,934 [Thread-725] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e
2020-04-02 05:06:14,933 [Thread-752] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 116ms
2020-04-02 05:06:14,951 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 137ms
2020-04-02 05:06:14,951 [Thread-725] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-7ce1b737-0eee-4f00-839c-4fec5e166377
2020-04-02 05:06:14,958 [Thread-725] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:06:14,958 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:14,970 [Thread-756] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:06:14,970 [Thread-756] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:14,974 [Thread-757] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:06:14,974 [Thread-756] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 4ms
2020-04-02 05:06:14,974 [Thread-757] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:14,974 [Thread-757] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 1ms
2020-04-02 05:06:14,977 [Thread-698] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 27ms
2020-04-02 05:06:14,977 [Thread-725] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-2adfadcc-fe85-46cc-a9fd-fcfeef7eb8bf
2020-04-02 05:06:14,978 [Thread-725] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:06:14,978 [Thread-698] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:42 AM with interval of 21600000ms
2020-04-02 05:06:14,978 [Thread-725] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:14,979 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:06:14,981 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:14,981 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid e734c7f8-e260-4a32-81ca-cb5f6a5e9d01) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:14,982 [IPC Server handler 8 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33541, datanodeUuid=e734c7f8-e260-4a32-81ca-cb5f6a5e9d01, infoPort=39221, infoSecurePort=0, ipcPort=43523, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage e734c7f8-e260-4a32-81ca-cb5f6a5e9d01
2020-04-02 05:06:14,983 [Thread-725] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:06:14,983 [IPC Server handler 8 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:33541
2020-04-02 05:06:14,983 [IPC Server handler 8 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN e734c7f8-e260-4a32-81ca-cb5f6a5e9d01 (127.0.0.1:33541).
2020-04-02 05:06:14,983 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-ef2825cc-f5eb-465c-9fd4-76c8eb930a1d): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,984 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-ef2825cc-f5eb-465c-9fd4-76c8eb930a1d): no suitable block pools found to scan.  Waiting 1814399994 ms.
2020-04-02 05:06:14,986 [Thread-725] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:06:14,986 [Thread-725] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:14,986 [Thread-725] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:14,986 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-107e4a4d-7a98-4345-ac58-2d5c79e493aa): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:14,987 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-107e4a4d-7a98-4345-ac58-2d5c79e493aa): no suitable block pools found to scan.  Waiting 1814399991 ms.
2020-04-02 05:06:15,006 [Thread-725] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,010 [Thread-762] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:06:15,012 [Thread-763] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:06:15,014 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid e734c7f8-e260-4a32-81ca-cb5f6a5e9d01) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:15,014 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:15,023 [IPC Server handler 7 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-107e4a4d-7a98-4345-ac58-2d5c79e493aa for DN 127.0.0.1:33541
2020-04-02 05:06:15,023 [IPC Server handler 7 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ef2825cc-f5eb-465c-9fd4-76c8eb930a1d for DN 127.0.0.1:33541
2020-04-02 05:06:15,026 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33211
2020-04-02 05:06:15,027 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:15,027 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:15,028 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:15,028 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@5767b2af] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:15,029 [Socket Reader #1 for port 34186] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34186
2020-04-02 05:06:15,035 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34186
2020-04-02 05:06:15,039 [IPC Server handler 6 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33541, datanodeUuid=e734c7f8-e260-4a32-81ca-cb5f6a5e9d01, infoPort=39221, infoSecurePort=0, ipcPort=43523, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:15,040 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:15,040 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:15,053 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7cd001fb4abd8300: Processing first storage report for DS-ef2825cc-f5eb-465c-9fd4-76c8eb930a1d from datanode e734c7f8-e260-4a32-81ca-cb5f6a5e9d01
2020-04-02 05:06:15,053 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7cd001fb4abd8300: from storage DS-ef2825cc-f5eb-465c-9fd4-76c8eb930a1d node DatanodeRegistration(127.0.0.1:33541, datanodeUuid=e734c7f8-e260-4a32-81ca-cb5f6a5e9d01, infoPort=39221, infoSecurePort=0, ipcPort=43523, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 11 msecs, invalidatedBlocks: 0
2020-04-02 05:06:15,054 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:40403 to rack /r4
2020-04-02 05:06:15,054 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:15,054 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7cd001fb4abd8300: Processing first storage report for DS-107e4a4d-7a98-4345-ac58-2d5c79e493aa from datanode e734c7f8-e260-4a32-81ca-cb5f6a5e9d01
2020-04-02 05:06:15,055 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7cd001fb4abd8300: from storage DS-107e4a4d-7a98-4345-ac58-2d5c79e493aa node DatanodeRegistration(127.0.0.1:33541, datanodeUuid=e734c7f8-e260-4a32-81ca-cb5f6a5e9d01, infoPort=39221, infoSecurePort=0, ipcPort=43523, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:15,055 [IPC Server handler 6 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x7cd001fb4abd8300
2020-04-02 05:06:15,056 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x7cd001fb4abd8300,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 31 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:15,056 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,055 [IPC Server listener on 34186] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34186: starting
2020-04-02 05:06:15,059 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34186 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:15,060 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:15,060 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 7 with hostname set to: host8
2020-04-02 05:06:15,060 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host8 to rack /r4
2020-04-02 05:06:15,061 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:06:15,069 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:15,122 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:15,126 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:15,126 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,126 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:15,127 [Thread-770] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:15,129 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host8
2020-04-02 05:06:15,129 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,129 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:15,134 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46847
2020-04-02 05:06:15,134 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:15,134 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:15,142 [Thread-763] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 130ms
2020-04-02 05:06:15,143 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,144 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:15,145 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:15,145 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,146 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:15,147 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:15,147 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:15,147 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:15,148 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 46662
2020-04-02 05:06:15,148 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:15,149 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3249a1ce{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:15,150 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2f4919b0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:15,162 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@28486680{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:15,163 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4d7e7435{HTTP/1.1,[http/1.1]}{localhost:46662}
2020-04-02 05:06:15,163 [main] INFO  server.Server (Server.java:doStart(419)) - Started @30847ms
2020-04-02 05:06:15,172 [Thread-770] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:15,194 [Thread-770] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:15,228 [Thread-770] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:15,228 [Thread-770] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:15,229 [Thread-770] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-882e2d6c-af1a-40c6-b9e2-3e387a900e42 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:06:15,229 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:32897
2020-04-02 05:06:15,230 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:15,230 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:15,230 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:15,232 [Thread-762] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 222ms
2020-04-02 05:06:15,233 [Thread-725] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 228ms
2020-04-02 05:06:15,235 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6e78fcf5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:15,235 [Socket Reader #1 for port 43255] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43255
2020-04-02 05:06:15,240 [Thread-770] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:15,240 [Thread-770] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:15,241 [Thread-770] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ede2c325-0118-475b-85a1-6734c11df769 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:06:15,241 [Thread-791] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:06:15,241 [Thread-791] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:15,241 [Thread-791] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 1ms
2020-04-02 05:06:15,242 [Thread-794] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:06:15,242 [Thread-794] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:15,242 [Thread-794] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-04-02 05:06:15,242 [Thread-725] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 8ms
2020-04-02 05:06:15,243 [Thread-725] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 9:42 AM with interval of 21600000ms
2020-04-02 05:06:15,243 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43255
2020-04-02 05:06:15,243 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:06:15,243 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-7ce1b737-0eee-4f00-839c-4fec5e166377): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,244 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:15,244 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-7ce1b737-0eee-4f00-839c-4fec5e166377): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:15,244 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-2adfadcc-fe85-46cc-a9fd-fcfeef7eb8bf): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,245 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-2adfadcc-fe85-46cc-a9fd-fcfeef7eb8bf): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:06:15,255 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:15,256 [IPC Server handler 4 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37939, datanodeUuid=d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e, infoPort=36418, infoSecurePort=0, ipcPort=35233, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e
2020-04-02 05:06:15,257 [IPC Server handler 4 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:37939
2020-04-02 05:06:15,257 [IPC Server handler 4 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e (127.0.0.1:37939).
2020-04-02 05:06:15,258 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:15,258 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:15,299 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:15,299 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:15,301 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:46847 to rack /r4
2020-04-02 05:06:15,302 [Thread-800] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:15,303 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:15,303 [IPC Server listener on 43255] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43255: starting
2020-04-02 05:06:15,334 [IPC Server handler 3 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-7ce1b737-0eee-4f00-839c-4fec5e166377 for DN 127.0.0.1:37939
2020-04-02 05:06:15,334 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43255 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:15,335 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:15,337 [IPC Server handler 3 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-2adfadcc-fe85-46cc-a9fd-fcfeef7eb8bf for DN 127.0.0.1:37939
2020-04-02 05:06:15,338 [Thread-800] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:15,338 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 8 with hostname set to: host9
2020-04-02 05:06:15,339 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host9 to rack /r5
2020-04-02 05:06:15,344 [Thread-800] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:15,346 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:15,350 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:15,351 [IPC Server handler 1 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37939, datanodeUuid=d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e, infoPort=36418, infoSecurePort=0, ipcPort=35233, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:15,351 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x164a985442346ca0: Processing first storage report for DS-7ce1b737-0eee-4f00-839c-4fec5e166377 from datanode d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e
2020-04-02 05:06:15,351 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x164a985442346ca0: from storage DS-7ce1b737-0eee-4f00-839c-4fec5e166377 node DatanodeRegistration(127.0.0.1:37939, datanodeUuid=d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e, infoPort=36418, infoSecurePort=0, ipcPort=35233, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:15,352 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x164a985442346ca0: Processing first storage report for DS-2adfadcc-fe85-46cc-a9fd-fcfeef7eb8bf from datanode d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e
2020-04-02 05:06:15,352 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x164a985442346ca0: from storage DS-2adfadcc-fe85-46cc-a9fd-fcfeef7eb8bf node DatanodeRegistration(127.0.0.1:37939, datanodeUuid=d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e, infoPort=36418, infoSecurePort=0, ipcPort=35233, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:15,352 [IPC Server handler 1 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x164a985442346ca0
2020-04-02 05:06:15,353 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x164a985442346ca0,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:15,353 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,353 [Thread-800] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:15,354 [Thread-800] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:15,355 [Thread-800] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9586b024-98a5-4e92-96a3-372450566666 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:06:15,356 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:15,356 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:15,356 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,356 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:15,357 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host9
2020-04-02 05:06:15,357 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,357 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:15,359 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37184
2020-04-02 05:06:15,359 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:15,359 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:15,365 [Thread-770] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,366 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,368 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:15,369 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:15,369 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,371 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:15,371 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:15,371 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:15,371 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:15,372 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37085
2020-04-02 05:06:15,372 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:15,374 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@381cad29{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:15,374 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@62515a47{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:15,379 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@757194dc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:15,380 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5a865416{HTTP/1.1,[http/1.1]}{localhost:37085}
2020-04-02 05:06:15,380 [main] INFO  server.Server (Server.java:doStart(419)) - Started @31064ms
2020-04-02 05:06:15,393 [Thread-770] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,394 [Thread-770] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:15,394 [Thread-770] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:15,406 [Thread-800] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:15,406 [Thread-800] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:15,407 [Thread-800] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-60021584-bf50-4f1a-9808-9671afc8af5d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:06:15,407 [Thread-770] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,410 [Thread-770] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,411 [Thread-770] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:15,411 [Thread-770] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:15,427 [Thread-770] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:15,438 [Thread-770] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 1ee71676-afc1-4817-8cf0-6d7c531e6267
2020-04-02 05:06:15,443 [Thread-770] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-882e2d6c-af1a-40c6-b9e2-3e387a900e42
2020-04-02 05:06:15,443 [Thread-770] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:06:15,481 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:42037
2020-04-02 05:06:15,482 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:15,482 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:15,482 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:15,483 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7ff2b8d2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:15,497 [Thread-800] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,497 [Thread-800] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,498 [Thread-800] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:15,498 [Thread-800] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:15,506 [Socket Reader #1 for port 38526] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38526
2020-04-02 05:06:15,543 [Thread-770] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ede2c325-0118-475b-85a1-6734c11df769
2020-04-02 05:06:15,557 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38526
2020-04-02 05:06:15,558 [Thread-770] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:06:15,559 [Thread-770] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:15,563 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:15,564 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:15,565 [Thread-825] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:15,565 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:37184 to rack /r5
2020-04-02 05:06:15,582 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:15,582 [IPC Server listener on 38526] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38526: starting
2020-04-02 05:06:15,584 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38526 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:15,584 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:15,585 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 9 with hostname set to: host10
2020-04-02 05:06:15,585 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host10 to rack /r6
2020-04-02 05:06:15,585 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:15,586 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:15,588 [Thread-825] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:15,596 [Thread-800] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,596 [Thread-800] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,596 [Thread-800] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:15,596 [Thread-800] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:15,597 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:15,598 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:15,599 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,599 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:15,599 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host10
2020-04-02 05:06:15,599 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:15,599 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:15,600 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:35968
2020-04-02 05:06:15,600 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:15,600 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:15,604 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,616 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:15,622 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:15,622 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:15,623 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:15,624 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:15,624 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:15,624 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:15,625 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40547
2020-04-02 05:06:15,625 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:15,600 [Thread-770] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:06:15,614 [Thread-800] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:15,614 [Thread-825] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:15,650 [Thread-770] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:06:15,654 [Thread-770] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:15,654 [Thread-770] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:15,650 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@70807224{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:15,655 [Thread-825] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:15,655 [Thread-825] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:15,659 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@400d912a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:15,659 [Thread-770] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,661 [Thread-825] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-eca3589e-6e07-453e-92fe-f5f21d054cdc for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:06:15,664 [Thread-843] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:06:15,664 [Thread-842] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:06:15,665 [Thread-800] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 73af68fb-7209-4b99-a33e-5eecce3c572e
2020-04-02 05:06:15,668 [Thread-800] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9586b024-98a5-4e92-96a3-372450566666
2020-04-02 05:06:15,669 [Thread-800] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:06:15,670 [Thread-800] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-60021584-bf50-4f1a-9808-9671afc8af5d
2020-04-02 05:06:15,670 [Thread-800] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:06:15,671 [Thread-800] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:15,672 [Thread-800] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:06:15,674 [Thread-825] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:15,674 [Thread-825] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:15,674 [Thread-825] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-4ec0d535-0b71-486e-b022-f0d8056a4b0f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:06:15,686 [Thread-800] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:06:15,687 [Thread-800] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:15,687 [Thread-800] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:15,701 [Thread-825] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,702 [Thread-825] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,702 [Thread-825] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:15,702 [Thread-825] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:15,734 [Thread-800] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,735 [Thread-847] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:06:15,736 [Thread-848] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:06:15,774 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@29f0802c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:15,776 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3a60c416{HTTP/1.1,[http/1.1]}{localhost:40547}
2020-04-02 05:06:15,776 [main] INFO  server.Server (Server.java:doStart(419)) - Started @31460ms
2020-04-02 05:06:15,844 [Thread-825] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,844 [Thread-825] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,844 [Thread-825] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:15,845 [Thread-825] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:15,846 [Thread-843] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 182ms
2020-04-02 05:06:15,857 [Thread-842] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 193ms
2020-04-02 05:06:15,851 [Thread-825] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:15,863 [Thread-825] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 886f6269-ae64-4fb9-9267-79fd9de1a442
2020-04-02 05:06:15,870 [Thread-848] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 134ms
2020-04-02 05:06:15,871 [Thread-770] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 211ms
2020-04-02 05:06:15,870 [Thread-825] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-eca3589e-6e07-453e-92fe-f5f21d054cdc
2020-04-02 05:06:15,883 [Thread-853] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:06:15,884 [Thread-854] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:06:15,884 [Thread-853] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:15,884 [Thread-854] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:15,885 [Thread-853] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 1ms
2020-04-02 05:06:15,887 [Thread-825] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:06:15,887 [Thread-854] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 1ms
2020-04-02 05:06:15,888 [Thread-770] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 5ms
2020-04-02 05:06:15,888 [Thread-770] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:37 AM with interval of 21600000ms
2020-04-02 05:06:15,888 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:06:15,889 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-882e2d6c-af1a-40c6-b9e2-3e387a900e42): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,889 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:15,890 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-882e2d6c-af1a-40c6-b9e2-3e387a900e42): no suitable block pools found to scan.  Waiting 1814399998 ms.
2020-04-02 05:06:15,890 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-ede2c325-0118-475b-85a1-6734c11df769): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,917 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 1ee71676-afc1-4817-8cf0-6d7c531e6267) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:15,919 [IPC Server handler 9 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:40403, datanodeUuid=1ee71676-afc1-4817-8cf0-6d7c531e6267, infoPort=33211, infoSecurePort=0, ipcPort=34186, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage 1ee71676-afc1-4817-8cf0-6d7c531e6267
2020-04-02 05:06:15,920 [IPC Server handler 9 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:40403
2020-04-02 05:06:15,920 [IPC Server handler 9 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 1ee71676-afc1-4817-8cf0-6d7c531e6267 (127.0.0.1:40403).
2020-04-02 05:06:15,926 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 1ee71676-afc1-4817-8cf0-6d7c531e6267) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:15,926 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:15,927 [Thread-825] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-4ec0d535-0b71-486e-b022-f0d8056a4b0f
2020-04-02 05:06:15,927 [Thread-825] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:06:15,928 [Thread-825] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:15,929 [Thread-825] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:15,958 [IPC Server handler 8 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-882e2d6c-af1a-40c6-b9e2-3e387a900e42 for DN 127.0.0.1:40403
2020-04-02 05:06:15,958 [IPC Server handler 8 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ede2c325-0118-475b-85a1-6734c11df769 for DN 127.0.0.1:40403
2020-04-02 05:06:15,960 [IPC Server handler 7 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:40403, datanodeUuid=1ee71676-afc1-4817-8cf0-6d7c531e6267, infoPort=33211, infoSecurePort=0, ipcPort=34186, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:15,954 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-ede2c325-0118-475b-85a1-6734c11df769): no suitable block pools found to scan.  Waiting 1814399934 ms.
2020-04-02 05:06:15,960 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe1f8c0fc6716a32e: Processing first storage report for DS-ede2c325-0118-475b-85a1-6734c11df769 from datanode 1ee71676-afc1-4817-8cf0-6d7c531e6267
2020-04-02 05:06:15,962 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe1f8c0fc6716a32e: from storage DS-ede2c325-0118-475b-85a1-6734c11df769 node DatanodeRegistration(127.0.0.1:40403, datanodeUuid=1ee71676-afc1-4817-8cf0-6d7c531e6267, infoPort=33211, infoSecurePort=0, ipcPort=34186, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 2 msecs, invalidatedBlocks: 0
2020-04-02 05:06:15,963 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe1f8c0fc6716a32e: Processing first storage report for DS-882e2d6c-af1a-40c6-b9e2-3e387a900e42 from datanode 1ee71676-afc1-4817-8cf0-6d7c531e6267
2020-04-02 05:06:15,963 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe1f8c0fc6716a32e: from storage DS-882e2d6c-af1a-40c6-b9e2-3e387a900e42 node DatanodeRegistration(127.0.0.1:40403, datanodeUuid=1ee71676-afc1-4817-8cf0-6d7c531e6267, infoPort=33211, infoSecurePort=0, ipcPort=34186, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:15,963 [IPC Server handler 7 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xe1f8c0fc6716a32e
2020-04-02 05:06:15,964 [Thread-825] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:15,964 [Thread-825] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:15,964 [Thread-825] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:15,982 [Thread-825] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:15,986 [Thread-859] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:06:15,988 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:16,000 [Thread-847] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 265ms
2020-04-02 05:06:15,992 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33874
2020-04-02 05:06:16,001 [Thread-800] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 266ms
2020-04-02 05:06:16,002 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:16,002 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:16,002 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:16,003 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@469d003c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:16,019 [Thread-860] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:06:16,026 [Thread-862] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:06:16,026 [Thread-862] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:16,043 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe1f8c0fc6716a32e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 84 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:16,043 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,045 [Thread-862] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 20ms
2020-04-02 05:06:16,053 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34621
2020-04-02 05:06:16,066 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:16,067 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:16,070 [Socket Reader #1 for port 34621] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34621
2020-04-02 05:06:16,086 [Thread-866] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:06:16,101 [Thread-859] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 114ms
2020-04-02 05:06:16,093 [Thread-871] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:16,093 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:35968 to rack /r6
2020-04-02 05:06:16,103 [Thread-866] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:16,138 [IPC Server listener on 34621] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34621: starting
2020-04-02 05:06:16,138 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:16,138 [Thread-866] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 36ms
2020-04-02 05:06:16,139 [Thread-800] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 138ms
2020-04-02 05:06:16,139 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:06:16,140 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:16,140 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-9586b024-98a5-4e92-96a3-372450566666): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,140 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-9586b024-98a5-4e92-96a3-372450566666): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:16,159 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-60021584-bf50-4f1a-9808-9671afc8af5d): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,160 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34621 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:16,162 [Thread-800] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:33 AM with interval of 21600000ms
2020-04-02 05:06:16,160 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-60021584-bf50-4f1a-9808-9671afc8af5d): no suitable block pools found to scan.  Waiting 1814399979 ms.
2020-04-02 05:06:16,166 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 73af68fb-7209-4b99-a33e-5eecce3c572e) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:16,168 [Thread-871] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:16,204 [Thread-860] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 185ms
2020-04-02 05:06:16,205 [Thread-825] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 223ms
2020-04-02 05:06:16,209 [Thread-887] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:06:16,210 [Thread-887] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:16,210 [Thread-886] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:06:16,210 [Thread-886] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:16,210 [IPC Server handler 4 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46847, datanodeUuid=73af68fb-7209-4b99-a33e-5eecce3c572e, infoPort=32897, infoSecurePort=0, ipcPort=43255, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage 73af68fb-7209-4b99-a33e-5eecce3c572e
2020-04-02 05:06:16,211 [IPC Server handler 4 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:46847
2020-04-02 05:06:16,211 [IPC Server handler 4 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 73af68fb-7209-4b99-a33e-5eecce3c572e (127.0.0.1:46847).
2020-04-02 05:06:16,212 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 73af68fb-7209-4b99-a33e-5eecce3c572e) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:16,212 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:16,218 [Thread-871] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:16,227 [IPC Server handler 0 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9586b024-98a5-4e92-96a3-372450566666 for DN 127.0.0.1:46847
2020-04-02 05:06:16,227 [Thread-887] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 18ms
2020-04-02 05:06:16,232 [Thread-871] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:16,232 [Thread-871] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:16,232 [Thread-871] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-04-02 05:06:16,238 [IPC Server handler 0 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-60021584-bf50-4f1a-9808-9671afc8af5d for DN 127.0.0.1:46847
2020-04-02 05:06:16,240 [Thread-886] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 30ms
2020-04-02 05:06:16,240 [Thread-825] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 35ms
2020-04-02 05:06:16,241 [Thread-825] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:23 AM with interval of 21600000ms
2020-04-02 05:06:16,241 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:16,241 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 886f6269-ae64-4fb9-9267-79fd9de1a442) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:16,241 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-eca3589e-6e07-453e-92fe-f5f21d054cdc): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,245 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-eca3589e-6e07-453e-92fe-f5f21d054cdc): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:06:16,245 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:16,246 [IPC Server handler 3 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46847, datanodeUuid=73af68fb-7209-4b99-a33e-5eecce3c572e, infoPort=32897, infoSecurePort=0, ipcPort=43255, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:16,246 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4ec0d535-0b71-486e-b022-f0d8056a4b0f): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,246 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd41a1d72129808bf: Processing first storage report for DS-60021584-bf50-4f1a-9808-9671afc8af5d from datanode 73af68fb-7209-4b99-a33e-5eecce3c572e
2020-04-02 05:06:16,246 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd41a1d72129808bf: from storage DS-60021584-bf50-4f1a-9808-9671afc8af5d node DatanodeRegistration(127.0.0.1:46847, datanodeUuid=73af68fb-7209-4b99-a33e-5eecce3c572e, infoPort=32897, infoSecurePort=0, ipcPort=43255, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:16,246 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd41a1d72129808bf: Processing first storage report for DS-9586b024-98a5-4e92-96a3-372450566666 from datanode 73af68fb-7209-4b99-a33e-5eecce3c572e
2020-04-02 05:06:16,246 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4ec0d535-0b71-486e-b022-f0d8056a4b0f): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:06:16,247 [Thread-871] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:16,246 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd41a1d72129808bf: from storage DS-9586b024-98a5-4e92-96a3-372450566666 node DatanodeRegistration(127.0.0.1:46847, datanodeUuid=73af68fb-7209-4b99-a33e-5eecce3c572e, infoPort=32897, infoSecurePort=0, ipcPort=43255, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:16,247 [Thread-871] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 1121040457. Formatting...
2020-04-02 05:06:16,247 [Thread-871] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-04-02 05:06:16,250 [IPC Server handler 3 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd41a1d72129808bf
2020-04-02 05:06:16,251 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd41a1d72129808bf,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 12 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:16,251 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,257 [IPC Server handler 2 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37184, datanodeUuid=886f6269-ae64-4fb9-9267-79fd9de1a442, infoPort=42037, infoSecurePort=0, ipcPort=38526, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage 886f6269-ae64-4fb9-9267-79fd9de1a442
2020-04-02 05:06:16,257 [IPC Server handler 2 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:37184
2020-04-02 05:06:16,258 [IPC Server handler 2 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 886f6269-ae64-4fb9-9267-79fd9de1a442 (127.0.0.1:37184).
2020-04-02 05:06:16,258 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 886f6269-ae64-4fb9-9267-79fd9de1a442) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:16,258 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:16,270 [Thread-871] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,271 [Thread-871] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,271 [Thread-871] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:16,271 [Thread-871] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:16,275 [IPC Server handler 3 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,277 [IPC Server handler 9 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-eca3589e-6e07-453e-92fe-f5f21d054cdc for DN 127.0.0.1:37184
2020-04-02 05:06:16,278 [IPC Server handler 9 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-4ec0d535-0b71-486e-b022-f0d8056a4b0f for DN 127.0.0.1:37184
2020-04-02 05:06:16,284 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:16,285 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:16,295 [Thread-871] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,295 [Thread-871] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,296 [Thread-871] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-1399669768-172.17.0.13-1585803972402 is not formatted. Formatting ...
2020-04-02 05:06:16,296 [Thread-871] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-1399669768-172.17.0.13-1585803972402 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1399669768-172.17.0.13-1585803972402/current
2020-04-02 05:06:16,297 [IPC Server handler 8 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37184, datanodeUuid=886f6269-ae64-4fb9-9267-79fd9de1a442, infoPort=42037, infoSecurePort=0, ipcPort=38526, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:16,298 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd219f0347d1520c3: Processing first storage report for DS-eca3589e-6e07-453e-92fe-f5f21d054cdc from datanode 886f6269-ae64-4fb9-9267-79fd9de1a442
2020-04-02 05:06:16,298 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd219f0347d1520c3: from storage DS-eca3589e-6e07-453e-92fe-f5f21d054cdc node DatanodeRegistration(127.0.0.1:37184, datanodeUuid=886f6269-ae64-4fb9-9267-79fd9de1a442, infoPort=42037, infoSecurePort=0, ipcPort=38526, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:16,298 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xd219f0347d1520c3: Processing first storage report for DS-4ec0d535-0b71-486e-b022-f0d8056a4b0f from datanode 886f6269-ae64-4fb9-9267-79fd9de1a442
2020-04-02 05:06:16,298 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xd219f0347d1520c3: from storage DS-4ec0d535-0b71-486e-b022-f0d8056a4b0f node DatanodeRegistration(127.0.0.1:37184, datanodeUuid=886f6269-ae64-4fb9-9267-79fd9de1a442, infoPort=42037, infoSecurePort=0, ipcPort=38526, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:16,299 [IPC Server handler 8 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xd219f0347d1520c3
2020-04-02 05:06:16,302 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xd219f0347d1520c3,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 18 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:16,302 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,306 [Thread-871] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=null
2020-04-02 05:06:16,311 [Thread-871] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 24124e6b-d78e-4049-a3cf-cbf34ce58cd1
2020-04-02 05:06:16,317 [Thread-871] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b
2020-04-02 05:06:16,318 [Thread-871] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-04-02 05:06:16,319 [Thread-871] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2
2020-04-02 05:06:16,319 [Thread-871] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-04-02 05:06:16,320 [Thread-871] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:16,321 [Thread-871] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:16,329 [Thread-871] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:16,334 [Thread-871] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:16,338 [Thread-871] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:16,357 [Thread-871] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,357 [Thread-893] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:06:16,358 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:06:16,388 [IPC Server handler 7 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,389 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:16,389 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:16,426 [Thread-893] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 69ms
2020-04-02 05:06:16,433 [Thread-894] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 74ms
2020-04-02 05:06:16,437 [Thread-871] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 81ms
2020-04-02 05:06:16,442 [Thread-897] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:06:16,442 [Thread-898] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:06:16,442 [Thread-897] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:16,442 [Thread-898] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:16,443 [Thread-898] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 1ms
2020-04-02 05:06:16,443 [Thread-897] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 1ms
2020-04-02 05:06:16,450 [Thread-871] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 12ms
2020-04-02 05:06:16,450 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:16,450 [Thread-871] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:19 AM with interval of 21600000ms
2020-04-02 05:06:16,451 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,451 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:16,451 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:16,465 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 24124e6b-d78e-4049-a3cf-cbf34ce58cd1) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:16,466 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b): finished scanning block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,466 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b): no suitable block pools found to scan.  Waiting 1814399984 ms.
2020-04-02 05:06:16,467 [IPC Server handler 5 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:35968, datanodeUuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1, infoPort=33874, infoSecurePort=0, ipcPort=34621, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage 24124e6b-d78e-4049-a3cf-cbf34ce58cd1
2020-04-02 05:06:16,468 [IPC Server handler 5 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:35968
2020-04-02 05:06:16,468 [IPC Server handler 5 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 24124e6b-d78e-4049-a3cf-cbf34ce58cd1 (127.0.0.1:35968).
2020-04-02 05:06:16,468 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 24124e6b-d78e-4049-a3cf-cbf34ce58cd1) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:16,469 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:16,477 [IPC Server handler 6 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b for DN 127.0.0.1:35968
2020-04-02 05:06:16,478 [IPC Server handler 6 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2 for DN 127.0.0.1:35968
2020-04-02 05:06:16,482 [IPC Server handler 4 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:35968, datanodeUuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1, infoPort=33874, infoSecurePort=0, ipcPort=34621, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:16,483 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c0a40f12c78ab64: Processing first storage report for DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b from datanode 24124e6b-d78e-4049-a3cf-cbf34ce58cd1
2020-04-02 05:06:16,483 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c0a40f12c78ab64: from storage DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b node DatanodeRegistration(127.0.0.1:35968, datanodeUuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1, infoPort=33874, infoSecurePort=0, ipcPort=34621, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:16,483 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9c0a40f12c78ab64: Processing first storage report for DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2 from datanode 24124e6b-d78e-4049-a3cf-cbf34ce58cd1
2020-04-02 05:06:16,483 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9c0a40f12c78ab64: from storage DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2 node DatanodeRegistration(127.0.0.1:35968, datanodeUuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1, infoPort=33874, infoSecurePort=0, ipcPort=34621, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:16,484 [IPC Server handler 4 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x9c0a40f12c78ab64
2020-04-02 05:06:16,484 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9c0a40f12c78ab64,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:16,484 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,498 [IPC Server handler 0 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,500 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:16,505 [IPC Server handler 2 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,507 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:16,510 [IPC Server handler 3 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:06:16,524 [IPC Server handler 9 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:16,535 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2280)) - MiniDFSCluster Stopping DataNode host10:35968 from a total of 10 datanodes.
2020-04-02 05:06:16,535 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34621 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:16,535 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:16,536 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@28952dea] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:16,552 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2) exiting.
2020-04-02 05:06:16,553 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b) exiting.
2020-04-02 05:06:16,567 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29f0802c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:16,568 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3a60c416{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:16,569 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@400d912a{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:16,569 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@70807224{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:16,582 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34621
2020-04-02 05:06:16,613 [IPC Server listener on 34621] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34621
2020-04-02 05:06:16,614 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:16,615 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:16,615 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 24124e6b-d78e-4049-a3cf-cbf34ce58cd1) service to localhost/127.0.0.1:38036
2020-04-02 05:06:16,615 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 24124e6b-d78e-4049-a3cf-cbf34ce58cd1)
2020-04-02 05:06:16,615 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:16,648 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:16,678 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:16,682 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:16,682 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:16,683 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:16,683 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:16,692 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:16,692 [main] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(752)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:35968, removeBlocksFromBlockMap true
2020-04-02 05:06:16,697 [main] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:35968
2020-04-02 05:06:16,697 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(121)) - stop datanode host10
2020-04-02 05:06:16,702 [IPC Server handler 8 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:16,711 [IPC Server handler 1 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:16,793 [IPC Server handler 7 on 38036] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:06:16,794 [IPC Server handler 7 on 38036] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-60021584-bf50-4f1a-9808-9671afc8af5d:NORMAL:127.0.0.1:46847, [DISK]DS-8a972036-9411-4c36-b97b-2d88eed67424:NORMAL:127.0.0.1:33203, [DISK]DS-eca3589e-6e07-453e-92fe-f5f21d054cdc:NORMAL:127.0.0.1:37184, [DISK]DS-a4999444-6a44-4c7d-9632-4297bde8079e:NORMAL:127.0.0.1:36674, [DISK]DS-ef2825cc-f5eb-465c-9fd4-76c8eb930a1d:NORMAL:127.0.0.1:33541]
2020-04-02 05:06:16,794 [IPC Server handler 7 on 38036] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:46847, 127.0.0.1:37184, 127.0.0.1:36674, 127.0.0.1:33203, 127.0.0.1:33541]
2020-04-02 05:06:16,795 [IPC Server handler 7 on 38036] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:46847, 127.0.0.1:40403, 127.0.0.1:37184, 127.0.0.1:36674, 127.0.0.1:38484, 127.0.0.1:33203, 127.0.0.1:37406, 127.0.0.1:37939, 127.0.0.1:33541 for /foo
2020-04-02 05:06:16,878 [DataXceiver for client DFSClient_NONMAPREDUCE_-1238163375_1 at /127.0.0.1:50124 [Receiving block BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775792_1001 src: /127.0.0.1:50124 dest: /127.0.0.1:46847
2020-04-02 05:06:16,952 [DataXceiver for client DFSClient_NONMAPREDUCE_-1238163375_1 at /127.0.0.1:51168 [Receiving block BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775789_1001 src: /127.0.0.1:51168 dest: /127.0.0.1:36674
2020-04-02 05:06:16,972 [DataXceiver for client DFSClient_NONMAPREDUCE_-1238163375_1 at /127.0.0.1:45586 [Receiving block BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775791_1001 src: /127.0.0.1:45586 dest: /127.0.0.1:40403
2020-04-02 05:06:16,973 [DataXceiver for client DFSClient_NONMAPREDUCE_-1238163375_1 at /127.0.0.1:59752 [Receiving block BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775790_1001 src: /127.0.0.1:59752 dest: /127.0.0.1:37184
2020-04-02 05:06:16,998 [DataXceiver for client DFSClient_NONMAPREDUCE_-1238163375_1 at /127.0.0.1:59318 [Receiving block BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775787_1001 src: /127.0.0.1:59318 dest: /127.0.0.1:33203
2020-04-02 05:06:17,188 [DataXceiver for client DFSClient_NONMAPREDUCE_-1238163375_1 at /127.0.0.1:43938 [Receiving block BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775788_1001 src: /127.0.0.1:43938 dest: /127.0.0.1:38484
2020-04-02 05:06:17,191 [IPC Server handler 0 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33203, datanodeUuid=2047b1a2-0248-4bab-9b75-1a8bd68dad42, infoPort=34959, infoSecurePort=0, ipcPort=34685, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,202 [DataXceiver for client DFSClient_NONMAPREDUCE_-1238163375_1 at /127.0.0.1:58856 [Receiving block BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775785_1001 src: /127.0.0.1:58856 dest: /127.0.0.1:37939
2020-04-02 05:06:17,249 [DataXceiver for client DFSClient_NONMAPREDUCE_-1238163375_1 at /127.0.0.1:45254 [Receiving block BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775786_1001 src: /127.0.0.1:45254 dest: /127.0.0.1:37406
2020-04-02 05:06:17,307 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:33203 size 134217728 replicaState = RBW
2020-04-02 05:06:17,307 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,307 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:33203
2020-04-02 05:06:17,307 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33203 receiving: 1, received: 0, deleted: 0
2020-04-02 05:06:17,307 [DataXceiver for client DFSClient_NONMAPREDUCE_-1238163375_1 at /127.0.0.1:47562 [Receiving block BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775784_1001 src: /127.0.0.1:47562 dest: /127.0.0.1:33541
2020-04-02 05:06:17,307 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:17,315 [IPC Server handler 2 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37406, datanodeUuid=18b1e12e-d15f-4706-9fc5-77c30f1a842d, infoPort=45973, infoSecurePort=0, ipcPort=33004, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,316 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:37406 size 134217728 replicaState = RBW
2020-04-02 05:06:17,334 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,334 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:37406
2020-04-02 05:06:17,334 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37406 receiving: 1, received: 0, deleted: 0
2020-04-02 05:06:17,525 [IPC Server handler 9 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36674, datanodeUuid=5c029312-1ed1-4153-bc14-151f396cd82e, infoPort=42357, infoSecurePort=0, ipcPort=44895, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,526 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:36674 size 134217728 replicaState = RBW
2020-04-02 05:06:17,526 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,526 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVING_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:36674
2020-04-02 05:06:17,526 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36674 receiving: 1, received: 0, deleted: 0
2020-04-02 05:06:17,653 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:50124, dest: /127.0.0.1:46847, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238163375_1, offset: 0, srvID: 73af68fb-7209-4b99-a33e-5eecce3c572e, blockid: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775792_1001, duration(ns): 703229460
2020-04-02 05:06:17,653 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:17,656 [IPC Server handler 8 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46847, datanodeUuid=73af68fb-7209-4b99-a33e-5eecce3c572e, infoPort=32897, infoSecurePort=0, ipcPort=43255, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,657 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:46847 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:17,657 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,657 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:46847 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:17,657 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:46847
2020-04-02 05:06:17,657 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46847 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,660 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45586, dest: /127.0.0.1:40403, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238163375_1, offset: 0, srvID: 1ee71676-afc1-4817-8cf0-6d7c531e6267, blockid: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775791_1001, duration(ns): 682806508
2020-04-02 05:06:17,661 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:17,670 [IPC Server handler 1 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:40403, datanodeUuid=1ee71676-afc1-4817-8cf0-6d7c531e6267, infoPort=33211, infoSecurePort=0, ipcPort=34186, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:40403 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:17,670 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:40403 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:17,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:40403
2020-04-02 05:06:17,670 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:40403 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,682 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59752, dest: /127.0.0.1:37184, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238163375_1, offset: 0, srvID: 886f6269-ae64-4fb9-9267-79fd9de1a442, blockid: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775790_1001, duration(ns): 677405058
2020-04-02 05:06:17,682 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:17,683 [IPC Server handler 7 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37184, datanodeUuid=886f6269-ae64-4fb9-9267-79fd9de1a442, infoPort=42037, infoSecurePort=0, ipcPort=38526, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,684 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:37184 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:17,684 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,684 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37184 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:17,684 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:37184
2020-04-02 05:06:17,684 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37184 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,689 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51168, dest: /127.0.0.1:36674, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238163375_1, offset: 0, srvID: 5c029312-1ed1-4153-bc14-151f396cd82e, blockid: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775789_1001, duration(ns): 725297552
2020-04-02 05:06:17,690 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:17,694 [IPC Server handler 5 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36674, datanodeUuid=5c029312-1ed1-4153-bc14-151f396cd82e, infoPort=42357, infoSecurePort=0, ipcPort=44895, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,698 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:36674 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:17,698 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,698 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36674 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:17,699 [IPC Server handler 6 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:38484, datanodeUuid=a5efa792-723c-4068-901e-e38ee351ef30, infoPort=39424, infoSecurePort=0, ipcPort=42206, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,701 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:36674
2020-04-02 05:06:17,701 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:43938, dest: /127.0.0.1:38484, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238163375_1, offset: 0, srvID: a5efa792-723c-4068-901e-e38ee351ef30, blockid: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775788_1001, duration(ns): 455880907
2020-04-02 05:06:17,702 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:17,701 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36674 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,702 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:38484 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:17,702 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,707 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:38484 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:17,708 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:38484
2020-04-02 05:06:17,708 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:38484 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,713 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:59318, dest: /127.0.0.1:33203, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238163375_1, offset: 0, srvID: 2047b1a2-0248-4bab-9b75-1a8bd68dad42, blockid: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775787_1001, duration(ns): 609773310
2020-04-02 05:06:17,714 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:17,715 [IPC Server handler 0 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33203, datanodeUuid=2047b1a2-0248-4bab-9b75-1a8bd68dad42, infoPort=34959, infoSecurePort=0, ipcPort=34685, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,715 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:33203 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:17,715 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,715 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33203 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:17,715 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:33203
2020-04-02 05:06:17,715 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33203 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,721 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:45254, dest: /127.0.0.1:37406, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238163375_1, offset: 0, srvID: 18b1e12e-d15f-4706-9fc5-77c30f1a842d, blockid: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775786_1001, duration(ns): 467000406
2020-04-02 05:06:17,721 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:17,751 [IPC Server handler 4 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37406, datanodeUuid=18b1e12e-d15f-4706-9fc5-77c30f1a842d, infoPort=45973, infoSecurePort=0, ipcPort=33004, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,752 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:58856, dest: /127.0.0.1:37939, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238163375_1, offset: 0, srvID: d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e, blockid: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775785_1001, duration(ns): 487455632
2020-04-02 05:06:17,752 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:17,752 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:37406 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:17,752 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,752 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37406 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:17,752 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:37406
2020-04-02 05:06:17,752 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37406 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,753 [IPC Server handler 2 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37939, datanodeUuid=d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e, infoPort=36418, infoSecurePort=0, ipcPort=35233, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,765 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:37939 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:17,765 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,765 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37939 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:17,765 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:37939
2020-04-02 05:06:17,765 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37939 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,771 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:47562, dest: /127.0.0.1:33541, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-1238163375_1, offset: 0, srvID: e734c7f8-e260-4a32-81ca-cb5f6a5e9d01, blockid: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775784_1001, duration(ns): 452172900
2020-04-02 05:06:17,772 [IPC Server handler 3 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33541, datanodeUuid=e734c7f8-e260-4a32-81ca-cb5f6a5e9d01, infoPort=39221, infoSecurePort=0, ipcPort=43523, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) 1 blocks.
2020-04-02 05:06:17,772 [PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-1399669768-172.17.0.13-1585803972402:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:17,773 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:33541 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:17,773 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:17,774 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33541 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:17,774 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:33541
2020-04-02 05:06:17,774 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33541 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:17,791 [IPC Server handler 9 on 38036] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /foo is closed by DFSClient_NONMAPREDUCE_-1238163375_1
2020-04-02 05:06:17,799 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:testReconstructForNotEnoughRacks(168)) - Created file /foo
2020-04-02 05:06:17,800 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:17,806 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:17,815 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:17,815 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:17,815 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:17,816 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:17,816 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host10
2020-04-02 05:06:17,816 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:17,816 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:17,817 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36749
2020-04-02 05:06:17,817 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:17,818 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:17,819 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:17,820 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:17,821 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:17,821 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:17,833 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:17,833 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:17,833 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:17,834 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:17,834 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43880
2020-04-02 05:06:17,835 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:17,837 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a933be2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:17,837 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@516ebdf8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:17,841 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1a411233{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:17,842 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@70325d20{HTTP/1.1,[http/1.1]}{localhost:43880}
2020-04-02 05:06:17,842 [main] INFO  server.Server (Server.java:doStart(419)) - Started @33526ms
2020-04-02 05:06:17,883 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:37562
2020-04-02 05:06:17,883 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:17,883 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:17,884 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:17,884 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d847d32] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:17,885 [Socket Reader #1 for port 40915] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40915
2020-04-02 05:06:17,906 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40915
2020-04-02 05:06:17,917 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:17,917 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:17,918 [Thread-951] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036 starting to offer service
2020-04-02 05:06:17,919 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:17,919 [IPC Server listener on 40915] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40915: starting
2020-04-02 05:06:17,920 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40915 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:17,934 [Thread-951] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:38036
2020-04-02 05:06:17,937 [Thread-951] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:17,938 [IPC Server handler 1 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:17,939 [Thread-951] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:17,941 [Thread-951] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:17,942 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:17,942 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:17,954 [Thread-951] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:17,954 [Thread-951] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:17,981 [Thread-951] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:17,981 [Thread-951] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:17,982 [Thread-951] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=1121040457;bpid=BP-1399669768-172.17.0.13-1585803972402;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=1121040457;c=1585803972402;bpid=BP-1399669768-172.17.0.13-1585803972402;dnuuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1
2020-04-02 05:06:17,985 [Thread-951] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b
2020-04-02 05:06:17,985 [Thread-951] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-04-02 05:06:18,001 [Thread-951] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2
2020-04-02 05:06:18,002 [Thread-951] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-04-02 05:06:18,002 [Thread-951] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:18,003 [Thread-951] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:18,005 [Thread-951] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:18,006 [Thread-951] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:18,006 [Thread-951] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:18,009 [Thread-951] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:18,009 [Thread-964] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:06:18,011 [Thread-964] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1399669768-172.17.0.13-1585803972402/current: 24576
2020-04-02 05:06:18,011 [Thread-965] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:06:18,012 [Thread-965] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1399669768-172.17.0.13-1585803972402/current: 24576
2020-04-02 05:06:18,021 [Thread-964] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 11ms
2020-04-02 05:06:18,046 [IPC Server handler 6 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:18,047 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:18,048 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:18,048 [Thread-965] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-1399669768-172.17.0.13-1585803972402 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 36ms
2020-04-02 05:06:18,048 [Thread-951] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-1399669768-172.17.0.13-1585803972402: 40ms
2020-04-02 05:06:18,050 [Thread-966] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:06:18,050 [Thread-966] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:18,050 [Thread-966] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 0ms
2020-04-02 05:06:18,050 [Thread-967] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:06:18,051 [Thread-967] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1399669768-172.17.0.13-1585803972402/current/replicas doesn't exist 
2020-04-02 05:06:18,051 [Thread-967] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 0ms
2020-04-02 05:06:18,051 [Thread-951] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-1399669768-172.17.0.13-1585803972402: 2ms
2020-04-02 05:06:18,052 [Thread-951] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 8:34 AM with interval of 21600000ms
2020-04-02 05:06:18,053 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b): no suitable block pools found to scan.  Waiting 1814398397 ms.
2020-04-02 05:06:18,057 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2): no suitable block pools found to scan.  Waiting 1814398393 ms.
2020-04-02 05:06:18,063 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 24124e6b-d78e-4049-a3cf-cbf34ce58cd1) service to localhost/127.0.0.1:38036 beginning handshake with NN
2020-04-02 05:06:18,066 [IPC Server handler 0 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36749, datanodeUuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1, infoPort=37562, infoSecurePort=0, ipcPort=40915, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) storage 24124e6b-d78e-4049-a3cf-cbf34ce58cd1
2020-04-02 05:06:18,066 [IPC Server handler 0 on 38036] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1076)) - BLOCK* registerDatanode: 127.0.0.1:35968 is replaced by DatanodeRegistration(127.0.0.1:36749, datanodeUuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1, infoPort=37562, infoSecurePort=0, ipcPort=40915, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402) with the same storageID 24124e6b-d78e-4049-a3cf-cbf34ce58cd1
2020-04-02 05:06:18,066 [IPC Server handler 0 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:35968
2020-04-02 05:06:18,067 [IPC Server handler 0 on 38036] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:36749
2020-04-02 05:06:18,067 [IPC Server handler 0 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b:NORMAL:127.0.0.1:36749 failed.
2020-04-02 05:06:18,067 [IPC Server handler 0 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2:NORMAL:127.0.0.1:36749 failed.
2020-04-02 05:06:18,067 [IPC Server handler 0 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b:FAILED:127.0.0.1:36749 from DataNode 127.0.0.1:36749
2020-04-02 05:06:18,067 [IPC Server handler 0 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2:FAILED:127.0.0.1:36749 from DataNode 127.0.0.1:36749
2020-04-02 05:06:18,068 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 24124e6b-d78e-4049-a3cf-cbf34ce58cd1) service to localhost/127.0.0.1:38036 successfully registered with NN
2020-04-02 05:06:18,068 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:38036 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:18,070 [IPC Server handler 4 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b for DN 127.0.0.1:36749
2020-04-02 05:06:18,072 [IPC Server handler 4 on 38036] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2 for DN 127.0.0.1:36749
2020-04-02 05:06:18,074 [IPC Server handler 4 on 38036] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 24124e6b-d78e-4049-a3cf-cbf34ce58cd1 (127.0.0.1:36749) requested a lease even though it wasn't yet registered.  Registering now.
2020-04-02 05:06:18,074 [IPC Server handler 4 on 38036] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 24124e6b-d78e-4049-a3cf-cbf34ce58cd1 (127.0.0.1:36749).
2020-04-02 05:06:18,076 [IPC Server handler 2 on 38036] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36749, datanodeUuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1, infoPort=37562, infoSecurePort=0, ipcPort=40915, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), reports.length=2
2020-04-02 05:06:18,076 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe4075fc5bfe30888: Processing first storage report for DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b from datanode 24124e6b-d78e-4049-a3cf-cbf34ce58cd1
2020-04-02 05:06:18,077 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe4075fc5bfe30888: from storage DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b node DatanodeRegistration(127.0.0.1:36749, datanodeUuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1, infoPort=37562, infoSecurePort=0, ipcPort=40915, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:18,077 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xe4075fc5bfe30888: Processing first storage report for DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2 from datanode 24124e6b-d78e-4049-a3cf-cbf34ce58cd1
2020-04-02 05:06:18,077 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xe4075fc5bfe30888: from storage DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2 node DatanodeRegistration(127.0.0.1:36749, datanodeUuid=24124e6b-d78e-4049-a3cf-cbf34ce58cd1, infoPort=37562, infoSecurePort=0, ipcPort=40915, storageInfo=lv=-57;cid=testClusterID;nsid=1121040457;c=1585803972402), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:18,077 [IPC Server handler 2 on 38036] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xe4075fc5bfe30888
2020-04-02 05:06:18,078 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xe4075fc5bfe30888,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:18,078 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:18,149 [IPC Server handler 3 on 38036] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:18,151 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:18,151 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:testReconstructForNotEnoughRacks(188)) - topology is: Number of racks: 6
Expected number of leaves:10
/r1/127.0.0.1:33203
/r1/127.0.0.1:37406
/r2/127.0.0.1:36674
/r2/127.0.0.1:38484
/r3/127.0.0.1:33541
/r3/127.0.0.1:37939
/r4/127.0.0.1:40403
/r4/127.0.0.1:46847
/r5/127.0.0.1:37184
/r6/127.0.0.1:36749

2020-04-02 05:06:18,154 [Reconstruction Queue Initializer] DEBUG BlockStateChange (LowRedundancyBlocks.java:add(293)) - BLOCK* NameSystem.LowRedundancyBlock.add: blk_-9223372036854775792_1001 has only 9 replicas and need 9 replicas so is added to neededReconstructions at priority level 3
2020-04-02 05:06:18,154 [Reconstruction Queue Initializer] TRACE blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3441)) - under replicated block blk_-9223372036854775792_1001: UNDER_REPLICATED
2020-04-02 05:06:18,168 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 1
2020-04-02 05:06:18,168 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:18,168 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 1
2020-04-02 05:06:18,168 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:18,168 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:18,168 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 16 msec
2020-04-02 05:06:18,308 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:<init>(47)) - Creating an ErasureCodingWork to blk_-9223372036854775792_1001 reconstruct 
2020-04-02 05:06:18,308 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=1}
2020-04-02 05:06:18,308 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseLocalRack(634)) - Failed to choose from local rack (location = /r4), retry with the rack of the next replica (location = /r4)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:831)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:719)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:626)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:586)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:416)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:292)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:143)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1862)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1814)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4550)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:18,309 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseFromNextRack(666)) - Failed to choose from the next rack (location = /r4), retry choosing randomly
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:831)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:719)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseFromNextRack(BlockPlacementPolicyDefault.java:662)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:638)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:586)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:416)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:292)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:143)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1862)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1814)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4550)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:18,309 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-9586b024-98a5-4e92-96a3-372450566666:NORMAL:127.0.0.1:46847, [DISK]DS-882e2d6c-af1a-40c6-b9e2-3e387a900e42:NORMAL:127.0.0.1:40403, [DISK]DS-eca3589e-6e07-453e-92fe-f5f21d054cdc:NORMAL:127.0.0.1:37184, [DISK]DS-6f25a350-f34c-45bf-b18b-4c952a30f504:NORMAL:127.0.0.1:36674, [DISK]DS-c37adb17-7d66-4a8c-9bdd-e13da2a362b1:NORMAL:127.0.0.1:38484, [DISK]DS-0b152d58-24a6-420c-ad6a-7f73cf4d3171:NORMAL:127.0.0.1:33203, [DISK]DS-0a75c363-880f-40b8-af71-017fdd589f4d:NORMAL:127.0.0.1:37406, [DISK]DS-7ce1b737-0eee-4f00-839c-4fec5e166377:NORMAL:127.0.0.1:37939, [DISK]DS-107e4a4d-7a98-4345-ac58-2d5c79e493aa:NORMAL:127.0.0.1:33541, [DISK]DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b:NORMAL:127.0.0.1:36749]
2020-04-02 05:06:18,309 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:36749, 127.0.0.1:38484, 127.0.0.1:37406, 127.0.0.1:37939, 127.0.0.1:46847, 127.0.0.1:37184, 127.0.0.1:36674, 127.0.0.1:40403, 127.0.0.1:33203, 127.0.0.1:33541]
2020-04-02 05:06:18,311 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:isInNewRack(1997)) - check if target 127.0.0.1:36749 increases racks, srcs=[127.0.0.1:46847, 127.0.0.1:40403, 127.0.0.1:37184, 127.0.0.1:36674, 127.0.0.1:38484, 127.0.0.1:33203, 127.0.0.1:37406, 127.0.0.1:37939, 127.0.0.1:33541]
2020-04-02 05:06:18,312 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:createReplicationWork(161)) - Add replication task from source 127.0.0.1:37939 to target [DISK]DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b:NORMAL:127.0.0.1:36749 for EC block blk_-9223372036854775785_1001
2020-04-02 05:06:18,312 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:validateReconstructionWork(2054)) - BLOCK* block blk_-9223372036854775792_1001 is moved from neededReconstruction to pendingReconstruction
2020-04-02 05:06:18,312 [RedundancyMonitor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 3
2020-04-02 05:06:18,313 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1895)) - BLOCK* ask [127.0.0.1:46847, 127.0.0.1:40403, 127.0.0.1:37184, 127.0.0.1:36674, 127.0.0.1:38484, 127.0.0.1:33203, 127.0.0.1:37406, 127.0.0.1:37939, 127.0.0.1:33541] to replicate blk_-9223372036854775792_1001 to datanode(s) 127.0.0.1:36749
2020-04-02 05:06:18,313 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:19,153 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:19,157 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 9
2020-04-02 05:06:19,157 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40915 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:19,157 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:19,158 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5bb3131b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:19,191 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-0b9f0cb9-337a-43f4-ad87-11179a02e8c2) exiting.
2020-04-02 05:06:19,191 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-d2c860f5-0faf-4de9-91bb-0f4e85dbe58b) exiting.
2020-04-02 05:06:19,666 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:19,913 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1a411233{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:19,914 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@70325d20{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:19,915 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@516ebdf8{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:19,915 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a933be2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:19,958 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40915
2020-04-02 05:06:19,961 [IPC Server listener on 40915] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40915
2020-04-02 05:06:19,985 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:19,985 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:19,985 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 24124e6b-d78e-4049-a3cf-cbf34ce58cd1) service to localhost/127.0.0.1:38036
2020-04-02 05:06:19,985 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 24124e6b-d78e-4049-a3cf-cbf34ce58cd1)
2020-04-02 05:06:19,985 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:20,013 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:20,081 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:20,081 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:20,082 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:20,082 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:20,090 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:20,090 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:06:20,091 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38526 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:20,091 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:20,091 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 886f6269-ae64-4fb9-9267-79fd9de1a442) service to localhost/127.0.0.1:38036
2020-04-02 05:06:20,091 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 886f6269-ae64-4fb9-9267-79fd9de1a442)
2020-04-02 05:06:20,091 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:20,091 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7af1cd63] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:20,123 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:20,123 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-eca3589e-6e07-453e-92fe-f5f21d054cdc) exiting.
2020-04-02 05:06:20,124 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-4ec0d535-0b71-486e-b022-f0d8056a4b0f) exiting.
2020-04-02 05:06:20,619 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@757194dc{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:20,627 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:20,661 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5a865416{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:20,669 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:20,671 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:20,672 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  impl.FsDatasetImpl (InstrumentedLock.java:logWarning(143)) - Lock held time above threshold: lock identifier: org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl lockHeldTimeMs=580 ms. Suppressed 0 lock warnings. The stack trace is: java.lang.Thread.getStackTrace(Thread.java:1559)
org.apache.hadoop.util.StringUtils.getStackTrace(StringUtils.java:1032)
org.apache.hadoop.util.InstrumentedLock.logWarning(InstrumentedLock.java:148)
org.apache.hadoop.util.InstrumentedLock.check(InstrumentedLock.java:186)
org.apache.hadoop.util.InstrumentedLock.unlock(InstrumentedLock.java:133)
org.apache.hadoop.util.AutoCloseableLock.release(AutoCloseableLock.java:84)
org.apache.hadoop.util.AutoCloseableLock.close(AutoCloseableLock.java:96)
org.apache.hadoop.hdfs.server.datanode.fsdataset.impl.FsDatasetImpl.shutdownBlockPool(FsDatasetImpl.java:2807)
org.apache.hadoop.hdfs.server.datanode.DataNode.shutdownBlockPool(DataNode.java:1654)
org.apache.hadoop.hdfs.server.datanode.BPOfferService.shutdownActor(BPOfferService.java:473)
org.apache.hadoop.hdfs.server.datanode.BPServiceActor.cleanUp(BPServiceActor.java:590)
org.apache.hadoop.hdfs.server.datanode.BPServiceActor.run(BPServiceActor.java:854)
java.lang.Thread.run(Thread.java:748)

2020-04-02 05:06:20,714 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@62515a47{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:20,714 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@381cad29{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:20,775 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38526
2020-04-02 05:06:20,798 [IPC Server listener on 38526] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38526
2020-04-02 05:06:20,803 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:20,887 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:20,887 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:20,889 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:20,889 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:20,897 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:20,898 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:06:20,898 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43255 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:20,898 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:20,901 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@5f212d84] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:20,910 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 73af68fb-7209-4b99-a33e-5eecce3c572e) service to localhost/127.0.0.1:38036
2020-04-02 05:06:20,911 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 73af68fb-7209-4b99-a33e-5eecce3c572e)
2020-04-02 05:06:20,919 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:20,927 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:20,964 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-9586b024-98a5-4e92-96a3-372450566666) exiting.
2020-04-02 05:06:20,965 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-60021584-bf50-4f1a-9808-9671afc8af5d) exiting.
2020-04-02 05:06:21,066 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@28486680{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:21,068 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:21,071 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4d7e7435{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:21,072 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2f4919b0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:21,072 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3249a1ce{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:21,120 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43255
2020-04-02 05:06:21,122 [IPC Server listener on 43255] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43255
2020-04-02 05:06:21,122 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:21,276 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:21,276 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:21,292 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:21,292 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:21,354 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:21,355 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:06:21,355 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34186 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:21,355 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:21,355 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6813a331] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:21,363 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-882e2d6c-af1a-40c6-b9e2-3e387a900e42) exiting.
2020-04-02 05:06:21,363 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-ede2c325-0118-475b-85a1-6734c11df769) exiting.
2020-04-02 05:06:21,453 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3cc20577{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:21,455 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 1ee71676-afc1-4817-8cf0-6d7c531e6267) service to localhost/127.0.0.1:38036
2020-04-02 05:06:21,456 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 1ee71676-afc1-4817-8cf0-6d7c531e6267)
2020-04-02 05:06:21,456 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:21,466 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@33a630fa{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:21,467 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:21,474 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4beddc56{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:21,474 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4fcc529{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:21,480 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:21,502 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34186
2020-04-02 05:06:21,586 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:21,586 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:21,590 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:21,590 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:21,600 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:21,600 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:06:21,600 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35233 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:21,601 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:21,601 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e) service to localhost/127.0.0.1:38036
2020-04-02 05:06:21,601 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid d60d17b5-9f3b-44b3-a2b7-7b7584cbc29e)
2020-04-02 05:06:21,601 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:21,605 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1f14f20c] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:21,609 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:21,618 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:21,625 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:21,626 [IPC Server listener on 34186] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34186
2020-04-02 05:06:21,637 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-7ce1b737-0eee-4f00-839c-4fec5e166377) exiting.
2020-04-02 05:06:21,637 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-2adfadcc-fe85-46cc-a9fd-fcfeef7eb8bf) exiting.
2020-04-02 05:06:21,672 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@29006752{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:21,673 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:21,674 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@470a9030{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:21,682 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f4037ed{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:21,682 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@b0964b2{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:21,765 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35233
2020-04-02 05:06:21,805 [IPC Server listener on 35233] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35233
2020-04-02 05:06:21,818 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:21,819 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:21,813 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:21,833 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:21,850 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:21,886 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:21,886 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:06:21,886 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43523 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:21,886 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid e734c7f8-e260-4a32-81ca-cb5f6a5e9d01) service to localhost/127.0.0.1:38036
2020-04-02 05:06:21,886 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:21,893 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-107e4a4d-7a98-4345-ac58-2d5c79e493aa) exiting.
2020-04-02 05:06:21,896 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-ef2825cc-f5eb-465c-9fd4-76c8eb930a1d) exiting.
2020-04-02 05:06:21,886 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid e734c7f8-e260-4a32-81ca-cb5f6a5e9d01)
2020-04-02 05:06:21,904 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@16943e88] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:21,909 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:21,986 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:22,017 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5bdaf2ce{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:22,070 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42d236fb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:22,070 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1500e009{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:22,071 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@d2387c8{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:22,090 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43523
2020-04-02 05:06:22,094 [IPC Server listener on 43523] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43523
2020-04-02 05:06:22,133 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:22,138 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:22,156 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:22,156 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:22,163 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:22,164 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:06:22,164 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 42206 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:22,164 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:22,164 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6bfdb014] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:22,183 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-d848e0c6-36e8-4cb1-b11d-8e2be0adaf15) exiting.
2020-04-02 05:06:22,185 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:22,183 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-c37adb17-7d66-4a8c-9bdd-e13da2a362b1) exiting.
2020-04-02 05:06:22,189 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:22,209 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid a5efa792-723c-4068-901e-e38ee351ef30) service to localhost/127.0.0.1:38036
2020-04-02 05:06:22,250 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid a5efa792-723c-4068-901e-e38ee351ef30)
2020-04-02 05:06:22,475 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2577d6c8{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:22,493 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:22,518 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3163987e{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:22,538 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:22,574 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:22,575 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1d8e2eea{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:22,575 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f34a967{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:22,648 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 42206
2020-04-02 05:06:22,695 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:22,695 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:22,715 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:22,715 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:22,740 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:22,745 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:22,747 [IPC Server listener on 42206] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 42206
2020-04-02 05:06:22,758 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:22,759 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:06:22,759 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44895 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:22,759 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 5c029312-1ed1-4153-bc14-151f396cd82e) service to localhost/127.0.0.1:38036
2020-04-02 05:06:22,759 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2fb69ff6] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:22,759 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:22,760 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-6f25a350-f34c-45bf-b18b-4c952a30f504) exiting.
2020-04-02 05:06:22,761 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-a4999444-6a44-4c7d-9632-4297bde8079e) exiting.
2020-04-02 05:06:22,759 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 5c029312-1ed1-4153-bc14-151f396cd82e)
2020-04-02 05:06:22,794 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:22,855 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:22,856 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@7da10b5b{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:22,857 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@219f4597{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:22,863 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27f3b6d6{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:22,864 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1929425f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:22,909 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:22,913 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44895
2020-04-02 05:06:22,914 [IPC Server listener on 44895] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44895
2020-04-02 05:06:22,923 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:22,980 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:22,980 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:22,981 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:22,981 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:22,990 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:22,990 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:22,990 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 33004 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:22,991 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 18b1e12e-d15f-4706-9fc5-77c30f1a842d) service to localhost/127.0.0.1:38036
2020-04-02 05:06:22,991 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:22,991 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@669d2b1b] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:22,991 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 18b1e12e-d15f-4706-9fc5-77c30f1a842d)
2020-04-02 05:06:22,992 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-0a75c363-880f-40b8-af71-017fdd589f4d) exiting.
2020-04-02 05:06:23,011 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-420b4f4f-b924-4a7a-8ecd-6af6132cf010) exiting.
2020-04-02 05:06:23,016 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:23,060 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:23,060 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:23,142 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@53bf7094{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:23,144 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@26f1249d{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:23,145 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4f8caaf3{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:23,146 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ab9b447{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:23,167 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 33004
2020-04-02 05:06:23,215 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:23,215 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:23,216 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:23,216 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:23,215 [IPC Server listener on 33004] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 33004
2020-04-02 05:06:23,215 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:23,278 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:23,278 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:23,278 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34685 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:23,279 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:23,281 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@12365c88] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:23,282 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 2047b1a2-0248-4bab-9b75-1a8bd68dad42) service to localhost/127.0.0.1:38036
2020-04-02 05:06:23,282 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-0b152d58-24a6-420c-ad6a-7f73cf4d3171) exiting.
2020-04-02 05:06:23,283 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-8a972036-9411-4c36-b97b-2d88eed67424) exiting.
2020-04-02 05:06:23,388 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@30865a90{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:23,390 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6134ac4a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:23,391 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5bb3d42d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:23,391 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@64d7b720{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:23,395 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-1399669768-172.17.0.13-1585803972402 (Datanode Uuid 2047b1a2-0248-4bab-9b75-1a8bd68dad42)
2020-04-02 05:06:23,453 [BP-1399669768-172.17.0.13-1585803972402 heartbeating to localhost/127.0.0.1:38036] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-1399669768-172.17.0.13-1585803972402
2020-04-02 05:06:23,458 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34685
2020-04-02 05:06:23,460 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:23,460 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:23,460 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:23,460 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:23,465 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:23,469 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:23,470 [IPC Server listener on 34685] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34685
2020-04-02 05:06:23,482 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-1399669768-172.17.0.13-1585803972402] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:23,518 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:23,520 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:23,520 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 38036 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:23,520 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:23,522 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@632aa1a3] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:23,523 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:06:23,523 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@20765ed5] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:23,523 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 18 Number of transactions batched in Syncs: 2 Number of syncs: 8 SyncTimes(ms): 10 4 
2020-04-02 05:06:23,524 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:06:23,524 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:06:23,525 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:23,527 [CacheReplicationMonitor(604009340)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:23,555 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38036
2020-04-02 05:06:23,559 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:23,559 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:23,560 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:23,560 [IPC Server listener on 38036] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38036
2020-04-02 05:06:23,565 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@54e81b21] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:23,580 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:23,580 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:23,582 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1db0ec27{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:23,590 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3d9fc57a{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:23,590 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@39fc6b2c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:23,591 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6ac4944a{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:23,595 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:23,597 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:23,597 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness#testReconstructForNotEnoughRacks
[msx] writeFile testName = org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness#testReconstructForNotEnoughRacks
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] test Started org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness#testReconstructionWithDecommission
[msx] perform reset as unitTestCounterInClass 2 is larger than zero
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
2020-04-02 05:06:23,614 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:<init>(492)) - starting cluster: numNameNodes=1, numDataNodes=11
Formatting using clusterid: testClusterID
2020-04-02 05:06:23,616 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:23,617 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:23,617 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:23,617 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:23,617 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:23,617 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:23,617 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:23,617 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:23,618 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:23,619 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:06:23,619 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:23,620 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:23,620 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:23
2020-04-02 05:06:23,620 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:23,620 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:23,620 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.9 GB = 39.3 MB
2020-04-02 05:06:23,620 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:23,624 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:23,624 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:23,624 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:23,625 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:23,630 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:23,630 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:23,630 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.9 GB = 19.6 MB
2020-04-02 05:06:23,631 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:23,868 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:23,868 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:23,868 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:23,868 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:23,871 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:23,871 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:23,871 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:23,871 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:23,872 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:06:23,872 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:23,873 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:23,873 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:23,873 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:23,873 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:23,873 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:23,873 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:23,873 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:23,873 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:06:23,873 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:23,874 [main] INFO  namenode.FSImage (FSImage.java:format(170)) - Allocated new BlockPoolId: BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:23,879 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 has been successfully formatted.
2020-04-02 05:06:23,881 [main] INFO  common.Storage (NNStorage.java:format(583)) - Storage directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 has been successfully formatted.
2020-04-02 05:06:23,896 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:23,904 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(449)) - Saving image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 using no compression
2020-04-02 05:06:23,911 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:06:23,930 [FSImageSaver for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2 of type IMAGE_AND_EDITS] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:save(453)) - Image file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/fsimage.ckpt_0000000000000000000 of size 426 bytes saved in 0 seconds .
2020-04-02 05:06:23,934 [main] INFO  namenode.NNStorageRetentionManager (NNStorageRetentionManager.java:getImageTxIdToRetain(203)) - Going to retain 1 images with txid >= 0
2020-04-02 05:06:23,935 [main] INFO  namenode.NameNode (NameNode.java:createNameNode(1613)) - createNameNode []
2020-04-02 05:06:23,976 [main] INFO  impl.MetricsConfig (MetricsConfig.java:loadFirst(121)) - loaded properties from hadoop-metrics2.properties
2020-04-02 05:06:23,987 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 0 second(s).
2020-04-02 05:06:23,987 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - NameNode metrics system started
2020-04-02 05:06:23,989 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] NameNode init, vvmode is none, do nothing
2020-04-02 05:06:23,989 [main] INFO  namenode.NameNodeUtils (NameNodeUtils.java:getClientNamenodeAddress(79)) - fs.defaultFS is hdfs://127.0.0.1:0
2020-04-02 05:06:24,009 [main] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1605)) - Starting Web-server for hdfs at: http://localhost:0
2020-04-02 05:06:24,014 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:24,016 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:24,014 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@599f571f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:24,018 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.namenode is not defined
2020-04-02 05:06:24,018 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:24,019 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:24,020 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hdfs
2020-04-02 05:06:24,020 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:24,020 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:24,021 [main] INFO  http.HttpServer2 (NameNodeHttpServer.java:initWebHdfs(100)) - Added filter 'org.apache.hadoop.hdfs.web.AuthFilter' (class=org.apache.hadoop.hdfs.web.AuthFilter)
2020-04-02 05:06:24,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addJerseyResourcePackage(789)) - addJerseyResourcePackage: packageName=org.apache.hadoop.hdfs.server.namenode.web.resources;org.apache.hadoop.hdfs.web.resources, pathSpec=/webhdfs/v1/*
2020-04-02 05:06:24,022 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 42677
2020-04-02 05:06:24,022 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:24,047 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2d7e1102{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:24,048 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2adddc06{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:24,051 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1c12f3ee{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs/,AVAILABLE}{/hdfs}
2020-04-02 05:06:24,052 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d467c87{HTTP/1.1,[http/1.1]}{localhost:42677}
2020-04-02 05:06:24,052 [main] INFO  server.Server (Server.java:doStart(419)) - Started @39736ms
2020-04-02 05:06:24,053 [main] INFO  namenode.FSEditLog (FSEditLog.java:newInstance(227)) - Edit logging is async:true
2020-04-02 05:06:24,053 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(749)) - KeyProvider: null
2020-04-02 05:06:24,053 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(121)) - fsLock is fair: true
2020-04-02 05:06:24,053 [main] INFO  namenode.FSNamesystem (FSNamesystemLock.java:<init>(139)) - Detailed lock hold time metrics enabled: false
2020-04-02 05:06:24,054 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(774)) - fsOwner             = root (auth:SIMPLE)
2020-04-02 05:06:24,054 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(775)) - supergroup          = supergroup
2020-04-02 05:06:24,054 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(776)) - isPermissionEnabled = true
2020-04-02 05:06:24,054 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:<init>(787)) - HA Enabled: false
2020-04-02 05:06:24,054 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,054 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(301)) - dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000
2020-04-02 05:06:24,054 [main] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:<init>(309)) - dfs.namenode.datanode.registration.ip-hostname-check=true
2020-04-02 05:06:24,055 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(79)) - dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000
2020-04-02 05:06:24,055 [main] INFO  blockmanagement.BlockManager (InvalidateBlocks.java:printBlockDeletionTime(85)) - The block deletion will start around 2020 Apr 02 05:06:24
2020-04-02 05:06:24,055 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map BlocksMap
2020-04-02 05:06:24,055 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:24,055 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 2.0% max memory 1.8 GB = 36.4 MB
2020-04-02 05:06:24,056 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^22 = 4194304 entries
2020-04-02 05:06:24,063 [main] INFO  blockmanagement.BlockManager (BlockManager.java:createBlockTokenSecretManager(579)) - dfs.block.access.token.enable = false
2020-04-02 05:06:24,063 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.redundancy.interval.seconds(1) assuming SECONDS
2020-04-02 05:06:24,063 [main] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - No unit for dfs.namenode.safemode.extension(0) assuming MILLISECONDS
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(161)) - dfs.namenode.safemode.threshold-pct = 0.9990000128746033
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(162)) - dfs.namenode.safemode.min.datanodes = 0
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManagerSafeMode (BlockManagerSafeMode.java:<init>(164)) - dfs.namenode.safemode.extension = 0
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(565)) - defaultReplication         = 3
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(566)) - maxReplication             = 512
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(567)) - minReplication             = 1
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(568)) - maxReplicationStreams      = 2
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(569)) - redundancyRecheckInterval  = 1000ms
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(570)) - encryptDataTransfer        = false
2020-04-02 05:06:24,064 [main] INFO  blockmanagement.BlockManager (BlockManager.java:<init>(571)) - maxNumBlocksToLog          = 1000
2020-04-02 05:06:24,064 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map INodeMap
2020-04-02 05:06:24,064 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:24,065 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 1.0% max memory 1.8 GB = 18.2 MB
2020-04-02 05:06:24,065 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^21 = 2097152 entries
2020-04-02 05:06:24,067 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(285)) - ACLs enabled? false
2020-04-02 05:06:24,067 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(289)) - POSIX ACL inheritance enabled? true
2020-04-02 05:06:24,067 [main] INFO  namenode.FSDirectory (FSDirectory.java:<init>(293)) - XAttrs enabled? true
2020-04-02 05:06:24,068 [main] INFO  namenode.NameNode (FSDirectory.java:<init>(357)) - Caching file names occurring more than 10 times
2020-04-02 05:06:24,068 [main] INFO  snapshot.SnapshotManager (SnapshotManager.java:<init>(124)) - Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536
2020-04-02 05:06:24,068 [main] INFO  snapshot.SnapshotManager (DirectoryDiffListFactory.java:init(43)) - SkipList is disabled
2020-04-02 05:06:24,068 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map cachedBlocks
2020-04-02 05:06:24,068 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:24,068 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.25% max memory 1.8 GB = 4.6 MB
2020-04-02 05:06:24,068 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^19 = 524288 entries
2020-04-02 05:06:24,069 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(76)) - NNTop conf: dfs.namenode.top.window.num.buckets = 10
2020-04-02 05:06:24,069 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(78)) - NNTop conf: dfs.namenode.top.num.users = 10
2020-04-02 05:06:24,070 [main] INFO  metrics.TopMetrics (TopMetrics.java:logConf(80)) - NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25
2020-04-02 05:06:24,070 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(990)) - Retry cache on namenode is enabled
2020-04-02 05:06:24,070 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:initRetryCache(998)) - Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis
2020-04-02 05:06:24,070 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(395)) - Computing capacity for map NameNodeRetryCache
2020-04-02 05:06:24,070 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(396)) - VM type       = 64-bit
2020-04-02 05:06:24,070 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(397)) - 0.029999999329447746% max memory 1.8 GB = 559.3 KB
2020-04-02 05:06:24,071 [main] INFO  util.GSet (LightWeightGSet.java:computeCapacity(402)) - capacity      = 2^16 = 65536 entries
2020-04-02 05:06:24,077 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:24,089 [main] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:24,091 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current
2020-04-02 05:06:24,091 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:recoverUnfinalizedSegments(396)) - Recovering unfinalized segments in /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current
2020-04-02 05:06:24,092 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(718)) - No edit log streams selected.
2020-04-02 05:06:24,092 [main] INFO  namenode.FSImage (FSImage.java:loadFSImageFile(782)) - Planning to load image: FSImageFile(file=/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000, cpktTxId=0000000000000000000)
2020-04-02 05:06:24,093 [main] INFO  namenode.FSImageFormatPBINode (FSImageFormatPBINode.java:loadINodeSection(233)) - Loading 1 INodes.
2020-04-02 05:06:24,098 [main] INFO  namenode.FSImageFormatProtobuf (FSImageFormatProtobuf.java:load(183)) - Loaded FSImage in 0 seconds.
2020-04-02 05:06:24,098 [main] INFO  namenode.FSImage (FSImage.java:loadFSImage(951)) - Loaded image for txid 0 from /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/fsimage_0000000000000000000
2020-04-02 05:06:24,098 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFSImage(1102)) - Need to save fs image? false (staleImage=false, haEnabled=false, isRollingUpgrade=false)
2020-04-02 05:06:24,102 [main] INFO  namenode.FSEditLog (FSEditLog.java:startLogSegment(1361)) - Starting log segment at 1
2020-04-02 05:06:24,122 [main] INFO  namenode.NameCache (NameCache.java:initialized(143)) - initialized with 0 entries 0 lookups
2020-04-02 05:06:24,123 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:loadFromDisk(721)) - Finished loading FSImage in 52 msecs
2020-04-02 05:06:24,126 [main] INFO  namenode.NameNode (NameNodeRpcServer.java:<init>(446)) - RPC server is binding to localhost:0
2020-04-02 05:06:24,126 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:24,134 [Socket Reader #1 for port 35549] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35549
2020-04-02 05:06:24,137 [main] INFO  namenode.NameNode (NameNode.java:initialize(710)) - Clients are to use localhost:35549 to access this namenode/service.
2020-04-02 05:06:24,156 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:registerMBean(5000)) - Registered FSNamesystemState, ReplicatedBlocksState and ECBlockGroupsState MBeans.
2020-04-02 05:06:24,188 [main] INFO  namenode.LeaseManager (LeaseManager.java:getNumUnderConstructionBlocks(171)) - Number of blocks under construction: 0
2020-04-02 05:06:24,189 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@715fb77] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:pendingReconstructionCheck(261)) - PendingReconstructionMonitor checking Q
2020-04-02 05:06:24,194 [main] INFO  blockmanagement.BlockManager (BlockManager.java:initializeReplQueues(4792)) - initializing replication queues
2020-04-02 05:06:24,199 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(396)) - STATE* Leaving safe mode after 0 secs
2020-04-02 05:06:24,199 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(402)) - STATE* Network topology has 0 racks and 0 datanodes
2020-04-02 05:06:24,199 [main] INFO  hdfs.StateChange (BlockManagerSafeMode.java:leaveSafeMode(404)) - STATE* UnderReplicatedBlocks has 0 blocks
2020-04-02 05:06:24,213 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:24,213 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:24,213 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:24,214 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:24,214 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:24,214 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 15 msec
2020-04-02 05:06:24,227 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:24,228 [IPC Server listener on 35549] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35549: starting
2020-04-02 05:06:24,266 [main] INFO  namenode.NameNode (NameNode.java:startCommonServices(816)) - NameNode RPC up at: localhost/127.0.0.1:35549
2020-04-02 05:06:24,267 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:startActiveServices(1214)) - Starting services required for active state
2020-04-02 05:06:24,267 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(769)) - Initializing quota with 4 thread(s)
2020-04-02 05:06:24,274 [main] INFO  namenode.FSDirectory (FSDirectory.java:updateCountForQuota(778)) - Quota initialization completed in 7 milliseconds
name space=1
storage space=0
storage types=RAM_DISK=0, SSD=0, DISK=0, ARCHIVE=0, PROVIDED=0
2020-04-02 05:06:24,282 [main] INFO  namenode.NameNode (NameNode.java:<init>(963)) - [msx-restart] NameNode 35549 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:24,291 [CacheReplicationMonitor(75657833)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(160)) - Starting CacheReplicationMonitor with interval 30000 milliseconds
2020-04-02 05:06:24,364 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 0 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:24,365 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 0 with hostname set to: host1
2020-04-02 05:06:24,365 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host1 to rack /r1
2020-04-02 05:06:24,365 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:24,369 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:24,377 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:24,378 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:24,378 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,378 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:24,378 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host1
2020-04-02 05:06:24,378 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,379 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:24,379 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37730
2020-04-02 05:06:24,379 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:24,379 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:24,381 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:24,382 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:24,383 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:24,384 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:24,384 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:24,385 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:24,385 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:24,385 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:24,386 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 45693
2020-04-02 05:06:24,386 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:24,415 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@cda0432{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:24,420 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7004e3d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:24,424 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4bdcaf36{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:24,424 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@61d01788{HTTP/1.1,[http/1.1]}{localhost:45693}
2020-04-02 05:06:24,424 [main] INFO  server.Server (Server.java:doStart(419)) - Started @40108ms
2020-04-02 05:06:24,460 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35240
2020-04-02 05:06:24,461 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:24,461 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:24,461 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:24,462 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@264c5d07] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:24,462 [Socket Reader #1 for port 44661] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44661
2020-04-02 05:06:24,466 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44661
2020-04-02 05:06:24,480 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:24,480 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:24,486 [Thread-1032] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:24,507 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:37730 to rack /r1
2020-04-02 05:06:24,508 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:24,509 [IPC Server listener on 44661] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44661: starting
2020-04-02 05:06:24,510 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44661 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:24,511 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 1 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:24,511 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 1 with hostname set to: host2
2020-04-02 05:06:24,511 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host2 to rack /r1
2020-04-02 05:06:24,521 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:24,521 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:24,523 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:24,523 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:24,523 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,523 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:24,523 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host2
2020-04-02 05:06:24,523 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,524 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:24,524 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42968
2020-04-02 05:06:24,524 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:24,524 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:24,535 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:24,536 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:24,550 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:24,551 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:24,552 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:24,553 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:24,553 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:24,553 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:24,555 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 37379
2020-04-02 05:06:24,555 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:24,565 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6d2d99fc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:24,566 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5e3a39cd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:24,569 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5226e402{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:24,596 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@1440c311{HTTP/1.1,[http/1.1]}{localhost:37379}
2020-04-02 05:06:24,596 [main] INFO  server.Server (Server.java:doStart(419)) - Started @40280ms
2020-04-02 05:06:24,626 [Thread-1032] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:24,634 [Thread-1032] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:24,641 [Thread-1032] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:24,642 [Thread-1032] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:24,642 [Thread-1032] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 
2020-04-02 05:06:24,646 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43338
2020-04-02 05:06:24,660 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:24,660 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@783ec989] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:24,660 [Thread-1032] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:24,660 [Thread-1032] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:24,660 [Thread-1032] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6f852d23-017e-4ab4-8829-fc057e9e3305 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 
2020-04-02 05:06:24,660 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:24,666 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:24,669 [Socket Reader #1 for port 40706] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40706
2020-04-02 05:06:24,675 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40706
2020-04-02 05:06:24,686 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:24,687 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:24,690 [Thread-1056] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:24,712 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:42968 to rack /r1
2020-04-02 05:06:24,721 [IPC Server listener on 40706] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40706: starting
2020-04-02 05:06:24,725 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:24,737 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40706 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:24,738 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 2 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:24,738 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 2 with hostname set to: host3
2020-04-02 05:06:24,738 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host3 to rack /r2
2020-04-02 05:06:24,738 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:24,743 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:24,766 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:24,766 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:24,767 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,767 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:24,767 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host3
2020-04-02 05:06:24,767 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,767 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:24,768 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:34808
2020-04-02 05:06:24,768 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:24,768 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:24,769 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:24,770 [Thread-1056] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:24,796 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:24,797 [Thread-1056] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:24,799 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:24,799 [Thread-1056] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:24,800 [Thread-1056] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:24,799 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:24,800 [Thread-1056] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 
2020-04-02 05:06:24,801 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:24,801 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:24,801 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:24,801 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:24,802 [Thread-1056] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:24,802 [Thread-1056] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:24,802 [Thread-1056] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e340360f-798e-455a-bff2-ca67dfad9811 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 
2020-04-02 05:06:24,803 [Thread-1032] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:24,803 [Thread-1032] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:24,811 [Thread-1056] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:24,811 [Thread-1056] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:24,811 [Thread-1056] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:24,811 [Thread-1056] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:24,812 [Thread-1032] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:24,812 [Thread-1032] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:24,806 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 38856
2020-04-02 05:06:24,814 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:24,817 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a4d7f76{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:24,818 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53dfacba{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:24,829 [Thread-1056] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:24,834 [Thread-1056] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:24,834 [Thread-1056] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:24,834 [Thread-1056] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:24,830 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5972d253{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:24,836 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4fcc0416{HTTP/1.1,[http/1.1]}{localhost:38856}
2020-04-02 05:06:24,836 [main] INFO  server.Server (Server.java:doStart(419)) - Started @40520ms
2020-04-02 05:06:24,843 [Thread-1056] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:24,849 [Thread-1056] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ba26eabe-5db3-42d6-ba4b-937e2c42a5ac
2020-04-02 05:06:24,860 [Thread-1032] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:24,860 [Thread-1032] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:24,860 [Thread-1032] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:24,860 [Thread-1032] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:24,861 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35946
2020-04-02 05:06:24,862 [Thread-1032] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:24,863 [Thread-1032] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e
2020-04-02 05:06:24,865 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:24,866 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:24,866 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:24,875 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1473b8c0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:24,876 [Socket Reader #1 for port 40364] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40364
2020-04-02 05:06:24,892 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40364
2020-04-02 05:06:24,892 [Thread-1056] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6
2020-04-02 05:06:24,892 [Thread-1056] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, StorageType: DISK
2020-04-02 05:06:24,901 [Thread-1056] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e340360f-798e-455a-bff2-ca67dfad9811
2020-04-02 05:06:24,902 [Thread-1056] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, StorageType: DISK
2020-04-02 05:06:24,902 [Thread-1056] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:24,917 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:24,917 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:24,918 [Thread-1056] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:24,921 [Thread-1082] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:24,926 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:34808 to rack /r2
2020-04-02 05:06:24,930 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:24,934 [IPC Server listener on 40364] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40364: starting
2020-04-02 05:06:24,954 [Thread-1056] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:24,954 [Thread-1056] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:24,958 [Thread-1032] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681
2020-04-02 05:06:24,958 [Thread-1032] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, StorageType: DISK
2020-04-02 05:06:24,959 [Thread-1082] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:24,971 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40364 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:24,971 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 3 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:24,972 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 3 with hostname set to: host4
2020-04-02 05:06:24,972 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host4 to rack /r2
2020-04-02 05:06:24,972 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:06:24,977 [Thread-1082] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:24,981 [Thread-1032] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6f852d23-017e-4ab4-8829-fc057e9e3305
2020-04-02 05:06:24,982 [Thread-1032] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, StorageType: DISK
2020-04-02 05:06:24,982 [Thread-1032] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:24,982 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:24,982 [Thread-1056] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:24,983 [Thread-1056] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:24,983 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:24,984 [Thread-1032] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:24,984 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:24,984 [Thread-1094] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:06:24,984 [Thread-1095] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:06:24,984 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,984 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:24,986 [Thread-1082] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:24,986 [Thread-1082] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:24,986 [Thread-1082] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 
2020-04-02 05:06:24,990 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host4
2020-04-02 05:06:24,990 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:24,990 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:24,990 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33247
2020-04-02 05:06:24,991 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:24,991 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:24,991 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:24,993 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:25,001 [Thread-1032] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:25,002 [Thread-1032] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:25,002 [Thread-1032] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:25,002 [Thread-1032] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,002 [Thread-1101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:25,002 [Thread-1102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:25,007 [Thread-1082] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,007 [Thread-1082] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,008 [Thread-1082] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-f3ce3a5f-8b0d-4a66-9555-87ade95f49bc for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 
2020-04-02 05:06:25,010 [Thread-1094] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 26ms
2020-04-02 05:06:25,018 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:25,019 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,020 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:25,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:25,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:25,021 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:25,022 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 35178
2020-04-02 05:06:25,022 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:25,026 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@53093491{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:25,027 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@76b224cd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:25,030 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4c0884e8{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:25,030 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@231baf51{HTTP/1.1,[http/1.1]}{localhost:35178}
2020-04-02 05:06:25,031 [main] INFO  server.Server (Server.java:doStart(419)) - Started @40715ms
2020-04-02 05:06:25,033 [Thread-1082] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,033 [Thread-1082] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,034 [Thread-1082] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,034 [Thread-1082] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,058 [Thread-1095] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 75ms
2020-04-02 05:06:25,059 [Thread-1056] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 75ms
2020-04-02 05:06:25,069 [Thread-1101] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 66ms
2020-04-02 05:06:25,072 [Thread-1102] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 69ms
2020-04-02 05:06:25,073 [Thread-1082] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,073 [Thread-1082] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,073 [Thread-1082] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,073 [Thread-1082] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,075 [Thread-1032] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 72ms
2020-04-02 05:06:25,087 [Thread-1082] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:25,094 [Thread-1108] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3...
2020-04-02 05:06:25,094 [Thread-1082] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2
2020-04-02 05:06:25,098 [Thread-1108] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,098 [Thread-1108] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3: 4ms
2020-04-02 05:06:25,103 [Thread-1110] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1...
2020-04-02 05:06:25,104 [Thread-1109] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4...
2020-04-02 05:06:25,107 [Thread-1110] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,108 [Thread-1110] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1: 5ms
2020-04-02 05:06:25,109 [Thread-1109] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,109 [Thread-1109] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4: 5ms
2020-04-02 05:06:25,109 [Thread-1056] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 50ms
2020-04-02 05:06:25,110 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4
2020-04-02 05:06:25,112 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3
2020-04-02 05:06:25,112 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,113 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:06:25,124 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e340360f-798e-455a-bff2-ca67dfad9811): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,124 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e340360f-798e-455a-bff2-ca67dfad9811): no suitable block pools found to scan.  Waiting 1814399986 ms.
2020-04-02 05:06:25,134 [Thread-1111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2...
2020-04-02 05:06:25,134 [Thread-1111] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,138 [Thread-1111] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2: 4ms
2020-04-02 05:06:25,140 [Thread-1032] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 65ms
2020-04-02 05:06:25,140 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1
2020-04-02 05:06:25,140 [Thread-1082] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8
2020-04-02 05:06:25,141 [Thread-1082] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, StorageType: DISK
2020-04-02 05:06:25,141 [Thread-1032] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:33 AM with interval of 21600000ms
2020-04-02 05:06:25,141 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,141 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:25,144 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2
2020-04-02 05:06:25,144 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-6f852d23-017e-4ab4-8829-fc057e9e3305): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,145 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-6f852d23-017e-4ab4-8829-fc057e9e3305): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:06:25,154 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:25,164 [IPC Server handler 4 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37730, datanodeUuid=0c0cd15a-d4ed-482d-8394-6ccbb807ad9e, infoPort=35240, infoSecurePort=0, ipcPort=44661, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e
2020-04-02 05:06:25,165 [IPC Server handler 4 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:37730
2020-04-02 05:06:25,165 [IPC Server handler 4 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e (127.0.0.1:37730).
2020-04-02 05:06:25,169 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:25,169 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:25,174 [Thread-1056] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:41 AM with interval of 21600000ms
2020-04-02 05:06:25,196 [Thread-1082] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-f3ce3a5f-8b0d-4a66-9555-87ade95f49bc
2020-04-02 05:06:25,196 [Thread-1082] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, StorageType: DISK
2020-04-02 05:06:25,197 [Thread-1082] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:25,198 [Thread-1082] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:25,199 [Thread-1082] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:25,199 [Thread-1082] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:25,199 [Thread-1082] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:25,201 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:25,222 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ba26eabe-5db3-42d6-ba4b-937e2c42a5ac) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:25,225 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46646
2020-04-02 05:06:25,227 [IPC Server handler 5 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681 for DN 127.0.0.1:37730
2020-04-02 05:06:25,227 [IPC Server handler 5 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6f852d23-017e-4ab4-8829-fc057e9e3305 for DN 127.0.0.1:37730
2020-04-02 05:06:25,228 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73877e19] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:25,228 [Thread-1082] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,228 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:25,228 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:25,229 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:25,229 [Thread-1121] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:06:25,229 [Thread-1123] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:06:25,230 [Socket Reader #1 for port 41418] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 41418
2020-04-02 05:06:25,236 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:41418
2020-04-02 05:06:25,245 [IPC Server handler 7 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42968, datanodeUuid=ba26eabe-5db3-42d6-ba4b-937e2c42a5ac, infoPort=43338, infoSecurePort=0, ipcPort=40706, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage ba26eabe-5db3-42d6-ba4b-937e2c42a5ac
2020-04-02 05:06:25,246 [IPC Server handler 7 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r1/127.0.0.1:42968
2020-04-02 05:06:25,246 [IPC Server handler 7 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ba26eabe-5db3-42d6-ba4b-937e2c42a5ac (127.0.0.1:42968).
2020-04-02 05:06:25,250 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ba26eabe-5db3-42d6-ba4b-937e2c42a5ac) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:25,250 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:25,266 [IPC Server handler 6 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37730, datanodeUuid=0c0cd15a-d4ed-482d-8394-6ccbb807ad9e, infoPort=35240, infoSecurePort=0, ipcPort=44661, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:25,286 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x12a01ceec9f85a94: Processing first storage report for DS-6f852d23-017e-4ab4-8829-fc057e9e3305 from datanode 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e
2020-04-02 05:06:25,286 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x12a01ceec9f85a94: from storage DS-6f852d23-017e-4ab4-8829-fc057e9e3305 node DatanodeRegistration(127.0.0.1:37730, datanodeUuid=0c0cd15a-d4ed-482d-8394-6ccbb807ad9e, infoPort=35240, infoSecurePort=0, ipcPort=44661, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,286 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x12a01ceec9f85a94: Processing first storage report for DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681 from datanode 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e
2020-04-02 05:06:25,286 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x12a01ceec9f85a94: from storage DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681 node DatanodeRegistration(127.0.0.1:37730, datanodeUuid=0c0cd15a-d4ed-482d-8394-6ccbb807ad9e, infoPort=35240, infoSecurePort=0, ipcPort=44661, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,286 [IPC Server handler 6 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x12a01ceec9f85a94
2020-04-02 05:06:25,287 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:25,287 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:25,287 [Thread-1123] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 58ms
2020-04-02 05:06:25,291 [IPC Server handler 0 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6 for DN 127.0.0.1:42968
2020-04-02 05:06:25,305 [IPC Server handler 0 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e340360f-798e-455a-bff2-ca67dfad9811 for DN 127.0.0.1:42968
2020-04-02 05:06:25,287 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x12a01ceec9f85a94,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 37 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:25,306 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,307 [IPC Server handler 1 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42968, datanodeUuid=ba26eabe-5db3-42d6-ba4b-937e2c42a5ac, infoPort=43338, infoSecurePort=0, ipcPort=40706, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:25,310 [Thread-1130] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:25,310 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:33247 to rack /r2
2020-04-02 05:06:25,311 [Thread-1121] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 82ms
2020-04-02 05:06:25,311 [Thread-1082] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 83ms
2020-04-02 05:06:25,312 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 41418 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:25,312 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 4 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:25,312 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 4 with hostname set to: host5
2020-04-02 05:06:25,312 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host5 to rack /r3
2020-04-02 05:06:25,313 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:06:25,313 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:25,313 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1b6af25b600ccd8c: Processing first storage report for DS-e340360f-798e-455a-bff2-ca67dfad9811 from datanode ba26eabe-5db3-42d6-ba4b-937e2c42a5ac
2020-04-02 05:06:25,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1b6af25b600ccd8c: from storage DS-e340360f-798e-455a-bff2-ca67dfad9811 node DatanodeRegistration(127.0.0.1:42968, datanodeUuid=ba26eabe-5db3-42d6-ba4b-937e2c42a5ac, infoPort=43338, infoSecurePort=0, ipcPort=40706, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x1b6af25b600ccd8c: Processing first storage report for DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6 from datanode ba26eabe-5db3-42d6-ba4b-937e2c42a5ac
2020-04-02 05:06:25,314 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x1b6af25b600ccd8c: from storage DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6 node DatanodeRegistration(127.0.0.1:42968, datanodeUuid=ba26eabe-5db3-42d6-ba4b-937e2c42a5ac, infoPort=43338, infoSecurePort=0, ipcPort=40706, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,314 [IPC Server handler 1 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x1b6af25b600ccd8c
2020-04-02 05:06:25,314 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x1b6af25b600ccd8c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 8 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:25,314 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,315 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:25,315 [IPC Server listener on 41418] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 41418: starting
2020-04-02 05:06:25,315 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:25,316 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:25,316 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,316 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:25,316 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host5
2020-04-02 05:06:25,316 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,316 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:25,317 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:37044
2020-04-02 05:06:25,317 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:25,317 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:25,322 [Thread-1131] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5...
2020-04-02 05:06:25,322 [Thread-1131] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,322 [Thread-1131] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5: 0ms
2020-04-02 05:06:25,346 [Thread-1130] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:25,366 [Thread-1130] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:25,368 [Thread-1130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,368 [Thread-1130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,368 [Thread-1130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-e597eea4-a429-4c33-beff-4b8242e19398 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 
2020-04-02 05:06:25,369 [Thread-1144] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6...
2020-04-02 05:06:25,370 [Thread-1144] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,372 [Thread-1130] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,372 [Thread-1130] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,372 [Thread-1130] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-bf3e5ff2-fbec-4007-96fd-557942b0b82d for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 
2020-04-02 05:06:25,373 [Thread-1144] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6: 4ms
2020-04-02 05:06:25,374 [Thread-1082] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 63ms
2020-04-02 05:06:25,374 [Thread-1082] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:50 AM with interval of 21600000ms
2020-04-02 05:06:25,374 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5
2020-04-02 05:06:25,375 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,375 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:25,375 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6
2020-04-02 05:06:25,375 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f3ce3a5f-8b0d-4a66-9555-87ade95f49bc): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,399 [Thread-1130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,399 [Thread-1130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,399 [Thread-1130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,399 [Thread-1130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,404 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,405 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:25,410 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:25,410 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,411 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:25,411 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:25,411 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:25,411 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:25,412 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43885
2020-04-02 05:06:25,412 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:25,421 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f3ce3a5f-8b0d-4a66-9555-87ade95f49bc): no suitable block pools found to scan.  Waiting 1814399953 ms.
2020-04-02 05:06:25,424 [Thread-1130] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,424 [Thread-1130] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,425 [Thread-1130] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,425 [Thread-1130] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,426 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@982bb90{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:25,427 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7bef452c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:25,430 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4cd1c1dc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:25,430 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@47f08b81{HTTP/1.1,[http/1.1]}{localhost:43885}
2020-04-02 05:06:25,430 [main] INFO  server.Server (Server.java:doStart(419)) - Started @41114ms
2020-04-02 05:06:25,452 [Thread-1130] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:25,452 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:25,455 [IPC Server handler 4 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:34808, datanodeUuid=9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2, infoPort=35946, infoSecurePort=0, ipcPort=40364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2
2020-04-02 05:06:25,456 [IPC Server handler 4 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:34808
2020-04-02 05:06:25,456 [IPC Server handler 4 on 35549] INFO  blockmanagement.DatanodeManager (DatanodeManager.java:checkIfClusterIsNowMultiRack(1386)) - DN 127.0.0.1:34808 joining cluster has expanded a formerly single-rack cluster to be multi-rack. Re-checking all blocks for replication, since they should now be replicated cross-rack
2020-04-02 05:06:25,458 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:40515
2020-04-02 05:06:25,461 [Thread-1130] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID a9fbe79b-52db-4b37-b18b-cd2580cb2bea
2020-04-02 05:06:25,462 [IPC Server handler 4 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2 (127.0.0.1:34808).
2020-04-02 05:06:25,466 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:25,466 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:25,467 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3475)) - Total number of blocks            = 0
2020-04-02 05:06:25,467 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3476)) - Number of invalid blocks          = 0
2020-04-02 05:06:25,467 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3477)) - Number of under-replicated blocks = 0
2020-04-02 05:06:25,467 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3478)) - Number of  over-replicated blocks = 0
2020-04-02 05:06:25,467 [Reconstruction Queue Initializer] INFO  blockmanagement.BlockManager (BlockManager.java:processMisReplicatesAsync(3480)) - Number of blocks being written    = 0
2020-04-02 05:06:25,467 [Reconstruction Queue Initializer] INFO  hdfs.StateChange (BlockManager.java:processMisReplicatesAsync(3483)) - STATE* Replication Queue initialization scan for invalid, over- and under-replicated blocks completed in 4 msec
2020-04-02 05:06:25,467 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:25,467 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:25,468 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:25,469 [Thread-1130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-e597eea4-a429-4c33-beff-4b8242e19398
2020-04-02 05:06:25,469 [Thread-1130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, StorageType: DISK
2020-04-02 05:06:25,470 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2787de58] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:25,478 [Socket Reader #1 for port 44364] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 44364
2020-04-02 05:06:25,480 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:44364
2020-04-02 05:06:25,482 [Thread-1130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-bf3e5ff2-fbec-4007-96fd-557942b0b82d
2020-04-02 05:06:25,483 [Thread-1130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, StorageType: DISK
2020-04-02 05:06:25,483 [Thread-1130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:25,509 [IPC Server handler 5 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8 for DN 127.0.0.1:34808
2020-04-02 05:06:25,510 [IPC Server handler 5 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-f3ce3a5f-8b0d-4a66-9555-87ade95f49bc for DN 127.0.0.1:34808
2020-04-02 05:06:25,514 [IPC Server handler 7 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:34808, datanodeUuid=9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2, infoPort=35946, infoSecurePort=0, ipcPort=40364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:25,514 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9eb16f39ceeee372: Processing first storage report for DS-f3ce3a5f-8b0d-4a66-9555-87ade95f49bc from datanode 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2
2020-04-02 05:06:25,514 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9eb16f39ceeee372: from storage DS-f3ce3a5f-8b0d-4a66-9555-87ade95f49bc node DatanodeRegistration(127.0.0.1:34808, datanodeUuid=9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2, infoPort=35946, infoSecurePort=0, ipcPort=40364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,514 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x9eb16f39ceeee372: Processing first storage report for DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8 from datanode 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2
2020-04-02 05:06:25,514 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x9eb16f39ceeee372: from storage DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8 node DatanodeRegistration(127.0.0.1:34808, datanodeUuid=9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2, infoPort=35946, infoSecurePort=0, ipcPort=40364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,514 [IPC Server handler 7 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x9eb16f39ceeee372
2020-04-02 05:06:25,515 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x9eb16f39ceeee372,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:25,515 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,523 [Thread-1130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:06:25,528 [Thread-1130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:06:25,528 [Thread-1130] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:25,528 [Thread-1130] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:25,540 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:25,540 [Thread-1130] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,540 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:25,542 [Thread-1161] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:06:25,546 [Thread-1163] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:06:25,547 [Thread-1162] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:25,549 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:37044 to rack /r3
2020-04-02 05:06:25,555 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:25,556 [IPC Server listener on 44364] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 44364: starting
2020-04-02 05:06:25,567 [Thread-1162] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:25,577 [Thread-1161] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 35ms
2020-04-02 05:06:25,580 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 44364 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:25,580 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 5 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:25,580 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 5 with hostname set to: host6
2020-04-02 05:06:25,580 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host6 to rack /r3
2020-04-02 05:06:25,581 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:06:25,581 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:25,582 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:25,582 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:25,583 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,583 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:25,583 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host6
2020-04-02 05:06:25,583 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,583 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:25,587 [Thread-1162] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:25,587 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:36458
2020-04-02 05:06:25,587 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:25,588 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:25,588 [Thread-1162] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,588 [Thread-1162] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,590 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,591 [Thread-1163] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 45ms
2020-04-02 05:06:25,591 [Thread-1130] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 51ms
2020-04-02 05:06:25,592 [Thread-1162] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-a207bb28-410c-481d-8fe8-a34d79121b4f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 
2020-04-02 05:06:25,593 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:25,596 [Thread-1162] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,596 [Thread-1162] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,596 [Thread-1162] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6a1c04de-bad7-4ba3-a256-c0e9eb63dba7 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 
2020-04-02 05:06:25,598 [Thread-1179] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7...
2020-04-02 05:06:25,598 [Thread-1179] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,598 [Thread-1179] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7: 1ms
2020-04-02 05:06:25,606 [Thread-1180] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8...
2020-04-02 05:06:25,606 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:25,606 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:25,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:25,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:25,607 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:25,608 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 41864
2020-04-02 05:06:25,608 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:25,606 [Thread-1180] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,609 [Thread-1180] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8: 3ms
2020-04-02 05:06:25,609 [Thread-1130] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 18ms
2020-04-02 05:06:25,609 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8
2020-04-02 05:06:25,610 [Thread-1130] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:59 AM with interval of 21600000ms
2020-04-02 05:06:25,610 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-bf3e5ff2-fbec-4007-96fd-557942b0b82d): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,610 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7
2020-04-02 05:06:25,610 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-bf3e5ff2-fbec-4007-96fd-557942b0b82d): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:25,612 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-e597eea4-a429-4c33-beff-4b8242e19398): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,612 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@76075d65{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:25,612 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-e597eea4-a429-4c33-beff-4b8242e19398): no suitable block pools found to scan.  Waiting 1814399997 ms.
2020-04-02 05:06:25,612 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@27b71f50{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:25,614 [Thread-1162] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,614 [Thread-1162] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,614 [Thread-1162] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,614 [Thread-1162] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,616 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid a9fbe79b-52db-4b37-b18b-cd2580cb2bea) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:25,626 [IPC Server handler 2 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33247, datanodeUuid=a9fbe79b-52db-4b37-b18b-cd2580cb2bea, infoPort=46646, infoSecurePort=0, ipcPort=41418, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage a9fbe79b-52db-4b37-b18b-cd2580cb2bea
2020-04-02 05:06:25,626 [IPC Server handler 2 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r2/127.0.0.1:33247
2020-04-02 05:06:25,627 [IPC Server handler 2 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN a9fbe79b-52db-4b37-b18b-cd2580cb2bea (127.0.0.1:33247).
2020-04-02 05:06:25,628 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid a9fbe79b-52db-4b37-b18b-cd2580cb2bea) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:25,628 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:25,633 [Thread-1162] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,633 [Thread-1162] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,633 [Thread-1162] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,633 [Thread-1162] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,634 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@57540fd0{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:25,635 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5cf8edcf{HTTP/1.1,[http/1.1]}{localhost:41864}
2020-04-02 05:06:25,635 [main] INFO  server.Server (Server.java:doStart(419)) - Started @41319ms
2020-04-02 05:06:25,641 [Thread-1162] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:25,645 [IPC Server handler 9 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-e597eea4-a429-4c33-beff-4b8242e19398 for DN 127.0.0.1:33247
2020-04-02 05:06:25,646 [IPC Server handler 9 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-bf3e5ff2-fbec-4007-96fd-557942b0b82d for DN 127.0.0.1:33247
2020-04-02 05:06:25,648 [IPC Server handler 6 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33247, datanodeUuid=a9fbe79b-52db-4b37-b18b-cd2580cb2bea, infoPort=46646, infoSecurePort=0, ipcPort=41418, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:25,648 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc5f40d8fb0af3c7a: Processing first storage report for DS-bf3e5ff2-fbec-4007-96fd-557942b0b82d from datanode a9fbe79b-52db-4b37-b18b-cd2580cb2bea
2020-04-02 05:06:25,648 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc5f40d8fb0af3c7a: from storage DS-bf3e5ff2-fbec-4007-96fd-557942b0b82d node DatanodeRegistration(127.0.0.1:33247, datanodeUuid=a9fbe79b-52db-4b37-b18b-cd2580cb2bea, infoPort=46646, infoSecurePort=0, ipcPort=41418, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,648 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc5f40d8fb0af3c7a: Processing first storage report for DS-e597eea4-a429-4c33-beff-4b8242e19398 from datanode a9fbe79b-52db-4b37-b18b-cd2580cb2bea
2020-04-02 05:06:25,648 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc5f40d8fb0af3c7a: from storage DS-e597eea4-a429-4c33-beff-4b8242e19398 node DatanodeRegistration(127.0.0.1:33247, datanodeUuid=a9fbe79b-52db-4b37-b18b-cd2580cb2bea, infoPort=46646, infoSecurePort=0, ipcPort=41418, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,648 [IPC Server handler 6 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xc5f40d8fb0af3c7a
2020-04-02 05:06:25,649 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc5f40d8fb0af3c7a,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:25,649 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,651 [Thread-1162] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 874ddb90-8989-4188-8171-bd95d2ab0583
2020-04-02 05:06:25,653 [Thread-1162] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-a207bb28-410c-481d-8fe8-a34d79121b4f
2020-04-02 05:06:25,654 [Thread-1162] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, StorageType: DISK
2020-04-02 05:06:25,655 [Thread-1162] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6a1c04de-bad7-4ba3-a256-c0e9eb63dba7
2020-04-02 05:06:25,655 [Thread-1162] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, StorageType: DISK
2020-04-02 05:06:25,655 [Thread-1162] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:25,656 [Thread-1162] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:06:25,665 [Thread-1162] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:06:25,666 [Thread-1162] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:25,666 [Thread-1162] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:25,689 [Thread-1162] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,701 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:35072
2020-04-02 05:06:25,702 [Thread-1189] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:06:25,704 [Thread-1191] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:06:25,710 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:25,710 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:25,710 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:25,711 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@629f066f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:25,711 [Socket Reader #1 for port 39632] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 39632
2020-04-02 05:06:25,725 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:39632
2020-04-02 05:06:25,734 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:25,735 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:25,736 [Thread-1199] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:25,737 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:36458 to rack /r3
2020-04-02 05:06:25,737 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:25,737 [IPC Server listener on 39632] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 39632: starting
2020-04-02 05:06:25,738 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 39632 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:25,739 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 6 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:25,739 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 6 with hostname set to: host7
2020-04-02 05:06:25,739 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host7 to rack /r4
2020-04-02 05:06:25,740 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:06:25,743 [Thread-1199] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:25,757 [Thread-1191] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 53ms
2020-04-02 05:06:25,757 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:25,770 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:25,770 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:25,770 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,770 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:25,770 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host7
2020-04-02 05:06:25,771 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,771 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:25,771 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33731
2020-04-02 05:06:25,771 [Thread-1199] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:25,771 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:25,772 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:25,773 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,773 [Thread-1199] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,774 [Thread-1199] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,774 [Thread-1199] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 
2020-04-02 05:06:25,775 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:25,777 [Thread-1199] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,777 [Thread-1199] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,777 [Thread-1199] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-5d27cc6e-7a7e-4b9c-980d-cbeac70640d0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 
2020-04-02 05:06:25,790 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:25,790 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,791 [Thread-1199] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,791 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:25,791 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:25,792 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:25,792 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:25,794 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44199
2020-04-02 05:06:25,794 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:25,795 [Thread-1199] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,795 [Thread-1199] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,795 [Thread-1199] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,799 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@393881f0{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:25,799 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4158debd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:25,803 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@77a281fc{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:25,803 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@4912d525{HTTP/1.1,[http/1.1]}{localhost:44199}
2020-04-02 05:06:25,803 [main] INFO  server.Server (Server.java:doStart(419)) - Started @41487ms
2020-04-02 05:06:25,808 [Thread-1199] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,808 [Thread-1199] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,809 [Thread-1199] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,809 [Thread-1199] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,818 [Thread-1199] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:25,822 [Thread-1199] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 6183ec45-626a-4231-a4a4-eb75700b84c5
2020-04-02 05:06:25,824 [Thread-1199] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef
2020-04-02 05:06:25,824 [Thread-1199] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, StorageType: DISK
2020-04-02 05:06:25,825 [Thread-1199] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-5d27cc6e-7a7e-4b9c-980d-cbeac70640d0
2020-04-02 05:06:25,825 [Thread-1199] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, StorageType: DISK
2020-04-02 05:06:25,826 [Thread-1199] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:25,826 [Thread-1199] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:06:25,838 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:43185
2020-04-02 05:06:25,827 [Thread-1189] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 125ms
2020-04-02 05:06:25,838 [Thread-1162] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 138ms
2020-04-02 05:06:25,839 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:25,839 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:25,839 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:25,839 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@765df79d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:25,842 [Thread-1219] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9...
2020-04-02 05:06:25,842 [Thread-1219] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,843 [Thread-1219] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9: 1ms
2020-04-02 05:06:25,843 [Thread-1199] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:06:25,843 [Thread-1199] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:25,843 [Thread-1199] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:25,847 [Thread-1199] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,847 [Thread-1222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:06:25,847 [Thread-1223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:06:25,849 [Socket Reader #1 for port 37899] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 37899
2020-04-02 05:06:25,854 [Thread-1221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10...
2020-04-02 05:06:25,854 [Thread-1221] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,854 [Thread-1221] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10: 0ms
2020-04-02 05:06:25,854 [Thread-1162] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 15ms
2020-04-02 05:06:25,855 [Thread-1162] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:22 AM with interval of 21600000ms
2020-04-02 05:06:25,857 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:37899
2020-04-02 05:06:25,857 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9
2020-04-02 05:06:25,858 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-a207bb28-410c-481d-8fe8-a34d79121b4f): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,858 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-a207bb28-410c-481d-8fe8-a34d79121b4f): no suitable block pools found to scan.  Waiting 1814399996 ms.
2020-04-02 05:06:25,858 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10
2020-04-02 05:06:25,859 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-6a1c04de-bad7-4ba3-a256-c0e9eb63dba7): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,859 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-6a1c04de-bad7-4ba3-a256-c0e9eb63dba7): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:06:25,860 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:25,860 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:25,861 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 874ddb90-8989-4188-8171-bd95d2ab0583) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:25,861 [Thread-1232] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:25,861 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:33731 to rack /r4
2020-04-02 05:06:25,862 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:25,862 [IPC Server handler 1 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:37044, datanodeUuid=874ddb90-8989-4188-8171-bd95d2ab0583, infoPort=40515, infoSecurePort=0, ipcPort=44364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 874ddb90-8989-4188-8171-bd95d2ab0583
2020-04-02 05:06:25,862 [IPC Server listener on 37899] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 37899: starting
2020-04-02 05:06:25,863 [IPC Server handler 1 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:37044
2020-04-02 05:06:25,864 [IPC Server handler 1 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 874ddb90-8989-4188-8171-bd95d2ab0583 (127.0.0.1:37044).
2020-04-02 05:06:25,865 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 37899 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:25,865 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 874ddb90-8989-4188-8171-bd95d2ab0583) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:25,865 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:25,865 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 7 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:25,865 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 7 with hostname set to: host8
2020-04-02 05:06:25,869 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host8 to rack /r4
2020-04-02 05:06:25,869 [Thread-1232] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:25,875 [Thread-1232] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:25,877 [IPC Server handler 4 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-a207bb28-410c-481d-8fe8-a34d79121b4f for DN 127.0.0.1:37044
2020-04-02 05:06:25,878 [IPC Server handler 4 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6a1c04de-bad7-4ba3-a256-c0e9eb63dba7 for DN 127.0.0.1:37044
2020-04-02 05:06:25,879 [IPC Server handler 5 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:37044, datanodeUuid=874ddb90-8989-4188-8171-bd95d2ab0583, infoPort=40515, infoSecurePort=0, ipcPort=44364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:25,879 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc1687f4ed2ef479c: Processing first storage report for DS-a207bb28-410c-481d-8fe8-a34d79121b4f from datanode 874ddb90-8989-4188-8171-bd95d2ab0583
2020-04-02 05:06:25,880 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc1687f4ed2ef479c: from storage DS-a207bb28-410c-481d-8fe8-a34d79121b4f node DatanodeRegistration(127.0.0.1:37044, datanodeUuid=874ddb90-8989-4188-8171-bd95d2ab0583, infoPort=40515, infoSecurePort=0, ipcPort=44364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,880 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc1687f4ed2ef479c: Processing first storage report for DS-6a1c04de-bad7-4ba3-a256-c0e9eb63dba7 from datanode 874ddb90-8989-4188-8171-bd95d2ab0583
2020-04-02 05:06:25,880 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc1687f4ed2ef479c: from storage DS-6a1c04de-bad7-4ba3-a256-c0e9eb63dba7 node DatanodeRegistration(127.0.0.1:37044, datanodeUuid=874ddb90-8989-4188-8171-bd95d2ab0583, infoPort=40515, infoSecurePort=0, ipcPort=44364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,880 [IPC Server handler 5 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xc1687f4ed2ef479c
2020-04-02 05:06:25,880 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc1687f4ed2ef479c,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 1 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:25,880 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,890 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:06:25,897 [Thread-1232] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,898 [Thread-1232] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,898 [Thread-1232] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-9674fb44-3f94-4af4-b754-d5a2483a230e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 
2020-04-02 05:06:25,906 [Thread-1223] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 59ms
2020-04-02 05:06:25,910 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:25,912 [Thread-1232] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,912 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:25,912 [Thread-1232] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,912 [Thread-1232] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-69abce45-7fd1-412a-be89-0b8bab3b233e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 
2020-04-02 05:06:25,912 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:25,913 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,913 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:25,913 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host8
2020-04-02 05:06:25,914 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,914 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:25,914 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:33106
2020-04-02 05:06:25,914 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:25,915 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:25,915 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,917 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:25,917 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:25,917 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,918 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:25,918 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:25,918 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:25,919 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:25,919 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34506
2020-04-02 05:06:25,919 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:25,920 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7fab4be7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:25,921 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d74c3ba{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:25,924 [Thread-1222] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 78ms
2020-04-02 05:06:25,925 [Thread-1199] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 78ms
2020-04-02 05:06:25,925 [Thread-1250] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11...
2020-04-02 05:06:25,926 [Thread-1251] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12...
2020-04-02 05:06:25,926 [Thread-1250] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,926 [Thread-1251] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:25,926 [Thread-1251] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12: 0ms
2020-04-02 05:06:25,926 [Thread-1250] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11: 0ms
2020-04-02 05:06:25,928 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@70e3f36f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:25,929 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@49601f82{HTTP/1.1,[http/1.1]}{localhost:34506}
2020-04-02 05:06:25,929 [main] INFO  server.Server (Server.java:doStart(419)) - Started @41613ms
2020-04-02 05:06:25,929 [Thread-1199] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 5ms
2020-04-02 05:06:25,930 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12
2020-04-02 05:06:25,930 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-5d27cc6e-7a7e-4b9c-980d-cbeac70640d0): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,930 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11
2020-04-02 05:06:25,930 [Thread-1199] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:21 AM with interval of 21600000ms
2020-04-02 05:06:25,930 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,931 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-5d27cc6e-7a7e-4b9c-980d-cbeac70640d0): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:25,931 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:25,938 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 6183ec45-626a-4231-a4a4-eb75700b84c5) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:25,939 [IPC Server handler 7 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:36458, datanodeUuid=6183ec45-626a-4231-a4a4-eb75700b84c5, infoPort=35072, infoSecurePort=0, ipcPort=39632, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 6183ec45-626a-4231-a4a4-eb75700b84c5
2020-04-02 05:06:25,942 [IPC Server handler 7 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r3/127.0.0.1:36458
2020-04-02 05:06:25,942 [IPC Server handler 7 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 6183ec45-626a-4231-a4a4-eb75700b84c5 (127.0.0.1:36458).
2020-04-02 05:06:25,943 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 6183ec45-626a-4231-a4a4-eb75700b84c5) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:25,943 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:25,944 [Thread-1232] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,945 [Thread-1232] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,945 [Thread-1232] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,945 [Thread-1232] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,951 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46497
2020-04-02 05:06:25,958 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:25,958 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:25,958 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:25,965 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2b8d084] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:25,965 [Socket Reader #1 for port 46395] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 46395
2020-04-02 05:06:25,967 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:46395
2020-04-02 05:06:25,968 [IPC Server handler 8 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef for DN 127.0.0.1:36458
2020-04-02 05:06:25,969 [Thread-1232] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,969 [Thread-1232] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,969 [Thread-1232] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:25,969 [Thread-1232] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:25,975 [Thread-1232] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:25,977 [IPC Server handler 8 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-5d27cc6e-7a7e-4b9c-980d-cbeac70640d0 for DN 127.0.0.1:36458
2020-04-02 05:06:25,978 [IPC Server handler 2 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:36458, datanodeUuid=6183ec45-626a-4231-a4a4-eb75700b84c5, infoPort=35072, infoSecurePort=0, ipcPort=39632, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:25,978 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:25,978 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x35667f3f6941ed0b: Processing first storage report for DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef from datanode 6183ec45-626a-4231-a4a4-eb75700b84c5
2020-04-02 05:06:25,979 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x35667f3f6941ed0b: from storage DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef node DatanodeRegistration(127.0.0.1:36458, datanodeUuid=6183ec45-626a-4231-a4a4-eb75700b84c5, infoPort=35072, infoSecurePort=0, ipcPort=39632, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,979 [Thread-1232] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 499eb5ac-ae2d-44fb-9673-4fe321174279
2020-04-02 05:06:25,979 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x35667f3f6941ed0b: Processing first storage report for DS-5d27cc6e-7a7e-4b9c-980d-cbeac70640d0 from datanode 6183ec45-626a-4231-a4a4-eb75700b84c5
2020-04-02 05:06:25,979 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x35667f3f6941ed0b: from storage DS-5d27cc6e-7a7e-4b9c-980d-cbeac70640d0 node DatanodeRegistration(127.0.0.1:36458, datanodeUuid=6183ec45-626a-4231-a4a4-eb75700b84c5, infoPort=35072, infoSecurePort=0, ipcPort=39632, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:25,979 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:25,979 [IPC Server handler 2 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x35667f3f6941ed0b
2020-04-02 05:06:25,980 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x35667f3f6941ed0b,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:25,980 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,980 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:33106 to rack /r4
2020-04-02 05:06:25,980 [Thread-1261] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:25,980 [Thread-1232] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-9674fb44-3f94-4af4-b754-d5a2483a230e
2020-04-02 05:06:25,981 [Thread-1232] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, StorageType: DISK
2020-04-02 05:06:25,981 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:25,982 [IPC Server listener on 46395] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 46395: starting
2020-04-02 05:06:25,983 [Thread-1232] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-69abce45-7fd1-412a-be89-0b8bab3b233e
2020-04-02 05:06:25,983 [Thread-1232] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, StorageType: DISK
2020-04-02 05:06:25,985 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 46395 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:25,986 [Thread-1232] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:25,986 [Thread-1261] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:25,987 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 8 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:25,987 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 8 with hostname set to: host9
2020-04-02 05:06:25,987 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host9 to rack /r5
2020-04-02 05:06:25,988 [Thread-1232] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:06:25,988 [Thread-1232] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:06:25,988 [Thread-1232] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:25,988 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:25,987 [Thread-1261] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:25,988 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:25,988 [Thread-1232] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:25,989 [Thread-1232] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:25,989 [Thread-1274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:06:25,989 [Thread-1275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:06:25,989 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:25,990 [Thread-1261] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,990 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:25,990 [Thread-1261] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,990 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,990 [Thread-1261] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-8f6a1812-bbcb-49b0-b908-019163e1029e for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 
2020-04-02 05:06:25,990 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:25,991 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host9
2020-04-02 05:06:25,991 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:25,991 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:25,992 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46180
2020-04-02 05:06:25,992 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:25,992 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:25,993 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,993 [Thread-1261] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:25,993 [Thread-1261] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:25,993 [Thread-1261] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-6183ce27-b812-46b5-9295-07522be01ed0 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 
2020-04-02 05:06:25,994 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:25,994 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:25,994 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:25,995 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:25,995 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:25,995 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:25,996 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:25,996 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 43103
2020-04-02 05:06:25,996 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:25,998 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1dcca8d3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:25,999 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@52a70627{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:26,002 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@50d3bf39{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:26,002 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@25a73de1{HTTP/1.1,[http/1.1]}{localhost:43103}
2020-04-02 05:06:26,008 [main] INFO  server.Server (Server.java:doStart(419)) - Started @41692ms
2020-04-02 05:06:26,011 [Thread-1261] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,011 [Thread-1261] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,011 [Thread-1261] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:26,011 [Thread-1261] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:26,018 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:46059
2020-04-02 05:06:26,019 [Thread-1274] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 30ms
2020-04-02 05:06:26,019 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:26,019 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@771db12c] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:26,019 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:26,019 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:26,020 [Socket Reader #1 for port 43719] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 43719
2020-04-02 05:06:26,022 [Thread-1275] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 33ms
2020-04-02 05:06:26,022 [Thread-1232] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 33ms
2020-04-02 05:06:26,022 [Thread-1287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13...
2020-04-02 05:06:26,022 [Thread-1288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14...
2020-04-02 05:06:26,022 [Thread-1287] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,023 [Thread-1288] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,023 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:43719
2020-04-02 05:06:26,024 [Thread-1261] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,026 [Thread-1261] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,206 [Thread-1261] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:26,208 [Thread-1261] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:26,023 [Thread-1288] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14: 0ms
2020-04-02 05:06:26,023 [Thread-1287] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13: 0ms
2020-04-02 05:06:26,208 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:26,210 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:26,211 [Thread-1232] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 189ms
2020-04-02 05:06:26,211 [Thread-1292] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:26,211 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13
2020-04-02 05:06:26,211 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:46180 to rack /r5
2020-04-02 05:06:26,211 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-9674fb44-3f94-4af4-b754-d5a2483a230e): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,212 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:26,212 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-9674fb44-3f94-4af4-b754-d5a2483a230e): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:26,212 [IPC Server listener on 43719] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 43719: starting
2020-04-02 05:06:26,213 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 43719 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:26,213 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14
2020-04-02 05:06:26,234 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-69abce45-7fd1-412a-be89-0b8bab3b233e): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,234 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-69abce45-7fd1-412a-be89-0b8bab3b233e): no suitable block pools found to scan.  Waiting 1814399977 ms.
2020-04-02 05:06:26,226 [Thread-1261] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:26,218 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 9 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:26,252 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 9 with hostname set to: host10
2020-04-02 05:06:26,252 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host10 to rack /r5
2020-04-02 05:06:26,252 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:26,213 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:26,218 [Thread-1232] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 11:01 AM with interval of 21600000ms
2020-04-02 05:06:26,253 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:26,234 [Thread-1292] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:26,276 [Thread-1261] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 5054b13f-a3f6-4074-bc6c-a1ca74a9f377
2020-04-02 05:06:26,276 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 499eb5ac-ae2d-44fb-9673-4fe321174279) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:26,278 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:26,279 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:26,279 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:26,279 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:26,280 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host10
2020-04-02 05:06:26,280 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:26,280 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:26,280 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:41962
2020-04-02 05:06:26,281 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:26,281 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:26,283 [IPC Server handler 0 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33731, datanodeUuid=499eb5ac-ae2d-44fb-9673-4fe321174279, infoPort=43185, infoSecurePort=0, ipcPort=37899, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 499eb5ac-ae2d-44fb-9673-4fe321174279
2020-04-02 05:06:26,283 [IPC Server handler 0 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:33731
2020-04-02 05:06:26,283 [IPC Server handler 0 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 499eb5ac-ae2d-44fb-9673-4fe321174279 (127.0.0.1:33731).
2020-04-02 05:06:26,290 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 499eb5ac-ae2d-44fb-9673-4fe321174279) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:26,290 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:26,293 [Thread-1261] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-8f6a1812-bbcb-49b0-b908-019163e1029e
2020-04-02 05:06:26,294 [Thread-1261] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, StorageType: DISK
2020-04-02 05:06:26,294 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:26,296 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:26,296 [Thread-1261] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-6183ce27-b812-46b5-9295-07522be01ed0
2020-04-02 05:06:26,296 [Thread-1261] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, StorageType: DISK
2020-04-02 05:06:26,296 [Thread-1261] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:26,297 [Thread-1261] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:06:26,297 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:26,298 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:26,299 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:26,303 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:26,303 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:26,303 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:26,304 [Thread-1261] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:06:26,304 [Thread-1261] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:26,304 [Thread-1261] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:26,304 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44029
2020-04-02 05:06:26,304 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:26,321 [Thread-1292] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:26,322 [Thread-1261] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,322 [Thread-1314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:06:26,328 [IPC Server handler 1 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-9674fb44-3f94-4af4-b754-d5a2483a230e for DN 127.0.0.1:33731
2020-04-02 05:06:26,328 [IPC Server handler 1 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-69abce45-7fd1-412a-be89-0b8bab3b233e for DN 127.0.0.1:33731
2020-04-02 05:06:26,329 [IPC Server handler 3 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33731, datanodeUuid=499eb5ac-ae2d-44fb-9673-4fe321174279, infoPort=43185, infoSecurePort=0, ipcPort=37899, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:26,331 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6a9d5dff{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:26,331 [Thread-1315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:06:26,331 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2bac9ba{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:26,332 [Thread-1292] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:26,332 [Thread-1292] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:26,332 [Thread-1292] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 
2020-04-02 05:06:26,334 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf7e9222ad4741081: Processing first storage report for DS-69abce45-7fd1-412a-be89-0b8bab3b233e from datanode 499eb5ac-ae2d-44fb-9673-4fe321174279
2020-04-02 05:06:26,334 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf7e9222ad4741081: from storage DS-69abce45-7fd1-412a-be89-0b8bab3b233e node DatanodeRegistration(127.0.0.1:33731, datanodeUuid=499eb5ac-ae2d-44fb-9673-4fe321174279, infoPort=43185, infoSecurePort=0, ipcPort=37899, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,334 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xf7e9222ad4741081: Processing first storage report for DS-9674fb44-3f94-4af4-b754-d5a2483a230e from datanode 499eb5ac-ae2d-44fb-9673-4fe321174279
2020-04-02 05:06:26,334 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xf7e9222ad4741081: from storage DS-9674fb44-3f94-4af4-b754-d5a2483a230e node DatanodeRegistration(127.0.0.1:33731, datanodeUuid=499eb5ac-ae2d-44fb-9673-4fe321174279, infoPort=43185, infoSecurePort=0, ipcPort=37899, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,334 [IPC Server handler 3 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xf7e9222ad4741081
2020-04-02 05:06:26,335 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@6be25526{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:26,335 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xf7e9222ad4741081,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:26,335 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,335 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@42435b98{HTTP/1.1,[http/1.1]}{localhost:44029}
2020-04-02 05:06:26,335 [main] INFO  server.Server (Server.java:doStart(419)) - Started @42019ms
2020-04-02 05:06:26,339 [Thread-1292] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:26,339 [Thread-1292] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:26,339 [Thread-1292] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 
2020-04-02 05:06:26,349 [Thread-1292] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,357 [Thread-1292] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,358 [Thread-1292] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:26,358 [Thread-1292] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:26,379 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34063
2020-04-02 05:06:26,380 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:26,380 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:26,381 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:26,382 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@70e02081] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:26,384 [Socket Reader #1 for port 40450] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 40450
2020-04-02 05:06:26,400 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:40450
2020-04-02 05:06:26,409 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:26,409 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:26,410 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:41962 to rack /r5
2020-04-02 05:06:26,411 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:26,411 [IPC Server listener on 40450] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 40450: starting
2020-04-02 05:06:26,411 [Thread-1324] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:26,412 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 40450 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:26,413 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1632)) - Starting DataNode 10 with dfs.datanode.data.dir: [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21,[DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-04-02 05:06:26,413 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1637)) - Starting DataNode 10 with hostname set to: host11
2020-04-02 05:06:26,413 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1642)) - Adding node with hostname : host11 to rack /r6
2020-04-02 05:06:26,414 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-04-02 05:06:26,415 [Thread-1292] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,415 [Thread-1292] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,415 [Thread-1292] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:26,415 [Thread-1292] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:26,418 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-04-02 05:06:26,419 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:26,419 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:26,419 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:26,420 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:26,420 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host11
2020-04-02 05:06:26,420 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:26,420 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:26,421 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46530
2020-04-02 05:06:26,421 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:26,421 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:26,423 [Thread-1314] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 100ms
2020-04-02 05:06:26,424 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:26,427 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:26,428 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:26,428 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:26,429 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:26,423 [Thread-1315] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 92ms
2020-04-02 05:06:26,426 [Thread-1292] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:26,436 [Thread-1261] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 114ms
2020-04-02 05:06:26,448 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:26,448 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:26,448 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:26,449 [Thread-1338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15...
2020-04-02 05:06:26,449 [Thread-1338] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,449 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 34285
2020-04-02 05:06:26,449 [Thread-1292] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 42af86f4-4249-4b00-a816-b31104ce7014
2020-04-02 05:06:26,457 [Thread-1339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16...
2020-04-02 05:06:26,457 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:26,457 [Thread-1339] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,460 [Thread-1338] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15: 11ms
2020-04-02 05:06:26,471 [Thread-1339] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16: 14ms
2020-04-02 05:06:26,471 [Thread-1324] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:26,473 [Thread-1261] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 34ms
2020-04-02 05:06:26,508 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16
2020-04-02 05:06:26,508 [Thread-1261] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:13 AM with interval of 21600000ms
2020-04-02 05:06:26,508 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-6183ce27-b812-46b5-9295-07522be01ed0): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,508 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15
2020-04-02 05:06:26,508 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-8f6a1812-bbcb-49b0-b908-019163e1029e): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,509 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-6183ce27-b812-46b5-9295-07522be01ed0): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:26,509 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-8f6a1812-bbcb-49b0-b908-019163e1029e): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:26,504 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@49798e84{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:26,502 [Thread-1292] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9
2020-04-02 05:06:26,500 [Thread-1324] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:26,511 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 5054b13f-a3f6-4074-bc6c-a1ca74a9f377) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:26,514 [Thread-1292] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:06:26,514 [Thread-1324] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:26,514 [IPC Server handler 5 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:33106, datanodeUuid=5054b13f-a3f6-4074-bc6c-a1ca74a9f377, infoPort=46497, infoSecurePort=0, ipcPort=46395, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 5054b13f-a3f6-4074-bc6c-a1ca74a9f377
2020-04-02 05:06:26,515 [Thread-1324] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:26,515 [IPC Server handler 5 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r4/127.0.0.1:33106
2020-04-02 05:06:26,515 [Thread-1324] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-0f872257-0803-4a7c-9b42-bc5c33391e2b for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 
2020-04-02 05:06:26,515 [IPC Server handler 5 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 5054b13f-a3f6-4074-bc6c-a1ca74a9f377 (127.0.0.1:33106).
2020-04-02 05:06:26,516 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 5054b13f-a3f6-4074-bc6c-a1ca74a9f377) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:26,516 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:26,521 [Thread-1292] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de
2020-04-02 05:06:26,521 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3015db78{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:26,523 [Thread-1324] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:26,523 [Thread-1324] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:26,523 [Thread-1324] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 
2020-04-02 05:06:26,522 [Thread-1292] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:06:26,538 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@1ba05e38{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:26,538 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6c298dc{HTTP/1.1,[http/1.1]}{localhost:34285}
2020-04-02 05:06:26,539 [main] INFO  server.Server (Server.java:doStart(419)) - Started @42223ms
2020-04-02 05:06:26,541 [Thread-1292] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:26,547 [Thread-1324] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,548 [Thread-1324] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,548 [Thread-1324] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:26,548 [Thread-1324] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:26,548 [IPC Server handler 7 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-8f6a1812-bbcb-49b0-b908-019163e1029e for DN 127.0.0.1:33106
2020-04-02 05:06:26,553 [Thread-1292] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:26,558 [Thread-1292] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:26,558 [Thread-1292] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:26,558 [Thread-1292] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:26,571 [Thread-1292] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,572 [Thread-1348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:06:26,572 [Thread-1349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:06:26,577 [Thread-1324] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,579 [Thread-1324] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,579 [Thread-1324] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:26,579 [Thread-1324] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:26,581 [Thread-1324] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:26,583 [Thread-1324] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID ac5d1b19-0726-415d-bf37-2b9000785dd3
2020-04-02 05:06:26,585 [Thread-1324] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0f872257-0803-4a7c-9b42-bc5c33391e2b
2020-04-02 05:06:26,585 [Thread-1324] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-04-02 05:06:26,586 [Thread-1324] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886
2020-04-02 05:06:26,586 [Thread-1324] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-04-02 05:06:26,586 [Thread-1324] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:26,587 [Thread-1324] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:26,587 [Thread-1324] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:26,587 [Thread-1324] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:26,587 [Thread-1324] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:26,590 [IPC Server handler 7 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-6183ce27-b812-46b5-9295-07522be01ed0 for DN 127.0.0.1:33106
2020-04-02 05:06:26,590 [Thread-1324] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,591 [Thread-1352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:06:26,591 [Thread-1353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:06:26,593 [IPC Server handler 8 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:33106, datanodeUuid=5054b13f-a3f6-4074-bc6c-a1ca74a9f377, infoPort=46497, infoSecurePort=0, ipcPort=46395, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:26,593 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb426ab977f36394e: Processing first storage report for DS-8f6a1812-bbcb-49b0-b908-019163e1029e from datanode 5054b13f-a3f6-4074-bc6c-a1ca74a9f377
2020-04-02 05:06:26,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb426ab977f36394e: from storage DS-8f6a1812-bbcb-49b0-b908-019163e1029e node DatanodeRegistration(127.0.0.1:33106, datanodeUuid=5054b13f-a3f6-4074-bc6c-a1ca74a9f377, infoPort=46497, infoSecurePort=0, ipcPort=46395, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xb426ab977f36394e: Processing first storage report for DS-6183ce27-b812-46b5-9295-07522be01ed0 from datanode 5054b13f-a3f6-4074-bc6c-a1ca74a9f377
2020-04-02 05:06:26,594 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xb426ab977f36394e: from storage DS-6183ce27-b812-46b5-9295-07522be01ed0 node DatanodeRegistration(127.0.0.1:33106, datanodeUuid=5054b13f-a3f6-4074-bc6c-a1ca74a9f377, infoPort=46497, infoSecurePort=0, ipcPort=46395, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,594 [IPC Server handler 8 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xb426ab977f36394e
2020-04-02 05:06:26,594 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xb426ab977f36394e,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:26,595 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,625 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:33476
2020-04-02 05:06:26,627 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:26,627 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:26,627 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@723ed581] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:26,627 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:26,628 [Socket Reader #1 for port 35135] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 35135
2020-04-02 05:06:26,646 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:35135
2020-04-02 05:06:26,651 [Thread-1349] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 79ms
2020-04-02 05:06:26,653 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:26,653 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:26,655 [Thread-1364] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:26,655 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:startDataNodes(1697)) - Adding node with service : 127.0.0.1:46530 to rack /r6
2020-04-02 05:06:26,655 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:26,655 [IPC Server listener on 35135] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 35135: starting
2020-04-02 05:06:26,692 [Thread-1364] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:26,692 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 35135 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:26,703 [Thread-1364] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:26,709 [IPC Server handler 9 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:26,710 [Thread-1348] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 138ms
2020-04-02 05:06:26,713 [Thread-1364] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:26,714 [Thread-1364] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:26,714 [Thread-1364] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-733d9975-fce7-4435-94c9-e43ca04369b5 for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 
2020-04-02 05:06:26,714 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:26,715 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:26,718 [Thread-1352] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 127ms
2020-04-02 05:06:26,719 [Thread-1364] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:26,719 [Thread-1364] INFO  common.Storage (DataStorage.java:loadStorageDirectory(282)) - Storage directory with location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 is not formatted for namespace 940059269. Formatting...
2020-04-02 05:06:26,720 [Thread-1364] INFO  common.Storage (DataStorage.java:createStorageID(160)) - Generated new storageID DS-1472bf47-db39-4471-86fd-8d0e3df73f7f for directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 
2020-04-02 05:06:26,720 [Thread-1353] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 129ms
2020-04-02 05:06:26,720 [Thread-1324] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 129ms
2020-04-02 05:06:26,721 [Thread-1376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:06:26,721 [Thread-1377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:06:26,721 [Thread-1377] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,721 [Thread-1376] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,721 [Thread-1377] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 0ms
2020-04-02 05:06:26,723 [Thread-1376] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 2ms
2020-04-02 05:06:26,721 [Thread-1292] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 149ms
2020-04-02 05:06:26,724 [Thread-1378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:06:26,724 [Thread-1324] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 4ms
2020-04-02 05:06:26,724 [Thread-1378] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,724 [Thread-1379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:06:26,724 [Thread-1378] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 0ms
2020-04-02 05:06:26,724 [Thread-1379] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,724 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:26,724 [Thread-1324] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 7:04 AM with interval of 21600000ms
2020-04-02 05:06:26,725 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-0f872257-0803-4a7c-9b42-bc5c33391e2b): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,725 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-0f872257-0803-4a7c-9b42-bc5c33391e2b): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:26,727 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:26,736 [Thread-1379] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 12ms
2020-04-02 05:06:26,737 [Thread-1292] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 13ms
2020-04-02 05:06:26,737 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,737 [Thread-1292] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:03 AM with interval of 21600000ms
2020-04-02 05:06:26,738 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886): no suitable block pools found to scan.  Waiting 1814399986 ms.
2020-04-02 05:06:26,738 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:26,738 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ac5d1b19-0726-415d-bf37-2b9000785dd3) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:26,738 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:26,741 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,741 [IPC Server handler 6 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:41962, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=34063, infoSecurePort=0, ipcPort=40450, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage ac5d1b19-0726-415d-bf37-2b9000785dd3
2020-04-02 05:06:26,742 [IPC Server handler 6 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:41962
2020-04-02 05:06:26,742 [IPC Server handler 6 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ac5d1b19-0726-415d-bf37-2b9000785dd3 (127.0.0.1:41962).
2020-04-02 05:06:26,741 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 42af86f4-4249-4b00-a816-b31104ce7014) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:26,742 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9): no suitable block pools found to scan.  Waiting 1814399995 ms.
2020-04-02 05:06:26,743 [IPC Server handler 0 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46180, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=46059, infoSecurePort=0, ipcPort=43719, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 42af86f4-4249-4b00-a816-b31104ce7014
2020-04-02 05:06:26,744 [IPC Server handler 0 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:46180
2020-04-02 05:06:26,744 [IPC Server handler 0 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 42af86f4-4249-4b00-a816-b31104ce7014 (127.0.0.1:46180).
2020-04-02 05:06:26,744 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 42af86f4-4249-4b00-a816-b31104ce7014) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:26,744 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:26,753 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,754 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de): no suitable block pools found to scan.  Waiting 1814399983 ms.
2020-04-02 05:06:26,754 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ac5d1b19-0726-415d-bf37-2b9000785dd3) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:26,754 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:26,754 [Thread-1364] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,755 [Thread-1364] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,755 [Thread-1364] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:26,755 [Thread-1364] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:26,759 [IPC Server handler 1 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9 for DN 127.0.0.1:46180
2020-04-02 05:06:26,759 [IPC Server handler 1 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de for DN 127.0.0.1:46180
2020-04-02 05:06:26,763 [IPC Server handler 4 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46180, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=46059, infoSecurePort=0, ipcPort=43719, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:26,764 [IPC Server handler 3 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0f872257-0803-4a7c-9b42-bc5c33391e2b for DN 127.0.0.1:41962
2020-04-02 05:06:26,765 [IPC Server handler 3 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886 for DN 127.0.0.1:41962
2020-04-02 05:06:26,766 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x960d944a8dde560d: Processing first storage report for DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9 from datanode 42af86f4-4249-4b00-a816-b31104ce7014
2020-04-02 05:06:26,766 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x960d944a8dde560d: from storage DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9 node DatanodeRegistration(127.0.0.1:46180, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=46059, infoSecurePort=0, ipcPort=43719, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,766 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x960d944a8dde560d: Processing first storage report for DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de from datanode 42af86f4-4249-4b00-a816-b31104ce7014
2020-04-02 05:06:26,766 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x960d944a8dde560d: from storage DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de node DatanodeRegistration(127.0.0.1:46180, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=46059, infoSecurePort=0, ipcPort=43719, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,766 [IPC Server handler 4 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x960d944a8dde560d
2020-04-02 05:06:26,767 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x960d944a8dde560d,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 1 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:26,767 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,769 [IPC Server handler 5 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:41962, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=34063, infoSecurePort=0, ipcPort=40450, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:26,770 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7fc9171b57b4a147: Processing first storage report for DS-0f872257-0803-4a7c-9b42-bc5c33391e2b from datanode ac5d1b19-0726-415d-bf37-2b9000785dd3
2020-04-02 05:06:26,770 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7fc9171b57b4a147: from storage DS-0f872257-0803-4a7c-9b42-bc5c33391e2b node DatanodeRegistration(127.0.0.1:41962, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=34063, infoSecurePort=0, ipcPort=40450, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,770 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x7fc9171b57b4a147: Processing first storage report for DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886 from datanode ac5d1b19-0726-415d-bf37-2b9000785dd3
2020-04-02 05:06:26,770 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x7fc9171b57b4a147: from storage DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886 node DatanodeRegistration(127.0.0.1:41962, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=34063, infoSecurePort=0, ipcPort=40450, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,770 [IPC Server handler 5 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x7fc9171b57b4a147
2020-04-02 05:06:26,772 [Thread-1364] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,772 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x7fc9171b57b4a147,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 6 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:26,772 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,772 [Thread-1364] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,773 [Thread-1364] INFO  common.Storage (BlockPoolSliceStorage.java:loadStorageDirectory(168)) - Block pool storage directory for location [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22 and block pool id BP-2135288147-172.17.0.13-1585803983874 is not formatted. Formatting ...
2020-04-02 05:06:26,773 [Thread-1364] INFO  common.Storage (BlockPoolSliceStorage.java:format(280)) - Formatting block pool BP-2135288147-172.17.0.13-1585803983874 directory /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2135288147-172.17.0.13-1585803983874/current
2020-04-02 05:06:26,775 [Thread-1364] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=null
2020-04-02 05:06:26,777 [Thread-1364] INFO  datanode.DataNode (DataNode.java:checkDatanodeUuid(1556)) - Generated and persisted new Datanode UUID 573d2bf6-d743-43bf-8e91-35daa7de056c
2020-04-02 05:06:26,778 [Thread-1364] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-733d9975-fce7-4435-94c9-e43ca04369b5
2020-04-02 05:06:26,778 [Thread-1364] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, StorageType: DISK
2020-04-02 05:06:26,779 [Thread-1364] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1472bf47-db39-4471-86fd-8d0e3df73f7f
2020-04-02 05:06:26,779 [Thread-1364] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, StorageType: DISK
2020-04-02 05:06:26,779 [Thread-1364] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:26,780 [Thread-1364] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-04-02 05:06:26,780 [Thread-1364] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-04-02 05:06:26,780 [Thread-1364] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-04-02 05:06:26,781 [Thread-1364] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-04-02 05:06:26,781 [Thread-1364] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,781 [Thread-1388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-04-02 05:06:26,781 [Thread-1389] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-04-02 05:06:26,840 [IPC Server handler 7 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:26,841 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:26,841 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:26,845 [Thread-1389] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 64ms
2020-04-02 05:06:26,849 [Thread-1388] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 68ms
2020-04-02 05:06:26,851 [Thread-1364] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 70ms
2020-04-02 05:06:26,853 [Thread-1392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-04-02 05:06:26,853 [Thread-1393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-04-02 05:06:26,854 [Thread-1392] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,854 [Thread-1393] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:26,854 [Thread-1393] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 0ms
2020-04-02 05:06:26,854 [Thread-1392] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 1ms
2020-04-02 05:06:26,854 [Thread-1364] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 3ms
2020-04-02 05:06:26,855 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-04-02 05:06:26,855 [Thread-1364] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 6:03 AM with interval of 21600000ms
2020-04-02 05:06:26,855 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(386)) - Now scanning bpid BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-04-02 05:06:26,855 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-733d9975-fce7-4435-94c9-e43ca04369b5): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,856 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-733d9975-fce7-4435-94c9-e43ca04369b5): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:26,855 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:runLoop(544)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-1472bf47-db39-4471-86fd-8d0e3df73f7f): finished scanning block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,856 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-1472bf47-db39-4471-86fd-8d0e3df73f7f): no suitable block pools found to scan.  Waiting 1814399999 ms.
2020-04-02 05:06:26,861 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 573d2bf6-d743-43bf-8e91-35daa7de056c) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:26,865 [IPC Server handler 8 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46530, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=33476, infoSecurePort=0, ipcPort=35135, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 573d2bf6-d743-43bf-8e91-35daa7de056c
2020-04-02 05:06:26,866 [IPC Server handler 8 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:46530
2020-04-02 05:06:26,866 [IPC Server handler 8 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 573d2bf6-d743-43bf-8e91-35daa7de056c (127.0.0.1:46530).
2020-04-02 05:06:26,866 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 573d2bf6-d743-43bf-8e91-35daa7de056c) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:26,867 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:26,876 [IPC Server handler 2 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-733d9975-fce7-4435-94c9-e43ca04369b5 for DN 127.0.0.1:46530
2020-04-02 05:06:26,876 [IPC Server handler 2 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1472bf47-db39-4471-86fd-8d0e3df73f7f for DN 127.0.0.1:46530
2020-04-02 05:06:26,877 [IPC Server handler 9 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46530, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=33476, infoSecurePort=0, ipcPort=35135, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:26,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4e40701acb83fd97: Processing first storage report for DS-733d9975-fce7-4435-94c9-e43ca04369b5 from datanode 573d2bf6-d743-43bf-8e91-35daa7de056c
2020-04-02 05:06:26,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4e40701acb83fd97: from storage DS-733d9975-fce7-4435-94c9-e43ca04369b5 node DatanodeRegistration(127.0.0.1:46530, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=33476, infoSecurePort=0, ipcPort=35135, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0x4e40701acb83fd97: Processing first storage report for DS-1472bf47-db39-4471-86fd-8d0e3df73f7f from datanode 573d2bf6-d743-43bf-8e91-35daa7de056c
2020-04-02 05:06:26,878 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0x4e40701acb83fd97: from storage DS-1472bf47-db39-4471-86fd-8d0e3df73f7f node DatanodeRegistration(127.0.0.1:46530, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=33476, infoSecurePort=0, ipcPort=35135, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:26,878 [IPC Server handler 9 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0x4e40701acb83fd97
2020-04-02 05:06:26,880 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0x4e40701acb83fd97,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 3 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:26,880 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:26,944 [IPC Server handler 6 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:26,945 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:26,949 [IPC Server handler 0 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:26,955 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:26,957 [IPC Server handler 1 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=enableErasureCodingPolicy	src=RS-6-3-1024k	dst=null	perm=null	proto=rpc
2020-04-02 05:06:26,972 [IPC Server handler 3 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=setErasureCodingPolicy	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:26,978 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2280)) - MiniDFSCluster Stopping DataNode host9:46180 from a total of 11 datanodes.
2020-04-02 05:06:26,978 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 43719 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:26,978 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:26,978 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@45792847] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:26,983 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9) exiting.
2020-04-02 05:06:26,983 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de) exiting.
2020-04-02 05:06:27,053 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@50d3bf39{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:27,053 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@25a73de1{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:27,054 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@52a70627{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:27,054 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1dcca8d3{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:27,067 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 43719
2020-04-02 05:06:27,079 [IPC Server listener on 43719] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 43719
2020-04-02 05:06:27,079 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:27,079 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 42af86f4-4249-4b00-a816-b31104ce7014) service to localhost/127.0.0.1:35549
2020-04-02 05:06:27,079 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 42af86f4-4249-4b00-a816-b31104ce7014)
2020-04-02 05:06:27,079 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:27,079 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:27,088 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:27,103 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:27,107 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:27,108 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:27,118 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:27,118 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:27,119 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:27,119 [main] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(752)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:46180, removeBlocksFromBlockMap true
2020-04-02 05:06:27,130 [main] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r5/127.0.0.1:46180
2020-04-02 05:06:27,142 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(121)) - stop datanode host9
2020-04-02 05:06:27,143 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2280)) - MiniDFSCluster Stopping DataNode host10:41962 from a total of 10 datanodes.
2020-04-02 05:06:27,143 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40450 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:27,143 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:27,143 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@3104351d] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:27,151 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-0f872257-0803-4a7c-9b42-bc5c33391e2b) exiting.
2020-04-02 05:06:27,152 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886) exiting.
2020-04-02 05:06:27,213 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@6be25526{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:27,214 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@42435b98{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:27,214 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2bac9ba{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:27,214 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a9d5dff{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:27,216 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40450
2020-04-02 05:06:27,217 [IPC Server listener on 40450] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40450
2020-04-02 05:06:27,217 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:27,217 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:27,220 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ac5d1b19-0726-415d-bf37-2b9000785dd3) service to localhost/127.0.0.1:35549
2020-04-02 05:06:27,220 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ac5d1b19-0726-415d-bf37-2b9000785dd3)
2020-04-02 05:06:27,220 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:27,237 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:27,241 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:27,245 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:27,245 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:27,248 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:27,249 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:27,249 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:27,250 [main] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(752)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:41962, removeBlocksFromBlockMap true
2020-04-02 05:06:27,250 [main] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r5/127.0.0.1:41962
2020-04-02 05:06:27,250 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(121)) - stop datanode host10
2020-04-02 05:06:27,251 [IPC Server handler 4 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=mkdirs	src=/	dst=null	perm=root:supergroup:rwxr-xr-x	proto=rpc
2020-04-02 05:06:27,254 [IPC Server handler 5 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=create	src=/foo	dst=null	perm=root:supergroup:rw-r--r--	proto=rpc
2020-04-02 05:06:27,256 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:27,279 [IPC Server handler 7 on 35549] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=9}
2020-04-02 05:06:27,280 [IPC Server handler 7 on 35549] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-e340360f-798e-455a-bff2-ca67dfad9811:NORMAL:127.0.0.1:42968, [DISK]DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef:NORMAL:127.0.0.1:36458, [DISK]DS-bf3e5ff2-fbec-4007-96fd-557942b0b82d:NORMAL:127.0.0.1:33247, [DISK]DS-69abce45-7fd1-412a-be89-0b8bab3b233e:NORMAL:127.0.0.1:33731, [DISK]DS-733d9975-fce7-4435-94c9-e43ca04369b5:NORMAL:127.0.0.1:46530]
2020-04-02 05:06:27,280 [IPC Server handler 7 on 35549] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:36458, 127.0.0.1:33731, 127.0.0.1:33247, 127.0.0.1:42968, 127.0.0.1:46530]
2020-04-02 05:06:27,281 [IPC Server handler 7 on 35549] INFO  hdfs.StateChange (FSDirWriteFileOp.java:logAllocatedBlock(804)) - BLOCK* allocate blk_-9223372036854775792_1001, replicas=127.0.0.1:42968, 127.0.0.1:37730, 127.0.0.1:33247, 127.0.0.1:34808, 127.0.0.1:46530, 127.0.0.1:36458, 127.0.0.1:37044, 127.0.0.1:33731, 127.0.0.1:33106 for /foo
2020-04-02 05:06:27,335 [DataXceiver for client DFSClient_NONMAPREDUCE_-94329666_1 at /127.0.0.1:44552 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775791_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775791_1001 src: /127.0.0.1:44552 dest: /127.0.0.1:37730
2020-04-02 05:06:27,340 [DataXceiver for client DFSClient_NONMAPREDUCE_-94329666_1 at /127.0.0.1:57840 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775792_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775792_1001 src: /127.0.0.1:57840 dest: /127.0.0.1:42968
2020-04-02 05:06:27,392 [DataXceiver for client DFSClient_NONMAPREDUCE_-94329666_1 at /127.0.0.1:46620 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775790_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775790_1001 src: /127.0.0.1:46620 dest: /127.0.0.1:33247
2020-04-02 05:06:27,411 [DataXceiver for client DFSClient_NONMAPREDUCE_-94329666_1 at /127.0.0.1:52864 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775789_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775789_1001 src: /127.0.0.1:52864 dest: /127.0.0.1:34808
2020-04-02 05:06:27,434 [DataXceiver for client DFSClient_NONMAPREDUCE_-94329666_1 at /127.0.0.1:41526 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001 src: /127.0.0.1:41526 dest: /127.0.0.1:46530
2020-04-02 05:06:27,458 [DataXceiver for client DFSClient_NONMAPREDUCE_-94329666_1 at /127.0.0.1:60162 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001 src: /127.0.0.1:60162 dest: /127.0.0.1:36458
2020-04-02 05:06:27,507 [DataXceiver for client DFSClient_NONMAPREDUCE_-94329666_1 at /127.0.0.1:60888 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775786_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775786_1001 src: /127.0.0.1:60888 dest: /127.0.0.1:37044
2020-04-02 05:06:27,523 [DataXceiver for client DFSClient_NONMAPREDUCE_-94329666_1 at /127.0.0.1:51012 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775785_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775785_1001 src: /127.0.0.1:51012 dest: /127.0.0.1:33731
2020-04-02 05:06:27,542 [DataXceiver for client DFSClient_NONMAPREDUCE_-94329666_1 at /127.0.0.1:44404 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775784_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775784_1001 src: /127.0.0.1:44404 dest: /127.0.0.1:33106
2020-04-02 05:06:27,646 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:57840, dest: /127.0.0.1:42968, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-94329666_1, offset: 0, srvID: ba26eabe-5db3-42d6-ba4b-937e2c42a5ac, blockid: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775792_1001, duration(ns): 299278489
2020-04-02 05:06:27,646 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775792_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:27,647 [IPC Server handler 2 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:42968, datanodeUuid=ba26eabe-5db3-42d6-ba4b-937e2c42a5ac, infoPort=43338, infoSecurePort=0, ipcPort=40706, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:27,647 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775792_1001 on 127.0.0.1:42968 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:27,647 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:27,648 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:42968 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:27,648 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775792_1001 is received from 127.0.0.1:42968
2020-04-02 05:06:27,648 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:42968 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:27,658 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44552, dest: /127.0.0.1:37730, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-94329666_1, offset: 0, srvID: 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e, blockid: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775791_1001, duration(ns): 296319483
2020-04-02 05:06:27,658 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775791_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:27,659 [IPC Server handler 9 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37730, datanodeUuid=0c0cd15a-d4ed-482d-8394-6ccbb807ad9e, infoPort=35240, infoSecurePort=0, ipcPort=44661, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:27,659 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775791_1001 on 127.0.0.1:37730 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:27,659 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:27,659 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37730 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:27,659 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775791_1001 is received from 127.0.0.1:37730
2020-04-02 05:06:27,659 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:46620, dest: /127.0.0.1:33247, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-94329666_1, offset: 0, srvID: a9fbe79b-52db-4b37-b18b-cd2580cb2bea, blockid: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775790_1001, duration(ns): 265760637
2020-04-02 05:06:27,659 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37730 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:27,659 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775790_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:27,660 [IPC Server handler 6 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33247, datanodeUuid=a9fbe79b-52db-4b37-b18b-cd2580cb2bea, infoPort=46646, infoSecurePort=0, ipcPort=41418, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:27,660 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775790_1001 on 127.0.0.1:33247 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:27,660 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:27,661 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33247 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:27,661 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:52864, dest: /127.0.0.1:34808, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-94329666_1, offset: 0, srvID: 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2, blockid: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775789_1001, duration(ns): 247732054
2020-04-02 05:06:27,661 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775790_1001 is received from 127.0.0.1:33247
2020-04-02 05:06:27,661 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775789_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:27,661 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33247 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:27,662 [IPC Server handler 0 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:34808, datanodeUuid=9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2, infoPort=35946, infoSecurePort=0, ipcPort=40364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:27,662 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775789_1001 on 127.0.0.1:34808 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:27,662 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:27,662 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:34808 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:27,662 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:41526, dest: /127.0.0.1:46530, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-94329666_1, offset: 0, srvID: 573d2bf6-d743-43bf-8e91-35daa7de056c, blockid: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001, duration(ns): 226430677
2020-04-02 05:06:27,662 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775789_1001 is received from 127.0.0.1:34808
2020-04-02 05:06:27,662 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:34808 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:27,662 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:27,663 [IPC Server handler 1 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46530, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=33476, infoSecurePort=0, ipcPort=35135, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:27,663 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:46530 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:27,663 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:27,663 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:46530 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:27,663 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:46530
2020-04-02 05:06:27,663 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46530 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:27,664 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60162, dest: /127.0.0.1:36458, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-94329666_1, offset: 0, srvID: 6183ec45-626a-4231-a4a4-eb75700b84c5, blockid: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001, duration(ns): 204403935
2020-04-02 05:06:27,664 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:27,665 [IPC Server handler 3 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:36458, datanodeUuid=6183ec45-626a-4231-a4a4-eb75700b84c5, infoPort=35072, infoSecurePort=0, ipcPort=39632, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:27,665 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:36458 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:27,665 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:27,665 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:36458 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:27,665 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:36458
2020-04-02 05:06:27,665 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:36458 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:27,666 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:60888, dest: /127.0.0.1:37044, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-94329666_1, offset: 0, srvID: 874ddb90-8989-4188-8171-bd95d2ab0583, blockid: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775786_1001, duration(ns): 156468997
2020-04-02 05:06:27,666 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775786_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:27,667 [IPC Server handler 4 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:37044, datanodeUuid=874ddb90-8989-4188-8171-bd95d2ab0583, infoPort=40515, infoSecurePort=0, ipcPort=44364, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:27,667 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775786_1001 on 127.0.0.1:37044 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:27,667 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:27,667 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:37044 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:27,667 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775786_1001 is received from 127.0.0.1:37044
2020-04-02 05:06:27,667 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:37044 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:27,668 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:51012, dest: /127.0.0.1:33731, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-94329666_1, offset: 0, srvID: 499eb5ac-ae2d-44fb-9673-4fe321174279, blockid: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775785_1001, duration(ns): 142307958
2020-04-02 05:06:27,668 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775785_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:27,668 [IPC Server handler 5 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33731, datanodeUuid=499eb5ac-ae2d-44fb-9673-4fe321174279, infoPort=43185, infoSecurePort=0, ipcPort=37899, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:27,669 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775785_1001 on 127.0.0.1:33731 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:27,669 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:27,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33731 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:27,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775785_1001 is received from 127.0.0.1:33731
2020-04-02 05:06:27,669 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33731 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:27,669 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  DataNode.clienttrace (BlockReceiver.java:finalizeBlock(1533)) - src: /127.0.0.1:44404, dest: /127.0.0.1:33106, bytes: 2097152, op: HDFS_WRITE, cliID: DFSClient_NONMAPREDUCE_-94329666_1, offset: 0, srvID: 5054b13f-a3f6-4074-bc6c-a1ca74a9f377, blockid: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775784_1001, duration(ns): 121787356
2020-04-02 05:06:27,669 [PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE] INFO  datanode.DataNode (BlockReceiver.java:run(1506)) - PacketResponder: BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775784_1001, type=LAST_IN_PIPELINE terminating
2020-04-02 05:06:27,677 [IPC Server handler 7 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:33106, datanodeUuid=5054b13f-a3f6-4074-bc6c-a1ca74a9f377, infoPort=46497, infoSecurePort=0, ipcPort=46395, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:27,680 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775784_1001 on 127.0.0.1:33106 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:27,680 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = UNDER_CONSTRUCTION
2020-04-02 05:06:27,680 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:33106 is added to blk_-9223372036854775792_1001 (size=0)
2020-04-02 05:06:27,680 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775784_1001 is received from 127.0.0.1:33106
2020-04-02 05:06:27,680 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:33106 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:27,701 [IPC Server handler 8 on 35549] INFO  hdfs.StateChange (FSNamesystem.java:completeFile(2861)) - DIR* completeFile: /foo is closed by DFSClient_NONMAPREDUCE_-94329666_1
2020-04-02 05:06:27,706 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:27,706 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:27,707 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:27,707 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:27,707 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:27,708 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:27,708 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host9
2020-04-02 05:06:27,708 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:27,708 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:27,709 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:46363
2020-04-02 05:06:27,709 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:27,709 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:27,710 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:27,712 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:27,714 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:27,714 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:27,715 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:27,715 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:27,716 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:27,716 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:27,716 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 44935
2020-04-02 05:06:27,717 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:27,718 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@60d1b21f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:27,718 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@546621c4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:27,726 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5a8ba37c{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:27,726 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@37c2eacb{HTTP/1.1,[http/1.1]}{localhost:44935}
2020-04-02 05:06:27,726 [main] INFO  server.Server (Server.java:doStart(419)) - Started @43411ms
2020-04-02 05:06:27,744 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:34454
2020-04-02 05:06:27,745 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@32b9bd12] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:27,745 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:27,745 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:27,746 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:27,746 [Socket Reader #1 for port 45966] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 45966
2020-04-02 05:06:27,752 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:45966
2020-04-02 05:06:27,765 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:27,765 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:27,766 [Thread-1446] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:27,768 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:27,768 [IPC Server listener on 45966] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 45966: starting
2020-04-02 05:06:27,772 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 45966 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:27,772 [Thread-1446] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:27,774 [Thread-1446] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:27,775 [IPC Server handler 9 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:27,775 [Thread-1446] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:27,775 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:27,775 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:27,777 [Thread-1446] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:27,785 [Thread-1446] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:27,786 [Thread-1446] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:27,800 [Thread-1446] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:27,801 [Thread-1446] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:27,802 [Thread-1446] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=42af86f4-4249-4b00-a816-b31104ce7014
2020-04-02 05:06:27,803 [Thread-1446] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9
2020-04-02 05:06:27,804 [Thread-1446] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, StorageType: DISK
2020-04-02 05:06:27,805 [Thread-1446] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de
2020-04-02 05:06:27,805 [Thread-1446] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, StorageType: DISK
2020-04-02 05:06:27,805 [Thread-1446] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:27,806 [Thread-1446] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:27,807 [Thread-1446] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17
2020-04-02 05:06:27,807 [Thread-1446] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:27,808 [Thread-1446] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18
2020-04-02 05:06:27,808 [Thread-1446] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:27,808 [Thread-1459] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:06:27,808 [Thread-1460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:06:27,810 [Thread-1460] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2135288147-172.17.0.13-1585803983874/current: 24576
2020-04-02 05:06:27,810 [Thread-1459] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2135288147-172.17.0.13-1585803983874/current: 24576
2020-04-02 05:06:27,817 [Thread-1460] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 8ms
2020-04-02 05:06:27,818 [Thread-1459] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 10ms
2020-04-02 05:06:27,821 [Thread-1446] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 14ms
2020-04-02 05:06:27,822 [Thread-1461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17...
2020-04-02 05:06:27,822 [Thread-1462] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18...
2020-04-02 05:06:27,822 [Thread-1461] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:27,822 [Thread-1462] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:27,831 [Thread-1461] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17: 9ms
2020-04-02 05:06:27,831 [Thread-1462] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18: 9ms
2020-04-02 05:06:27,832 [Thread-1446] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 10ms
2020-04-02 05:06:27,832 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9): no suitable block pools found to scan.  Waiting 1814398905 ms.
2020-04-02 05:06:27,833 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de): no suitable block pools found to scan.  Waiting 1814398904 ms.
2020-04-02 05:06:27,833 [Thread-1446] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:10 AM with interval of 21600000ms
2020-04-02 05:06:27,837 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 42af86f4-4249-4b00-a816-b31104ce7014) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:27,838 [IPC Server handler 6 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:46363, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=34454, infoSecurePort=0, ipcPort=45966, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 42af86f4-4249-4b00-a816-b31104ce7014
2020-04-02 05:06:27,838 [IPC Server handler 6 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1076)) - BLOCK* registerDatanode: 127.0.0.1:46180 is replaced by DatanodeRegistration(127.0.0.1:46363, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=34454, infoSecurePort=0, ipcPort=45966, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) with the same storageID 42af86f4-4249-4b00-a816-b31104ce7014
2020-04-02 05:06:27,838 [IPC Server handler 6 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r5/127.0.0.1:46180
2020-04-02 05:06:27,838 [IPC Server handler 6 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:46363
2020-04-02 05:06:27,839 [IPC Server handler 6 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9:NORMAL:127.0.0.1:46363 failed.
2020-04-02 05:06:27,839 [IPC Server handler 6 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de:NORMAL:127.0.0.1:46363 failed.
2020-04-02 05:06:27,839 [IPC Server handler 6 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9:FAILED:127.0.0.1:46363 from DataNode 127.0.0.1:46363
2020-04-02 05:06:27,839 [IPC Server handler 6 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de:FAILED:127.0.0.1:46363 from DataNode 127.0.0.1:46363
2020-04-02 05:06:27,840 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 42af86f4-4249-4b00-a816-b31104ce7014) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:27,840 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:27,845 [IPC Server handler 0 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9 for DN 127.0.0.1:46363
2020-04-02 05:06:27,848 [IPC Server handler 0 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de for DN 127.0.0.1:46363
2020-04-02 05:06:27,860 [IPC Server handler 0 on 35549] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 42af86f4-4249-4b00-a816-b31104ce7014 (127.0.0.1:46363) requested a lease even though it wasn't yet registered.  Registering now.
2020-04-02 05:06:27,860 [IPC Server handler 0 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 42af86f4-4249-4b00-a816-b31104ce7014 (127.0.0.1:46363).
2020-04-02 05:06:27,862 [IPC Server handler 1 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:46363, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=34454, infoSecurePort=0, ipcPort=45966, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:27,862 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc1adbabf28ad11: Processing first storage report for DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9 from datanode 42af86f4-4249-4b00-a816-b31104ce7014
2020-04-02 05:06:27,862 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc1adbabf28ad11: from storage DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9 node DatanodeRegistration(127.0.0.1:46363, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=34454, infoSecurePort=0, ipcPort=45966, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:27,862 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xc1adbabf28ad11: Processing first storage report for DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de from datanode 42af86f4-4249-4b00-a816-b31104ce7014
2020-04-02 05:06:27,862 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xc1adbabf28ad11: from storage DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de node DatanodeRegistration(127.0.0.1:46363, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=34454, infoSecurePort=0, ipcPort=45966, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:27,863 [IPC Server handler 1 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xc1adbabf28ad11
2020-04-02 05:06:27,863 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xc1adbabf28ad11,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 2 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:27,863 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:27,877 [IPC Server handler 3 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:27,878 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:27,878 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopDataNode(2280)) - MiniDFSCluster Stopping DataNode host11:46530 from a total of 10 datanodes.
2020-04-02 05:06:27,878 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 35135 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:27,878 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:27,878 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@121c54fa] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:27,885 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-1472bf47-db39-4471-86fd-8d0e3df73f7f) exiting.
2020-04-02 05:06:27,886 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-733d9975-fce7-4435-94c9-e43ca04369b5) exiting.
2020-04-02 05:06:27,920 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1ba05e38{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:27,921 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6c298dc{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:27,922 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3015db78{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:27,922 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@49798e84{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:27,926 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35135
2020-04-02 05:06:27,926 [IPC Server listener on 35135] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35135
2020-04-02 05:06:27,926 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:27,926 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:27,929 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 573d2bf6-d743-43bf-8e91-35daa7de056c) service to localhost/127.0.0.1:35549
2020-04-02 05:06:27,929 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 573d2bf6-d743-43bf-8e91-35daa7de056c)
2020-04-02 05:06:27,929 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:27,937 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:27,944 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:27,957 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:27,958 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:27,961 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:27,962 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:27,962 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:27,963 [main] INFO  hdfs.StateChange (DatanodeManager.java:removeDeadDatanode(752)) - BLOCK* removeDeadDatanode: lost heartbeat from 127.0.0.1:46530, removeBlocksFromBlockMap true
2020-04-02 05:06:27,963 [main] DEBUG BlockStateChange (BlockManager.java:removeStoredBlock(3781)) - BLOCK* removeStoredBlock: blk_-9223372036854775792_1001 from 127.0.0.1:46530
2020-04-02 05:06:27,964 [main] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 8 replicas and needs 9 replicas so is added to neededReconstructions at priority level 2
2020-04-02 05:06:27,964 [main] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:46530
2020-04-02 05:06:27,964 [main] INFO  blockmanagement.TestReconstructStripedBlocksWithRackAwareness (TestReconstructStripedBlocksWithRackAwareness.java:stopDataNode(121)) - stop datanode host11
2020-04-02 05:06:28,258 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:<init>(47)) - Creating an ErasureCodingWork to blk_-9223372036854775792_1001 reconstruct 
2020-04-02 05:06:28,259 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=1}
2020-04-02 05:06:28,259 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseLocalRack(634)) - Failed to choose from local rack (location = /r1), retry with the rack of the next replica (location = /r1)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:831)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:719)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:626)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:586)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:416)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:292)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:143)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1862)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1814)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4550)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:28,260 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseFromNextRack(666)) - Failed to choose from the next rack (location = /r1), retry choosing randomly
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:831)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:719)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseFromNextRack(BlockPlacementPolicyDefault.java:662)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:638)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:586)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:416)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:292)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:143)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1862)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1814)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4550)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:28,261 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6:NORMAL:127.0.0.1:42968, [DISK]DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681:NORMAL:127.0.0.1:37730, [DISK]DS-e597eea4-a429-4c33-beff-4b8242e19398:NORMAL:127.0.0.1:33247, [DISK]DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8:NORMAL:127.0.0.1:34808, [DISK]DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef:NORMAL:127.0.0.1:36458, [DISK]DS-a207bb28-410c-481d-8fe8-a34d79121b4f:NORMAL:127.0.0.1:37044, [DISK]DS-9674fb44-3f94-4af4-b754-d5a2483a230e:NORMAL:127.0.0.1:33731, [DISK]DS-8f6a1812-bbcb-49b0-b908-019163e1029e:NORMAL:127.0.0.1:33106, [DISK]DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9:NORMAL:127.0.0.1:46363]
2020-04-02 05:06:28,261 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:34808, 127.0.0.1:36458, 127.0.0.1:33731, 127.0.0.1:33247, 127.0.0.1:37044, 127.0.0.1:42968, 127.0.0.1:37730, 127.0.0.1:33106, 127.0.0.1:46363]
2020-04-02 05:06:28,265 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (DatanodeDescriptor.java:addBlockToBeErasureCoded(658)) - Adding block reconstruction task BlockECReconstructionInfo(
  Recovering BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775792_1001 From: [127.0.0.1:42968, 127.0.0.1:37730, 127.0.0.1:33247, 127.0.0.1:34808, 127.0.0.1:36458, 127.0.0.1:37044, 127.0.0.1:33731, 127.0.0.1:33106] To: [[127.0.0.1:46363])
 Block Indices: [0, 1, 2, 3, 5, 6, 7, 8]to 127.0.0.1:46363, current queue size is 1
2020-04-02 05:06:28,265 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:validateReconstructionWork(2054)) - BLOCK* block blk_-9223372036854775792_1001 is moved from neededReconstruction to pendingReconstruction
2020-04-02 05:06:28,265 [RedundancyMonitor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 2
2020-04-02 05:06:28,265 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1895)) - BLOCK* ask [127.0.0.1:42968, 127.0.0.1:37730, 127.0.0.1:33247, 127.0.0.1:34808, 127.0.0.1:36458, 127.0.0.1:37044, 127.0.0.1:33731, 127.0.0.1:33106] to replicate blk_-9223372036854775792_1001 to datanode(s) 127.0.0.1:46363
2020-04-02 05:06:28,265 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:29,266 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:30,266 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:30,843 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(793)) - DatanodeCommand action: DNA_ERASURE_CODING_RECOVERY
2020-04-02 05:06:30,911 [DataXceiver for client  at /127.0.0.1:43524 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001 src: /127.0.0.1:43524 dest: /127.0.0.1:46363
2020-04-02 05:06:31,006 [DataXceiver for client  at /127.0.0.1:43524 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775788_1001 src: /127.0.0.1:43524 dest: /127.0.0.1:46363 of size 2097152
2020-04-02 05:06:31,010 [IPC Server handler 5 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:46363, datanodeUuid=42af86f4-4249-4b00-a816-b31104ce7014, infoPort=34454, infoSecurePort=0, ipcPort=45966, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:31,011 [Block report processor] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:decrement(108)) - Removing pending reconstruction for blk_-9223372036854775792_1001
2020-04-02 05:06:31,011 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:46363 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:31,011 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:31,011 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:46363 is added to blk_-9223372036854775792_1001 (size=12582912)
2020-04-02 05:06:31,011 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775788_1001 is received from 127.0.0.1:46363
2020-04-02 05:06:31,011 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:46363 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:31,267 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:31,967 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:31,967 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:31,978 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:31,978 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:31,978 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:31,978 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:31,978 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host10
2020-04-02 05:06:31,978 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:31,979 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:31,979 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:44263
2020-04-02 05:06:31,979 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:31,979 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:31,986 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:31,987 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:31,988 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:31,988 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:31,989 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:31,989 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:31,989 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:31,989 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:31,990 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 40546
2020-04-02 05:06:31,990 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:31,997 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2e34384c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:31,998 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1f52eb6f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:32,002 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@545e57d7{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:32,002 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2bc9a775{HTTP/1.1,[http/1.1]}{localhost:40546}
2020-04-02 05:06:32,002 [main] INFO  server.Server (Server.java:doStart(419)) - Started @47686ms
2020-04-02 05:06:32,033 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:45945
2020-04-02 05:06:32,035 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:32,035 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:32,035 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:32,038 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@42f9c19a] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:32,045 [Socket Reader #1 for port 38604] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 38604
2020-04-02 05:06:32,051 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:38604
2020-04-02 05:06:32,055 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:32,055 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:32,092 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:32,097 [IPC Server listener on 38604] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 38604: starting
2020-04-02 05:06:32,123 [Thread-1492] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:32,166 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 38604 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:32,167 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-04-02 05:06:32,167 [main] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-04-02 05:06:32,170 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - DataNode metrics system started (again)
2020-04-02 05:06:32,170 [main] INFO  conf.Configured (ReconfAgent.java:performReconf(74)) - [msx-restart] DataNode init, vvmode is none, do nothing
2020-04-02 05:06:32,170 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:32,170 [main] INFO  datanode.BlockScanner (BlockScanner.java:<init>(184)) - Initialized block scanner with targetBytesPerSec 1048576
2020-04-02 05:06:32,170 [main] INFO  datanode.DataNode (DataNode.java:<init>(510)) - Configured hostname is host11
2020-04-02 05:06:32,171 [main] INFO  common.Util (Util.java:isDiskStatsEnabled(394)) - dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling
2020-04-02 05:06:32,171 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1410)) - Starting DataNode with maxLockedMemory = 0
2020-04-02 05:06:32,171 [main] INFO  datanode.DataNode (DataNode.java:initDataXceiver(1158)) - Opened streaming server at /127.0.0.1:42407
2020-04-02 05:06:32,171 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(78)) - Balancing bandwidth is 10485760 bytes/s
2020-04-02 05:06:32,171 [main] INFO  datanode.DataNode (DataXceiverServer.java:<init>(79)) - Number threads for balancing is 50
2020-04-02 05:06:32,172 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:32,173 [Thread-1492] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:32,173 [main] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2020-04-02 05:06:32,175 [Thread-1492] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:32,178 [main] INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.datanode is not defined
2020-04-02 05:06:32,178 [main] INFO  http.HttpServer2 (HttpServer2.java:getWebAppsPath(1052)) - Web server is in development mode. Resources will be read from the source tree.
2020-04-02 05:06:32,179 [main] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(970)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2020-04-02 05:06:32,180 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(943)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context datanode
2020-04-02 05:06:32,180 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2020-04-02 05:06:32,180 [main] INFO  http.HttpServer2 (HttpServer2.java:addFilter(953)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2020-04-02 05:06:32,180 [Thread-1492] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:32,180 [main] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1186)) - Jetty bound to port 33713
2020-04-02 05:06:32,180 [main] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2020-04-02 05:06:32,189 [Thread-1492] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:32,194 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@365553de{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,AVAILABLE}
2020-04-02 05:06:32,195 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5c0f79f0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,AVAILABLE}
2020-04-02 05:06:32,202 [main] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@54aca26f{/,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode/,AVAILABLE}{/datanode}
2020-04-02 05:06:32,202 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@314ed053{HTTP/1.1,[http/1.1]}{localhost:33713}
2020-04-02 05:06:32,203 [main] INFO  server.Server (Server.java:doStart(419)) - Started @47887ms
2020-04-02 05:06:32,205 [Thread-1492] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,206 [Thread-1492] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,215 [Thread-1492] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,215 [Thread-1492] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,216 [Thread-1492] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=ac5d1b19-0726-415d-bf37-2b9000785dd3
2020-04-02 05:06:32,222 [main] INFO  web.DatanodeHttpServer (DatanodeHttpServer.java:start(255)) - Listening HTTP traffic on /127.0.0.1:38840
2020-04-02 05:06:32,223 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1438)) - dnUserName = root
2020-04-02 05:06:32,223 [main] INFO  datanode.DataNode (DataNode.java:startDataNode(1439)) - supergroup = supergroup
2020-04-02 05:06:32,223 [main] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue queueCapacity: 1000 scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler
2020-04-02 05:06:32,224 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@486bc9a4] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2020-04-02 05:06:32,224 [Socket Reader #1 for port 34167] INFO  ipc.Server (Server.java:run(1070)) - Starting Socket Reader #1 for port 34167
2020-04-02 05:06:32,226 [Thread-1492] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-0f872257-0803-4a7c-9b42-bc5c33391e2b
2020-04-02 05:06:32,226 [Thread-1492] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, StorageType: DISK
2020-04-02 05:06:32,231 [Thread-1492] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886
2020-04-02 05:06:32,231 [Thread-1492] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, StorageType: DISK
2020-04-02 05:06:32,232 [Thread-1492] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:32,232 [Thread-1492] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:32,233 [Thread-1492] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19
2020-04-02 05:06:32,233 [Thread-1492] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:32,233 [Thread-1492] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20
2020-04-02 05:06:32,248 [Thread-1492] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,248 [Thread-1514] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:06:32,248 [Thread-1515] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:06:32,250 [Thread-1514] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2135288147-172.17.0.13-1585803983874/current: 24576
2020-04-02 05:06:32,250 [Thread-1515] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2135288147-172.17.0.13-1585803983874/current: 24576
2020-04-02 05:06:32,251 [main] INFO  datanode.DataNode (DataNode.java:initIpcServer(1044)) - Opened IPC server at /127.0.0.1:34167
2020-04-02 05:06:32,257 [main] INFO  datanode.DataNode (BlockPoolManager.java:refreshNamenodes(149)) - Refresh request received for nameservices: null
2020-04-02 05:06:32,258 [main] INFO  datanode.DataNode (BlockPoolManager.java:doRefreshNamenodes(210)) - Starting BPOfferServices for nameservices: <default>
2020-04-02 05:06:32,258 [Thread-1514] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 9ms
2020-04-02 05:06:32,259 [Thread-1519] INFO  datanode.DataNode (BPServiceActor.java:run(810)) - Block pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549 starting to offer service
2020-04-02 05:06:32,259 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1310)) - IPC Server Responder: starting
2020-04-02 05:06:32,276 [IPC Server listener on 34167] INFO  ipc.Server (Server.java:run(1149)) - IPC Server listener on 34167: starting
2020-04-02 05:06:32,278 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:32,282 [main] INFO  datanode.DataNode (DataNode.java:runDatanodeDaemon(2674)) - [msx-restart] DataNode 34167 start, check after start, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:32,292 [Thread-1519] INFO  datanode.DataNode (BPOfferService.java:verifyAndSetNamespaceInfo(378)) - Acknowledging ACTIVE Namenode during handshakeBlock pool <registering> (Datanode Uuid unassigned) service to localhost/127.0.0.1:35549
2020-04-02 05:06:32,296 [IPC Server handler 9 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:32,297 [Thread-1515] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 48ms
2020-04-02 05:06:32,306 [Thread-1519] INFO  common.Storage (DataStorage.java:getParallelVolumeLoadThreadsNum(354)) - Using 2 threads to upgrade data directories (dfs.datanode.parallel.volumes.load.threads.num=2, dataDirs=2)
2020-04-02 05:06:32,310 [Thread-1492] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 62ms
2020-04-02 05:06:32,310 [Thread-1530] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19...
2020-04-02 05:06:32,310 [Thread-1531] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20...
2020-04-02 05:06:32,310 [Thread-1530] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:32,311 [Thread-1531] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:32,311 [Thread-1530] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19: 0ms
2020-04-02 05:06:32,311 [Thread-1531] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20: 0ms
2020-04-02 05:06:32,311 [Thread-1492] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 1ms
2020-04-02 05:06:32,311 [Thread-1519] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:32,315 [Thread-1492] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 10:41 AM with interval of 21600000ms
2020-04-02 05:06:32,316 [Thread-1519] INFO  common.Storage (Storage.java:tryLock(905)) - Lock on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/in_use.lock acquired by nodename 7584@5909b7672181
2020-04-02 05:06:32,317 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886): no suitable block pools found to scan.  Waiting 1814394407 ms.
2020-04-02 05:06:32,317 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-0f872257-0803-4a7c-9b42-bc5c33391e2b): no suitable block pools found to scan.  Waiting 1814394407 ms.
2020-04-02 05:06:32,327 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ac5d1b19-0726-415d-bf37-2b9000785dd3) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:32,329 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:32,330 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:32,332 [IPC Server handler 0 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:44263, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=45945, infoSecurePort=0, ipcPort=38604, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage ac5d1b19-0726-415d-bf37-2b9000785dd3
2020-04-02 05:06:32,332 [IPC Server handler 0 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1076)) - BLOCK* registerDatanode: 127.0.0.1:41962 is replaced by DatanodeRegistration(127.0.0.1:44263, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=45945, infoSecurePort=0, ipcPort=38604, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) with the same storageID ac5d1b19-0726-415d-bf37-2b9000785dd3
2020-04-02 05:06:32,332 [IPC Server handler 0 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r5/127.0.0.1:41962
2020-04-02 05:06:32,332 [IPC Server handler 0 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r5/127.0.0.1:44263
2020-04-02 05:06:32,332 [IPC Server handler 0 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-0f872257-0803-4a7c-9b42-bc5c33391e2b:NORMAL:127.0.0.1:44263 failed.
2020-04-02 05:06:32,332 [IPC Server handler 0 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886:NORMAL:127.0.0.1:44263 failed.
2020-04-02 05:06:32,332 [IPC Server handler 0 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886:FAILED:127.0.0.1:44263 from DataNode 127.0.0.1:44263
2020-04-02 05:06:32,332 [IPC Server handler 0 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-0f872257-0803-4a7c-9b42-bc5c33391e2b:FAILED:127.0.0.1:44263 from DataNode 127.0.0.1:44263
2020-04-02 05:06:32,334 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ac5d1b19-0726-415d-bf37-2b9000785dd3) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:32,334 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:32,346 [IPC Server handler 1 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-0f872257-0803-4a7c-9b42-bc5c33391e2b for DN 127.0.0.1:44263
2020-04-02 05:06:32,346 [IPC Server handler 1 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886 for DN 127.0.0.1:44263
2020-04-02 05:06:32,356 [IPC Server handler 1 on 35549] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN ac5d1b19-0726-415d-bf37-2b9000785dd3 (127.0.0.1:44263) requested a lease even though it wasn't yet registered.  Registering now.
2020-04-02 05:06:32,356 [IPC Server handler 1 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN ac5d1b19-0726-415d-bf37-2b9000785dd3 (127.0.0.1:44263).
2020-04-02 05:06:32,364 [IPC Server handler 3 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:44263, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=45945, infoSecurePort=0, ipcPort=38604, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:32,364 [Thread-1519] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,364 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xbe468c07f29afee8: Processing first storage report for DS-0f872257-0803-4a7c-9b42-bc5c33391e2b from datanode ac5d1b19-0726-415d-bf37-2b9000785dd3
2020-04-02 05:06:32,365 [Thread-1519] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,365 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xbe468c07f29afee8: from storage DS-0f872257-0803-4a7c-9b42-bc5c33391e2b node DatanodeRegistration(127.0.0.1:44263, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=45945, infoSecurePort=0, ipcPort=38604, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:32,365 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xbe468c07f29afee8: Processing first storage report for DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886 from datanode ac5d1b19-0726-415d-bf37-2b9000785dd3
2020-04-02 05:06:32,365 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xbe468c07f29afee8: from storage DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886 node DatanodeRegistration(127.0.0.1:44263, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=45945, infoSecurePort=0, ipcPort=38604, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:32,365 [IPC Server handler 3 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xbe468c07f29afee8
2020-04-02 05:06:32,366 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xbe468c07f29afee8,  containing 2 storage report(s), of which we sent 2. The reports had 0 total blocks and used 1 RPC(s). This took 0 msec to generate and 9 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:32,366 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,373 [Thread-1519] INFO  common.Storage (BlockPoolSliceStorage.java:recoverTransitionRead(251)) - Analyzing storage directories for bpid BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,374 [Thread-1519] INFO  common.Storage (Storage.java:lock(864)) - Locking is disabled for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,375 [Thread-1519] INFO  datanode.DataNode (DataNode.java:initStorage(1732)) - Setting up storage: nsid=940059269;bpid=BP-2135288147-172.17.0.13-1585803983874;lv=-57;nsInfo=lv=-64;cid=testClusterID;nsid=940059269;c=1585803983874;bpid=BP-2135288147-172.17.0.13-1585803983874;dnuuid=573d2bf6-d743-43bf-8e91-35daa7de056c
2020-04-02 05:06:32,378 [Thread-1519] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-733d9975-fce7-4435-94c9-e43ca04369b5
2020-04-02 05:06:32,378 [Thread-1519] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, StorageType: DISK
2020-04-02 05:06:32,379 [Thread-1519] INFO  impl.FsDatasetImpl (FsVolumeList.java:addVolume(306)) - Added new volume: DS-1472bf47-db39-4471-86fd-8d0e3df73f7f
2020-04-02 05:06:32,379 [Thread-1519] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addVolume(450)) - Added volume - [DISK]file:/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, StorageType: DISK
2020-04-02 05:06:32,379 [Thread-1519] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:registerMBean(2280)) - Registered FSDatasetState MBean
2020-04-02 05:06:32,380 [Thread-1519] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-04-02 05:06:32,381 [Thread-1519] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21
2020-04-02 05:06:32,381 [Thread-1519] INFO  checker.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(137)) - Scheduling a check for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-04-02 05:06:32,381 [Thread-1519] INFO  checker.DatasetVolumeChecker (DatasetVolumeChecker.java:checkAllVolumes(221)) - Scheduled health check for volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22
2020-04-02 05:06:32,381 [Thread-1519] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:addBlockPool(2791)) - Adding block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,382 [Thread-1537] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-04-02 05:06:32,382 [Thread-1538] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(409)) - Scanning block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-04-02 05:06:32,394 [Thread-1537] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2135288147-172.17.0.13-1585803983874/current: 2138119
2020-04-02 05:06:32,395 [Thread-1538] INFO  impl.FsDatasetImpl (BlockPoolSlice.java:loadDfsUsed(291)) - Cached dfsUsed found for /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2135288147-172.17.0.13-1585803983874/current: 24576
2020-04-02 05:06:32,409 [Thread-1537] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 28ms
2020-04-02 05:06:32,422 [Thread-1538] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(414)) - Time taken to scan block pool BP-2135288147-172.17.0.13-1585803983874 on /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 40ms
2020-04-02 05:06:32,424 [Thread-1519] INFO  impl.FsDatasetImpl (FsVolumeList.java:addBlockPool(440)) - Total time to scan all replicas for block pool BP-2135288147-172.17.0.13-1585803983874: 43ms
2020-04-02 05:06:32,433 [Thread-1540] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22...
2020-04-02 05:06:32,434 [Thread-1540] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(871)) - Replica Cache file: /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas doesn't exist 
2020-04-02 05:06:32,434 [IPC Server handler 4 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:32,437 [Thread-1539] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(198)) - Adding replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21...
2020-04-02 05:06:32,438 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shouldWait(2702)) - dnInfo.length != numDataNodes
2020-04-02 05:06:32,445 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2623)) - Waiting for cluster to become active
2020-04-02 05:06:32,443 [Thread-1539] INFO  impl.BlockPoolSlice (BlockPoolSlice.java:readReplicasFromCache(920)) - Successfully read replica from cache file : /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2135288147-172.17.0.13-1585803983874/current/replicas
2020-04-02 05:06:32,446 [Thread-1539] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21: 8ms
2020-04-02 05:06:32,438 [Thread-1540] INFO  impl.FsDatasetImpl (FsVolumeList.java:run(203)) - Time to add replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874 on volume /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22: 4ms
2020-04-02 05:06:32,450 [Thread-1519] INFO  impl.FsDatasetImpl (FsVolumeList.java:getAllVolumesMap(230)) - Total time to add all replicas to map for block pool BP-2135288147-172.17.0.13-1585803983874: 26ms
2020-04-02 05:06:32,451 [Thread-1519] INFO  datanode.DirectoryScanner (DirectoryScanner.java:start(283)) - Periodic Directory Tree Verification scan starting at 4/2/20 5:40 AM with interval of 21600000ms
2020-04-02 05:06:32,451 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-1472bf47-db39-4471-86fd-8d0e3df73f7f): no suitable block pools found to scan.  Waiting 1814394404 ms.
2020-04-02 05:06:32,453 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:findNextUsableBlockIter(403)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-733d9975-fce7-4435-94c9-e43ca04369b5): no suitable block pools found to scan.  Waiting 1814394402 ms.
2020-04-02 05:06:32,465 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(764)) - Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 573d2bf6-d743-43bf-8e91-35daa7de056c) service to localhost/127.0.0.1:35549 beginning handshake with NN
2020-04-02 05:06:32,470 [IPC Server handler 5 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1040)) - BLOCK* registerDatanode: from DatanodeRegistration(127.0.0.1:42407, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=38840, infoSecurePort=0, ipcPort=34167, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) storage 573d2bf6-d743-43bf-8e91-35daa7de056c
2020-04-02 05:06:32,470 [IPC Server handler 5 on 35549] INFO  hdfs.StateChange (DatanodeManager.java:registerDatanode(1076)) - BLOCK* registerDatanode: 127.0.0.1:46530 is replaced by DatanodeRegistration(127.0.0.1:42407, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=38840, infoSecurePort=0, ipcPort=34167, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) with the same storageID 573d2bf6-d743-43bf-8e91-35daa7de056c
2020-04-02 05:06:32,470 [IPC Server handler 5 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:remove(219)) - Removing a node: /r6/127.0.0.1:46530
2020-04-02 05:06:32,470 [IPC Server handler 5 on 35549] INFO  net.NetworkTopology (NetworkTopology.java:add(145)) - Adding a new node: /r6/127.0.0.1:42407
2020-04-02 05:06:32,470 [IPC Server handler 5 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-733d9975-fce7-4435-94c9-e43ca04369b5:NORMAL:127.0.0.1:42407 failed.
2020-04-02 05:06:32,470 [IPC Server handler 5 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateFailedStorage(562)) - [DISK]DS-1472bf47-db39-4471-86fd-8d0e3df73f7f:NORMAL:127.0.0.1:42407 failed.
2020-04-02 05:06:32,470 [IPC Server handler 5 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-733d9975-fce7-4435-94c9-e43ca04369b5:FAILED:127.0.0.1:42407 from DataNode 127.0.0.1:42407
2020-04-02 05:06:32,471 [IPC Server handler 5 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:pruneStorageMap(548)) - Removed storage [DISK]DS-1472bf47-db39-4471-86fd-8d0e3df73f7f:FAILED:127.0.0.1:42407 from DataNode 127.0.0.1:42407
2020-04-02 05:06:32,471 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:register(783)) - Block pool Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 573d2bf6-d743-43bf-8e91-35daa7de056c) service to localhost/127.0.0.1:35549 successfully registered with NN
2020-04-02 05:06:32,471 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(612)) - For namenode localhost/127.0.0.1:35549 using BLOCKREPORT_INTERVAL of 21600000msec CACHEREPORT_INTERVAL of 10000msec Initial delay: 0msec; heartBeatInterval=3000
2020-04-02 05:06:32,477 [IPC Server handler 7 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-733d9975-fce7-4435-94c9-e43ca04369b5 for DN 127.0.0.1:42407
2020-04-02 05:06:32,479 [IPC Server handler 7 on 35549] INFO  blockmanagement.DatanodeDescriptor (DatanodeDescriptor.java:updateStorage(987)) - Adding new storage ID DS-1472bf47-db39-4471-86fd-8d0e3df73f7f for DN 127.0.0.1:42407
2020-04-02 05:06:32,480 [IPC Server handler 7 on 35549] WARN  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:requestLease(230)) - DN 573d2bf6-d743-43bf-8e91-35daa7de056c (127.0.0.1:42407) requested a lease even though it wasn't yet registered.  Registering now.
2020-04-02 05:06:32,480 [IPC Server handler 7 on 35549] INFO  blockmanagement.BlockReportLeaseManager (BlockReportLeaseManager.java:registerNode(204)) - Registered DN 573d2bf6-d743-43bf-8e91-35daa7de056c (127.0.0.1:42407).
2020-04-02 05:06:32,482 [IPC Server handler 8 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42407, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=38840, infoSecurePort=0, ipcPort=34167, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:32,482 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xeedde79c5e16bf86: Processing first storage report for DS-733d9975-fce7-4435-94c9-e43ca04369b5 from datanode 573d2bf6-d743-43bf-8e91-35daa7de056c
2020-04-02 05:06:32,482 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processFirstBlockReport(2778)) - Initial report of block blk_-9223372036854775788 on 127.0.0.1:42407 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:32,483 [Block report processor] DEBUG BlockStateChange (LowRedundancyBlocks.java:update(466)) - BLOCK* NameSystem.LowRedundancyBlock.update: blk_-9223372036854775792_1001 has only 9 replicas and needs 9 replicas so is added to neededReconstructions at priority level 3
2020-04-02 05:06:32,483 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xeedde79c5e16bf86: from storage DS-733d9975-fce7-4435-94c9-e43ca04369b5 node DatanodeRegistration(127.0.0.1:42407, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=38840, infoSecurePort=0, ipcPort=34167, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 1, hasStaleStorage: true, processing time: 1 msecs, invalidatedBlocks: 0
2020-04-02 05:06:32,483 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2541)) - BLOCK* processReport 0xeedde79c5e16bf86: Processing first storage report for DS-1472bf47-db39-4471-86fd-8d0e3df73f7f from datanode 573d2bf6-d743-43bf-8e91-35daa7de056c
2020-04-02 05:06:32,483 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xeedde79c5e16bf86: from storage DS-1472bf47-db39-4471-86fd-8d0e3df73f7f node DatanodeRegistration(127.0.0.1:42407, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=38840, infoSecurePort=0, ipcPort=34167, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:32,483 [IPC Server handler 8 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xeedde79c5e16bf86
2020-04-02 05:06:32,486 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xeedde79c5e16bf86,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 5 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:32,486 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,550 [IPC Server handler 9 on 35549] INFO  FSNamesystem.audit (FSNamesystem.java:logAuditMessage(7947)) - allowed=true	ugi=root (auth:SIMPLE)	ip=/127.0.0.1	cmd=datanodeReport	src=null	dst=null	perm=null	proto=rpc
2020-04-02 05:06:32,554 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:waitActive(2678)) - Cluster is active
2020-04-02 05:06:32,558 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:offerService(695)) - Forcing a full block report to localhost/127.0.0.1:35549
2020-04-02 05:06:32,559 [IPC Server handler 0 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReport(1517)) - *BLOCK* NameNode.blockReport: from DatanodeRegistration(127.0.0.1:42407, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=38840, infoSecurePort=0, ipcPort=34167, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), reports.length=2
2020-04-02 05:06:32,559 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:reportDiffSorted(2859)) - Reported block blk_-9223372036854775788_1001 on 127.0.0.1:42407 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:32,559 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:reportDiffSortedInner(2926)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:32,559 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xeedde79c5e16bf87: from storage DS-733d9975-fce7-4435-94c9-e43ca04369b5 node DatanodeRegistration(127.0.0.1:42407, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=38840, infoSecurePort=0, ipcPort=34167, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 1, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:32,559 [Block report processor] INFO  BlockStateChange (BlockManager.java:processReport(2570)) - BLOCK* processReport 0xeedde79c5e16bf87: from storage DS-1472bf47-db39-4471-86fd-8d0e3df73f7f node DatanodeRegistration(127.0.0.1:42407, datanodeUuid=573d2bf6-d743-43bf-8e91-35daa7de056c, infoPort=38840, infoSecurePort=0, ipcPort=34167, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874), blocks: 0, hasStaleStorage: false, processing time: 0 msecs, invalidatedBlocks: 0
2020-04-02 05:06:32,560 [IPC Server handler 0 on 35549] DEBUG blockmanagement.BlockManager (BlockManager.java:removeBRLeaseIfNeeded(2593)) - Processing RPC with index 0 out of total 1 RPCs in processReport 0xeedde79c5e16bf87
2020-04-02 05:06:32,562 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPServiceActor.java:blockReport(422)) - Successfully sent block report 0xeedde79c5e16bf87,  containing 2 storage report(s), of which we sent 2. The reports had 1 total blocks and used 1 RPC(s). This took 0 msec to generate and 4 msecs for RPC and NN processing. Got back one command: FinalizeCommand/5.
2020-04-02 05:06:32,562 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BPOfferService.java:processCommandFromActive(759)) - Got finalize command for block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:32,657 [main] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:46363 [DISK]DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9:NORMAL:127.0.0.1:46363 with 1 blocks
2020-04-02 05:06:32,657 [main] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:startDecommission(216)) - Starting decommission of 127.0.0.1:46363 [DISK]DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de:NORMAL:127.0.0.1:46363 with 0 blocks
2020-04-02 05:06:33,192 [DatanodeAdminMonitor-0] INFO  BlockStateChange (DatanodeAdminManager.java:logBlockReplicationInfo(401)) - Block: blk_-9223372036854775792_1001, Expected Replicas: 9, live replicas: 9, corrupt replicas: 0, decommissioned replicas: 0, decommissioning replicas: 1, maintenance replicas: 0, live entering maintenance replicas: 0, excess replicas: 0, Is Open File: false, Datanodes having this block: 127.0.0.1:42968 127.0.0.1:37730 127.0.0.1:33247 127.0.0.1:34808 127.0.0.1:46363 127.0.0.1:36458 127.0.0.1:37044 127.0.0.1:33731 127.0.0.1:33106 127.0.0.1:42407 , Current Datanode: 127.0.0.1:46363, Is current datanode decommissioning: true, Is current datanode entering maintenance: false
2020-04-02 05:06:33,194 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(500)) - Checked 1 blocks and 1 nodes this tick
2020-04-02 05:06:33,278 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:<init>(47)) - Creating an ErasureCodingWork to blk_-9223372036854775792_1001 reconstruct 
2020-04-02 05:06:33,280 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseTarget(406)) - storageTypes={DISK=1}
2020-04-02 05:06:33,281 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseLocalRack(634)) - Failed to choose from local rack (location = /r1), retry with the rack of the next replica (location = /r1)
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:831)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:719)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:626)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:586)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:416)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:292)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:143)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1862)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1814)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4550)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:33,281 [RedundancyMonitor] DEBUG blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyDefault.java:chooseFromNextRack(666)) - Failed to choose from the next rack (location = /r1), retry choosing randomly
org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicy$NotEnoughReplicasException: 
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:831)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseRandom(BlockPlacementPolicyDefault.java:719)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseFromNextRack(BlockPlacementPolicyDefault.java:662)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalRack(BlockPlacementPolicyDefault.java:638)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseLocalStorage(BlockPlacementPolicyDefault.java:586)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseOnce(BlockPlacementPolicyRackFaultTolerant.java:218)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyRackFaultTolerant.chooseTargetInOrder(BlockPlacementPolicyRackFaultTolerant.java:126)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:416)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:292)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockPlacementPolicyDefault.chooseTarget(BlockPlacementPolicyDefault.java:143)
	at org.apache.hadoop.hdfs.server.blockmanagement.ErasureCodingWork.chooseTargets(ErasureCodingWork.java:60)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeReconstructionWorkForBlocks(BlockManager.java:1862)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeBlockReconstructionWork(BlockManager.java:1814)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.computeDatanodeWork(BlockManager.java:4683)
	at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager$RedundancyMonitor.run(BlockManager.java:4550)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:33,282 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(135)) - Chosen nodes: [[DISK]DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6:NORMAL:127.0.0.1:42968, [DISK]DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681:NORMAL:127.0.0.1:37730, [DISK]DS-e597eea4-a429-4c33-beff-4b8242e19398:NORMAL:127.0.0.1:33247, [DISK]DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8:NORMAL:127.0.0.1:34808, [DISK]DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef:NORMAL:127.0.0.1:36458, [DISK]DS-a207bb28-410c-481d-8fe8-a34d79121b4f:NORMAL:127.0.0.1:37044, [DISK]DS-9674fb44-3f94-4af4-b754-d5a2483a230e:NORMAL:127.0.0.1:33731, [DISK]DS-8f6a1812-bbcb-49b0-b908-019163e1029e:NORMAL:127.0.0.1:33106, [DISK]DS-733d9975-fce7-4435-94c9-e43ca04369b5:NORMAL:127.0.0.1:42407, [DISK]DS-0f872257-0803-4a7c-9b42-bc5c33391e2b:NORMAL:127.0.0.1:44263]
2020-04-02 05:06:33,282 [RedundancyMonitor] TRACE blockmanagement.BlockPlacementPolicy (BlockPlacementPolicyRackFaultTolerant.java:chooseTargetInOrder(136)) - Excluded nodes: [127.0.0.1:34808, 127.0.0.1:36458, 127.0.0.1:33731, 127.0.0.1:33247, 127.0.0.1:37044, 127.0.0.1:42968, 127.0.0.1:37730, 127.0.0.1:46363, 127.0.0.1:33106, 127.0.0.1:42407, 127.0.0.1:44263]
2020-04-02 05:06:33,282 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (BlockManager.java:isInNewRack(1997)) - check if target 127.0.0.1:44263 increases racks, srcs=[127.0.0.1:42968, 127.0.0.1:37730, 127.0.0.1:33247, 127.0.0.1:34808, 127.0.0.1:46363, 127.0.0.1:36458, 127.0.0.1:37044, 127.0.0.1:33731, 127.0.0.1:33106, 127.0.0.1:42407]
2020-04-02 05:06:33,282 [RedundancyMonitor] DEBUG blockmanagement.BlockManager (ErasureCodingWork.java:createReplicationWork(161)) - Add replication task from source 127.0.0.1:36458 to target [DISK]DS-0f872257-0803-4a7c-9b42-bc5c33391e2b:NORMAL:127.0.0.1:44263 for EC block blk_-9223372036854775787_1001
2020-04-02 05:06:33,282 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:validateReconstructionWork(2054)) - BLOCK* block blk_-9223372036854775792_1001 is moved from neededReconstruction to pendingReconstruction
2020-04-02 05:06:33,282 [RedundancyMonitor] DEBUG BlockStateChange (LowRedundancyBlocks.java:remove(376)) - BLOCK* NameSystem.LowRedundancyBlock.remove: Removing block blk_-9223372036854775792_1001 from priority queue 3
2020-04-02 05:06:33,282 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1895)) - BLOCK* ask [127.0.0.1:42968, 127.0.0.1:37730, 127.0.0.1:33247, 127.0.0.1:34808, 127.0.0.1:46363, 127.0.0.1:36458, 127.0.0.1:37044, 127.0.0.1:33731, 127.0.0.1:33106, 127.0.0.1:42407] to replicate blk_-9223372036854775792_1001 to datanode(s) 127.0.0.1:44263
2020-04-02 05:06:33,282 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:34,282 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 1
2020-04-02 05:06:34,945 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (DataNode.java:transferBlock(2353)) - DatanodeRegistration(127.0.0.1:36458, datanodeUuid=6183ec45-626a-4231-a4a4-eb75700b84c5, infoPort=35072, infoSecurePort=0, ipcPort=39632, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) Starting thread to transfer BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001 to 127.0.0.1:44263 
2020-04-02 05:06:34,952 [DataXceiver for client  at /127.0.0.1:58858 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(738)) - Receiving BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001 src: /127.0.0.1:58858 dest: /127.0.0.1:44263
2020-04-02 05:06:34,953 [org.apache.hadoop.hdfs.server.datanode.DataNode$DataTransfer@cd18a2a] INFO  datanode.DataNode (DataNode.java:run(2566)) - DataTransfer, at host6:36458: Transmitted BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001 (numBytes=2097152) to /127.0.0.1:44263
2020-04-02 05:06:34,959 [DataXceiver for client  at /127.0.0.1:58858 [Receiving block BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001]] INFO  datanode.DataNode (DataXceiver.java:writeBlock(914)) - Received BP-2135288147-172.17.0.13-1585803983874:blk_-9223372036854775787_1001 src: /127.0.0.1:58858 dest: /127.0.0.1:44263 of size 2097152
2020-04-02 05:06:34,960 [IPC Server handler 5 on 35549] DEBUG BlockStateChange (NameNodeRpcServer.java:blockReceivedAndDeleted(1574)) - *BLOCK* NameNode.blockReceivedAndDeleted: from DatanodeRegistration(127.0.0.1:44263, datanodeUuid=ac5d1b19-0726-415d-bf37-2b9000785dd3, infoPort=45945, infoSecurePort=0, ipcPort=38604, storageInfo=lv=-57;cid=testClusterID;nsid=940059269;c=1585803983874) 1 blocks.
2020-04-02 05:06:34,960 [Block report processor] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:decrement(108)) - Removing pending reconstruction for blk_-9223372036854775792_1001
2020-04-02 05:06:34,960 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3911)) - Reported block blk_-9223372036854775787_1001 on 127.0.0.1:44263 size 2097152 replicaState = FINALIZED
2020-04-02 05:06:34,960 [Block report processor] DEBUG blockmanagement.BlockManager (BlockManager.java:processAndHandleReportedBlock(3934)) - In memory blockUCState = COMPLETE
2020-04-02 05:06:34,960 [Block report processor] DEBUG BlockStateChange (BlockManager.java:addStoredBlock(3243)) - BLOCK* addStoredBlock: 127.0.0.1:44263 is added to blk_-9223372036854775792_1001 (size=12582912)
2020-04-02 05:06:34,961 [Block report processor] DEBUG BlockStateChange (ExcessRedundancyMap.java:add(86)) - BLOCK* ExcessRedundancyMap.add(127.0.0.1:36458, blk_-9223372036854775792_1001)
2020-04-02 05:06:34,961 [Block report processor] DEBUG BlockStateChange (InvalidateBlocks.java:add(190)) - BLOCK* InvalidateBlocks: add blk_-9223372036854775787_1001 to 127.0.0.1:36458
2020-04-02 05:06:34,961 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processChosenExcessRedundancy(3762)) - BLOCK* chooseExcessRedundancies: ([DISK]DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef:NORMAL:127.0.0.1:36458, blk_-9223372036854775792_1001) is added to invalidated blocks set
2020-04-02 05:06:34,961 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4044)) - BLOCK* block RECEIVED_BLOCK: blk_-9223372036854775787_1001 is received from 127.0.0.1:44263
2020-04-02 05:06:34,961 [Block report processor] DEBUG BlockStateChange (BlockManager.java:processIncrementalBlockReport(4047)) - *BLOCK* NameNode.processIncrementalBlockReport: from 127.0.0.1:44263 receiving: 0, received: 1, deleted: 0
2020-04-02 05:06:35,283 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:35,283 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:invalidateWorkForOneNode(4375)) - BLOCK* BlockManager: ask 127.0.0.1:36458 to delete [blk_-9223372036854775787_1001]
2020-04-02 05:06:36,190 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:setDecommissioned(332)) - Decommissioning complete for node 127.0.0.1:46363
2020-04-02 05:06:36,190 [DatanodeAdminMonitor-0] INFO  blockmanagement.DatanodeAdminManager (DatanodeAdminManager.java:run(500)) - Checked 2 blocks and 1 nodes this tick
2020-04-02 05:06:36,283 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:36,662 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdown(1998)) - Shutting down the Mini HDFS Cluster
2020-04-02 05:06:36,662 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 10
2020-04-02 05:06:36,662 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 34167 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:36,662 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:36,662 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6a9950f1] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:36,664 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22, DS-1472bf47-db39-4471-86fd-8d0e3df73f7f) exiting.
2020-04-02 05:06:36,664 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21, DS-733d9975-fce7-4435-94c9-e43ca04369b5) exiting.
2020-04-02 05:06:36,707 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@54aca26f{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:36,711 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@314ed053{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:36,712 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5c0f79f0{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:36,712 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@365553de{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:36,730 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 34167
2020-04-02 05:06:36,733 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:36,733 [IPC Server listener on 34167] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 34167
2020-04-02 05:06:36,738 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:36,738 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 573d2bf6-d743-43bf-8e91-35daa7de056c) service to localhost/127.0.0.1:35549
2020-04-02 05:06:36,738 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 573d2bf6-d743-43bf-8e91-35daa7de056c)
2020-04-02 05:06:36,738 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:36,749 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data21/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:36,753 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data22/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:36,758 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:36,759 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:36,760 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:36,760 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:36,769 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:36,770 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 9
2020-04-02 05:06:36,770 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 38604 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:36,770 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@2679311f] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:36,770 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:36,775 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19, DS-0f872257-0803-4a7c-9b42-bc5c33391e2b) exiting.
2020-04-02 05:06:36,785 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20, DS-58fb9d9c-26a9-44a2-93a4-0e3d7c485886) exiting.
2020-04-02 05:06:36,816 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@545e57d7{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:36,821 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2bc9a775{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:36,821 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1f52eb6f{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:36,821 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2e34384c{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:36,843 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 38604
2020-04-02 05:06:36,850 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:36,850 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:36,850 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ac5d1b19-0726-415d-bf37-2b9000785dd3) service to localhost/127.0.0.1:35549
2020-04-02 05:06:36,850 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ac5d1b19-0726-415d-bf37-2b9000785dd3)
2020-04-02 05:06:36,850 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:36,853 [IPC Server listener on 38604] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 38604
2020-04-02 05:06:36,888 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data19/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:36,896 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data20/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:36,899 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:36,900 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:36,901 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:36,910 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:36,910 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:36,910 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 8
2020-04-02 05:06:36,910 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 45966 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:36,910 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:36,911 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@6fd1660] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:36,918 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17, DS-39e6fab5-64d6-4529-84c7-1ccbc0543dc9) exiting.
2020-04-02 05:06:36,919 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18, DS-44a469c7-8ed9-47de-bfb6-ee88c9bcf9de) exiting.
2020-04-02 05:06:36,938 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5a8ba37c{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:36,946 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@37c2eacb{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:36,954 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@546621c4{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:36,954 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@60d1b21f{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:36,962 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 45966
2020-04-02 05:06:36,970 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:36,971 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:36,971 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 42af86f4-4249-4b00-a816-b31104ce7014) service to localhost/127.0.0.1:35549
2020-04-02 05:06:36,971 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 42af86f4-4249-4b00-a816-b31104ce7014)
2020-04-02 05:06:36,971 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:36,973 [IPC Server listener on 45966] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 45966
2020-04-02 05:06:36,999 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data17/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,037 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data18/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,045 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:37,046 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:37,061 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:37,061 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:37,066 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:37,066 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 7
2020-04-02 05:06:37,066 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 46395 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:37,066 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:37,081 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1e9804b9] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:37,082 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16, DS-6183ce27-b812-46b5-9295-07522be01ed0) exiting.
2020-04-02 05:06:37,082 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15, DS-8f6a1812-bbcb-49b0-b908-019163e1029e) exiting.
2020-04-02 05:06:37,113 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@70e3f36f{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:37,115 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@49601f82{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:37,126 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d74c3ba{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:37,126 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7fab4be7{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:37,142 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 46395
2020-04-02 05:06:37,150 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:37,150 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 5054b13f-a3f6-4074-bc6c-a1ca74a9f377) service to localhost/127.0.0.1:35549
2020-04-02 05:06:37,151 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 5054b13f-a3f6-4074-bc6c-a1ca74a9f377)
2020-04-02 05:06:37,151 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:37,153 [IPC Server listener on 46395] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 46395
2020-04-02 05:06:37,153 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:37,176 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data15/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,182 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data16/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,190 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:37,190 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:37,193 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:37,194 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:37,195 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:37,195 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 6
2020-04-02 05:06:37,195 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 37899 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:37,196 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:37,196 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@7df60067] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:37,221 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13, DS-9674fb44-3f94-4af4-b754-d5a2483a230e) exiting.
2020-04-02 05:06:37,221 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14, DS-69abce45-7fd1-412a-be89-0b8bab3b233e) exiting.
2020-04-02 05:06:37,275 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@77a281fc{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:37,282 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4912d525{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:37,282 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4158debd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:37,282 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@393881f0{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:37,284 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:37,300 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 37899
2020-04-02 05:06:37,303 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:37,303 [IPC Server listener on 37899] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 37899
2020-04-02 05:06:37,303 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:37,303 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 499eb5ac-ae2d-44fb-9673-4fe321174279) service to localhost/127.0.0.1:35549
2020-04-02 05:06:37,303 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 499eb5ac-ae2d-44fb-9673-4fe321174279)
2020-04-02 05:06:37,318 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:37,334 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data13/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,357 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data14/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,361 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:37,361 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:37,364 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:37,364 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:37,365 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:37,365 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 5
2020-04-02 05:06:37,365 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 39632 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:37,365 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:37,365 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@1bcf67e8] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:37,372 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12, DS-5d27cc6e-7a7e-4b9c-980d-cbeac70640d0) exiting.
2020-04-02 05:06:37,372 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11, DS-be697bcb-39fb-4117-a2dd-0267a69ee4ef) exiting.
2020-04-02 05:06:37,442 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@57540fd0{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:37,443 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5cf8edcf{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:37,443 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@27b71f50{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:37,443 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@76075d65{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:37,453 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 39632
2020-04-02 05:06:37,455 [IPC Server listener on 39632] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 39632
2020-04-02 05:06:37,455 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:37,461 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:37,462 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 6183ec45-626a-4231-a4a4-eb75700b84c5) service to localhost/127.0.0.1:35549
2020-04-02 05:06:37,462 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 6183ec45-626a-4231-a4a4-eb75700b84c5)
2020-04-02 05:06:37,462 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:37,492 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data11/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,537 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data12/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,541 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:37,542 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:37,553 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:37,554 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:37,556 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:37,556 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 4
2020-04-02 05:06:37,556 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44364 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:37,556 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:37,556 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@14151bc5] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:37,569 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10, DS-6a1c04de-bad7-4ba3-a256-c0e9eb63dba7) exiting.
2020-04-02 05:06:37,570 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9, DS-a207bb28-410c-481d-8fe8-a34d79121b4f) exiting.
2020-04-02 05:06:37,613 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4cd1c1dc{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:37,618 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@47f08b81{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:37,618 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7bef452c{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:37,618 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@982bb90{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:37,635 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44364
2020-04-02 05:06:37,637 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:37,637 [IPC Server listener on 44364] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44364
2020-04-02 05:06:37,650 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:37,650 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 874ddb90-8989-4188-8171-bd95d2ab0583) service to localhost/127.0.0.1:35549
2020-04-02 05:06:37,650 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 874ddb90-8989-4188-8171-bd95d2ab0583)
2020-04-02 05:06:37,650 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:37,683 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data9/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,705 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:37,706 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:37,713 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:37,714 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:37,717 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data10/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,718 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:37,718 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 3
2020-04-02 05:06:37,718 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 41418 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:37,718 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:37,718 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@76911385] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:37,723 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8, DS-bf3e5ff2-fbec-4007-96fd-557942b0b82d) exiting.
2020-04-02 05:06:37,723 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7, DS-e597eea4-a429-4c33-beff-4b8242e19398) exiting.
2020-04-02 05:06:37,913 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4c0884e8{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:37,918 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@231baf51{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:37,918 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@76b224cd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:37,919 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53093491{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:37,926 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 41418
2020-04-02 05:06:37,928 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:37,928 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:37,928 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid a9fbe79b-52db-4b37-b18b-cd2580cb2bea) service to localhost/127.0.0.1:35549
2020-04-02 05:06:37,928 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid a9fbe79b-52db-4b37-b18b-cd2580cb2bea)
2020-04-02 05:06:37,928 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:37,934 [IPC Server listener on 41418] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 41418
2020-04-02 05:06:37,936 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data7/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,963 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data8/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:37,988 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:37,989 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:38,010 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:38,011 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:38,012 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:38,013 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 2
2020-04-02 05:06:38,013 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40364 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:38,013 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:38,013 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@72209d93] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:38,045 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6, DS-f3ce3a5f-8b0d-4a66-9555-87ade95f49bc) exiting.
2020-04-02 05:06:38,045 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5, DS-3229de8a-cc9b-465c-8b4b-2bb36a6877d8) exiting.
2020-04-02 05:06:38,119 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5972d253{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:38,126 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@4fcc0416{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:38,133 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@53dfacba{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:38,134 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6a4d7f76{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:38,137 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40364
2020-04-02 05:06:38,138 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:38,139 [IPC Server listener on 40364] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40364
2020-04-02 05:06:38,147 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:38,147 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2) service to localhost/127.0.0.1:35549
2020-04-02 05:06:38,147 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 9a6b0b0c-29fa-4b23-a98b-2e71ddd256a2)
2020-04-02 05:06:38,147 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:38,161 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data5/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:38,183 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data6/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:38,222 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:38,222 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:38,233 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:38,234 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:38,234 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:38,235 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 1
2020-04-02 05:06:38,235 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 40706 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:38,235 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:38,235 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@488b50ec] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:38,246 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3, DS-941ec5c6-505b-4dd8-b643-4413ea7b31d6) exiting.
2020-04-02 05:06:38,246 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4, DS-e340360f-798e-455a-bff2-ca67dfad9811) exiting.
2020-04-02 05:06:38,286 [RedundancyMonitor] DEBUG BlockStateChange (BlockManager.java:computeReconstructionWorkForBlocks(1900)) - BLOCK* neededReconstruction = 0 pendingReconstruction = 0
2020-04-02 05:06:38,323 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5226e402{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:38,330 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@1440c311{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:38,332 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5e3a39cd{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:38,332 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6d2d99fc{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:38,335 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 40706
2020-04-02 05:06:38,340 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:38,340 [IPC Server listener on 40706] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 40706
2020-04-02 05:06:38,340 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:38,341 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ba26eabe-5db3-42d6-ba4b-937e2c42a5ac) service to localhost/127.0.0.1:35549
2020-04-02 05:06:38,341 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid ba26eabe-5db3-42d6-ba4b-937e2c42a5ac)
2020-04-02 05:06:38,341 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:38,424 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data3/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:38,453 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:38,453 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:38,467 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:38,467 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:38,473 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:38,474 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:shutdownDataNode(2046)) - Shutting down DataNode 0
2020-04-02 05:06:38,474 [main] INFO  datanode.DataNode (DataNode.java:shutdown(1991)) - [msx-restart] DataNode 44661 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:38,474 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data4/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:38,474 [main] WARN  datanode.DirectoryScanner (DirectoryScanner.java:shutdown(342)) - DirectoryScanner: shutdown has been called
2020-04-02 05:06:38,474 [org.apache.hadoop.hdfs.server.datanode.DataXceiverServer@a567e72] INFO  datanode.DataNode (DataXceiverServer.java:closeAllPeers(281)) - Closing all peers.
2020-04-02 05:06:38,481 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2, DS-6f852d23-017e-4ab4-8829-fc057e9e3305) exiting.
2020-04-02 05:06:38,486 [VolumeScannerThread(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1)] INFO  datanode.VolumeScanner (VolumeScanner.java:run(642)) - VolumeScanner(/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1, DS-ab7ec6f2-39ee-42ab-a9cf-5378954d9681) exiting.
2020-04-02 05:06:38,512 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4bdcaf36{/,null,UNAVAILABLE}{/datanode}
2020-04-02 05:06:38,514 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@61d01788{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:38,515 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7004e3d{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:38,515 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@cda0432{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:38,533 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 44661
2020-04-02 05:06:38,541 [IPC Server listener on 44661] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 44661
2020-04-02 05:06:38,542 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.IncrementalBlockReportManager (IncrementalBlockReportManager.java:waitTillNextIBR(160)) - IncrementalBlockReportManager interrupted
2020-04-02 05:06:38,542 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:38,542 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] WARN  datanode.DataNode (BPServiceActor.java:run(853)) - Ending block pool service for: Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e) service to localhost/127.0.0.1:35549
2020-04-02 05:06:38,650 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  datanode.DataNode (BlockPoolManager.java:remove(102)) - Removed Block pool BP-2135288147-172.17.0.13-1585803983874 (Datanode Uuid 0c0cd15a-d4ed-482d-8394-6ccbb807ad9e)
2020-04-02 05:06:38,650 [BP-2135288147-172.17.0.13-1585803983874 heartbeating to localhost/127.0.0.1:35549] INFO  impl.FsDatasetImpl (FsDatasetImpl.java:shutdownBlockPool(2802)) - Removing block pool BP-2135288147-172.17.0.13-1585803983874
2020-04-02 05:06:38,685 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data1/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:38,701 [refreshUsed-/root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/data/data2/current/BP-2135288147-172.17.0.13-1585803983874] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2020-04-02 05:06:38,712 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(192)) - Shutting down all async disk service threads
2020-04-02 05:06:38,712 [main] INFO  impl.FsDatasetAsyncDiskService (FsDatasetAsyncDiskService.java:shutdown(200)) - All async disk service threads have been shut down
2020-04-02 05:06:38,723 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(176)) - Shutting down all async lazy persist service threads
2020-04-02 05:06:38,723 [main] INFO  impl.RamDiskAsyncLazyPersistService (RamDiskAsyncLazyPersistService.java:shutdown(183)) - All async lazy persist service threads have been shut down
2020-04-02 05:06:38,727 [main] INFO  datanode.DataNode (DataNode.java:shutdown(2159)) - Shutdown complete.
2020-04-02 05:06:38,727 [main] INFO  hdfs.MiniDFSCluster (MiniDFSCluster.java:stopAndJoinNameNode(2079)) - Shutting down the namenode
2020-04-02 05:06:38,727 [main] INFO  namenode.NameNode (NameNode.java:stop(1011)) - [msx-restart] NameNode 35549 stop, double check before stop, dfs.namenode.fs-limits.max-directory-items = 1048576
2020-04-02 05:06:38,727 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:38,728 [main] INFO  namenode.FSEditLog (FSEditLog.java:endCurrentLogSegment(1406)) - Ending log segment 1, 8
2020-04-02 05:06:38,728 [main] INFO  namenode.FSEditLog (FSEditLog.java:printStatistics(774)) - Number of transactions: 9 Total time for transactions(ms): 12 Number of transactions batched in Syncs: 2 Number of syncs: 8 SyncTimes(ms): 2 1 
2020-04-02 05:06:38,729 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-1/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:06:38,730 [main] INFO  namenode.FileJournalManager (FileJournalManager.java:finalizeLogSegment(143)) - Finalizing edits file /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_inprogress_0000000000000000001 -> /root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs/name-0-2/current/edits_0000000000000000001-0000000000000000009
2020-04-02 05:06:38,730 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$NameNodeEditLogRoller@bd2f5a9] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4018)) - NameNodeEditLogRoller was interrupted, exiting
2020-04-02 05:06:38,730 [FSEditLogAsync] INFO  namenode.FSEditLog (FSEditLogAsync.java:run(253)) - FSEditLogAsync was interrupted, exiting
2020-04-02 05:06:38,730 [org.apache.hadoop.hdfs.server.namenode.FSNamesystem$LazyPersistFileScrubber@4d4960c8] INFO  namenode.FSNamesystem (FSNamesystem.java:run(4109)) - LazyPersistFileScrubber was interrupted, exiting
2020-04-02 05:06:38,730 [CacheReplicationMonitor(75657833)] INFO  blockmanagement.CacheReplicationMonitor (CacheReplicationMonitor.java:run(169)) - Shutting down CacheReplicationMonitor
2020-04-02 05:06:38,730 [main] INFO  ipc.Server (Server.java:stop(3077)) - Stopping server on 35549
2020-04-02 05:06:38,741 [RedundancyMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4557)) - Stopping RedundancyMonitor.
2020-04-02 05:06:38,741 [StorageInfoMonitor] INFO  blockmanagement.BlockManager (BlockManager.java:run(4592)) - Stopping thread.
2020-04-02 05:06:38,741 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1315)) - Stopping IPC Server Responder
2020-04-02 05:06:38,741 [IPC Server listener on 35549] INFO  ipc.Server (Server.java:run(1181)) - Stopping IPC Server listener on 35549
2020-04-02 05:06:38,775 [org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor@715fb77] DEBUG blockmanagement.BlockManager (PendingReconstructionBlocks.java:run(248)) - PendingReconstructionMonitor thread is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.blockmanagement.PendingReconstructionBlocks$PendingReconstructionMonitor.run(PendingReconstructionBlocks.java:246)
	at java.lang.Thread.run(Thread.java:748)
2020-04-02 05:06:38,818 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopActiveServices(1323)) - Stopping services started for active state
2020-04-02 05:06:38,818 [main] INFO  namenode.FSNamesystem (FSNamesystem.java:stopStandbyServices(1419)) - Stopping services started for standby state
2020-04-02 05:06:38,826 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@1c12f3ee{/,null,UNAVAILABLE}{/hdfs}
2020-04-02 05:06:38,847 [main] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d467c87{HTTP/1.1,[http/1.1]}{localhost:0}
2020-04-02 05:06:38,848 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2adddc06{/static,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/static/,UNAVAILABLE}
2020-04-02 05:06:38,848 [main] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2d7e1102{/logs,file:///root/hadoop-3.1.2-src/hadoop-hdfs-project/hadoop-hdfs/target/log/,UNAVAILABLE}
2020-04-02 05:06:38,862 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(210)) - Stopping DataNode metrics system...
2020-04-02 05:06:38,959 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:stop(216)) - DataNode metrics system stopped.
2020-04-02 05:06:38,960 [main] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:shutdown(607)) - DataNode metrics system shutdown complete.
[msx] test Finished org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness#testReconstructionWithDecommission
[msx] writeFile testName = org.apache.hadoop.hdfs.server.blockmanagement.TestReconstructStripedBlocksWithRackAwareness#testReconstructionWithDecommission
[msx] succeed
[msx] reset reconf_instanceWithV2Alive to false
[msx] reset reconf_instanceWithV2HC to -1
[msx] reset reconf_init_point_index to 0
[msx] all testRunFinished
